

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>plenoptic.tools.optim &mdash; plenoptic 1.3.2.dev217 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=9edc463e" />
      <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css" />
      <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=9c3e77be" />
      <link rel="stylesheet" type="text/css" href="../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
      <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
      <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=a2d047e6" />

  
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=4ba52da5"></script>
      <script src="../_static/doctools.js?v=fd6eb6e6"></script>
      <script src="../_static/sphinx_highlight.js?v=6ffebe34"></script>
      <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="../_static/copybutton.js?v=6dbb43f8"></script>
      <script>let toggleHintShow = 'Click to show';</script>
      <script>let toggleHintHide = 'Click to hide';</script>
      <script>let toggleOpenOnPrint = 'true';</script>
      <script src="../_static/togglebutton.js?v=1ae7504c"></script>
      <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
      <script src="../_static/design-tabs.js?v=f930bc37"></script>
      <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
      <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@4/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            plenoptic
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Basic concepts</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../install.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../jupyter.html">Using Jupyter to Run Example Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../conceptual_intro.html">Conceptual Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models.html">Model requirements</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/quickstart.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../citation.html">Citation Guide and Bibliography</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Synthesis method introductions</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/intro/Eigendistortions.html">Eigendistortions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/intro/MAD_Competition_1.html">MAD Competition Conceptual Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/intro/MAD_Competition_2.html">MAD Competition Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/intro/Metamer.html">Metamers</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Models and metrics</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/models/Perceptual_distance.html">Perceptual distance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/models/Steerable_Pyramid.html">Steerable Pyramid</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/models/portilla_simoncelli/ps_index.html">Portilla-Simoncelli Texture Model</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Synthesis method examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/applications/Demo_Eigendistortion.html">Reproducing Berardino et al., 2017 (Eigendistortions)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/applications/Original_MAD.html">Reproducing Wang and Simoncelli, 2008 (MAD Competition)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced usage</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api.html">API Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tips.html">Tips and Tricks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reproducibility.html">Reproducibility and Compatibility</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/advanced/Display.html">Display and animate functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/advanced/Synthesis_extensions.html">Extending existing synthesis objects</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">For Developers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../synthesis.html">Synthesis object design</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">plenoptic</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">plenoptic.tools.optim</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/generated/plenoptic.tools.optim.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-plenoptic.tools.optim">
<span id="plenoptic-tools-optim"></span><h1>plenoptic.tools.optim<a class="headerlink" href="#module-plenoptic.tools.optim" title="Link to this heading"></a></h1>
<p>Tools related to optimization, such as objective functions.</p>
<p class="rubric">Functions</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#plenoptic.tools.optim.groupwise_relative_l2_norm_factory" title="plenoptic.tools.optim.groupwise_relative_l2_norm_factory"><code class="xref py py-obj docutils literal notranslate"><span class="pre">groupwise_relative_l2_norm_factory</span></code></a>(model, image)</p></td>
<td><p>Create loss function that computes groupwise relative L2 norm for synthesis.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#plenoptic.tools.optim.l2_norm" title="plenoptic.tools.optim.l2_norm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">l2_norm</span></code></a>(synth_rep, ref_rep, **kwargs)</p></td>
<td><p>Calculate the L2-norm of the difference between <code class="docutils literal notranslate"><span class="pre">ref_rep</span></code> and <code class="docutils literal notranslate"><span class="pre">synth_rep</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#plenoptic.tools.optim.mse" title="plenoptic.tools.optim.mse"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mse</span></code></a>(synth_rep, ref_rep, **kwargs)</p></td>
<td><p>Calculate the MSE between <code class="docutils literal notranslate"><span class="pre">synth_rep</span></code> and <code class="docutils literal notranslate"><span class="pre">ref_rep</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#plenoptic.tools.optim.penalize_range" title="plenoptic.tools.optim.penalize_range"><code class="xref py py-obj docutils literal notranslate"><span class="pre">penalize_range</span></code></a>(synth_img[, allowed_range])</p></td>
<td><p>Calculate quadratic penalty on values outside of <code class="docutils literal notranslate"><span class="pre">allowed_range</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#plenoptic.tools.optim.portilla_simoncelli_loss_factory" title="plenoptic.tools.optim.portilla_simoncelli_loss_factory"><code class="xref py py-obj docutils literal notranslate"><span class="pre">portilla_simoncelli_loss_factory</span></code></a>(model, image)</p></td>
<td><p>Create the loss function required for <code class="docutils literal notranslate"><span class="pre">PortillaSimoncelli</span></code> metamer synthesis.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#plenoptic.tools.optim.relative_sse" title="plenoptic.tools.optim.relative_sse"><code class="xref py py-obj docutils literal notranslate"><span class="pre">relative_sse</span></code></a>(synth_rep, ref_rep, **kwargs)</p></td>
<td><p>Calculate the relative sum of squared errors between two tensors.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#plenoptic.tools.optim.set_seed" title="plenoptic.tools.optim.set_seed"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_seed</span></code></a>([seed])</p></td>
<td><p>Set the seed.</p></td>
</tr>
</tbody>
</table>
<dl class="py function">
<dt class="sig sig-object py" id="plenoptic.tools.optim.groupwise_relative_l2_norm_factory">
<span class="sig-name descname"><span class="pre">groupwise_relative_l2_norm_factory</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reweighting_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/tools/optim.html#groupwise_relative_l2_norm_factory"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.tools.optim.groupwise_relative_l2_norm_factory" title="Link to this definition"></a></dt>
<dd><p>Create loss function that computes groupwise relative L2 norm for synthesis.</p>
<p>This loss factory returns a callable which should make optimization easier when
used as the <code class="docutils literal notranslate"><span class="pre">loss_function</span></code> when initializing
<a class="reference internal" href="plenoptic.synthesize.metamer.Metamer.html#plenoptic.synthesize.metamer.Metamer" title="plenoptic.synthesize.metamer.Metamer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Metamer</span></code></a> for synthesizing metamers. The
resulting loss function will normalize each group within the representation by the
L2 norm of that group on <code class="docutils literal notranslate"><span class="pre">image</span></code>, which should be the target image for that
synthesis.</p>
<p>This requires that <code class="docutils literal notranslate"><span class="pre">model</span></code> has two methods, <code class="docutils literal notranslate"><span class="pre">convert_to_dict</span></code> and
<code class="docutils literal notranslate"><span class="pre">convert_to_tensor</span></code>, which convert the representation between a tensor (as
returned by <code class="docutils literal notranslate"><span class="pre">forward</span></code>) and an <a class="reference external" href="https://docs.python.org/3/library/collections.html#collections.OrderedDict" title="(in Python v3.14)"><code class="xref py py-class docutils literal notranslate"><span class="pre">OrderedDict</span></code></a>. The dictionary
representation should have keys that define the different groups within the
representation, and its values should be tensors (of any shape).</p>
<p>The optional <code class="docutils literal notranslate"><span class="pre">reweighting_dict</span></code> argument allows users to further tweak the
weights, if necessary. If not <code class="docutils literal notranslate"><span class="pre">None</span></code>, keys should be a subset of those found in
the output of <code class="docutils literal notranslate"><span class="pre">model.convert_to_dict</span></code>, and whose values are Tensors (broadcastable
to the shape of the corresponding values in <code class="docutils literal notranslate"><span class="pre">model.convert_to_dict</span></code> output) which
will be multiplied by the corresponding group <em>after</em> normalization. Thus, a number
greater than 1 will increase its weight in the loss, a number less than 1 will
decrease the weight, and 0 will remove it from the calculation entirely.</p>
<p>For an example of a compliant model, see the
<a class="reference internal" href="plenoptic.simulate.models.portilla_simoncelli.html#plenoptic.simulate.models.portilla_simoncelli.PortillaSimoncelli" title="plenoptic.simulate.models.portilla_simoncelli.PortillaSimoncelli"><code class="xref py py-class docutils literal notranslate"><span class="pre">PortillaSimoncelli</span></code></a> model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a></span>) – An instantiated model.</p></li>
<li><p><strong>image</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – The target image for metamer synthesis.</p></li>
<li><p><strong>reweighting_dict</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.14)"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a> | <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>] | <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a></span> (default: <code class="docutils literal notranslate"><span class="pre">None</span></code>)) – Dictionary specifying further reweighting. See above for details.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.Callable" title="(in Python v3.14)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Callable</span></code></a>[[<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>], <a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>loss_func</em> – A callable to use as your loss function for metamer synthesis.</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.14)"><strong>ValueError</strong></a> – If <code class="docutils literal notranslate"><span class="pre">reweighting_dict</span></code> contains keys not found in the model representation
    (<code class="docutils literal notranslate"><span class="pre">model.convert_to_dict(model(image))</span></code>).</p>
</dd>
<dt class="field-odd">Warns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>UserWarning</strong> – If <code class="docutils literal notranslate"><span class="pre">model.convert_to_dict()</span></code> does not return an
<a class="reference external" href="https://docs.python.org/3/library/collections.html#collections.OrderedDict" title="(in Python v3.14)"><code class="xref py py-class docutils literal notranslate"><span class="pre">OrderedDict</span></code></a>. <code class="docutils literal notranslate"><span class="pre">convert_to_dict</span></code> and
<code class="docutils literal notranslate"><span class="pre">convert_to_tensor</span></code> need to invert each other, which means you should probably
use an <a class="reference external" href="https://docs.python.org/3/library/collections.html#collections.OrderedDict" title="(in Python v3.14)"><code class="xref py py-class docutils literal notranslate"><span class="pre">OrderedDict</span></code></a>, which guarantees that the order of the
keys is preserved. You can use
<a class="reference internal" href="plenoptic.tools.validate.html#plenoptic.tools.validate.validate_convert_tensor_dict" title="plenoptic.tools.validate.validate_convert_tensor_dict"><code class="xref py py-func docutils literal notranslate"><span class="pre">validate_convert_tensor_dict</span></code></a> to heuristically
check whether your model satisfies this constraint.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>Create the loss function with a simple model.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">plenoptic</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">po</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">collections</span><span class="w"> </span><span class="kn">import</span> <span class="n">OrderedDict</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span><span class="w"> </span><span class="nc">TestModel</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">detach_</span><span class="p">()</span>
<span class="gp">...</span>
<span class="gp">... </span>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">...</span>
<span class="gp">... </span>    <span class="k">def</span><span class="w"> </span><span class="nf">convert_to_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rep</span><span class="p">):</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">OrderedDict</span><span class="p">({</span><span class="sa">f</span><span class="s2">&quot;channel_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">:</span> <span class="n">rep</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">)})</span>
<span class="gp">...</span>
<span class="gp">... </span>    <span class="k">def</span><span class="w"> </span><span class="nf">convert_to_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rep_dict</span><span class="p">):</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">rep_dict</span><span class="o">.</span><span class="n">values</span><span class="p">()),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">einstein</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand_like</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">TestModel</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">groupwise_relative_l2_norm_factory</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">img</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">img</span><span class="p">),</span> <span class="n">model</span><span class="p">(</span><span class="n">img2</span><span class="p">))</span>
<span class="go">tensor(0.6512)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">l2_norm</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">img</span><span class="p">),</span> <span class="n">model</span><span class="p">(</span><span class="n">img2</span><span class="p">))</span>
<span class="go">tensor(78.5674)</span>
</pre></div>
</div>
<p>Use <code class="docutils literal notranslate"><span class="pre">reweighting_dict</span></code> to further tweak weighting.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">plenoptic</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">po</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">collections</span><span class="w"> </span><span class="kn">import</span> <span class="n">OrderedDict</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span><span class="w"> </span><span class="nc">TestModel</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">detach_</span><span class="p">()</span>
<span class="gp">...</span>
<span class="gp">... </span>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">...</span>
<span class="gp">... </span>    <span class="k">def</span><span class="w"> </span><span class="nf">convert_to_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rep</span><span class="p">):</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">OrderedDict</span><span class="p">({</span><span class="sa">f</span><span class="s2">&quot;channel_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">:</span> <span class="n">rep</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">)})</span>
<span class="gp">...</span>
<span class="gp">... </span>    <span class="k">def</span><span class="w"> </span><span class="nf">convert_to_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rep_dict</span><span class="p">):</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">rep_dict</span><span class="o">.</span><span class="n">values</span><span class="p">()),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">einstein</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand_like</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">TestModel</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reweighting_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;channel_0&quot;</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">groupwise_relative_l2_norm_factory</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">model</span><span class="p">,</span> <span class="n">img</span><span class="p">,</span> <span class="n">reweighting_dict</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">img</span><span class="p">),</span> <span class="n">model</span><span class="p">(</span><span class="n">img2</span><span class="p">))</span>
<span class="go">tensor(0.4822)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># channel_0 is of shape (1, 256, 256)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">channel_0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">convert_to_dict</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">img</span><span class="p">))[</span><span class="s2">&quot;channel_0&quot;</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">channel_0</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">128</span><span class="p">:]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reweighting_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;channel_0&quot;</span><span class="p">:</span> <span class="n">channel_0</span><span class="p">}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">groupwise_relative_l2_norm_factory</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">model</span><span class="p">,</span> <span class="n">img</span><span class="p">,</span> <span class="n">reweighting_dict</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">img</span><span class="p">),</span> <span class="n">model</span><span class="p">(</span><span class="n">img2</span><span class="p">))</span>
<span class="go">tensor(0.5612)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="plenoptic.tools.optim.l2_norm">
<span class="sig-name descname"><span class="pre">l2_norm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">synth_rep</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ref_rep</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/tools/optim.html#l2_norm"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.tools.optim.l2_norm" title="Link to this definition"></a></dt>
<dd><p>Calculate the L2-norm of the difference between <code class="docutils literal notranslate"><span class="pre">ref_rep</span></code> and <code class="docutils literal notranslate"><span class="pre">synth_rep</span></code>.</p>
<p>For two tensors, <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(y\)</span>, with <span class="math notranslate nohighlight">\(n\)</span> values
each:</p>
<div class="math notranslate nohighlight">
\[L2 = \sqrt{\sum_{i=1}^n (x_i - y_i)^2}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>synth_rep</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – The first tensor to compare, model representation of the
synthesized image.</p></li>
<li><p><strong>ref_rep</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – The second tensor to compare, model representation of the
reference image. must be same size as <code class="docutils literal notranslate"><span class="pre">synth_rep</span></code>.</p></li>
<li><p><strong>**kwargs</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.14)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></a></span>) – Ignored, only present to absorb extra arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>loss</em> – The L2-norm of the difference between <code class="docutils literal notranslate"><span class="pre">ref_rep</span></code> and <code class="docutils literal notranslate"><span class="pre">synth_rep</span></code>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="plenoptic.tools.optim.mse">
<span class="sig-name descname"><span class="pre">mse</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">synth_rep</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ref_rep</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/tools/optim.html#mse"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.tools.optim.mse" title="Link to this definition"></a></dt>
<dd><p>Calculate the MSE between <code class="docutils literal notranslate"><span class="pre">synth_rep</span></code> and <code class="docutils literal notranslate"><span class="pre">ref_rep</span></code>.</p>
<p>For two tensors, <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(y\)</span>, with <span class="math notranslate nohighlight">\(n\)</span> values
each:</p>
<div class="math notranslate nohighlight">
\[MSE = \frac{1}{n}\sum_{i=1}^n (x_i - y_i)^2\]</div>
<p>The two images must have a float dtype.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>synth_rep</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – The first tensor to compare, model representation of the
synthesized image.</p></li>
<li><p><strong>ref_rep</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – The second tensor to compare, model representation of the
reference image. must be same size as <code class="docutils literal notranslate"><span class="pre">synth_rep</span></code>.</p></li>
<li><p><strong>**kwargs</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.14)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></a></span>) – Ignored, only present to absorb extra arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>loss</em> – The mean-squared error between <code class="docutils literal notranslate"><span class="pre">synth_rep</span></code> and <code class="docutils literal notranslate"><span class="pre">ref_rep</span></code>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="plenoptic.tools.optim.penalize_range">
<span class="sig-name descname"><span class="pre">penalize_range</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">synth_img</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">allowed_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.0,</span> <span class="pre">1.0)</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/tools/optim.html#penalize_range"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.tools.optim.penalize_range" title="Link to this definition"></a></dt>
<dd><p>Calculate quadratic penalty on values outside of <code class="docutils literal notranslate"><span class="pre">allowed_range</span></code>.</p>
<p>Instead of clamping values to exactly fall in a range, this provides
a ‘softer’ way of doing it, by imposing a quadratic penalty on any
values outside the allowed_range. All values within the
allowed_range have a penalty of 0.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>synth_img</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – The tensor to penalize. the synthesized image.</p></li>
<li><p><strong>allowed_range</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.14)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]</span> (default: <code class="docutils literal notranslate"><span class="pre">(0.0,</span> <span class="pre">1.0)</span></code>)) – 2-tuple of values giving the (min, max) allowed values.</p></li>
<li><p><strong>**kwargs</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.14)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></a></span>) – Ignored, only present to absorb extra arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>penalty</em> – Penalty for values outside range.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="plenoptic.tools.optim.portilla_simoncelli_loss_factory">
<span class="sig-name descname"><span class="pre">portilla_simoncelli_loss_factory</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reweighting_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/tools/optim.html#portilla_simoncelli_loss_factory"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.tools.optim.portilla_simoncelli_loss_factory" title="Link to this definition"></a></dt>
<dd><p>Create the loss function required for <code class="docutils literal notranslate"><span class="pre">PortillaSimoncelli</span></code> metamer synthesis.</p>
<p>This loss factory returns a callable which should be used as the <code class="docutils literal notranslate"><span class="pre">loss_function</span></code>
when initializing <a class="reference internal" href="plenoptic.synthesize.metamer.Metamer.html#plenoptic.synthesize.metamer.Metamer" title="plenoptic.synthesize.metamer.Metamer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Metamer</span></code></a> for synthesizing
metamers with the
<a class="reference internal" href="plenoptic.simulate.models.portilla_simoncelli.html#plenoptic.simulate.models.portilla_simoncelli.PortillaSimoncelli" title="plenoptic.simulate.models.portilla_simoncelli.PortillaSimoncelli"><code class="xref py py-class docutils literal notranslate"><span class="pre">PortillaSimoncelli</span></code></a> model. It
zeroes the model’s representation of the images’ min/max pixel values and increases
the weight on the variance of the highpass residuals before computing the L2-norm.</p>
<p>The optional <code class="docutils literal notranslate"><span class="pre">reweighting_dict</span></code> argument allows users to tweak the weights. If not
<code class="docutils literal notranslate"><span class="pre">None</span></code>, keys should be a subset of those found in the output of
<a class="reference internal" href="plenoptic.simulate.models.portilla_simoncelli.html#plenoptic.simulate.models.portilla_simoncelli.PortillaSimoncelli.convert_to_dict" title="plenoptic.simulate.models.portilla_simoncelli.PortillaSimoncelli.convert_to_dict"><code class="xref py py-func docutils literal notranslate"><span class="pre">convert_to_dict</span></code></a>
and whose values are Tensors (broadcastable to the shape of the corresponding values
in <code class="docutils literal notranslate"><span class="pre">convert_to_dict</span></code> output) which will be multiplied by the corresponding
group. Thus, a number greater than 1 will increase its weight in the loss, a number
less than 1 will decrease the weight, and 0 will remove it from the calculation
entirely. <code class="docutils literal notranslate"><span class="pre">reweighting_dict</span></code> takes precedence, so e.g., if it includes a
<code class="docutils literal notranslate"><span class="pre">&quot;pixel_statistics&quot;</span></code> key, that will dictate how min/max pixel values are weighted.</p>
<p>To understand how the returned loss works and see how to write your own loss
factory, see <a class="reference internal" href="../tutorials/models/portilla_simoncelli/ps_optimization.html#ps-optimization"><span class="std std-ref">Portilla-Simoncelli optimization details</span></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="plenoptic.simulate.models.portilla_simoncelli.html#plenoptic.simulate.models.portilla_simoncelli.PortillaSimoncelli" title="plenoptic.simulate.models.portilla_simoncelli.PortillaSimoncelli"><code class="xref py py-class docutils literal notranslate"><span class="pre">PortillaSimoncelli</span></code></a></span>) – An instantiated
<a class="reference internal" href="plenoptic.simulate.models.portilla_simoncelli.html#plenoptic.simulate.models.portilla_simoncelli.PortillaSimoncelli" title="plenoptic.simulate.models.portilla_simoncelli.PortillaSimoncelli"><code class="xref py py-class docutils literal notranslate"><span class="pre">PortillaSimoncelli</span></code></a>
model.</p></li>
<li><p><strong>image</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – The target image for metamer synthesis, or an image with the same shape, dtype,
and device.</p></li>
<li><p><strong>reweighting_dict</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.14)"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a> | <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>] | <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a></span> (default: <code class="docutils literal notranslate"><span class="pre">None</span></code>)) – Dictionary specifying reweighting. See above for details.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.Callable" title="(in Python v3.14)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Callable</span></code></a>[[<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>], <a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>loss_func</em> – A callable to use as your loss function for <code class="docutils literal notranslate"><span class="pre">PortillaSimoncelli</span></code> metamer
synthesis.</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.14)"><strong>ValueError</strong></a> – If <code class="docutils literal notranslate"><span class="pre">reweighting_dict</span></code> contains keys not found in the model representation
    (<code class="docutils literal notranslate"><span class="pre">model.convert_to_dict(model(image))</span></code>).</p></li>
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.14)"><strong>ValueError</strong></a> – If model representation (<code class="docutils literal notranslate"><span class="pre">model.convert_to_dict(model(image))</span></code>) includes the
    key <code class="docutils literal notranslate"><span class="pre">&quot;pixel_statistics&quot;</span></code> but the corresponding tensor does not have
    <code class="docutils literal notranslate"><span class="pre">shape[-1]</span> <span class="pre">==</span> <span class="pre">6</span></code> or if it includes the key <code class="docutils literal notranslate"><span class="pre">&quot;var_highpass_residual&quot;</span></code> but the
    corresponding tensor does not have <code class="docutils literal notranslate"><span class="pre">shape[-1]</span> <span class="pre">==</span> <span class="pre">1</span></code> and the corresponding key
    is not included explicitly in <code class="docutils literal notranslate"><span class="pre">reweighting_dict</span></code>.</p></li>
</ul>
</dd>
<dt class="field-odd">Warns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>UserWarning</strong> – If model representation (<code class="docutils literal notranslate"><span class="pre">model.convert_to_dict(model(image))</span></code>) does not
include the keys <code class="docutils literal notranslate"><span class="pre">&quot;pixel_statistics&quot;</span></code> or <code class="docutils literal notranslate"><span class="pre">&quot;var_highpass_residual&quot;</span></code>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>Create the loss function.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">plenoptic</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">po</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">einstein</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand_like</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">simul</span><span class="o">.</span><span class="n">PortillaSimoncelli</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">portilla_simoncelli_loss_factory</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">img</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">img</span><span class="p">),</span> <span class="n">model</span><span class="p">(</span><span class="n">img2</span><span class="p">))</span>
<span class="go">tensor(31.9155)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">l2_norm</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">img</span><span class="p">),</span> <span class="n">model</span><span class="p">(</span><span class="n">img2</span><span class="p">))</span>
<span class="go">tensor(31.5433)</span>
</pre></div>
</div>
<p>Use the loss function for metamer synthesis.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">plenoptic</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">po</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">einstein</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">simul</span><span class="o">.</span><span class="n">PortillaSimoncelli</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">portilla_simoncelli_loss_factory</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">img</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">met</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">synth</span><span class="o">.</span><span class="n">Metamer</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss_function</span><span class="o">=</span><span class="n">loss</span><span class="p">)</span>
</pre></div>
</div>
<p>Use <code class="docutils literal notranslate"><span class="pre">reweighting_dict</span></code> to increase weight on image pixel moments, while keeping
min/max out of the loss. The model includes 6 pixel stats (see <a class="reference internal" href="../tutorials/models/portilla_simoncelli/ps_understand_stats.html#ps-model-stats"><span class="std std-ref">Understanding Portilla-Simoncelli model statistics</span></a>
for details)</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">plenoptic</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">po</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">einstein</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand_like</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">simul</span><span class="o">.</span><span class="n">PortillaSimoncelli</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rep</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">convert_to_dict</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">img</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pixel_stats</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pixel_stats</span> <span class="o">=</span> <span class="n">pixel_stats</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">rep</span><span class="p">[</span><span class="s2">&quot;pixel_statistics&quot;</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reweighting_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;pixel_statistics&quot;</span><span class="p">:</span> <span class="n">pixel_stats</span><span class="p">}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">portilla_simoncelli_loss_factory</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">model</span><span class="p">,</span> <span class="n">img</span><span class="p">,</span> <span class="n">reweighting_dict</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">img</span><span class="p">),</span> <span class="n">model</span><span class="p">(</span><span class="n">img2</span><span class="p">))</span>
<span class="go">tensor(35.9753)</span>
</pre></div>
</div>
<p>Use <code class="docutils literal notranslate"><span class="pre">reweighting_dict</span></code> to include min/max in the loss and increase the importance
of the standard deviations of the magnitude bands.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">plenoptic</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">po</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">einstein</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand_like</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">simul</span><span class="o">.</span><span class="n">PortillaSimoncelli</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reweighting_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;pixel_statistics&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;magnitude_std&quot;</span><span class="p">:</span> <span class="mi">100</span><span class="p">}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">portilla_simoncelli_loss_factory</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">model</span><span class="p">,</span> <span class="n">img</span><span class="p">,</span> <span class="n">reweighting_dict</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">img</span><span class="p">),</span> <span class="n">model</span><span class="p">(</span><span class="n">img2</span><span class="p">))</span>
<span class="go">tensor(251.5188)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="plenoptic.tools.optim.relative_sse">
<span class="sig-name descname"><span class="pre">relative_sse</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">synth_rep</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ref_rep</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/tools/optim.html#relative_sse"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.tools.optim.relative_sse" title="Link to this definition"></a></dt>
<dd><p>Calculate the relative sum of squared errors between two tensors.</p>
<p>This is the squared L2-norm of the difference between reference representation and
synthesized representation relative to the squared L2-norm of the reference
representation:</p>
<p>For two tensors, <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(y\)</span>:</p>
<div class="math notranslate nohighlight">
\[\frac{||x - y||_2^2}{||x||_2^2}\]</div>
<p>where <span class="math notranslate nohighlight">\(x\)</span> is <code class="docutils literal notranslate"><span class="pre">ref_rep</span></code>, <span class="math notranslate nohighlight">\(x\)</span> is <code class="docutils literal notranslate"><span class="pre">synth_rep</span></code>, and <span class="math notranslate nohighlight">\(||x||_2\)</span> is
the L2-norm.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>synth_rep</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – The first tensor to compare, model representation of the
synthesized image.</p></li>
<li><p><strong>ref_rep</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – The second tensor to compare, model representation of the
reference image. must be same size as <code class="docutils literal notranslate"><span class="pre">synth_rep</span></code>.</p></li>
<li><p><strong>**kwargs</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.14)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></a></span>) – Ignored, only present to absorb extra arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>loss</em> – Ratio of the squared l2-norm of the difference between <code class="docutils literal notranslate"><span class="pre">ref_rep</span></code> and
<code class="docutils literal notranslate"><span class="pre">synth_rep</span></code> to the squared l2-norm of <code class="docutils literal notranslate"><span class="pre">ref_rep</span></code>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="plenoptic.tools.optim.set_seed">
<span class="sig-name descname"><span class="pre">set_seed</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/tools/optim.html#set_seed"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.tools.optim.set_seed" title="Link to this definition"></a></dt>
<dd><p>Set the seed.</p>
<p>We call both <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.manual_seed.html#torch.manual_seed" title="(in PyTorch v2.10)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.manual_seed</span></code></a> and <a class="reference external" href="https://numpy.org/doc/stable/reference/random/generated/numpy.random.seed.html#numpy.random.seed" title="(in NumPy v2.4)"><code class="xref py py-func docutils literal notranslate"><span class="pre">numpy.random.seed</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>seed</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a> | <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a></span> (default: <code class="docutils literal notranslate"><span class="pre">None</span></code>)) – The seed to set. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, do nothing.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a></span></p>
</dd>
</dl>
</dd></dl>

</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2019-2025, Plenoptic authors.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>