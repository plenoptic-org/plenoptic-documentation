

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Using the Portilla-Simoncelli model in plenoptic &mdash; plenoptic 1.3.2.dev217 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/theme.css?v=9edc463e" />
      <link rel="stylesheet" type="text/css" href="../../../_static/plot_directive.css" />
      <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css?v=9c3e77be" />
      <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
      <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-design.min.css?v=95c83b7e" />
      <link rel="stylesheet" type="text/css" href="../../../_static/custom.css?v=a2d047e6" />

  
      <script src="../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../../_static/documentation_options.js?v=4ba52da5"></script>
      <script src="../../../_static/doctools.js?v=fd6eb6e6"></script>
      <script src="../../../_static/sphinx_highlight.js?v=6ffebe34"></script>
      <script src="../../../_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="../../../_static/copybutton.js?v=6dbb43f8"></script>
      <script>let toggleHintShow = 'Click to show';</script>
      <script>let toggleHintHide = 'Click to hide';</script>
      <script>let toggleOpenOnPrint = 'true';</script>
      <script src="../../../_static/togglebutton.js?v=1ae7504c"></script>
      <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
      <script src="../../../_static/design-tabs.js?v=f930bc37"></script>
      <script type="application/vnd.jupyter.widget-state+json">{"state": {"372576d9f4664027a79d164c9c65b2e2": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": "2", "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "dd0b425fc0f94a14bfa48101c91645cc": {"model_name": "ProgressStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "bar_color": null, "description_width": ""}}, "2e229af6477741229b1d50da4cfca74b": {"model_name": "FloatProgressModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "FloatProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "ProgressView", "bar_style": "danger", "description": "", "description_allow_html": false, "layout": "IPY_MODEL_372576d9f4664027a79d164c9c65b2e2", "max": 1.0, "min": 0.0, "orientation": "horizontal", "style": "IPY_MODEL_dd0b425fc0f94a14bfa48101c91645cc", "tabbable": null, "tooltip": null, "value": 0.0}}, "04a1ecdcdaf04a26a3af6c42e3391d41": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "e122b82f453442ce82d074964d79217b": {"model_name": "HTMLStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "background": null, "description_width": "", "font_size": null, "text_color": null}}, "2e949b450ad94dcfa5c5847a504de08f": {"model_name": "HTMLModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HTMLView", "description": "", "description_allow_html": false, "layout": "IPY_MODEL_04a1ecdcdaf04a26a3af6c42e3391d41", "placeholder": "\u200b", "style": "IPY_MODEL_e122b82f453442ce82d074964d79217b", "tabbable": null, "tooltip": null, "value": "\u2007\u20070%"}}, "a8d0abdde7374883a50ea33587a3be3e": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "8d9e7c5e5a7c4c7499d5b2e4d6b776f4": {"model_name": "HTMLStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "background": null, "description_width": "", "font_size": null, "text_color": null}}, "00c7505f8e9242c4af73a5a2f696acca": {"model_name": "HTMLModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HTMLView", "description": "", "description_allow_html": false, "layout": "IPY_MODEL_a8d0abdde7374883a50ea33587a3be3e", "placeholder": "\u200b", "style": "IPY_MODEL_8d9e7c5e5a7c4c7499d5b2e4d6b776f4", "tabbable": null, "tooltip": null, "value": "\u20070.00/1.00\u2007[00:00&lt;?,\u2007?B/s]"}}, "bdcd132e789744ca9f9ad847779e7e00": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": "inline-flex", "flex": null, "flex_flow": "row wrap", "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": "79px"}}, "11cc4e8da5af4d9194df1f61bc636548": {"model_name": "HBoxModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HBoxView", "box_style": "", "children": ["IPY_MODEL_2e949b450ad94dcfa5c5847a504de08f", "IPY_MODEL_2e229af6477741229b1d50da4cfca74b", "IPY_MODEL_00c7505f8e9242c4af73a5a2f696acca"], "layout": "IPY_MODEL_bdcd132e789744ca9f9ad847779e7e00", "tabbable": null, "tooltip": null}}, "4aed04082bf4442686f38fdaffa2d303": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "165493b88deb4f208c5ec6edc975c7fe": {"model_name": "ProgressStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "bar_color": null, "description_width": ""}}, "0d3606e1a1d24ccf9cb2407cdd65c7dc": {"model_name": "FloatProgressModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "FloatProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "ProgressView", "bar_style": "success", "description": "", "description_allow_html": false, "layout": "IPY_MODEL_4aed04082bf4442686f38fdaffa2d303", "max": 100.0, "min": 0.0, "orientation": "horizontal", "style": "IPY_MODEL_165493b88deb4f208c5ec6edc975c7fe", "tabbable": null, "tooltip": null, "value": 100.0}}, "3cab6007e5f74d8cb5f785a66d65da23": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "03291289ab994bbd94cbe3a40e06aa1b": {"model_name": "HTMLStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "background": null, "description_width": "", "font_size": null, "text_color": null}}, "37c58fa0971c48d788af08dbe35d28cf": {"model_name": "HTMLModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HTMLView", "description": "", "description_allow_html": false, "layout": "IPY_MODEL_3cab6007e5f74d8cb5f785a66d65da23", "placeholder": "\u200b", "style": "IPY_MODEL_03291289ab994bbd94cbe3a40e06aa1b", "tabbable": null, "tooltip": null, "value": "100%"}}, "8ae8441813e4432b947b70c17354518c": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "3784f380bba940b29ccd3d0cf2ae88af": {"model_name": "HTMLStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "background": null, "description_width": "", "font_size": null, "text_color": null}}, "b0e563f0d5734a388b6a4b1cb0bafbad": {"model_name": "HTMLModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HTMLView", "description": "", "description_allow_html": false, "layout": "IPY_MODEL_8ae8441813e4432b947b70c17354518c", "placeholder": "\u200b", "style": "IPY_MODEL_3784f380bba940b29ccd3d0cf2ae88af", "tabbable": null, "tooltip": null, "value": "\u2007100/100\u2007[01:12&lt;00:00,\u2007\u20071.16it/s,\u2007loss=5.5313e-03,\u2007learning_rate=1,\u2007gradient_norm=1.2386e-02,\u2007pixel_change_norm=1.2254e-01]"}}, "483a9b4bd3a149828130a0d5ee65ef39": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "e2f891b123784872bb3a70719d065aee": {"model_name": "HBoxModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HBoxView", "box_style": "", "children": ["IPY_MODEL_37c58fa0971c48d788af08dbe35d28cf", "IPY_MODEL_0d3606e1a1d24ccf9cb2407cdd65c7dc", "IPY_MODEL_b0e563f0d5734a388b6a4b1cb0bafbad"], "layout": "IPY_MODEL_483a9b4bd3a149828130a0d5ee65ef39", "tabbable": null, "tooltip": null}}}, "version_major": 2, "version_minor": 0}</script>
      <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
      <script crossorigin="anonymous" data-jupyter-widgets-cdn="https://cdn.jsdelivr.net/npm/" src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@1.0.6/dist/embed-amd.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Example Portilla-Simoncelli metamers from different texture classes" href="ps_examples.html" />
    <link rel="prev" title="What is a visual texture?" href="ps_intro.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html" class="icon icon-home">
            plenoptic
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Basic concepts</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../install.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../jupyter.html">Using Jupyter to Run Example Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../conceptual_intro.html">Conceptual Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../models.html">Model requirements</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../quickstart.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../citation.html">Citation Guide and Bibliography</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Synthesis method introductions</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../intro/Eigendistortions.html">Eigendistortions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intro/MAD_Competition_1.html">MAD Competition Conceptual Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intro/MAD_Competition_2.html">MAD Competition Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intro/Metamer.html">Metamers</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Models and metrics</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../Perceptual_distance.html">Perceptual distance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Steerable_Pyramid.html">Steerable Pyramid</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="ps_index.html">Portilla-Simoncelli Texture Model</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="ps_intro.html">What is a visual texture?</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Using the Portilla-Simoncelli model in plenoptic</a></li>
<li class="toctree-l2"><a class="reference internal" href="ps_examples.html">Example Portilla-Simoncelli metamers from different texture classes</a></li>
<li class="toctree-l2"><a class="reference internal" href="ps_understand_stats.html">Understanding Portilla-Simoncelli model statistics</a></li>
<li class="toctree-l2"><a class="reference internal" href="ps_optimization.html">Portilla-Simoncelli optimization details</a></li>
<li class="toctree-l2"><a class="reference internal" href="ps_limitations.html">Portilla-Simoncelli Model Limitations</a></li>
<li class="toctree-l2"><a class="reference internal" href="ps_matlab_differences.html">Notable differences between Matlab and Plenoptic Implementations</a></li>
<li class="toctree-l2"><a class="reference internal" href="ps_extensions.html">More than just texture metamers</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Synthesis method examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../applications/Demo_Eigendistortion.html">Reproducing Berardino et al., 2017 (Eigendistortions)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../applications/Original_MAD.html">Reproducing Wang and Simoncelli, 2008 (MAD Competition)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced usage</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../api.html">API Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tips.html">Tips and Tricks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../reproducibility.html">Reproducibility and Compatibility</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advanced/Display.html">Display and animate functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advanced/Synthesis_extensions.html">Extending existing synthesis objects</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">For Developers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../synthesis.html">Synthesis object design</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">plenoptic</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="ps_index.html">Portilla-Simoncelli Texture Model</a></li>
      <li class="breadcrumb-item active">Using the Portilla-Simoncelli model in plenoptic</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../_sources/tutorials/models/portilla_simoncelli/ps_basic_synthesis.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="cell tag_hide-input docutils container">
<details class="admonition hide above-input">
<summary aria-label="Toggle hidden content">
<p class="collapsed admonition-title">Show code cell source</p>
<p class="expanded admonition-title">Hide code cell source</p>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pooch</span>

<span class="c1"># don&#39;t have pooch output messages about downloading or untarring</span>
<span class="n">logger</span> <span class="o">=</span> <span class="n">pooch</span><span class="o">.</span><span class="n">get_logger</span><span class="p">()</span>
<span class="n">logger</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="s2">&quot;WARNING&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
</div>
<div class="important admonition">
<p class="admonition-title">Download</p>
<p>Download this notebook: <strong><a class="reference download internal" download="" href="../../../_downloads/1019a0e6d20422f721b40a86f30b4374/ps_basic_synthesis.ipynb"><code class="xref download myst-nb docutils literal notranslate"><span class="pre">ps_basic_synthesis.ipynb</span></code></a></strong>!</p>
</div>
<section class="tex2jax_ignore mathjax_ignore" id="using-the-portilla-simoncelli-model-in-plenoptic">
<span id="ps-basic-synth"></span><h1>Using the Portilla-Simoncelli model in plenoptic<a class="headerlink" href="#using-the-portilla-simoncelli-model-in-plenoptic" title="Link to this heading"></a></h1>
<p>The original <span id="id1"><a class="reference internal" href="../../../citation.html#id27" title="Javier Portilla and Eero P Simoncelli. A parametric texture model based on joint statistics of complex wavelet coefficients. International journal of computer vision, 40(1):49–70, 2000.">Portilla and Simoncelli, 2000</a></span> publication was accompanied by <a class="reference external" href="https://github.com/LabForComputationalVision/textureSynth/">matlab code</a> which computed the model’s output (“analysis”) and generated new metamers for the model (“synthesis”). This code was hyper-specific for the Portilla-Simoncelli texture model and would not work with any other models.</p>
<p><code class="docutils literal notranslate"><span class="pre">plenoptic</span></code> includes an implementation of the original model which is compatible with our gradient-based synthesis methods. In this notebook, we will introduce the <a class="reference internal" href="../../../generated/plenoptic.simulate.models.portilla_simoncelli.html#plenoptic.simulate.models.portilla_simoncelli.PortillaSimoncelli" title="plenoptic.simulate.models.portilla_simoncelli.PortillaSimoncelli"><code class="xref py py-class docutils literal notranslate"><span class="pre">PortillaSimoncelli</span></code></a> class and how to use it with the <a class="reference internal" href="../../../generated/plenoptic.synthesize.metamer.Metamer.html#plenoptic.synthesize.metamer.Metamer" title="plenoptic.synthesize.metamer.Metamer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Metamer</span></code></a> class to synthesize model metamers.</p>
<div class="warning dropdown admonition">
<p class="admonition-title">Reproducing the metamers in this notebook</p>
<p>Due to pytorch’s limitations, we <a class="reference internal" href="../../../reproducibility.html#reproduce"><span class="std std-ref">cannot guarantee perfect reproducibility</span></a>.
However, we’ve found the setup shown in this notebook works reliably across different images and produce good metamers efficiently.</p>
<p>If you use follow these basic steps and <strong>are not</strong> able to successfully synthesize a good <code class="docutils literal notranslate"><span class="pre">PortillaSimoncelli</span></code> <!-- skip-lint -->  model metamer, please post on our <a class="reference external" href="https://github.com/plenoptic-org/plenoptic/discussions/">discussion board</a> and we’ll try to help!</p>
<p>See <a class="reference internal" href="ps_optimization.html#ps-optimization"><span class="std std-ref">Portilla-Simoncelli optimization details</span></a> for more information about the specific decisions taken around optimization, including what “good” means.</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">plenoptic</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">po</span>

<span class="o">%</span><span class="k">load_ext</span> autoreload
<span class="o">%</span><span class="k">autoreload</span> 2

<span class="c1"># We need to download some additional images for this notebook.</span>
<span class="n">IMG_PATH</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">fetch_data</span><span class="p">(</span><span class="s2">&quot;portilla_simoncelli_images.tar.gz&quot;</span><span class="p">)</span>
<span class="c1"># use GPU if available</span>
<span class="n">DEVICE</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>

<span class="c1"># so that relative sizes of axes created by po.imshow and others look right</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s2">&quot;figure.dpi&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">72</span>

<span class="c1"># set seed for reproducibility</span>
<span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section id="a-quick-reminder-of-what-metamers-are-and-why-we-are-calculating-them">
<h2>A quick reminder of what metamers are and why we are calculating them<a class="headerlink" href="#a-quick-reminder-of-what-metamers-are-and-why-we-are-calculating-them" title="Link to this heading"></a></h2>
<p>Model metamers are images with different pixel values but (near-)identical model outputs. The primary reason that the original <span id="id2"><a class="reference internal" href="../../../citation.html#id27" title="Javier Portilla and Eero P Simoncelli. A parametric texture model based on joint statistics of complex wavelet coefficients. International journal of computer vision, 40(1):49–70, 2000.">Portilla and Simoncelli, 2000</a></span> paper developed the metamer procedure was to assess whether the model’s understanding of textures matches that of humans. While developing the model, the authors originally evaluated it by performing texture classification on a then-standard dataset (i.e., “is this a piece of fur or a patch of grass?”). The model aced the test, with 100% accuracy. After an initial moment of elation, the authors decided to double-check and performed the same evaluation with a far simpler model, which used the steerable pyramid to compute oriented energy (the first stage of the model described here). That model also classified the textures with 100% accuracy. The authors interpreted this as their evaluation being too easy, and sought a method that would allow them to determine whether their model better matched human texture perception.</p>
<p>In the metamer paradigm they eventually arrived at, the authors generated sets of model metamers. They then evaluated whether these images belonged to the same texture class: does this model metamer of a basket also look like a basket, or does it look like something else? Importantly, they were not evaluating whether the images were <em>indistinguishable</em>, but whether they belonged to the same texture family. This paradigm thus tests whether the model is capturing important information about how humans understand and group textures.</p>
</section>
<section id="plenoptic-s-portillasimoncelli-class">
<h2>Plenoptic’s PortillaSimoncelli class<a class="headerlink" href="#plenoptic-s-portillasimoncelli-class" title="Link to this heading"></a></h2>
<p>Before synthesizing a model metamer, let’s spend a bit of time with the <a class="reference internal" href="../../../generated/plenoptic.simulate.models.portilla_simoncelli.html#plenoptic.simulate.models.portilla_simoncelli.PortillaSimoncelli" title="plenoptic.simulate.models.portilla_simoncelli.PortillaSimoncelli"><code class="xref py py-class docutils literal notranslate"><span class="pre">PortillaSimoncelli</span></code></a> class. First, let’s grab a texture image:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">img</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">load_images</span><span class="p">(</span><span class="n">IMG_PATH</span> <span class="o">/</span> <span class="s2">&quot;fig4a.jpg&quot;</span><span class="p">)</span>
<span class="n">po</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/4cba88b8e7555215ae870d9f3771c93d33111e1948af9d82de4710bd0364aa6f.png" src="../../../_images/4cba88b8e7555215ae870d9f3771c93d33111e1948af9d82de4710bd0364aa6f.png" />
</div>
</div>
<p>Now let’s create an instance of the PortillaSimoncelli model with the following parameters:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">n_scales=4</span></code>, The number of scales in the steerable pyramid underlying the model.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">n_orientations=3</span></code>, The number of orientations in the steerable pyramid.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">spatial_corr_width=9</span></code>, The size of the window used to calculate the correlations across steerable pyramid bands.</p></li>
</ul>
<p>Running the model on an image will return a tensor of numbers summarizing the “texturiness” of that image, which we refer to as the model’s representation. These statistics are measurements of different properties that the authors considered relevant to a texture’s appearance (where a texture is defined above), and capture some of the repeating properties of these types of images.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">simul</span><span class="o">.</span><span class="n">PortillaSimoncelli</span><span class="p">(</span>
    <span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:],</span> <span class="n">n_scales</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">n_orientations</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">spatial_corr_width</span><span class="o">=</span><span class="mi">9</span>
<span class="p">)</span>
<span class="n">representation</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;The texture model has </span><span class="si">{</span><span class="n">representation</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2"> statistics. &quot;</span>
    <span class="s2">&quot;Here&#39;s the first several:&quot;</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">representation</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="mi">10</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The texture model has 807 statistics. Here&#39;s the first several:
tensor([[[ 4.3503e-01,  4.0737e-02,  1.6215e-01,  2.2822e+00,  0.0000e+00,
           9.9608e-01,  1.4031e-02, -8.3651e-02, -4.1651e-01,  2.0114e-03]]])
</pre></div>
</div>
</div>
</div>
<p>The model’s representation consists of several different classes of statistics. We will explore these statistics and how they relate to visual textures in more detail in the <a class="reference internal" href="ps_understand_stats.html#ps-model-stats"><span class="std std-ref">Understanding Portilla-Simoncelli model statistics</span></a> notebook, but the class has two methods which can help you better understand the representation:</p>
<ul class="simple">
<li><p><a class="reference internal" href="../../../generated/plenoptic.simulate.models.portilla_simoncelli.html#plenoptic.simulate.models.portilla_simoncelli.PortillaSimoncelli.convert_to_dict" title="plenoptic.simulate.models.portilla_simoncelli.PortillaSimoncelli.convert_to_dict"><code class="xref py py-func docutils literal notranslate"><span class="pre">convert_to_dict</span></code></a> will turn the representation tensor into a dictionary with informative keys:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rep_dict</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">convert_to_dict</span><span class="p">(</span><span class="n">representation</span><span class="p">)</span>
<span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">rep_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>pixel_statistics torch.Size([1, 1, 6])
auto_correlation_magnitude torch.Size([1, 1, 9, 9, 3, 4])
skew_reconstructed torch.Size([1, 1, 5])
kurtosis_reconstructed torch.Size([1, 1, 5])
auto_correlation_reconstructed torch.Size([1, 1, 9, 9, 5])
std_reconstructed torch.Size([1, 1, 5])
cross_orientation_correlation_magnitude torch.Size([1, 1, 3, 3, 4])
magnitude_std torch.Size([1, 1, 3, 4])
cross_scale_correlation_magnitude torch.Size([1, 1, 3, 3, 3])
cross_scale_correlation_real torch.Size([1, 1, 3, 6, 3])
var_highpass_residual torch.Size([1, 1, 1])
</pre></div>
</div>
</div>
</div>
<p>The statistics have also been reshaped so that e.g., the <code class="docutils literal notranslate"><span class="pre">auto_correlation_magnitude</span></code> representation has shape <code class="docutils literal notranslate"><span class="pre">(batch,</span> <span class="pre">channel,</span> <span class="pre">spatial_corr_width,</span> <span class="pre">spatial_corr_width,</span> <span class="pre">n_orientations,</span> <span class="pre">n_scales)</span></code>, which might make understanding the values easier.</p>
<ul class="simple">
<li><p><a class="reference internal" href="../../../generated/plenoptic.simulate.models.portilla_simoncelli.html#plenoptic.simulate.models.portilla_simoncelli.PortillaSimoncelli.plot_representation" title="plenoptic.simulate.models.portilla_simoncelli.PortillaSimoncelli.plot_representation"><code class="xref py py-func docutils literal notranslate"><span class="pre">plot_representation</span></code></a> will plot a summarized version of the representation tensor:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">plot_representation</span><span class="p">(</span><span class="n">representation</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(&lt;Figure size 864x360 with 8 Axes&gt;,
 [&lt;Axes: title={&#39;center&#39;: &#39;pixels+var_highpass&#39;}&gt;,
  &lt;Axes: title={&#39;center&#39;: &#39;std+skew+kurtosis recon&#39;}&gt;,
  &lt;Axes: title={&#39;center&#39;: &#39;magnitude_std&#39;}&gt;,
  &lt;Axes: title={&#39;center&#39;: &#39;auto_correlation_reconstructed&#39;}&gt;,
  &lt;Axes: title={&#39;center&#39;: &#39;auto_correlation_magnitude&#39;}&gt;,
  &lt;Axes: title={&#39;center&#39;: &#39;cross_orientation_correlation_magnitude&#39;}&gt;,
  &lt;Axes: title={&#39;center&#39;: &#39;cross_scale_correlation_magnitude&#39;}&gt;,
  &lt;Axes: title={&#39;center&#39;: &#39;cross_scale_correlation_real&#39;}&gt;])
</pre></div>
</div>
<img alt="../../../_images/9cd6d893e12075008162f232b8fa0962e91592f62df09fe4a0a7735c777bfa41.png" src="../../../_images/9cd6d893e12075008162f232b8fa0962e91592f62df09fe4a0a7735c777bfa41.png" />
</div>
</div>
<p>This plot will be also useful when investigating metamer synthesis progress, so that we can see which statistics are matched and which still differ.</p>
<p>When the model representation of two images match, the model considers the two images identical and we say that those two images are model metamers. Synthesizing a novel image that matches the representation of some arbitrary input is the goal of the <a class="reference internal" href="../../../generated/plenoptic.synthesize.metamer.Metamer.html#plenoptic.synthesize.metamer.Metamer" title="plenoptic.synthesize.metamer.Metamer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Metamer</span></code></a> class, as described in the next section.</p>
</section>
<section id="synthesizing-portilla-simoncelli-texture-model-metamers">
<h2>Synthesizing Portilla-Simoncelli Texture Model Metamers<a class="headerlink" href="#synthesizing-portilla-simoncelli-texture-model-metamers" title="Link to this heading"></a></h2>
<p>Synthesizing Portilla-Simoncelli model metamers require some additional options compared to the <a class="reference internal" href="../../intro/Metamer.html#metamer-nb"><span class="std std-ref">basic Metamer usage</span></a>. This section will demonstrate how to synthesize a model metamer for this wicker basket texture:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">po</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/4cba88b8e7555215ae870d9f3771c93d33111e1948af9d82de4710bd0364aa6f.png" src="../../../_images/4cba88b8e7555215ae870d9f3771c93d33111e1948af9d82de4710bd0364aa6f.png" />
</div>
</div>
<p>The following settings seem to reliably find good metamers for this model. Here, we just give a brief overview of these options; see the <a class="reference internal" href="ps_optimization.html#ps-optimization"><span class="std std-ref">Portilla-Simoncelli optimization details</span></a> notebook for more information.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">max_iter=100</span></code> puts an upper bound (of 100) on the number of iterations that the optimization will run.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">loss_function</span></code> <!-- skip-lint --> specifies the loss function to use. Here, we use a loss that we know works well for this model, which reweights some of the representation to find a better solution.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">optimizer</span></code> <!-- skip-lint --> / <code class="docutils literal notranslate"><span class="pre">optimizer_kwargs</span></code> specifies the torch optimizer to use and its keyword arguments. Here, we use <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.optim.LBFGS.html#torch.optim.LBFGS" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">LBFGS</span></code></a>, which uses an estimate of the Hessian matrix (which contains all second-order partial derivatives) to find the best solution.</p></li>
</ul>
<p>This process takes about 4 minutes on my laptop without a GPU. How long it will take depends on your system and, in particular, whether you have a GPU.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># send image and PS model to GPU, if available. then Metamer will also</span>
<span class="c1"># use GPU</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">simul</span><span class="o">.</span><span class="n">PortillaSimoncelli</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">portilla_simoncelli_loss_factory</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">img</span><span class="p">)</span>
<span class="n">met</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">synth</span><span class="o">.</span><span class="n">Metamer</span><span class="p">(</span>
    <span class="n">img</span><span class="p">,</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">loss_function</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">opt_kwargs</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;max_iter&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
    <span class="s2">&quot;max_eval&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
    <span class="s2">&quot;history_size&quot;</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span>
    <span class="s2">&quot;line_search_fn&quot;</span><span class="p">:</span> <span class="s2">&quot;strong_wolfe&quot;</span><span class="p">,</span>
    <span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
<span class="p">}</span>
<span class="n">met</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">LBFGS</span><span class="p">,</span> <span class="n">optimizer_kwargs</span><span class="o">=</span><span class="n">opt_kwargs</span><span class="p">)</span>
<span class="n">met</span><span class="o">.</span><span class="n">synthesize</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "e2f891b123784872bb3a70719d065aee"}</script></div>
</div>
<p>Now we can visualize the output of the synthesis optimization. First we compare the <em>Target image</em> and the <em>Synthesized image</em> side-by-side. We can see that they appear perceptually similar — that is, for this texture image, matching the Portilla-Simoncelli texture stats gives you an image that the human visual system <em>also</em> considers similar.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">po</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span>
    <span class="p">[</span><span class="n">met</span><span class="o">.</span><span class="n">image</span><span class="p">,</span> <span class="n">met</span><span class="o">.</span><span class="n">metamer</span><span class="p">],</span>
    <span class="n">title</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Target image&quot;</span><span class="p">,</span> <span class="s2">&quot;Synthesized metamer&quot;</span><span class="p">],</span>
    <span class="n">vrange</span><span class="o">=</span><span class="s2">&quot;auto1&quot;</span><span class="p">,</span>
<span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/cd04820646b1e2e4f485c81f4de24c9ccb05ccaf032f3cd800019b423ef80a12.png" src="../../../_images/cd04820646b1e2e4f485c81f4de24c9ccb05ccaf032f3cd800019b423ef80a12.png" />
</div>
</div>
<p>We can also use plenoptic’s <a class="reference internal" href="../../../generated/plenoptic.synthesize.metamer.html#plenoptic.synthesize.metamer.plot_synthesis_status" title="plenoptic.synthesize.metamer.plot_synthesis_status"><code class="xref py py-func docutils literal notranslate"><span class="pre">plot_synthesis_status</span></code></a> method to see how things are going. The image on the left shows the metamer at this moment in synthesis, while the center plot shows the loss over time, with the red dot pointing out the current loss, and the rightmost plot shows the representation error (i.e., the <a class="reference internal" href="../../../generated/plenoptic.simulate.models.portilla_simoncelli.html#plenoptic.simulate.models.portilla_simoncelli.PortillaSimoncelli.plot_representation" title="plenoptic.simulate.models.portilla_simoncelli.PortillaSimoncelli.plot_representation"><code class="xref py py-func docutils literal notranslate"><span class="pre">plot_representation</span></code></a> figure from above, but for <code class="docutils literal notranslate"><span class="pre">model(target</span> <span class="pre">image)</span> <span class="pre">-</span> <span class="pre">model(synthesized</span> <span class="pre">image)</span></code>).</p>
<p>We can see the synthesized texture on the leftmost plot. The overall synthesis error decreases over the synthesis iterations (subplot 2).  The remaining plots show us the error broken out by the different texture statistics; see <a class="reference internal" href="ps_understand_stats.html#ps-model-stats"><span class="std std-ref">Understanding Portilla-Simoncelli model statistics</span></a> to better understand them.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">po</span><span class="o">.</span><span class="n">synth</span><span class="o">.</span><span class="n">metamer</span><span class="o">.</span><span class="n">plot_synthesis_status</span><span class="p">(</span>
    <span class="n">met</span><span class="p">,</span> <span class="n">width_ratios</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;plot_representation_error&quot;</span><span class="p">:</span> <span class="mf">3.1</span><span class="p">}</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(&lt;Figure size 2131.2x360 with 11 Axes&gt;,
 {&#39;display_metamer&#39;: 0,
  &#39;plot_loss&#39;: 1,
  &#39;plot_representation_error&#39;: [3, 4, 5, 6, 7, 8, 9, 10, 2],
  &#39;misc&#39;: []})
</pre></div>
</div>
<img alt="../../../_images/be8e093adb78b1c9d86a6b038a5f239c4dbaed65a5359b7e4872071c6daa3fce.png" src="../../../_images/be8e093adb78b1c9d86a6b038a5f239c4dbaed65a5359b7e4872071c6daa3fce.png" />
</div>
</div>
</section>
<section id="further-reading">
<h2>Further reading<a class="headerlink" href="#further-reading" title="Link to this heading"></a></h2>
<p>To see more texture model metamers with different types of images, see the <a class="reference internal" href="ps_examples.html"><span class="doc std std-doc">Example Portilla-Simoncelli metamers from different texture classes</span></a> notebook.</p>
<p>Alternatively, to learn more:</p>
<ul class="simple">
<li><p>about the different components of the model’s representation, read the <a class="reference internal" href="ps_understand_stats.html#ps-model-stats"><span class="std std-ref">Understanding Portilla-Simoncelli model statistics</span></a> notebook.</p></li>
<li><p>about the optimization choices taken above, read the <a class="reference internal" href="ps_optimization.html#ps-optimization"><span class="std std-ref">Portilla-Simoncelli optimization details</span></a> notebook.</p></li>
</ul>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="ps_intro.html" class="btn btn-neutral float-left" title="What is a visual texture?" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="ps_examples.html" class="btn btn-neutral float-right" title="Example Portilla-Simoncelli metamers from different texture classes" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2019-2025, Plenoptic authors.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>