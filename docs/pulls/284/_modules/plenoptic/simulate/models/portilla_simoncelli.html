

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>plenoptic.simulate.models.portilla_simoncelli &mdash; plenoptic 1.1.1.dev88 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css?v=fa44fd50" />
      <link rel="stylesheet" type="text/css" href="../../../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../../../_static/plot_directive.css" />
      <link rel="stylesheet" type="text/css" href="../../../../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../../../../_static/tabs.css?v=4c969af8" />

  
      <script src="../../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../../../_static/documentation_options.js?v=d2682407"></script>
      <script src="../../../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../../../../_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="../../../../_static/copybutton.js?v=f281be69"></script>
      <script src="../../../../_static/tabs.js?v=3ee01567"></script>
      <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../../index.html" class="icon icon-home">
            plenoptic
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Basic concepts</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../install.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../jupyter.html">Using Jupyter to Run Example Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../jupyter.html#ffmpeg-and-videos">ffmpeg and videos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../conceptual_intro.html">Conceptual Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../models.html">Model requirements</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/00_quickstart.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../citation.html">Citation Guide</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Synthesis method introductions</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/intro/02_Eigendistortions.html">Eigendistortions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/intro/06_Metamer.html">Metamers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/intro/07_Simple_MAD.html">MAD Competition Conceptual Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/intro/08_MAD_Competition.html">MAD Competition Usage</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Models and metrics</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/models/03_Steerable_Pyramid.html">Steerable Pyramid</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/models/04_Perceptual_distance.html">Perceptual distance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/models/Metamer-Portilla-Simoncelli.html">Portilla-Simoncelli Texture Metamer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/models/pooled_texture_model.html">Pooled Texture Model</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Synthesis method examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/applications/09_Original_MAD.html">Reproducing Wang and Simoncelli, 2008 (MAD Competition)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/applications/Demo_Eigendistortion.html">Reproducing Berardino et al., 2017 (Eigendistortions)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced usage</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../synthesis.html">Synthesis object design</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tips.html">Tips and Tricks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../reproducibility.html">Reproducibility</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api/modules.html">API Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/advanced/Display.html">Display and animate functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/advanced/Synthesis_extensions.html">Extending existing synthesis objects</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">plenoptic</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">plenoptic.simulate.models.portilla_simoncelli</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for plenoptic.simulate.models.portilla_simoncelli</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;Portilla-Simoncelli texture statistics.</span>

<span class="sd">The Portilla-Simoncelli (PS) texture statistics are a set of image</span>
<span class="sd">statistics, first described in [1]_, that are proposed as a sufficient set</span>
<span class="sd">of measurements for describing visual textures. That is, if two texture</span>
<span class="sd">images have the same values for all PS texture stats, humans should</span>
<span class="sd">consider them as members of the same family of textures.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">OrderedDict</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Literal</span>

<span class="kn">import</span> <span class="nn">einops</span>
<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="nn">mpl</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">numpy.typing</span> <span class="kn">import</span> <span class="n">NDArray</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.fft</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">Tensor</span>

<span class="kn">from</span> <span class="nn">...tools</span> <span class="kn">import</span> <span class="n">signal</span><span class="p">,</span> <span class="n">stats</span>
<span class="kn">from</span> <span class="nn">...tools.data</span> <span class="kn">import</span> <span class="n">to_numpy</span>
<span class="kn">from</span> <span class="nn">...tools.display</span> <span class="kn">import</span> <span class="n">clean_stem_plot</span><span class="p">,</span> <span class="n">clean_up_axes</span><span class="p">,</span> <span class="n">update_stem</span>
<span class="kn">from</span> <span class="nn">...tools.validate</span> <span class="kn">import</span> <span class="n">validate_input</span>
<span class="kn">from</span> <span class="nn">..canonical_computations.steerable_pyramid_freq</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">SCALES_TYPE</span> <span class="k">as</span> <span class="n">PYR_SCALES_TYPE</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">..canonical_computations.steerable_pyramid_freq</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">SteerablePyramidFreq</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">..canonical_computations.weighted_average</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">WeightedAveragePyramid</span><span class="p">,</span>
    <span class="n">SimpleAverage</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">SCALES_TYPE</span> <span class="o">=</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;pixel_statistics&quot;</span><span class="p">]</span> <span class="o">|</span> <span class="n">PYR_SCALES_TYPE</span>


<span class="k">class</span> <span class="nc">_StatsComputer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    spatial_corr_width:</span>
<span class="sd">        The width of the spatial cross- and auto-correlation statistics</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">autocorr_masks</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Tensor</span><span class="p">],</span>
        <span class="n">spatial_corr_width</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">9</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">spatial_corr_width</span> <span class="o">=</span> <span class="n">spatial_corr_width</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">autocorr_masks</span> <span class="o">=</span> <span class="n">autocorr_masks</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="p">[</span><span class="n">SimpleAverage</span><span class="p">()]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_extra_dims</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="s2">&quot;o&quot;</span><span class="p">]</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">compute_pixel_stats</span><span class="p">(</span><span class="n">image</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute the pixel stats: first four moments, min, and max.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        image :</span>
<span class="sd">            4d tensor of shape (batch, channel, height, width) containing input</span>
<span class="sd">            image. Stats are computed indepently for each batch and channel.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        pixel_stats :</span>
<span class="sd">            3d tensor of shape (batch, channel, 6) containing the mean,</span>
<span class="sd">            variance, skew, kurtosis, minimum pixel value, and maximum pixel</span>
<span class="sd">            value (in that order)</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="c1"># we use torch.var instead of plenoptic.tools.variance, because our</span>
        <span class="c1"># variance is the uncorrected (or sample) variance and we want the</span>
        <span class="c1"># corrected one here.</span>
        <span class="n">var</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">skew</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">skew</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">var</span><span class="o">=</span><span class="n">var</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">kurtosis</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">kurtosis</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">var</span><span class="o">=</span><span class="n">var</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="c1"># can&#39;t compute min/max over two dims simultaneously with</span>
        <span class="c1"># torch.min/max, so use einops</span>
        <span class="n">img_min</span> <span class="o">=</span> <span class="n">einops</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="s2">&quot;b c h w -&gt; b c&quot;</span><span class="p">,</span> <span class="s2">&quot;min&quot;</span><span class="p">)</span>
        <span class="n">img_max</span> <span class="o">=</span> <span class="n">einops</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="s2">&quot;b c h w -&gt; b c&quot;</span><span class="p">,</span> <span class="s2">&quot;max&quot;</span><span class="p">)</span>
        <span class="c1"># mean needed to be unflattened to be used by skew and kurtosis</span>
        <span class="c1"># correctly, but we&#39;ll want it to be flattened like this in the final</span>
        <span class="c1"># representation tensor</span>
        <span class="k">return</span> <span class="n">einops</span><span class="o">.</span><span class="n">rearrange</span><span class="p">(</span>
            <span class="p">[</span><span class="n">mean</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">var</span><span class="p">,</span> <span class="n">skew</span><span class="p">,</span> <span class="n">kurtosis</span><span class="p">,</span> <span class="n">img_min</span><span class="p">,</span> <span class="n">img_max</span><span class="p">],</span>
            <span class="s2">&quot;s b c -&gt; b c 1 s&quot;</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">compute_autocorr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">coeffs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Tensor</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute the autocorrelation of some statistics.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        coeffs_list :</span>
<span class="sd">            List (of length s) of tensors of shape (batch, channel, *, height,</span>
<span class="sd">            width), where * is zero or one additional dimensions. Intended use</span>
<span class="sd">            case: magnitude_pyr_coeffs (which is list of length n_scales of 5d</span>
<span class="sd">            tensors, with * containing n_orientations) or reconstructed_images</span>
<span class="sd">            (which is a list of length n_scales+1 of 4d tensors)</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        autocorrs :</span>
<span class="sd">            Tensor of shape (batch, channel, spatial_corr_width,</span>
<span class="sd">            spatial_corr_width, *, s) containing the autocorrelation (up to</span>
<span class="sd">            distance ``spatial_corr_width//2``) of each element in</span>
<span class="sd">            ``coeffs_list``, computed independently over all but the final two</span>
<span class="sd">            dimensions.</span>
<span class="sd">        vars :</span>
<span class="sd">            3d Tensor of shape (batch, channel, *, s) containing the variance</span>
<span class="sd">            of each element in ``coeffs_list``, computed independently over all</span>
<span class="sd">            but the final two dimensions.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">coeffs_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&lt;</span> <span class="mi">4</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;coeffs_list must contain tensors of either 4 or 5 dimensions!&quot;</span>
            <span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">extra_dims</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_extra_dims</span><span class="p">[</span><span class="n">coeffs_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">4</span><span class="p">]</span>
            <span class="n">mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">autocorr_masks</span><span class="p">[</span><span class="n">coeffs_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">4</span><span class="p">]</span>
        <span class="k">except</span> <span class="ne">IndexError</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;coeffs_list must contain tensors of either 4 or 5 dimensions!&quot;</span>
            <span class="p">)</span>
        <span class="n">acs</span> <span class="o">=</span> <span class="p">[</span><span class="n">signal</span><span class="o">.</span><span class="n">autocorrelation</span><span class="p">(</span><span class="n">coeff</span><span class="p">)</span> <span class="k">for</span> <span class="n">coeff</span> <span class="ow">in</span> <span class="n">coeffs_list</span><span class="p">]</span>
        <span class="n">var</span> <span class="o">=</span> <span class="p">[</span><span class="n">signal</span><span class="o">.</span><span class="n">center_crop</span><span class="p">(</span><span class="n">ac</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">ac</span> <span class="ow">in</span> <span class="n">acs</span><span class="p">]</span>
        <span class="n">acs</span> <span class="o">=</span> <span class="p">[</span><span class="n">ac</span> <span class="o">/</span> <span class="n">v</span> <span class="k">for</span> <span class="n">ac</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">acs</span><span class="p">,</span> <span class="n">var</span><span class="p">)]</span>
        <span class="n">var</span> <span class="o">=</span> <span class="n">einops</span><span class="o">.</span><span class="n">rearrange</span><span class="p">(</span><span class="n">var</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;s b c </span><span class="si">{</span><span class="n">extra_dims</span><span class="si">}</span><span class="s2"> 1 1 -&gt; b c 1 </span><span class="si">{</span><span class="n">extra_dims</span><span class="si">}</span><span class="s2"> s&quot;</span><span class="p">)</span>
        <span class="n">acs</span> <span class="o">=</span> <span class="p">[</span><span class="n">signal</span><span class="o">.</span><span class="n">center_crop</span><span class="p">(</span><span class="n">ac</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">spatial_corr_width</span><span class="p">)</span> <span class="k">for</span> <span class="n">ac</span> <span class="ow">in</span> <span class="n">acs</span><span class="p">]</span>
        <span class="n">acs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">acs</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">acs</span> <span class="o">=</span> <span class="n">einops</span><span class="o">.</span><span class="n">rearrange</span><span class="p">(</span>
            <span class="n">acs</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;b c s </span><span class="si">{</span><span class="n">extra_dims</span><span class="si">}</span><span class="s2"> a1 a2 -&gt; b c 1 a1 a2 </span><span class="si">{</span><span class="n">extra_dims</span><span class="si">}</span><span class="s2"> s&quot;</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">acs</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">mask</span><span class="p">],</span> <span class="n">var</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">compute_skew_kurtosis_recon</span><span class="p">(</span>
        <span class="n">reconstructed_images</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Tensor</span><span class="p">],</span>
        <span class="n">var_recon</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">img_var</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute the skew and kurtosis of each lowpass reconstructed image.</span>

<span class="sd">        For each scale, if the ratio of its variance to the original image&#39;s</span>
<span class="sd">        pixel variance is below a threshold of</span>
<span class="sd">        torch.finfo(img_var.dtype).resolution (1e-6 for float32, 1e-15 for</span>
<span class="sd">        float64), skew and kurtosis are assigned default values of 0 or 3,</span>
<span class="sd">        respectively.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        reconstructed_images :</span>
<span class="sd">            List of length n_scales+1 containing the reconstructed unoriented</span>
<span class="sd">            image at each scale, from fine to coarse. The final image is</span>
<span class="sd">            reconstructed just from the residual lowpass image.</span>
<span class="sd">        var_recon :</span>
<span class="sd">            Tensor of shape (batch, channel, n_scales+1) containing the</span>
<span class="sd">            variance of each tensor in reconstruced_images</span>
<span class="sd">        img_var :</span>
<span class="sd">            Tensor of shape (batch, channel) containing the pixel variance</span>
<span class="sd">            (from pixel_stats tensor)</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        skew_recon, kurtosis_recon :</span>
<span class="sd">            Tensors of shape (batch, channel, n_scales+1) containing the skew</span>
<span class="sd">            and kurtosis, respectively, of each tensor in</span>
<span class="sd">            ``reconstructed_images``.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">skew_recon</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">stats</span><span class="o">.</span><span class="n">skew</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">var</span><span class="o">=</span><span class="n">var_recon</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">i</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">im</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">reconstructed_images</span><span class="p">)</span>
        <span class="p">]</span>
        <span class="n">skew_recon</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">skew_recon</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">kurtosis_recon</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">stats</span><span class="o">.</span><span class="n">kurtosis</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">var</span><span class="o">=</span><span class="n">var_recon</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">i</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">im</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">reconstructed_images</span><span class="p">)</span>
        <span class="p">]</span>
        <span class="n">kurtosis_recon</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">kurtosis_recon</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">skew_default</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">skew_recon</span><span class="p">)</span>
        <span class="n">kurtosis_default</span> <span class="o">=</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">kurtosis_recon</span><span class="p">)</span>
        <span class="c1"># if this variance ratio is too small, then use the default values</span>
        <span class="c1"># instead. unsqueeze is used here because var_recon is shape (batch,</span>
        <span class="c1"># channel, scales+1), whereas img_var is just (batch, channel)</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">img_var</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">resolution</span>
        <span class="n">unstable_locs</span> <span class="o">=</span> <span class="n">var_recon</span> <span class="o">/</span> <span class="n">img_var</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">res</span>
        <span class="n">skew_recon</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">unstable_locs</span><span class="p">,</span> <span class="n">skew_default</span><span class="p">,</span> <span class="n">skew_recon</span><span class="p">)</span>
        <span class="n">kurtosis_recon</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">unstable_locs</span><span class="p">,</span> <span class="n">kurtosis_default</span><span class="p">,</span> <span class="n">kurtosis_recon</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">skew_recon</span><span class="p">,</span> <span class="n">kurtosis_recon</span>

    <span class="k">def</span> <span class="nf">compute_cross_correlation</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">coeffs_tensor</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Tensor</span><span class="p">],</span>
        <span class="n">coeffs_tensor_other</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Tensor</span><span class="p">],</span>
        <span class="n">coeffs_var</span><span class="p">:</span> <span class="kc">None</span> <span class="o">|</span> <span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">coeffs_other_var</span><span class="p">:</span> <span class="kc">None</span> <span class="o">|</span> <span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute cross-correlations.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        coeffs_tensor, coeffs_tensor_other :</span>
<span class="sd">            The two lists of length scales, each containing 5d tensors of shape</span>
<span class="sd">            (batch, channel, n_orientations, height, width) to be correlated.</span>
<span class="sd">        coeffs_var, coeffs_other_var :</span>
<span class="sd">            Two optional tensors containing the variances of coeffs_tensor and</span>
<span class="sd">            coeffs_tensor_other, respectively, in case they&#39;ve already been computed.</span>
<span class="sd">            Should be of shape (batch, channel, n_orientations, n_scales). Used to</span>
<span class="sd">            normalize the covariances into cross-correlations.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        cross_corrs :</span>
<span class="sd">            Tensor of shape (batch, channel, n_orientations, n_orientations,</span>
<span class="sd">            scales) containing the cross-correlations at each</span>
<span class="sd">            scale.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">covars</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">coeff</span><span class="p">,</span> <span class="n">coeff_other</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span>
            <span class="nb">zip</span><span class="p">(</span><span class="n">coeffs_tensor</span><span class="p">,</span> <span class="n">coeffs_tensor_other</span><span class="p">)</span>
        <span class="p">):</span>
            <span class="c1"># precompute this, which we&#39;ll use for normalization</span>
            <span class="n">numel</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="o">*</span><span class="n">coeff</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:])</span>
            <span class="c1"># compute the covariance</span>
            <span class="n">covar</span> <span class="o">=</span> <span class="n">einops</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span>
                <span class="n">coeff</span><span class="p">,</span> <span class="n">coeff_other</span><span class="p">,</span> <span class="s2">&quot;b c o1 h w, b c o2 h w -&gt; b c o1 o2&quot;</span>
            <span class="p">)</span>
            <span class="n">covar</span> <span class="o">=</span> <span class="n">covar</span> <span class="o">/</span> <span class="n">numel</span>
            <span class="c1"># Then normalize it to get the Pearson product-moment correlation</span>
            <span class="c1"># coefficient, see</span>
            <span class="c1"># https://numpy.org/doc/stable/reference/generated/numpy.corrcoef.html.</span>
            <span class="k">if</span> <span class="n">coeffs_var</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># First, compute the variances of each coeff</span>
                <span class="n">coeff_var</span> <span class="o">=</span> <span class="n">einops</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span>
                    <span class="n">coeff</span><span class="p">,</span> <span class="n">coeff</span><span class="p">,</span> <span class="s2">&quot;b c o1 h w, b c o1 h w -&gt; b c o1&quot;</span>
                <span class="p">)</span>
                <span class="n">coeff_var</span> <span class="o">=</span> <span class="n">coeff_var</span> <span class="o">/</span> <span class="n">numel</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># coeffs_var will be shape (batch, channel, 1, ..., scales), where the 1</span>
                <span class="c1"># is a dummy dimension for the weights</span>
                <span class="n">coeff_var</span> <span class="o">=</span> <span class="n">coeffs_var</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">coeffs_other_var</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># First, compute the variances of each coeff</span>
                <span class="n">coeff_other_var</span> <span class="o">=</span> <span class="n">einops</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span>
                    <span class="n">coeff_other</span><span class="p">,</span> <span class="n">coeff_other</span><span class="p">,</span> <span class="s2">&quot;b c o1 h w, b c o1 h w -&gt; b c o1&quot;</span>
                <span class="p">)</span>
                <span class="n">coeff_other_var</span> <span class="o">=</span> <span class="n">coeff_other_var</span> <span class="o">/</span> <span class="n">numel</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># coeffs_other_var will be shape (batch, channel, 1, ..., scales), where</span>
                <span class="c1"># the 1 is a dummy dimension for the weights</span>
                <span class="n">coeff_other_var</span> <span class="o">=</span> <span class="n">coeffs_other_var</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span>
            <span class="c1"># Then compute the outer product of those variances.</span>
            <span class="n">var_outer_prod</span> <span class="o">=</span> <span class="n">einops</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span>
                <span class="n">coeff_var</span><span class="p">,</span> <span class="n">coeff_other_var</span><span class="p">,</span> <span class="s2">&quot;b c o1, b c o2 -&gt; b c o1 o2&quot;</span>
            <span class="p">)</span>
            <span class="c1"># And the sqrt of this is what we use to normalize the covariance</span>
            <span class="c1"># into the cross-correlation</span>
            <span class="n">covars</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">covar</span> <span class="o">/</span> <span class="n">var_outer_prod</span><span class="o">.</span><span class="n">sqrt</span><span class="p">())</span>
        <span class="k">return</span> <span class="n">einops</span><span class="o">.</span><span class="n">rearrange</span><span class="p">(</span><span class="n">covars</span><span class="p">,</span> <span class="s2">&quot;s b c o1 o2 -&gt; b c 1 o1 o2 s&quot;</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">_WeightedComputer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    weights:</span>

<span class="sd">    n_scales:</span>
<span class="sd">        The number of pyramid scales used to measure the statistics (default=4)</span>
<span class="sd">    n_orientations:</span>
<span class="sd">        The number of orientations used to measure the statistics (default=4)</span>
<span class="sd">    spatial_corr_width:</span>
<span class="sd">        The width of the spatial cross- and auto-correlation statistics</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">weights</span><span class="p">:</span> <span class="n">WeightedAveragePyramid</span><span class="p">,</span>
        <span class="n">autocorr_shifts</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">NDArray</span><span class="p">,</span> <span class="n">NDArray</span><span class="p">],</span>
        <span class="n">n_scales</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
        <span class="n">n_orientations</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span> <span class="o">=</span> <span class="n">n_scales</span>
        <span class="n">image_shape</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">image_shape</span>
        <span class="c1"># these are each lists of tensors of shape (batch, channel, n_autocorrs, height,</span>
        <span class="c1"># width), one per scale, where n_autocorrs is approximately</span>
        <span class="c1"># spatial_corr_width^2 / 2</span>
        <span class="n">rolls_h</span><span class="p">,</span> <span class="n">rolls_w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_autocorr_idx</span><span class="p">(</span>
            <span class="n">image_shape</span><span class="p">,</span> <span class="n">autocorr_shifts</span><span class="p">,</span> <span class="n">n_scales</span><span class="p">,</span> <span class="n">n_orientations</span>
        <span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">rolls_h</span><span class="p">,</span> <span class="n">rolls_w</span><span class="p">)):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;autocorr_5d_rolls_h_scale_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;autocorr_5d_rolls_w_scale_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>
        <span class="c1"># these share data with the full version above</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">rolls_h</span><span class="p">,</span> <span class="n">rolls_w</span><span class="p">)):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;autocorr_4d_rolls_h_scale_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">h</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;autocorr_4d_rolls_w_scale_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">w</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_autocorrs</span> <span class="o">=</span> <span class="n">rolls_h</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">autocorr_5d_rolls_h</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># inspired by</span>
        <span class="c1"># https://discuss.pytorch.org/t/why-no-nn-bufferlist-like-function-for-registered-buffer-tensor/18884/10</span>
        <span class="k">return</span> <span class="p">[</span>
            <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;autocorr_5d_rolls_h_scale_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="p">]</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">autocorr_5d_rolls_w</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># inspired by</span>
        <span class="c1"># https://discuss.pytorch.org/t/why-no-nn-bufferlist-like-function-for-registered-buffer-tensor/18884/10</span>
        <span class="k">return</span> <span class="p">[</span>
            <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;autocorr_5d_rolls_w_scale_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="p">]</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">autocorr_4d_rolls_h</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># inspired by</span>
        <span class="c1"># https://discuss.pytorch.org/t/why-no-nn-bufferlist-like-function-for-registered-buffer-tensor/18884/10</span>
        <span class="k">return</span> <span class="p">[</span>
            <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;autocorr_4d_rolls_h_scale_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="p">]</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">autocorr_4d_rolls_w</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># inspired by</span>
        <span class="c1"># https://discuss.pytorch.org/t/why-no-nn-bufferlist-like-function-for-registered-buffer-tensor/18884/10</span>
        <span class="k">return</span> <span class="p">[</span>
            <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;autocorr_4d_rolls_w_scale_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="p">]</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">create_autocorr_idx</span><span class="p">(</span>
        <span class="n">image_shape</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span>
        <span class="n">autocorr_shifts</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">NDArray</span><span class="p">,</span> <span class="n">NDArray</span><span class="p">],</span>
        <span class="n">n_scales</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">n_orientations</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="n">Tensor</span><span class="p">],</span> <span class="nb">list</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create indices used to shift images when computing autocorrelation.</span>

<span class="sd">        The autocorrelation of ``img`` is the product of ``img`` with itself shifted by</span>
<span class="sd">        a small number of pixels. That is: ``einops.einsum(img, img.roll(i, -1).roll(j,</span>
<span class="sd">        -2))`` for some relevant values of i and j. This method computes the indices</span>
<span class="sd">        corresponding to those rolls, so that we can simply call ``img.gather(rolls_h,</span>
<span class="sd">        -2).gather(rolls_w, -1)`` during the forward pass instead of ``img.roll(i,</span>
<span class="sd">        -1).roll(j, -2)``, which is less efficient.</span>

<span class="sd">        Because of the symmetry of autocorrelations (see Portilla-Simoncelli notebook</span>
<span class="sd">        for details), we do not need the full ``spatial_corr_width**2`` shifts, we only</span>
<span class="sd">        need everything below the diagonal (e.g., we don&#39;t need to roll both 1 pixel to</span>
<span class="sd">        the left and 1 pixel to the right).</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        spatial_corr_width :</span>
<span class="sd">            The width of the spatial auto-correlation.</span>
<span class="sd">        image_shape :</span>
<span class="sd">            Shape of input image.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        rolls_h, rolls_w :</span>
<span class="sd">            List of tensors of shape ``(1, 1, n_orientations, n_autocorrs, height,</span>
<span class="sd">            width)`` giving the shifts along the height (``shape[-2]``) and width</span>
<span class="sd">            (``shape[-1]``) dimensions required for computing the autocorrelations. Each</span>
<span class="sd">            entry in the list corresponds to a different scale, and thus height and</span>
<span class="sd">            width decrease.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">img_h</span><span class="p">,</span> <span class="n">img_w</span> <span class="o">=</span> <span class="n">image_shape</span>
        <span class="n">rolls_h</span><span class="p">,</span> <span class="n">rolls_w</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
        <span class="c1"># need one additional scale, since we compute the autocorrelation of the</span>
        <span class="c1"># reconstructed lowpass images as well</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_scales</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">arange_h</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">img_h</span><span class="p">)</span>
                <span class="o">.</span><span class="n">view</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">img_h</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
                <span class="o">.</span><span class="n">repeat</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_orientations</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">img_h</span><span class="p">))</span>
            <span class="p">)</span>
            <span class="n">arange_w</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">img_w</span><span class="p">)</span>
                <span class="o">.</span><span class="n">view</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">img_w</span><span class="p">))</span>
                <span class="o">.</span><span class="n">repeat</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_orientations</span><span class="p">,</span> <span class="n">img_w</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
            <span class="p">)</span>
            <span class="n">rolls_h</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">arange_h</span><span class="o">.</span><span class="n">roll</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">autocorr_shifts</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="mi">2</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">rolls_w</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">arange_w</span><span class="o">.</span><span class="n">roll</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">autocorr_shifts</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span> <span class="mi">2</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">img_h</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">img_h</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)</span>
            <span class="n">img_w</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">img_w</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">rolls_h</span><span class="p">,</span> <span class="n">rolls_w</span>

    <span class="k">def</span> <span class="nf">compute_pixel_stats</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute the weighted pixel stats: first four moments.</span>

<span class="sd">        Note that, in contrast with the non-weighted version, this does not include the</span>
<span class="sd">        min/max.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        image :</span>
<span class="sd">            4d tensor of shape (batch, channel, height, width) containing input</span>
<span class="sd">            image. Stats are computed indepently for each batch and channel.</span>
<span class="sd">        epsilon :</span>
<span class="sd">            Epsilon value to use in the denominator when computing the skew and</span>
<span class="sd">            kurtosis, to prevent them from blowing up.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        pixel_stats :</span>
<span class="sd">            4d tensor of shape (batch, channel, weights, 4) containing the mean, var,</span>
<span class="sd">            skew, kurtosis.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="n">weights</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
        <span class="c1"># these are all non-central moments...</span>
        <span class="n">moment_2</span> <span class="o">=</span> <span class="n">weights</span><span class="p">(</span><span class="n">image</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
        <span class="n">moment_3</span> <span class="o">=</span> <span class="n">weights</span><span class="p">(</span><span class="n">image</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">3</span><span class="p">))</span>
        <span class="n">moment_4</span> <span class="o">=</span> <span class="n">weights</span><span class="p">(</span><span class="n">image</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">4</span><span class="p">))</span>
        <span class="c1"># ... which we use to compute the var, skew, and kurtosis. the formulas we use</span>
        <span class="c1"># for var and skew here can be found on their respective wikipedia pages, and</span>
        <span class="c1"># the one for kurtosis comes from Eero working through the algebra</span>
        <span class="n">var</span> <span class="o">=</span> <span class="n">moment_2</span> <span class="o">-</span> <span class="n">mean</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">skew</span> <span class="o">=</span> <span class="p">(</span><span class="n">moment_3</span> <span class="o">-</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">mean</span> <span class="o">*</span> <span class="n">var</span> <span class="o">-</span> <span class="n">mean</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">3</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="n">var</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mf">1.5</span><span class="p">)</span> <span class="o">+</span> <span class="n">epsilon</span><span class="p">)</span>
        <span class="n">kurtosis</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">moment_4</span>
            <span class="o">-</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">mean</span> <span class="o">*</span> <span class="n">moment_3</span>
            <span class="o">+</span> <span class="mi">6</span> <span class="o">*</span> <span class="n">mean</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">moment_2</span>
            <span class="o">-</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">mean</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
        <span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">var</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">epsilon</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">mean</span><span class="p">,</span> <span class="n">var</span><span class="p">,</span> <span class="n">skew</span><span class="p">,</span> <span class="n">kurtosis</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">compute_autocorr</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">coeffs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">epsilon</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-6</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute the autocorrelation of some statistics.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        coeffs_list :</span>
<span class="sd">            List (of length s) of tensors of shape (batch, channel, *, height,</span>
<span class="sd">            width), where * is zero or one additional dimensions. Intended use</span>
<span class="sd">            case: magnitude_pyr_coeffs (which is list of length n_scales of 5d</span>
<span class="sd">            tensors, with * containing n_orientations) or reconstructed_images</span>
<span class="sd">            (which is a list of length n_scales+1 of 4d tensors)</span>
<span class="sd">        epsilon :</span>
<span class="sd">            Epsilon value to use in the denominator when normalizing the</span>
<span class="sd">            autocorrelations, to prevent them from blowing up.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        autocorrs :</span>
<span class="sd">            Tensor of shape (batch, channel, weights, n_autocorrs, *, s) containing the</span>
<span class="sd">            autocorrelation (up to distance ``spatial_corr_width//2``) of each element</span>
<span class="sd">            in ``coeffs_list``, computed independently over all but the final two</span>
<span class="sd">            dimensions. ``n_autocorrs`` is the number of unique autocorrelation values,</span>
<span class="sd">            which is approximately sptial_corr_width^2 / 2.</span>
<span class="sd">        vars :</span>
<span class="sd">            Tensor of shape (batch, channel, weights, *, s) containing the variance of</span>
<span class="sd">            each element in ``coeffs_list``, computed independently over all but the</span>
<span class="sd">            final two dimensions.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">coeffs_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">5</span><span class="p">:</span>
            <span class="n">dims</span> <span class="o">=</span> <span class="s2">&quot;o&quot;</span>
            <span class="n">rolls_h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">autocorr_5d_rolls_h</span>
            <span class="n">rolls_w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">autocorr_5d_rolls_w</span>
        <span class="k">elif</span> <span class="n">coeffs_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
            <span class="n">dims</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
            <span class="n">rolls_h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">autocorr_4d_rolls_h</span>
            <span class="n">rolls_w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">autocorr_4d_rolls_w</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;coeffs_list must contain tensors of either 4 or 5 dimensions!&quot;</span>
            <span class="p">)</span>
        <span class="c1"># the WeightedAveragePyramid will insert the weight dimension after the channel.</span>
        <span class="n">autocorr_expr</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;b c </span><span class="si">{</span><span class="n">dims</span><span class="si">}</span><span class="s2"> h w, b c shift </span><span class="si">{</span><span class="n">dims</span><span class="si">}</span><span class="s2"> h w -&gt; b c shift </span><span class="si">{</span><span class="n">dims</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="n">acs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="nb">vars</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="c1"># iterate through scales</span>
        <span class="k">for</span> <span class="n">coeff</span><span class="p">,</span> <span class="n">rolls_h</span><span class="p">,</span> <span class="n">rolls_w</span><span class="p">,</span> <span class="n">scale_weight</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
            <span class="n">coeffs_list</span><span class="p">,</span> <span class="n">rolls_h</span><span class="p">,</span> <span class="n">rolls_w</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span>
        <span class="p">):</span>
            <span class="c1"># the following two lines are equivalent to having two for loops over</span>
            <span class="c1"># range(-spatial_corr_width//2, spatial_corr_width//2) and using roll along</span>
            <span class="c1"># the last two indices, but is much more efficient, especially on the gpu.</span>
            <span class="n">rolled_coeff</span> <span class="o">=</span> <span class="n">einops</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span>
                <span class="n">coeff</span><span class="p">,</span>
                <span class="sa">f</span><span class="s2">&quot;b c </span><span class="si">{</span><span class="n">dims</span><span class="si">}</span><span class="s2"> h w -&gt; b c shift </span><span class="si">{</span><span class="n">dims</span><span class="si">}</span><span class="s2"> h w&quot;</span><span class="p">,</span>
                <span class="n">shift</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_autocorrs</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">rolled_coeff</span> <span class="o">=</span> <span class="n">rolled_coeff</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="n">rolls_h</span><span class="p">)</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">rolls_w</span><span class="p">)</span>
            <span class="n">autocorr</span> <span class="o">=</span> <span class="n">scale_weight</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="n">autocorr_expr</span><span class="p">,</span> <span class="n">coeff</span><span class="p">,</span> <span class="n">rolled_coeff</span><span class="p">)</span>
            <span class="c1"># this returns a view of autocorr that just selects out the variance, while</span>
            <span class="c1"># preserving the number of dims. we have specifically placed the (0, 0)</span>
            <span class="c1"># shift, which corresponds to the variance, as the last element. This is the</span>
            <span class="c1"># third dim, because we have inserted the weight dimensiona after the</span>
            <span class="c1"># channel.</span>
            <span class="n">var</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">narrow</span><span class="p">(</span><span class="n">autocorr</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="c1"># and then drop the variance from here</span>
            <span class="n">acs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">narrow</span><span class="p">(</span><span class="n">autocorr</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_autocorrs</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">var</span> <span class="o">+</span> <span class="n">epsilon</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="nb">vars</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">var</span><span class="p">)</span>
        <span class="n">acs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">acs</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="nb">vars</span> <span class="o">=</span> <span class="n">einops</span><span class="o">.</span><span class="n">rearrange</span><span class="p">(</span>
            <span class="nb">vars</span><span class="p">,</span>
            <span class="c1"># for vars, shift is always 1, so we&#39;re really just</span>
            <span class="c1"># squeezing it out here</span>
            <span class="sa">f</span><span class="s2">&quot;scales b c w shift </span><span class="si">{</span><span class="n">dims</span><span class="si">}</span><span class="s2"> -&gt; b c (w shift) </span><span class="si">{</span><span class="n">dims</span><span class="si">}</span><span class="s2"> scales&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">acs</span><span class="p">,</span> <span class="nb">vars</span>

    <span class="k">def</span> <span class="nf">compute_skew_kurtosis_recon</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">reconstructed_images</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Tensor</span><span class="p">],</span>
        <span class="n">var_recon</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">img_var</span><span class="p">:</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">epsilon</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-6</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute the skew and kurtosis of each lowpass reconstructed image.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        reconstructed_images :</span>
<span class="sd">            List of length n_scales+1 containing the reconstructed unoriented</span>
<span class="sd">            image at each scale, from fine to coarse. The final image is</span>
<span class="sd">            reconstructed just from the residual lowpass image.</span>
<span class="sd">        var_recon :</span>
<span class="sd">            Tensor of shape (batch, channel, weights, n_scales+1) containing the</span>
<span class="sd">            variance of each tensor in reconstruced_images</span>
<span class="sd">        epsilon :</span>
<span class="sd">            Epsilon value to use in the denominator when normalizing the</span>
<span class="sd">            skew and kurtosis, to prevent them from blowing up.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        skew_recon, kurtosis_recon :</span>
<span class="sd">            Tensors of shape (batch, channel, weights, n_scales+1) containing the skew</span>
<span class="sd">            and kurtosis, respectively, of each tensor in</span>
<span class="sd">            ``reconstructed_images``.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">skew_recon</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">([</span><span class="n">img</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span> <span class="k">for</span> <span class="n">img</span> <span class="ow">in</span> <span class="n">reconstructed_images</span><span class="p">])</span>
        <span class="n">kurtosis_recon</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">([</span><span class="n">img</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span> <span class="k">for</span> <span class="n">img</span> <span class="ow">in</span> <span class="n">reconstructed_images</span><span class="p">])</span>
        <span class="n">skew_recon</span> <span class="o">=</span> <span class="n">skew_recon</span> <span class="o">/</span> <span class="p">(</span><span class="n">var_recon</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mf">1.5</span><span class="p">)</span> <span class="o">+</span> <span class="n">epsilon</span><span class="p">)</span>
        <span class="n">kurtosis_recon</span> <span class="o">=</span> <span class="n">kurtosis_recon</span> <span class="o">/</span> <span class="p">(</span><span class="n">var_recon</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">epsilon</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">skew_recon</span><span class="p">,</span> <span class="n">kurtosis_recon</span>

    <span class="k">def</span> <span class="nf">compute_cross_correlation</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">coeffs_tensor</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Tensor</span><span class="p">],</span>
        <span class="n">coeffs_tensor_other</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Tensor</span><span class="p">],</span>
        <span class="n">coeffs_var</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">coeffs_other_var</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">epsilon</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-6</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute cross-correlations.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        coeffs_tensor, coeffs_tensor_other :</span>
<span class="sd">            The two lists of length scales, each containing 5d tensors of shape</span>
<span class="sd">            (batch, channel, n_orientations, height, width) to be correlated.</span>
<span class="sd">        coeffs_var, coeffs_other_var :</span>
<span class="sd">            Two optional tensors containing the variances of coeffs_tensor and</span>
<span class="sd">            coeffs_tensor_other, respectively, in case they&#39;ve already been computed.</span>
<span class="sd">            Should be of shape (batch, channel, *weights, n_orientations, n_scales). Note</span>
<span class="sd">            that by *weights, we indicate that the dimensions should not be combined, so</span>
<span class="sd">            that if ``len(weights)==2``, *weights would hold two dimensions. Used to</span>
<span class="sd">            normalize the covariances into cross-correlations. Intended use is the</span>
<span class="sd">            output of ``compute_autocorr``.</span>
<span class="sd">        epsilon :</span>
<span class="sd">            Epsilon value to use in the denominator when normalizing the</span>
<span class="sd">            correlations, to prevent them from blowing up.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        cross_corrs :</span>
<span class="sd">            Tensor of shape (batch, channel, weights, n_orientations, n_orientations,</span>
<span class="sd">            scales) containing the cross-correlations at each scale.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># these two get handled by the weights pyramid, which will insert the weights and</span>
        <span class="c1"># scales dimensions.</span>
        <span class="n">covar_expr</span> <span class="o">=</span> <span class="s2">&quot; b c o1 h w, b c o2 h w -&gt; b c o1 o2&quot;</span>
        <span class="n">var_expr</span> <span class="o">=</span> <span class="s2">&quot;b c o1 h w, b c o1 h w -&gt; b c o1&quot;</span>
        <span class="c1"># this one does not (because it&#39;s computed using the weighted variances), and so</span>
        <span class="c1"># we need to add the weights and scale dimensions ourselves</span>
        <span class="n">outer_prod_expr</span> <span class="o">=</span> <span class="s2">&quot;b c w o1 s, b c w o2 s -&gt; b c w o1 o2 s&quot;</span>
        <span class="c1"># compute the covariance</span>
        <span class="n">covars</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="n">covar_expr</span><span class="p">,</span> <span class="n">coeffs_tensor</span><span class="p">,</span> <span class="n">coeffs_tensor_other</span><span class="p">)</span>
        <span class="c1"># Then normalize it to get the Pearson product-moment correlation</span>
        <span class="c1"># coefficient, see</span>
        <span class="c1"># https://numpy.org/doc/stable/reference/generated/numpy.corrcoef.html.</span>
        <span class="k">if</span> <span class="n">coeffs_var</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">coeffs_var</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="n">var_expr</span><span class="p">,</span> <span class="n">coeffs_tensor</span><span class="p">,</span> <span class="n">coeffs_tensor</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">coeffs_other_var</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">coeffs_other_var</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span>
                <span class="n">var_expr</span><span class="p">,</span> <span class="n">coeffs_tensor_other</span><span class="p">,</span> <span class="n">coeffs_tensor_other</span>
            <span class="p">)</span>
        <span class="c1"># once we have the variances of each coefficient, we compute the outer product</span>
        <span class="c1"># of those variances.</span>
        <span class="n">var_outer_prod</span> <span class="o">=</span> <span class="n">einops</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="n">coeffs_var</span><span class="p">,</span> <span class="n">coeffs_other_var</span><span class="p">,</span> <span class="n">outer_prod_expr</span><span class="p">)</span>
        <span class="c1"># And the sqrt of this is what we use to normalize the covariance</span>
        <span class="c1"># into the cross-correlation</span>
        <span class="n">std_outer_prod</span> <span class="o">=</span> <span class="p">(</span><span class="n">var_outer_prod</span> <span class="o">+</span> <span class="n">epsilon</span><span class="p">)</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">covars</span> <span class="o">/</span> <span class="p">(</span><span class="n">std_outer_prod</span> <span class="o">+</span> <span class="n">epsilon</span><span class="p">)</span>


<div class="viewcode-block" id="PortillaSimoncelli">
<a class="viewcode-back" href="../../../../api/plenoptic.simulate.models.html#plenoptic.simulate.models.portilla_simoncelli.PortillaSimoncelli">[docs]</a>
<span class="k">class</span> <span class="nc">PortillaSimoncelli</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Portila-Simoncelli texture statistics.</span>

<span class="sd">    The Portilla-Simoncelli (PS) texture statistics are a set of image</span>
<span class="sd">    statistics, first described in [1]_, that are proposed as a sufficient set</span>
<span class="sd">    of measurements for describing visual textures. That is, if two texture</span>
<span class="sd">    images have the same values for all PS texture stats, humans should</span>
<span class="sd">    consider them as members of the same family of textures.</span>

<span class="sd">    The PS stats are computed based on the steerable pyramid [2]_. They consist</span>
<span class="sd">    of the local auto-correlations, cross-scale (within-orientation)</span>
<span class="sd">    correlations, and cross-orientation (within-scale) correlations of both the</span>
<span class="sd">    pyramid coefficients and the local energy (as computed by those</span>
<span class="sd">    coefficients). Additionally, they include the first four global moments</span>
<span class="sd">    (mean, variance, skew, and kurtosis) of the image and down-sampled versions</span>
<span class="sd">    of that image. See the paper and notebook for more description.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    image_shape:</span>
<span class="sd">        Shape of input image.</span>
<span class="sd">    n_scales:</span>
<span class="sd">        The number of pyramid scales used to measure the statistics (default=4)</span>
<span class="sd">    n_orientations:</span>
<span class="sd">        The number of orientations used to measure the statistics (default=4)</span>
<span class="sd">    spatial_corr_width:</span>
<span class="sd">        The width of the spatial cross- and auto-correlation statistics</span>
<span class="sd">    weights:</span>
<span class="sd">        List of one or two 3d tensors to use as weighting regions. If None, we average</span>
<span class="sd">        texture stats over whole image. Else, we use these tensors as weights to perform</span>
<span class="sd">        weighted averages of texture stats in regions across the image. See tutorial for</span>
<span class="sd">        more details.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    scales: list</span>
<span class="sd">        The names of the unique scales of coefficients in the pyramid, used for</span>
<span class="sd">        coarse-to-fine metamer synthesis.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] J Portilla and E P Simoncelli. A Parametric Texture Model based on</span>
<span class="sd">       Joint Statistics of Complex Wavelet Coefficients. Int&#39;l Journal of</span>
<span class="sd">       Computer Vision. 40(1):49-71, October, 2000.</span>
<span class="sd">       https://www.cns.nyu.edu/~eero/ABSTRACTS/portilla99-abstract.html</span>
<span class="sd">       https://www.cns.nyu.edu/~lcv/texture/</span>
<span class="sd">    .. [2] E P Simoncelli and W T Freeman, &quot;The Steerable Pyramid: A Flexible</span>
<span class="sd">       Architecture for Multi-Scale Derivative Computation,&quot; Second Int&#39;l Conf</span>
<span class="sd">       on Image Processing, Washington, DC, Oct 1995.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">image_shape</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span>
        <span class="n">n_scales</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
        <span class="n">n_orientations</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
        <span class="n">spatial_corr_width</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">9</span><span class="p">,</span>
        <span class="n">weights</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">image_shape</span> <span class="o">=</span> <span class="n">image_shape</span>
        <span class="k">if</span> <span class="nb">any</span><span class="p">([(</span><span class="n">image_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="mi">2</span><span class="o">**</span><span class="n">i</span><span class="p">)</span> <span class="o">%</span> <span class="mi">2</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_scales</span><span class="p">)])</span> <span class="ow">or</span> <span class="nb">any</span><span class="p">(</span>
            <span class="p">[(</span><span class="n">image_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">/</span> <span class="mi">2</span><span class="o">**</span><span class="n">i</span><span class="p">)</span> <span class="o">%</span> <span class="mi">2</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_scales</span><span class="p">)]</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Because of how the Portilla-Simoncelli model handles &quot;</span>
                <span class="s2">&quot;multiscale representations, it only works with images&quot;</span>
                <span class="s2">&quot; whose shape can be divided by 2 `n_scales` times.&quot;</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">spatial_corr_width</span> <span class="o">=</span> <span class="n">spatial_corr_width</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span> <span class="o">=</span> <span class="n">n_scales</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_orientations</span> <span class="o">=</span> <span class="n">n_orientations</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_pyr</span> <span class="o">=</span> <span class="n">SteerablePyramidFreq</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">image_shape</span><span class="p">,</span>
            <span class="n">height</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span><span class="p">,</span>
            <span class="n">order</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_orientations</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span>
            <span class="n">is_complex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">tight_frame</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">scales</span> <span class="o">=</span> <span class="p">(</span>
            <span class="p">[</span><span class="s2">&quot;pixel_statistics&quot;</span><span class="p">,</span> <span class="s2">&quot;residual_lowpass&quot;</span><span class="p">]</span>
            <span class="o">+</span> <span class="p">[</span><span class="n">ii</span> <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_scales</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)]</span>
            <span class="o">+</span> <span class="p">[</span><span class="s2">&quot;residual_highpass&quot;</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="n">autocorr_shifts</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_autocorr_shifts</span><span class="p">(</span><span class="n">spatial_corr_width</span><span class="p">)</span>
        <span class="n">autocorr_masks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_autocorr_mask</span><span class="p">()</span>
        <span class="c1"># this gives the indices of all non-redundant autocorrelations, including (0,</span>
        <span class="c1"># 0), which is the variance, and so we substract one.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_n_autocorrs</span> <span class="o">=</span> <span class="n">autocorr_shifts</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">weights</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_stats_computer</span> <span class="o">=</span> <span class="n">_StatsComputer</span><span class="p">(</span><span class="n">autocorr_masks</span><span class="p">,</span> <span class="n">spatial_corr_width</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">weights</span> <span class="o">=</span> <span class="n">WeightedAveragePyramid</span><span class="p">(</span><span class="o">*</span><span class="n">weights</span><span class="p">,</span> <span class="n">n_scales</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_stats_computer</span> <span class="o">=</span> <span class="n">_WeightedComputer</span><span class="p">(</span>
                <span class="n">weights</span><span class="p">,</span> <span class="n">autocorr_shifts</span><span class="p">,</span> <span class="n">n_scales</span><span class="p">,</span> <span class="n">n_orientations</span>
            <span class="p">)</span>

        <span class="c1"># Dictionary defining shape of the statistics and which scale they&#39;re</span>
        <span class="c1"># associated with</span>
        <span class="n">scales_shape_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_scales_shape_dict</span><span class="p">()</span>

        <span class="c1"># Dictionary defining necessary statistics, that is, those that are not</span>
        <span class="c1"># redundant</span>
        <span class="n">necessary_stats_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_necessary_stats_dict</span><span class="p">(</span><span class="n">scales_shape_dict</span><span class="p">)</span>
        <span class="c1"># turn this into tensor we can use in forward pass. first into a</span>
        <span class="c1"># boolean mask...</span>
        <span class="n">_necessary_stats_mask</span> <span class="o">=</span> <span class="n">einops</span><span class="o">.</span><span class="n">pack</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">necessary_stats_dict</span><span class="o">.</span><span class="n">values</span><span class="p">()),</span> <span class="s2">&quot;*&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="c1"># then into a tensor of indices</span>
        <span class="n">_necessary_stats_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">_necessary_stats_mask</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;_necessary_stats_mask&quot;</span><span class="p">,</span> <span class="n">_necessary_stats_mask</span><span class="p">)</span>

        <span class="c1"># This array is composed of the following values: &#39;pixel_statistics&#39;,</span>
        <span class="c1"># &#39;residual_lowpass&#39;, &#39;residual_highpass&#39; and integer values from 0 to</span>
        <span class="c1"># self.n_scales-1. It is the same size as the representation tensor</span>
        <span class="c1"># returned by this object&#39;s forward method. It must be a numpy array so</span>
        <span class="c1"># we can have a mixture of ints and strs (and so we can use np.in1d</span>
        <span class="c1"># later)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_representation_scales</span> <span class="o">=</span> <span class="n">einops</span><span class="o">.</span><span class="n">pack</span><span class="p">(</span>
            <span class="nb">list</span><span class="p">(</span><span class="n">scales_shape_dict</span><span class="o">.</span><span class="n">values</span><span class="p">()),</span> <span class="s2">&quot;*&quot;</span>
        <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="c1"># just select the scales of the necessary stats.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_representation_scales</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_representation_scales</span><span class="p">[</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_necessary_stats_mask</span>
        <span class="p">]</span>
        <span class="c1"># we store this information in order to convert the vector form back to the</span>
        <span class="c1"># dictionary.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_stats_shape_dict</span> <span class="o">=</span> <span class="n">necessary_stats_dict</span>
        <span class="c1"># and if we&#39;re looking at in the dictionary, we want the &quot;unfolded&quot; form for the</span>
        <span class="c1"># autocorrs, which have shape (spatial_corr_width, spatial_corr_width, ...),</span>
        <span class="c1"># including NaNs, rather than just (n_autocorrs, ...), without NaNs.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_stats_shape_dict</span><span class="p">[</span><span class="s2">&quot;auto_correlation_reconstructed&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">autocorr_masks</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_stats_shape_dict</span><span class="p">[</span><span class="s2">&quot;auto_correlation_magnitude&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">autocorr_masks</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_compute_autocorr_shifts</span><span class="p">(</span><span class="n">spatial_corr_width</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">NDArray</span><span class="p">,</span> <span class="n">NDArray</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot; &quot;&quot;&quot;</span>
        <span class="c1"># because of the symmetry of autocorrelation, in order to generate all</span>
        <span class="c1"># autocorrelations, we only need the lower triangle (so that we take the</span>
        <span class="c1"># autocorrelation between the image and itself shifted 1 pixel to the left, but</span>
        <span class="c1"># not also shifted 1 pixel to the right)...</span>
        <span class="n">half_width</span> <span class="o">=</span> <span class="p">(</span><span class="n">spatial_corr_width</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span>
        <span class="n">autocorr_shift_vals</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">i</span> <span class="o">-</span> <span class="n">half_width</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">tril_indices</span><span class="p">(</span><span class="n">spatial_corr_width</span><span class="p">)</span>
        <span class="p">]</span>
        <span class="c1"># if spatial_corr_width is even, then we also need these shifts:</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">mod</span><span class="p">(</span><span class="n">spatial_corr_width</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">autocorr_shift_vals</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span>
                <span class="p">[</span>
                    <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">spatial_corr_width</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span> <span class="o">-</span> <span class="n">half_width</span><span class="p">,</span>
                    <span class="n">autocorr_shift_vals</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                <span class="p">],</span>
                <span class="mi">0</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">autocorr_shift_vals</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span>
                <span class="p">[</span>
                    <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">spatial_corr_width</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span> <span class="o">-</span> <span class="n">half_width</span><span class="p">,</span>
                    <span class="n">autocorr_shift_vals</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                <span class="p">],</span>
                <span class="mi">0</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="c1"># and up to the central element on the diagonal.</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="o">!=</span> <span class="n">j</span> <span class="ow">or</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">autocorr_shift_vals</span><span class="p">)]</span>
        <span class="c1"># put the (0, 0) shift, which corresponds to the variance, at the very end, so</span>
        <span class="c1"># we know where it is</span>
        <span class="k">return</span> <span class="p">[</span>
            <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">i</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)],</span> <span class="mi">0</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">autocorr_shift_vals</span>
        <span class="p">]</span>

    <span class="k">def</span> <span class="nf">_compute_autocorr_mask</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute the boolean mask for necessary autocorrelation stats.&quot;&quot;&quot;</span>
        <span class="c1"># Pre-compute some necessary indices.</span>
        <span class="c1"># Lower triangular indices (including diagonal), for auto correlations</span>
        <span class="n">tril_inds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tril_indices</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">spatial_corr_width</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">spatial_corr_width</span><span class="p">)</span>
        <span class="c1"># Get the second half of the diagonal, i.e., everything from the center</span>
        <span class="c1"># element on. These are all repeated for the auto correlations. (As</span>
        <span class="c1"># these are autocorrelations (rather than auto-covariance) matrices,</span>
        <span class="c1"># they&#39;ve been normalized by the variance and so the center element is</span>
        <span class="c1"># always 1, and thus uninformative)</span>
        <span class="n">diag_repeated</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span>
            <span class="n">start</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">spatial_corr_width</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">spatial_corr_width</span>
        <span class="p">)</span>
        <span class="c1"># masks for the reconstructed_lowpass and magnitude autocorrs, respectively</span>
        <span class="n">masks</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">spatial_corr_width</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">spatial_corr_width</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span>
                <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span>
            <span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                <span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">spatial_corr_width</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">spatial_corr_width</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">n_orientations</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span><span class="p">,</span>
                <span class="p">),</span>
                <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span>
            <span class="p">),</span>
        <span class="p">]</span>
        <span class="k">for</span> <span class="n">mask</span> <span class="ow">in</span> <span class="n">masks</span><span class="p">:</span>
            <span class="c1"># Symmetry M_{i,j} = M_{n-i+1, n-j+1}</span>
            <span class="c1"># Start with all False, then place True in necessary stats.</span>
            <span class="n">mask</span><span class="p">[</span><span class="n">tril_inds</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">tril_inds</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="c1"># if spatial_corr_width is even, then the first row is not</span>
            <span class="c1"># redundant with anything either</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">mod</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">spatial_corr_width</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">mask</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">mask</span><span class="p">[</span><span class="n">diag_repeated</span><span class="p">,</span> <span class="n">diag_repeated</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">return</span> <span class="n">masks</span>

    <span class="k">def</span> <span class="nf">_create_scales_shape_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">OrderedDict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create dictionary defining scales and shape of each stat.</span>

<span class="sd">        This dictionary functions as metadata which is used for two main</span>
<span class="sd">        purposes:</span>

<span class="sd">        - Scale assignment. In order for optimization to work well, we proceed</span>
<span class="sd">          in a &quot;coarse-to-fine&quot; manner. That is, we start optimization by only</span>
<span class="sd">          considering the statistics related to the lowest frequencies, and</span>
<span class="sd">          gradually add in those related to higher and higher frequencies. This</span>
<span class="sd">          is similar to blurring the objective function and then gradually</span>
<span class="sd">          adding in finer and finer details. The numbers in this dictionary map</span>
<span class="sd">          the computed statistics to their corresponding scales, which we use</span>
<span class="sd">          in remove_scales to throw away some stats as needed.</span>

<span class="sd">        - Redundant stat identification. As described at the bottom of the</span>
<span class="sd">          notebook, the model incidentally computes a whole bunch of redundant</span>
<span class="sd">          stats, because auto- and cross-correlation matrices have certain</span>
<span class="sd">          symmetries. the _create_necessary_stats_dict method accepts the</span>
<span class="sd">          dictionary created here as input and uses the values to get the</span>
<span class="sd">          shapes of these and insert True/False as necessary.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        scales_shape_dict</span>
<span class="sd">           Dictionary defining shape and associated scales of each computed</span>
<span class="sd">           statistic. The keys name each statistic, with dummy arrays as</span>
<span class="sd">           values. These arrays have the same shape as the stat (excluding</span>
<span class="sd">           batch and channel), with values defining which scale they correspond</span>
<span class="sd">           to.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">shape_dict</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
        <span class="c1"># There are 6 pixel statistics</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_stats_computer</span><span class="p">,</span> <span class="n">_StatsComputer</span><span class="p">):</span>
            <span class="n">shape_dict</span><span class="p">[</span><span class="s2">&quot;pixel_statistics&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="mi">6</span> <span class="o">*</span> <span class="p">[</span><span class="s2">&quot;pixel_statistics&quot;</span><span class="p">])</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_stats_computer</span><span class="p">,</span> <span class="n">_WeightedComputer</span><span class="p">):</span>
            <span class="n">shape_dict</span><span class="p">[</span><span class="s2">&quot;pixel_statistics&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="mi">4</span> <span class="o">*</span> <span class="p">[</span><span class="s2">&quot;pixel_statistics&quot;</span><span class="p">])</span>

        <span class="c1"># These are the basic building blocks of the scale assignments for many</span>
        <span class="c1"># of the statistics calculated by the PortillaSimoncelli model.</span>
        <span class="n">scales</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span><span class="p">)</span>
        <span class="c1"># the cross-scale correlations exclude the coarsest scale</span>
        <span class="n">scales_without_coarsest</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="c1"># the statistics computed on the reconstructed bandpass images have an</span>
        <span class="c1"># extra scale corresponding to the lowpass residual</span>
        <span class="n">scales_with_lowpass</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
            <span class="n">scales</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="o">+</span> <span class="p">[</span><span class="s2">&quot;residual_lowpass&quot;</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">object</span>
        <span class="p">)</span>

        <span class="c1"># now we go through each statistic in order and create a dummy array</span>
        <span class="c1"># full of 1s with the same shape as the actual statistic (excluding the</span>
        <span class="c1"># batch and channel dimensions, as each stat is computed independently</span>
        <span class="c1"># across those dimensions). We then multiply it by one of the scales</span>
        <span class="c1"># arrays above to turn those 1s into values describing the</span>
        <span class="c1"># corresponding scale.</span>

        <span class="n">auto_corr_mag</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span>
            <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_autocorrs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_orientations</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span><span class="p">),</span>
            <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1"># this rearrange call is turning scales from 1d with shape (n_scales, )</span>
        <span class="c1"># to 3d with shape (1, 1, n_scales), so that it matches</span>
        <span class="c1"># auto_corr_mag. the following rearrange calls do similar.</span>
        <span class="n">auto_corr_mag</span> <span class="o">*=</span> <span class="n">einops</span><span class="o">.</span><span class="n">rearrange</span><span class="p">(</span><span class="n">scales</span><span class="p">,</span> <span class="s2">&quot;s -&gt; 1 1 s&quot;</span><span class="p">)</span>
        <span class="n">shape_dict</span><span class="p">[</span><span class="s2">&quot;auto_correlation_magnitude&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">auto_corr_mag</span>

        <span class="n">shape_dict</span><span class="p">[</span><span class="s2">&quot;skew_reconstructed&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">scales_with_lowpass</span>

        <span class="n">shape_dict</span><span class="p">[</span><span class="s2">&quot;kurtosis_reconstructed&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">scales_with_lowpass</span>

        <span class="n">auto_corr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span>
            <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_n_autocorrs</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
            <span class="p">),</span>
            <span class="n">dtype</span><span class="o">=</span><span class="nb">object</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">auto_corr</span> <span class="o">*=</span> <span class="n">einops</span><span class="o">.</span><span class="n">rearrange</span><span class="p">(</span><span class="n">scales_with_lowpass</span><span class="p">,</span> <span class="s2">&quot;s -&gt; 1 s&quot;</span><span class="p">)</span>
        <span class="n">shape_dict</span><span class="p">[</span><span class="s2">&quot;auto_correlation_reconstructed&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">auto_corr</span>

        <span class="n">shape_dict</span><span class="p">[</span><span class="s2">&quot;std_reconstructed&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">scales_with_lowpass</span>

        <span class="n">cross_orientation_corr_mag</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span>
            <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_orientations</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_orientations</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span><span class="p">),</span>
            <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">cross_orientation_corr_mag</span> <span class="o">*=</span> <span class="n">einops</span><span class="o">.</span><span class="n">rearrange</span><span class="p">(</span><span class="n">scales</span><span class="p">,</span> <span class="s2">&quot;s -&gt; 1 1 s&quot;</span><span class="p">)</span>
        <span class="n">shape_dict</span><span class="p">[</span><span class="s2">&quot;cross_orientation_correlation_magnitude&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">cross_orientation_corr_mag</span>
        <span class="p">)</span>

        <span class="n">mags_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">n_orientations</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
        <span class="n">mags_std</span> <span class="o">*=</span> <span class="n">einops</span><span class="o">.</span><span class="n">rearrange</span><span class="p">(</span><span class="n">scales</span><span class="p">,</span> <span class="s2">&quot;s -&gt; 1 s&quot;</span><span class="p">)</span>
        <span class="n">shape_dict</span><span class="p">[</span><span class="s2">&quot;magnitude_std&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">mags_std</span>

        <span class="n">cross_scale_corr_mag</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span>
            <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_orientations</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_orientations</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">cross_scale_corr_mag</span> <span class="o">*=</span> <span class="n">einops</span><span class="o">.</span><span class="n">rearrange</span><span class="p">(</span><span class="n">scales_without_coarsest</span><span class="p">,</span> <span class="s2">&quot;s -&gt; 1 1 s&quot;</span><span class="p">)</span>
        <span class="n">shape_dict</span><span class="p">[</span><span class="s2">&quot;cross_scale_correlation_magnitude&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">cross_scale_corr_mag</span>

        <span class="n">cross_scale_corr_real</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span>
            <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_orientations</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_orientations</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">cross_scale_corr_real</span> <span class="o">*=</span> <span class="n">einops</span><span class="o">.</span><span class="n">rearrange</span><span class="p">(</span><span class="n">scales_without_coarsest</span><span class="p">,</span> <span class="s2">&quot;s -&gt; 1 1 s&quot;</span><span class="p">)</span>
        <span class="n">shape_dict</span><span class="p">[</span><span class="s2">&quot;cross_scale_correlation_real&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">cross_scale_corr_real</span>

        <span class="n">shape_dict</span><span class="p">[</span><span class="s2">&quot;var_highpass_residual&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="s2">&quot;residual_highpass&quot;</span><span class="p">])</span>

        <span class="k">return</span> <span class="n">shape_dict</span>

    <span class="k">def</span> <span class="nf">_create_necessary_stats_dict</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">scales_shape_dict</span><span class="p">:</span> <span class="n">OrderedDict</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">OrderedDict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create mask specifying the necessary statistics.</span>

<span class="sd">        Some of the statistics computed by the model are redundant, due to</span>
<span class="sd">        symmetries. For example, about half of the values in the</span>
<span class="sd">        autocorrelation matrices are duplicates. See the Portilla-Simoncelli</span>
<span class="sd">        notebook for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        scales_shape_dict</span>
<span class="sd">            Dictionary defining shape and associated scales of each computed</span>
<span class="sd">            statistic.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        necessary_stats_dict</span>
<span class="sd">            Dictionary defining which statistics are necessary (i.e., not</span>
<span class="sd">            redundant). Will have the same keys as scales_shape_dict, with the</span>
<span class="sd">            values being boolean tensors of the same shape as</span>
<span class="sd">            scales_shape_dict&#39;s corresponding values. True denotes the</span>
<span class="sd">            statistics that will be included in the model&#39;s output, while False</span>
<span class="sd">            denotes the redundant ones we will toss.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">mask_dict</span> <span class="o">=</span> <span class="n">scales_shape_dict</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="c1"># Upper triangle indices, including diagonal. These are redundant stats</span>
        <span class="c1"># for cross_orientation_correlation_magnitude (because we&#39;ve normalized</span>
        <span class="c1"># this matrix to be true cross-correlations, the diagonals are all 1,</span>
        <span class="c1"># like for the auto-correlations)</span>
        <span class="n">triu_inds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">triu_indices</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_orientations</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_orientations</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">mask_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">k</span> <span class="o">==</span> <span class="s2">&quot;cross_orientation_correlation_magnitude&quot;</span><span class="p">:</span>
                <span class="c1"># Symmetry M_{i,j} = M_{j,i}.</span>
                <span class="c1"># Start with all True, then place False in redundant stats.</span>
                <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
                <span class="n">mask</span><span class="p">[</span><span class="n">triu_inds</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">triu_inds</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># all of the other stats have no redundancies</span>
                <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
            <span class="n">mask_dict</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">mask</span>
        <span class="k">return</span> <span class="n">mask_dict</span>

<div class="viewcode-block" id="PortillaSimoncelli.forward">
<a class="viewcode-back" href="../../../../api/plenoptic.simulate.models.html#plenoptic.simulate.models.portilla_simoncelli.PortillaSimoncelli.forward">[docs]</a>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">scales</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">SCALES_TYPE</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Generate Texture Statistics representation of an image.</span>

<span class="sd">        Note that separate batches and channels are analyzed in parallel.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        image :</span>
<span class="sd">            A 4d tensor (batch, channel, height, width) containing the image(s) to</span>
<span class="sd">            analyze.</span>
<span class="sd">        scales :</span>
<span class="sd">            Which scales to include in the returned representation. If None, we</span>
<span class="sd">            include all scales. Otherwise, can contain subset of values present</span>
<span class="sd">            in this model&#39;s ``scales`` attribute, and the returned tensor will</span>
<span class="sd">            then contain the subset corresponding to those scales.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        representation_tensor:</span>
<span class="sd">            3d tensor of shape (batch, channel, stats) containing the measured</span>
<span class="sd">            texture statistics.</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError :</span>
<span class="sd">            If `image` is not 4d or has a dtype other than float or complex.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">validate_input</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

        <span class="c1"># pyr_dict is the dictionary of complex-valued tensors returned by the</span>
        <span class="c1"># steerable pyramid. pyr_coeffs is a list (length n_scales) of 5d</span>
        <span class="c1"># tensors, each of shape (batch, channel, scales, n_orientations,</span>
        <span class="c1"># height, width) containing the complex-valued oriented bands, while</span>
        <span class="c1"># highpass is a real-valued 4d tensor of shape (batch, channel, height,</span>
        <span class="c1"># width). Note that the residual lowpass in pyr_dict has been demeaned.</span>
        <span class="c1"># We keep both the dict and list of pyramid coefficients because we</span>
        <span class="c1"># need the dictionary for reconstructing the image done later on.</span>
        <span class="n">pyr_dict</span><span class="p">,</span> <span class="n">pyr_coeffs</span><span class="p">,</span> <span class="n">highpass</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_pyr_coeffs</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

        <span class="c1"># Now, we create several intermediate representations that we&#39;ll use to</span>
        <span class="c1"># compute the texture statistics later.</span>

        <span class="c1"># First, two intermediate dictionaries: magnitude_pyr_coeffs and</span>
        <span class="c1"># real_pyr_coeffs, which contain the demeaned magnitude of the pyramid</span>
        <span class="c1"># coefficients and the real part of the pyramid coefficients</span>
        <span class="c1"># respectively.</span>
        <span class="p">(</span>
            <span class="n">mag_pyr_coeffs</span><span class="p">,</span>
            <span class="n">real_pyr_coeffs</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_intermediate_representations</span><span class="p">(</span><span class="n">pyr_coeffs</span><span class="p">)</span>

        <span class="c1"># Then, the reconstructed lowpass image at each scale. (this is a list</span>
        <span class="c1"># of length n_scales+1 containing tensors of shape (batch, channel,</span>
        <span class="c1"># height, width))</span>
        <span class="n">reconstructed_images</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_reconstruct_lowpass_at_each_scale</span><span class="p">(</span><span class="n">pyr_dict</span><span class="p">)</span>
        <span class="c1"># the reconstructed_images list goes from coarse-to-fine, but we want</span>
        <span class="c1"># each of the stats computed from it to go from fine-to-coarse, so we</span>
        <span class="c1"># reverse its direction.</span>
        <span class="n">reconstructed_images</span> <span class="o">=</span> <span class="n">reconstructed_images</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="c1"># Now, start calculating the PS texture stats.</span>

        <span class="c1"># Calculate pixel statistics (mean, variance, skew, kurtosis, min,</span>
        <span class="c1"># max).</span>
        <span class="n">pixel_stats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stats_computer</span><span class="o">.</span><span class="n">compute_pixel_stats</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

        <span class="c1"># Compute the central autocorrelation of the coefficient magnitudes. This is a</span>
        <span class="c1"># tensor of shape: (batch, channel, spatial_corr_width, spatial_corr_width,</span>
        <span class="c1"># n_orientations, n_scales).</span>
        <span class="n">autocorr_mags</span><span class="p">,</span> <span class="n">mags_var</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stats_computer</span><span class="o">.</span><span class="n">compute_autocorr</span><span class="p">(</span><span class="n">mag_pyr_coeffs</span><span class="p">)</span>
        <span class="c1"># mags_var is the variance of the magnitude coefficients at each scale (it&#39;s an</span>
        <span class="c1"># intermediary of the computation of the auto-correlations). We take the square</span>
        <span class="c1"># root to get the standard deviation.</span>
        <span class="n">mags_std</span> <span class="o">=</span> <span class="n">mags_var</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>

        <span class="c1"># Compute the central autocorrelation of the reconstructed lowpass</span>
        <span class="c1"># images at each scale (and their variances). autocorr_recon is a</span>
        <span class="c1"># tensor of shape (batch, channel, spatial_corr_width,</span>
        <span class="c1"># spatial_corr_width, n_scales+1), and var_recon is a tensor of shape</span>
        <span class="c1"># (batch, channel, n_scales+1)</span>
        <span class="n">autocorr_recon</span><span class="p">,</span> <span class="n">var_recon</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stats_computer</span><span class="o">.</span><span class="n">compute_autocorr</span><span class="p">(</span>
            <span class="n">reconstructed_images</span>
        <span class="p">)</span>
        <span class="c1"># Compute the standard deviation, skew, and kurtosis of each</span>
        <span class="c1"># reconstructed lowpass image. std_recon, skew_recon, and</span>
        <span class="c1"># kurtosis_recon will all end up as tensors of shape (batch, channel,</span>
        <span class="c1"># n_scales+1)</span>
        <span class="n">std_recon</span> <span class="o">=</span> <span class="n">var_recon</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>
        <span class="n">skew_recon</span><span class="p">,</span> <span class="n">kurtosis_recon</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stats_computer</span><span class="o">.</span><span class="n">compute_skew_kurtosis_recon</span><span class="p">(</span>
            <span class="n">reconstructed_images</span><span class="p">,</span> <span class="n">var_recon</span><span class="p">,</span> <span class="n">pixel_stats</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
        <span class="p">)</span>

        <span class="c1"># Compute the cross-orientation correlations between the magnitude</span>
        <span class="c1"># coefficients at each scale. this will be a tensor of shape (batch,</span>
        <span class="c1"># channel, n_orientations, n_orientations, n_scales)</span>
        <span class="n">cross_ori_corr_mags</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stats_computer</span><span class="o">.</span><span class="n">compute_cross_correlation</span><span class="p">(</span>
            <span class="n">mag_pyr_coeffs</span><span class="p">,</span> <span class="n">mag_pyr_coeffs</span><span class="p">,</span> <span class="n">mags_var</span><span class="p">,</span> <span class="n">mags_var</span>
        <span class="p">)</span>

        <span class="c1"># If we have more than one scale, compute the cross-scale correlations</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># First, double the phase the coefficients, so we can correctly</span>
            <span class="c1"># compute correlations across scales.</span>
            <span class="p">(</span>
                <span class="n">phase_doubled_mags</span><span class="p">,</span>
                <span class="n">phase_doubled_sep</span><span class="p">,</span>
            <span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_double_phase_pyr_coeffs</span><span class="p">(</span><span class="n">pyr_coeffs</span><span class="p">)</span>
            <span class="c1"># Compute the cross-scale correlations between the magnitude</span>
            <span class="c1"># coefficients. For each coefficient, we&#39;re correlating it with the</span>
            <span class="c1"># coefficients at the next-coarsest scale. this will be a tensor of</span>
            <span class="c1"># shape (batch, channel, n_orientations, n_orientations,</span>
            <span class="c1"># n_scales-1)</span>
            <span class="n">cross_scale_corr_mags</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stats_computer</span><span class="o">.</span><span class="n">compute_cross_correlation</span><span class="p">(</span>
                <span class="n">mag_pyr_coeffs</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">phase_doubled_mags</span><span class="p">,</span> <span class="n">mags_var</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="p">)</span>
            <span class="c1"># Compute the cross-scale correlations between the real</span>
            <span class="c1"># coefficients and the real and imaginary coefficients at the next</span>
            <span class="c1"># coarsest scale. this will be a tensor of shape (batch, channel,</span>
            <span class="c1"># n_orientations, 2*n_orientations, n_scales-1)</span>
            <span class="n">cross_scale_corr_real</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stats_computer</span><span class="o">.</span><span class="n">compute_cross_correlation</span><span class="p">(</span>
                <span class="n">real_pyr_coeffs</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">phase_doubled_sep</span>
            <span class="p">)</span>

        <span class="c1"># Compute the variance of the highpass residual. the unsqueeze is to make sure</span>
        <span class="c1"># that this is at least 3d, as required when we call einops.pack below</span>
        <span class="n">var_highpass_residual</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stats_computer</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span>
            <span class="n">highpass</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
        <span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Now, combine all these stats together, first into a list</span>
        <span class="n">all_stats</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">pixel_stats</span><span class="p">,</span>
            <span class="n">autocorr_mags</span><span class="p">,</span>
            <span class="n">skew_recon</span><span class="p">,</span>
            <span class="n">kurtosis_recon</span><span class="p">,</span>
            <span class="n">autocorr_recon</span><span class="p">,</span>
            <span class="n">std_recon</span><span class="p">,</span>
            <span class="n">cross_ori_corr_mags</span><span class="p">,</span>
            <span class="n">mags_std</span><span class="p">,</span>
        <span class="p">]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">all_stats</span> <span class="o">+=</span> <span class="p">[</span><span class="n">cross_scale_corr_mags</span><span class="p">,</span> <span class="n">cross_scale_corr_real</span><span class="p">]</span>
        <span class="n">all_stats</span> <span class="o">+=</span> <span class="p">[</span><span class="n">var_highpass_residual</span><span class="p">]</span>
        <span class="c1"># And then pack them into a 3d tensor</span>
        <span class="n">representation_tensor</span><span class="p">,</span> <span class="n">pack_info</span> <span class="o">=</span> <span class="n">einops</span><span class="o">.</span><span class="n">pack</span><span class="p">(</span><span class="n">all_stats</span><span class="p">,</span> <span class="s2">&quot;b c w *&quot;</span><span class="p">)</span>

        <span class="c1"># the only time when this is None is during testing, when we make sure</span>
        <span class="c1"># that our assumptions are all valid.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_necessary_stats_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># store this so we can unpack this info (only possible when we&#39;ve</span>
            <span class="c1"># discarded no stats)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_pack_info</span> <span class="o">=</span> <span class="n">pack_info</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Throw away all redundant statistics</span>
            <span class="n">representation_tensor</span> <span class="o">=</span> <span class="n">representation_tensor</span><span class="o">.</span><span class="n">index_select</span><span class="p">(</span>
                <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_necessary_stats_mask</span>
            <span class="p">)</span>

        <span class="c1"># Return the subset of stats corresponding to the specified scale.</span>
        <span class="k">if</span> <span class="n">scales</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">representation_tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">remove_scales</span><span class="p">(</span><span class="n">representation_tensor</span><span class="p">,</span> <span class="n">scales</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">representation_tensor</span></div>


<div class="viewcode-block" id="PortillaSimoncelli.remove_scales">
<a class="viewcode-back" href="../../../../api/plenoptic.simulate.models.html#plenoptic.simulate.models.portilla_simoncelli.PortillaSimoncelli.remove_scales">[docs]</a>
    <span class="k">def</span> <span class="nf">remove_scales</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">representation_tensor</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">scales_to_keep</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">SCALES_TYPE</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Remove statistics not associated with scales.</span>

<span class="sd">        For a given representation_tensor and a list of scales_to_keep, this</span>
<span class="sd">        attribute removes all statistics *not* associated with those scales.</span>

<span class="sd">        Note that calling this method will always remove statistics.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        representation_tensor:</span>
<span class="sd">            3d tensor containing the measured representation statistics.</span>
<span class="sd">        scales_to_keep:</span>
<span class="sd">            Which scales to include in the returned representation. Can contain</span>
<span class="sd">            subset of values present in this model&#39;s ``scales`` attribute, and</span>
<span class="sd">            the returned tensor will then contain the subset of the full</span>
<span class="sd">            representation corresponding to those scales.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        limited_representation_tensor :</span>
<span class="sd">            Representation tensor with some statistics removed.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># this is necessary because object is the dtype of</span>
        <span class="c1"># self._representation_scales</span>
        <span class="n">scales_to_keep</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">scales_to_keep</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">object</span><span class="p">)</span>
        <span class="c1"># np.in1d returns a 1d boolean array of the same shape as</span>
        <span class="c1"># self._representation_scales with True at each location where that</span>
        <span class="c1"># value appears in scales_to_keep. where then converts this boolean</span>
        <span class="c1"># array into indices</span>
        <span class="n">ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">in1d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_representation_scales</span><span class="p">,</span> <span class="n">scales_to_keep</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">ind</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">ind</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">representation_tensor</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">representation_tensor</span><span class="o">.</span><span class="n">index_select</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">ind</span><span class="p">)</span></div>


<div class="viewcode-block" id="PortillaSimoncelli.convert_to_tensor">
<a class="viewcode-back" href="../../../../api/plenoptic.simulate.models.html#plenoptic.simulate.models.portilla_simoncelli.PortillaSimoncelli.convert_to_tensor">[docs]</a>
    <span class="k">def</span> <span class="nf">convert_to_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">representation_dict</span><span class="p">:</span> <span class="n">OrderedDict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Convert dictionary of statistics to a tensor.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        representation_dict :</span>
<span class="sd">             Dictionary of representation.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        3d tensor of statistics.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        convert_to_dict:</span>
<span class="sd">            Convert tensor representation to dictionary.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">rep</span> <span class="o">=</span> <span class="n">einops</span><span class="o">.</span><span class="n">pack</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">representation_dict</span><span class="o">.</span><span class="n">values</span><span class="p">()),</span> <span class="s2">&quot;b c *&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">rep</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_representation_scales</span><span class="p">):</span>
            <span class="n">mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_necessary_stats_mask</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">mask</span> <span class="o">=</span> <span class="n">einops</span><span class="o">.</span><span class="n">pack</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_stats_shape_dict</span><span class="o">.</span><span class="n">values</span><span class="p">()),</span> <span class="s2">&quot;*&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">mask</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">rep</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="c1"># then get rid of all the nans / unnecessary stats</span>
        <span class="k">return</span> <span class="n">rep</span><span class="o">.</span><span class="n">index_select</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span></div>


<div class="viewcode-block" id="PortillaSimoncelli.convert_to_dict">
<a class="viewcode-back" href="../../../../api/plenoptic.simulate.models.html#plenoptic.simulate.models.portilla_simoncelli.PortillaSimoncelli.convert_to_dict">[docs]</a>
    <span class="k">def</span> <span class="nf">convert_to_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">representation_tensor</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">OrderedDict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Convert tensor of statistics to a dictionary.</span>

<span class="sd">        While the tensor representation is required by plenoptic&#39;s synthesis</span>
<span class="sd">        objects, the dictionary representation is easier to manually inspect.</span>

<span class="sd">        This dictionary will contain NaNs in its values: these are placeholders</span>
<span class="sd">        for the redundant statistics.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        representation_tensor</span>
<span class="sd">            3d tensor of statistics.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        rep</span>
<span class="sd">            Dictionary of representation, with informative keys.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        convert_to_tensor:</span>
<span class="sd">            Convert dictionary representation to tensor.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">representation_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_representation_scales</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;representation tensor is the wrong length (expected&quot;</span>
                <span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_representation_scales</span><span class="p">)</span><span class="si">}</span><span class="s2"> but got&quot;</span>
                <span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="n">representation_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">)! Did you remove some of&quot;</span>
                <span class="s2">&quot; the scales? (i.e., by setting scales in the forward pass)?&quot;</span>
                <span class="s2">&quot; convert_to_dict does not support such tensors.&quot;</span>
            <span class="p">)</span>

        <span class="n">rep</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stats_shape_dict</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">n_filled</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">rep</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="c1"># each statistic is a tensor with batch and channel dimensions as</span>
            <span class="c1"># found in representation_tensor and all the other dimensions</span>
            <span class="c1"># determined by the values in necessary_stats_dict.</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="o">*</span><span class="n">representation_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">3</span><span class="p">],</span> <span class="o">*</span><span class="n">v</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
            <span class="n">new_v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nan</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span>
                <span class="n">shape</span><span class="p">,</span>
                <span class="n">dtype</span><span class="o">=</span><span class="n">representation_tensor</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                <span class="n">device</span><span class="o">=</span><span class="n">representation_tensor</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="c1"># v.sum() gives the number of necessary elements from this stat</span>
            <span class="n">this_stat_vec</span> <span class="o">=</span> <span class="n">representation_tensor</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">n_filled</span> <span class="p">:</span> <span class="n">n_filled</span> <span class="o">+</span> <span class="n">v</span><span class="o">.</span><span class="n">sum</span><span class="p">()]</span>
            <span class="c1"># use boolean indexing to put the values from new_stat_vec in the</span>
            <span class="c1"># appropriate place</span>
            <span class="n">new_v</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">v</span><span class="p">]</span> <span class="o">=</span> <span class="n">this_stat_vec</span>
            <span class="n">rep</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_v</span>
            <span class="n">n_filled</span> <span class="o">+=</span> <span class="n">v</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">rep</span></div>


    <span class="k">def</span> <span class="nf">_compute_pyr_coeffs</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">image</span><span class="p">:</span> <span class="n">Tensor</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">OrderedDict</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute pyramid coefficients of image.</span>

<span class="sd">        Note that the residual lowpass has been demeaned independently for each</span>
<span class="sd">        batch and channel (and this is true of the lowpass returned separately</span>
<span class="sd">        as well as the one included in pyr_coeffs_dict)</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        image :</span>
<span class="sd">            4d tensor of shape (batch, channel, height, width) containing the</span>
<span class="sd">            image</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        pyr_coeffs_dict :</span>
<span class="sd">            OrderedDict of containing all pyramid coefficients.</span>
<span class="sd">        pyr_coeffs :</span>
<span class="sd">            List of length n_scales, containing 5d tensors of shape (batch,</span>
<span class="sd">            channel, n_orientations, height, width) containing the complex-valued</span>
<span class="sd">            oriented bands (note that height and width shrink by half on each</span>
<span class="sd">            scale). This excludes the residual highpass and lowpass bands.</span>
<span class="sd">        highpass :</span>
<span class="sd">            The residual highpass as a real-valued 4d tensor (batch, channel,</span>
<span class="sd">            height, width)</span>
<span class="sd">        lowpass :</span>
<span class="sd">            The residual lowpass as a real-valued 4d tensor (batch, channel,</span>
<span class="sd">            height, width). This tensor has been demeaned (independently for</span>
<span class="sd">            each batch and channel).</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">pyr_coeffs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pyr</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
        <span class="c1"># separate out the residuals and demean the residual lowpass</span>
        <span class="n">lowpass</span> <span class="o">=</span> <span class="n">pyr_coeffs</span><span class="p">[</span><span class="s2">&quot;residual_lowpass&quot;</span><span class="p">]</span>
        <span class="n">lowpass</span> <span class="o">=</span> <span class="n">lowpass</span> <span class="o">-</span> <span class="n">lowpass</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">pyr_coeffs</span><span class="p">[</span><span class="s2">&quot;residual_lowpass&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">lowpass</span>
        <span class="n">highpass</span> <span class="o">=</span> <span class="n">pyr_coeffs</span><span class="p">[</span><span class="s2">&quot;residual_highpass&quot;</span><span class="p">]</span>

        <span class="c1"># This is a list of tensors, one for each scale, where each tensor is</span>
        <span class="c1"># of shape (batch, channel, n_orientations, height, width) (note that</span>
        <span class="c1"># height and width halves on each scale)</span>
        <span class="n">coeffs_list</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">pyr_coeffs</span><span class="p">[(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)]</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_orientations</span><span class="p">)],</span> <span class="mi">2</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span><span class="p">)</span>
        <span class="p">]</span>
        <span class="k">return</span> <span class="n">pyr_coeffs</span><span class="p">,</span> <span class="n">coeffs_list</span><span class="p">,</span> <span class="n">highpass</span><span class="p">,</span> <span class="n">lowpass</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_compute_intermediate_representations</span><span class="p">(</span>
        <span class="n">pyr_coeffs</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="n">Tensor</span><span class="p">],</span> <span class="nb">list</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute useful intermediate representations.</span>

<span class="sd">        These representations are:</span>
<span class="sd">          1) demeaned magnitude of the pyramid coefficients,</span>
<span class="sd">          2) real part of the pyramid coefficients</span>

<span class="sd">        These two are used in computing some of the texture representation.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        pyr_coeffs :</span>
<span class="sd">            Complex steerable pyramid coefficients (without residuals), as list</span>
<span class="sd">            of length n_scales, containing 5d tensors of shape (batch, channel,</span>
<span class="sd">            n_orientations, height, width)</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        magnitude_pyr_coeffs :</span>
<span class="sd">           List of length n_scales, containing 5d tensors of shape (batch,</span>
<span class="sd">           channel, n_orientations, height, width) (same as ``pyr_coeffs``),</span>
<span class="sd">           containing the demeaned magnitude of the steerable pyramid</span>
<span class="sd">           coefficients (i.e., coeffs.abs() - coeffs.abs().mean((-2, -1)))</span>
<span class="sd">        real_pyr_coeffs :</span>
<span class="sd">           List of length n_scales, containing 5d tensors of shape (batch,</span>
<span class="sd">           channel, n_orientations, height, width) (same as ``pyr_coeffs``),</span>
<span class="sd">           containing the real components of the coefficients (i.e.</span>
<span class="sd">           coeffs.real)</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">magnitude_pyr_coeffs</span> <span class="o">=</span> <span class="p">[</span><span class="n">coeff</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span> <span class="k">for</span> <span class="n">coeff</span> <span class="ow">in</span> <span class="n">pyr_coeffs</span><span class="p">]</span>
        <span class="n">magnitude_means</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">mag</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">for</span> <span class="n">mag</span> <span class="ow">in</span> <span class="n">magnitude_pyr_coeffs</span>
        <span class="p">]</span>
        <span class="n">magnitude_pyr_coeffs</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">mag</span> <span class="o">-</span> <span class="n">mn</span> <span class="k">for</span> <span class="n">mag</span><span class="p">,</span> <span class="n">mn</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">magnitude_pyr_coeffs</span><span class="p">,</span> <span class="n">magnitude_means</span><span class="p">)</span>
        <span class="p">]</span>
        <span class="n">real_pyr_coeffs</span> <span class="o">=</span> <span class="p">[</span><span class="n">coeff</span><span class="o">.</span><span class="n">real</span> <span class="k">for</span> <span class="n">coeff</span> <span class="ow">in</span> <span class="n">pyr_coeffs</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">magnitude_pyr_coeffs</span><span class="p">,</span> <span class="n">real_pyr_coeffs</span>

    <span class="k">def</span> <span class="nf">_reconstruct_lowpass_at_each_scale</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">pyr_coeffs_dict</span><span class="p">:</span> <span class="n">OrderedDict</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Reconstruct the lowpass unoriented image at each scale.</span>

<span class="sd">        The autocorrelation, standard deviation, skew, and kurtosis of each of</span>
<span class="sd">        these images is part of the texture representation.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        pyr_coeffs_dict :</span>
<span class="sd">            Dictionary containing the steerable pyramid coefficients, with the</span>
<span class="sd">            lowpass residual demeaned.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        reconstructed_images :</span>
<span class="sd">            List of length n_scales+1 containing the reconstructed unoriented</span>
<span class="sd">            image at each scale, from fine to coarse. The final image is</span>
<span class="sd">            reconstructed just from the residual lowpass image. Each is a 4d</span>
<span class="sd">            tensor, this is a list because they are all different heights and</span>
<span class="sd">            widths.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">reconstructed_images</span> <span class="o">=</span> <span class="p">[</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_pyr</span><span class="o">.</span><span class="n">recon_pyr</span><span class="p">(</span><span class="n">pyr_coeffs_dict</span><span class="p">,</span> <span class="n">levels</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;residual_lowpass&quot;</span><span class="p">])</span>
        <span class="p">]</span>
        <span class="c1"># go through scales backwards</span>
        <span class="k">for</span> <span class="n">lev</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">recon</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pyr</span><span class="o">.</span><span class="n">recon_pyr</span><span class="p">(</span><span class="n">pyr_coeffs_dict</span><span class="p">,</span> <span class="n">levels</span><span class="o">=</span><span class="p">[</span><span class="n">lev</span><span class="p">])</span>
            <span class="n">reconstructed_images</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">recon</span> <span class="o">+</span> <span class="n">reconstructed_images</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="c1"># now downsample as necessary, so that these end up the same size as</span>
        <span class="c1"># their corresponding coefficients. We multiply by the factor of 4 here</span>
        <span class="c1"># in order to approximately equalize the steerable pyramid coefficient</span>
        <span class="c1"># values across scales. This could also be handled by making the</span>
        <span class="c1"># pyramid tight frame</span>
        <span class="n">reconstructed_images</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">signal</span><span class="o">.</span><span class="n">shrink</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="mi">2</span> <span class="o">**</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span> <span class="o">-</span> <span class="n">i</span><span class="p">))</span> <span class="o">*</span> <span class="mi">4</span> <span class="o">**</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span> <span class="o">-</span> <span class="n">i</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">reconstructed_images</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="p">]</span>
        <span class="k">return</span> <span class="n">reconstructed_images</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_double_phase_pyr_coeffs</span><span class="p">(</span>
        <span class="n">pyr_coeffs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Tensor</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="n">Tensor</span><span class="p">],</span> <span class="nb">list</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Upsample and double the phase of pyramid coefficients.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        pyr_coeffs :</span>
<span class="sd">            Complex steerable pyramid coefficients (without residuals), as list</span>
<span class="sd">            of length n_scales, containing 5d tensors of shape (batch, channel,</span>
<span class="sd">            n_orientations, height, width)</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        doubled_phase_mags :</span>
<span class="sd">            The demeaned magnitude (i.e., pyr_coeffs.abs()) of each upsampled</span>
<span class="sd">            double-phased coefficient. List of length n_scales-1 containing</span>
<span class="sd">            tensors of same shape the input (the finest scale has been</span>
<span class="sd">            removed).</span>
<span class="sd">        doubled_phase_separate :</span>
<span class="sd">            The real and imaginary parts of each double-phased coefficient.</span>
<span class="sd">            List of length n_scales-1, containing tensors of shape (batch,</span>
<span class="sd">            channel, 2*n_orientations, height, width), with the real component</span>
<span class="sd">            found at the same orientation index as the input, and the imaginary</span>
<span class="sd">            at orientation+self.n_orientations. (The finest scale has been</span>
<span class="sd">            removed.)</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">doubled_phase_mags</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">doubled_phase_sep</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="c1"># don&#39;t do this for the finest scale</span>
        <span class="k">for</span> <span class="n">coeff</span> <span class="ow">in</span> <span class="n">pyr_coeffs</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span>
            <span class="c1"># We divide by the factor of 4 here in order to approximately</span>
            <span class="c1"># equalize the steerable pyramid coefficient values across scales.</span>
            <span class="c1"># This could also be handled by making the pyramid tight frame</span>
            <span class="n">doubled_phase</span> <span class="o">=</span> <span class="n">signal</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">coeff</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="mf">4.0</span>
            <span class="n">doubled_phase</span> <span class="o">=</span> <span class="n">signal</span><span class="o">.</span><span class="n">modulate_phase</span><span class="p">(</span><span class="n">doubled_phase</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
            <span class="n">doubled_phase_mag</span> <span class="o">=</span> <span class="n">doubled_phase</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span>
            <span class="n">doubled_phase_mag</span> <span class="o">=</span> <span class="n">doubled_phase_mag</span> <span class="o">-</span> <span class="n">doubled_phase_mag</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span>
                <span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)</span>
            <span class="n">doubled_phase_mags</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">doubled_phase_mag</span><span class="p">)</span>
            <span class="n">doubled_phase_sep</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">einops</span><span class="o">.</span><span class="n">pack</span><span class="p">([</span><span class="n">doubled_phase</span><span class="o">.</span><span class="n">real</span><span class="p">,</span> <span class="n">doubled_phase</span><span class="o">.</span><span class="n">imag</span><span class="p">],</span> <span class="s2">&quot;b c * h w&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">doubled_phase_mags</span><span class="p">,</span> <span class="n">doubled_phase_sep</span>

<div class="viewcode-block" id="PortillaSimoncelli.plot_representation">
<a class="viewcode-back" href="../../../../api/plenoptic.simulate.models.html#plenoptic.simulate.models.portilla_simoncelli.PortillaSimoncelli.plot_representation">[docs]</a>
    <span class="k">def</span> <span class="nf">plot_representation</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">data</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">ax</span><span class="p">:</span> <span class="n">plt</span><span class="o">.</span><span class="n">Axes</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">figsize</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
        <span class="n">ylim</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">|</span> <span class="n">Literal</span><span class="p">[</span><span class="kc">False</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">batch_idx</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">title</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">plt</span><span class="o">.</span><span class="n">Figure</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="n">plt</span><span class="o">.</span><span class="n">Axes</span><span class="p">]]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Plot the representation in a human viewable format -- stem</span>
<span class="sd">        plots with data separated out by statistic type.</span>

<span class="sd">        This plots the representation of a single batch and averages over all</span>
<span class="sd">        channels in the representation.</span>

<span class="sd">        We create the following axes:</span>

<span class="sd">        - pixels+var_highpass: marginal pixel statistics (first four moments,</span>
<span class="sd">          min, max) and variance of the residual highpass.</span>

<span class="sd">        - std+skew+kurtosis recon: the standard deviation, skew, and kurtosis</span>
<span class="sd">          of the reconstructed lowpass image at each scale</span>

<span class="sd">        - magnitude_std: the standard deviation of the steerable pyramid</span>
<span class="sd">          coefficient magnitudes at each orientation and scale.</span>

<span class="sd">        - auto_correlation_reconstructed: the auto-correlation of the</span>
<span class="sd">          reconstructed lowpass image at each scale (summarized using Euclidean</span>
<span class="sd">          norm).</span>

<span class="sd">        - auto_correlation_magnitude: the auto-correlation of the pyramid</span>
<span class="sd">          coefficient magnitudes at each scale and orientation (summarized</span>
<span class="sd">          using Euclidean norm).</span>

<span class="sd">        - cross_orientation_correlation_magnitude: the cross-correlations</span>
<span class="sd">          between each orientation at each scale (summarized using Euclidean</span>
<span class="sd">          norm)</span>

<span class="sd">        If self.n_scales &gt; 1, we also have combination of the following, where all</span>
<span class="sd">        cross-correlations are summarized using Euclidean norm over the</span>
<span class="sd">        channel dimension:</span>

<span class="sd">        - cross_scale_correlation_magnitude: the cross-correlations between the</span>
<span class="sd">          pyramid coefficient magnitude at one scale and the same orientation</span>
<span class="sd">          at the next-coarsest scale.</span>

<span class="sd">        - cross_scale_correlation_real: the cross-correlations between the real</span>
<span class="sd">          component of the pyramid coefficients and the real and imaginary</span>
<span class="sd">          components (at the same orientation) at the next-coarsest scale.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data :</span>
<span class="sd">            The data to show on the plot. Else, should look like the output of</span>
<span class="sd">            ``self.forward(img)``, with the exact same structure (e.g., as</span>
<span class="sd">            returned by ``metamer.representation_error()`` or another instance</span>
<span class="sd">            of this class).</span>
<span class="sd">        ax :</span>
<span class="sd">            Axes where we will plot the data. If a ``plt.Axes`` instance, will</span>
<span class="sd">            subdivide into 6 or 8 new axes (depending on self.n_scales). If</span>
<span class="sd">            None, we create a new figure.</span>
<span class="sd">        figsize :</span>
<span class="sd">            The size of the figure. Ignored if ax is not None.</span>
<span class="sd">        ylim :</span>
<span class="sd">            If not None, the y-limits to use for this plot. If None, we use the</span>
<span class="sd">            default, slightly adjusted so that the minimum is 0. If False, do not</span>
<span class="sd">            change y-limits.</span>
<span class="sd">        batch_idx :</span>
<span class="sd">            Which index to take from the batch dimension (the first one)</span>
<span class="sd">        title : string</span>
<span class="sd">            Title for the plot</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        fig:</span>
<span class="sd">            Figure containing the plot</span>
<span class="sd">        axes:</span>
<span class="sd">            List of 6 or 8 axes containing the plot (depending on self.n_scales)</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># pick the batch_idx we want (but keep the data 3d), and average over</span>
        <span class="c1"># channels (but keep the data 3d). We keep data 3d because</span>
        <span class="c1"># convert_to_dict relies on it.</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">batch_idx</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="c1"># each of these values should now be a 3d tensor with 1 element in each</span>
        <span class="c1"># of the first two dims</span>
        <span class="n">rep</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">convert_to_dict</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
        <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_representation_for_plotting</span><span class="p">(</span><span class="n">rep</span><span class="p">)</span>

        <span class="c1"># Determine plot grid layout</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">n_rows</span> <span class="o">=</span> <span class="mi">3</span>
            <span class="n">n_cols</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_rows</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># then we don&#39;t have any cross-scale correlations, so fewer axes.</span>
            <span class="n">n_rows</span> <span class="o">=</span> <span class="mi">2</span>
            <span class="n">n_cols</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_rows</span><span class="p">))</span>

        <span class="c1"># Set up grid spec</span>
        <span class="k">if</span> <span class="n">ax</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># we add 2 to order because we&#39;re adding one to get the</span>
            <span class="c1"># number of orientations and then another one to add an</span>
            <span class="c1"># extra column for the mean luminance plot</span>
            <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">)</span>
            <span class="n">gs</span> <span class="o">=</span> <span class="n">mpl</span><span class="o">.</span><span class="n">gridspec</span><span class="o">.</span><span class="n">GridSpec</span><span class="p">(</span><span class="n">n_rows</span><span class="p">,</span> <span class="n">n_cols</span><span class="p">,</span> <span class="n">fig</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># want to make sure the axis we&#39;re taking over is basically invisible.</span>
            <span class="n">ax</span> <span class="o">=</span> <span class="n">clean_up_axes</span><span class="p">(</span>
                <span class="n">ax</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;top&quot;</span><span class="p">,</span> <span class="s2">&quot;right&quot;</span><span class="p">,</span> <span class="s2">&quot;bottom&quot;</span><span class="p">,</span> <span class="s2">&quot;left&quot;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">]</span>
            <span class="p">)</span>
            <span class="n">gs</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">get_subplotspec</span><span class="p">()</span><span class="o">.</span><span class="n">subgridspec</span><span class="p">(</span><span class="n">n_rows</span><span class="p">,</span> <span class="n">n_cols</span><span class="p">)</span>
            <span class="n">fig</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">figure</span>

        <span class="c1"># plot data</span>
        <span class="n">axes</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
            <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="n">gs</span><span class="p">[</span><span class="n">i</span> <span class="o">//</span> <span class="n">n_cols</span><span class="p">,</span> <span class="n">i</span> <span class="o">%</span> <span class="n">n_cols</span><span class="p">])</span>
            <span class="n">ax</span> <span class="o">=</span> <span class="n">clean_stem_plot</span><span class="p">(</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">v</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">ax</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">ylim</span><span class="o">=</span><span class="n">ylim</span><span class="p">)</span>
            <span class="n">axes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ax</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">title</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span></div>


    <span class="k">def</span> <span class="nf">_representation_for_plotting</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rep</span><span class="p">:</span> <span class="n">OrderedDict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">OrderedDict</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Convert the data into a dictionary representation that is more convenient</span>
<span class="sd">        for plotting.</span>

<span class="sd">        Intended as a helper function for plot_representation.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
        <span class="n">data</span><span class="p">[</span><span class="s2">&quot;pixels+var_highpass&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
            <span class="p">[</span><span class="n">rep</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;pixel_statistics&quot;</span><span class="p">),</span> <span class="n">rep</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;var_highpass_residual&quot;</span><span class="p">)],</span> <span class="o">-</span><span class="mi">1</span>
        <span class="p">)</span>
        <span class="n">data</span><span class="p">[</span><span class="s2">&quot;std+skew+kurtosis recon&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
            <span class="p">(</span>
                <span class="n">rep</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;std_reconstructed&quot;</span><span class="p">),</span>
                <span class="n">rep</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;skew_reconstructed&quot;</span><span class="p">),</span>
                <span class="n">rep</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;kurtosis_reconstructed&quot;</span><span class="p">),</span>
            <span class="p">),</span>
            <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">data</span><span class="p">[</span><span class="s2">&quot;magnitude_std&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">rep</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;magnitude_std&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># want to plot these in a specific order</span>
        <span class="n">all_keys</span> <span class="o">=</span> <span class="p">[</span>
            <span class="s2">&quot;auto_correlation_reconstructed&quot;</span><span class="p">,</span>
            <span class="s2">&quot;auto_correlation_magnitude&quot;</span><span class="p">,</span>
            <span class="s2">&quot;cross_orientation_correlation_magnitude&quot;</span><span class="p">,</span>
            <span class="s2">&quot;cross_scale_correlation_magnitude&quot;</span><span class="p">,</span>
            <span class="s2">&quot;cross_scale_correlation_real&quot;</span><span class="p">,</span>
        <span class="p">]</span>
        <span class="k">if</span> <span class="nb">set</span><span class="p">(</span><span class="n">rep</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span> <span class="o">!=</span> <span class="nb">set</span><span class="p">(</span><span class="n">all_keys</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;representation has unexpected keys!&quot;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">all_keys</span><span class="p">:</span>
            <span class="c1"># if we only have one scale, no cross-scale stats</span>
            <span class="k">if</span> <span class="n">k</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;cross_scale&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="c1"># we compute L2 norm manually, since there are NaNs (marking</span>
            <span class="c1"># redundant stats)</span>
            <span class="n">data</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">rep</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">nansum</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">data</span>

<div class="viewcode-block" id="PortillaSimoncelli.update_plot">
<a class="viewcode-back" href="../../../../api/plenoptic.simulate.models.html#plenoptic.simulate.models.portilla_simoncelli.PortillaSimoncelli.update_plot">[docs]</a>
    <span class="k">def</span> <span class="nf">update_plot</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">axes</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">plt</span><span class="o">.</span><span class="n">Axes</span><span class="p">],</span>
        <span class="n">data</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">batch_idx</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">plt</span><span class="o">.</span><span class="n">Artist</span><span class="p">]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Update the information in our representation plot.</span>

<span class="sd">        This is used for creating an animation of the representation</span>
<span class="sd">        over time. In order to create the animation, we need to know how</span>
<span class="sd">        to update the matplotlib Artists, and this provides a simple way</span>
<span class="sd">        of doing that. It relies on the fact that we&#39;ve used</span>
<span class="sd">        ``plot_representation`` to create the plots we want to update</span>
<span class="sd">        and so know that they&#39;re stem plots.</span>

<span class="sd">        We take the axes containing the representation information (note that</span>
<span class="sd">        this is probably a subset of the total number of axes in the figure, if</span>
<span class="sd">        we&#39;re showing other information, as done by ``Metamer.animate``), grab</span>
<span class="sd">        the representation from plotting and, since these are both lists,</span>
<span class="sd">        iterate through them, updating them to the values in ``data`` as we go.</span>

<span class="sd">        In order for this to be used by ``FuncAnimation``, we need to</span>
<span class="sd">        return Artists, so we return a list of the relevant artists, the</span>
<span class="sd">        ``markerline`` and ``stemlines`` from the ``StemContainer``.</span>

<span class="sd">        Currently, this averages over all channels in the representation.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        axes :</span>
<span class="sd">            A list of axes to update. We assume that these are the axes</span>
<span class="sd">            created by ``plot_representation`` and so contain stem plots</span>
<span class="sd">            in the correct order.</span>
<span class="sd">        batch_idx :</span>
<span class="sd">            Which index to take from the batch dimension (the first one)</span>
<span class="sd">        data :</span>
<span class="sd">            The data to show on the plot. Else, should look like the output of</span>
<span class="sd">            ``self.forward(img)``, with the exact same structure (e.g., as</span>
<span class="sd">            returned by ``metamer.representation_error()`` or another instance</span>
<span class="sd">            of this class).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        stem_artists :</span>
<span class="sd">            A list of the artists used to update the information on the</span>
<span class="sd">            stem plots</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">stem_artists</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">axes</span> <span class="o">=</span> <span class="p">[</span><span class="n">ax</span> <span class="k">for</span> <span class="n">ax</span> <span class="ow">in</span> <span class="n">axes</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">ax</span><span class="o">.</span><span class="n">containers</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span>
        <span class="c1"># pick the batch_idx we want (but keep the data 3d), and average over</span>
        <span class="c1"># channels (but keep the data 3d). We keep data 3d because</span>
        <span class="c1"># convert_to_dict relies on it.</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">batch_idx</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="c1"># each of these values should now be a 3d tensor with 1 element in each</span>
        <span class="c1"># of the first two dims</span>
        <span class="n">rep</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">convert_to_dict</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
        <span class="n">rep</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_representation_for_plotting</span><span class="p">(</span><span class="n">rep</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axes</span><span class="p">,</span> <span class="n">rep</span><span class="o">.</span><span class="n">values</span><span class="p">()):</span>
            <span class="n">vals</span> <span class="o">=</span> <span class="n">to_numpy</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
            <span class="n">sc</span> <span class="o">=</span> <span class="n">update_stem</span><span class="p">(</span><span class="n">ax</span><span class="o">.</span><span class="n">containers</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">vals</span><span class="p">)</span>
            <span class="n">stem_artists</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="n">sc</span><span class="o">.</span><span class="n">markerline</span><span class="p">,</span> <span class="n">sc</span><span class="o">.</span><span class="n">stemlines</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">stem_artists</span></div>
</div>

</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2019, Plenoptic authors.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>