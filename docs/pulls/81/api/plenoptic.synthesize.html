

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>plenoptic.synthesize package &mdash; plenoptic 1.2.1.dev138 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css" />
      <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />

  
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=f712bd2b"></script>
      <script src="../_static/doctools.js?v=9bcbadda"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="../_static/copybutton.js?v=35a8b989"></script>
      <script src="../_static/design-tabs.js?v=f930bc37"></script>
      <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
      <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
      <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="plenoptic.tools package" href="plenoptic.tools.html" />
    <link rel="prev" title="plenoptic.simulate.models package" href="plenoptic.simulate.models.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            plenoptic
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Basic concepts</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../install.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../jupyter.html">Using Jupyter to Run Example Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../conceptual_intro.html">Conceptual Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models.html">Model requirements</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/00_quickstart.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../citation.html">Citation Guide and Bibliography</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Synthesis method introductions</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/intro/02_Eigendistortions.html">Eigendistortions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/intro/06_Metamer.html">Metamers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/intro/07_Simple_MAD.html">MAD Competition Conceptual Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/intro/08_MAD_Competition.html">MAD Competition Usage</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Models and metrics</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/models/03_Steerable_Pyramid.html">Steerable Pyramid</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/models/04_Perceptual_distance.html">Perceptual distance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/models/Metamer-Portilla-Simoncelli.html">Portilla-Simoncelli Texture Metamer</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Synthesis method examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/applications/09_Original_MAD.html">Reproducing Wang and Simoncelli, 2008 (MAD Competition)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/applications/Demo_Eigendistortion.html">Reproducing Berardino et al., 2017 (Eigendistortions)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced usage</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../synthesis.html">Synthesis object design</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tips.html">Tips and Tricks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reproducibility.html">Reproducibility</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="modules.html">API Documentation</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="plenoptic.html">plenoptic package</a><ul class="current">
<li class="toctree-l3 current"><a class="reference internal" href="plenoptic.html#subpackages">Subpackages</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="plenoptic.data.html">plenoptic.data package</a></li>
<li class="toctree-l4"><a class="reference internal" href="plenoptic.metric.html">plenoptic.metric package</a></li>
<li class="toctree-l4"><a class="reference internal" href="plenoptic.simulate.html">plenoptic.simulate package</a></li>
<li class="toctree-l4 current"><a class="current reference internal" href="#">plenoptic.synthesize package</a></li>
<li class="toctree-l4"><a class="reference internal" href="plenoptic.tools.html">plenoptic.tools package</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="plenoptic.html#module-plenoptic">Module contents</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/advanced/Display.html">Display and animate functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/advanced/Synthesis_extensions.html">Extending existing synthesis objects</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">plenoptic</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="modules.html">plenoptic</a></li>
          <li class="breadcrumb-item"><a href="plenoptic.html">plenoptic package</a></li>
      <li class="breadcrumb-item active">plenoptic.synthesize package</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/api/plenoptic.synthesize.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="plenoptic-synthesize-package">
<h1>plenoptic.synthesize package<a class="headerlink" href="#plenoptic-synthesize-package" title="Link to this heading"></a></h1>
<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Link to this heading"></a></h2>
</section>
<section id="module-plenoptic.synthesize.autodiff">
<span id="plenoptic-synthesize-autodiff-module"></span><h2>plenoptic.synthesize.autodiff module<a class="headerlink" href="#module-plenoptic.synthesize.autodiff" title="Link to this heading"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="plenoptic.synthesize.autodiff.jacobian">
<span class="sig-prename descclassname"><span class="pre">plenoptic.synthesize.autodiff.</span></span><span class="sig-name descname"><span class="pre">jacobian</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/autodiff.html#jacobian"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.autodiff.jacobian" title="Link to this definition"></a></dt>
<dd><p>Explicitly compute the full Jacobian matrix.
N.B. This is only recommended for small input sizes (e.g. &lt;100x100 image)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Model output with gradient attached</p></li>
<li><p><strong>x</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Tensor with gradient function model input with gradient attached</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Jacobian matrix with <code class="docutils literal notranslate"><span class="pre">torch.Size([len(y),</span> <span class="pre">len(x)])</span></code></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>J</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="plenoptic.synthesize.autodiff.jacobian_vector_product">
<span class="sig-prename descclassname"><span class="pre">plenoptic.synthesize.autodiff.</span></span><span class="sig-name descname"><span class="pre">jacobian_vector_product</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">V</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dummy_vec</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/autodiff.html#jacobian_vector_product"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.autodiff.jacobian_vector_product" title="Link to this definition"></a></dt>
<dd><p>Compute Jacobian Vector Product: <span class="math notranslate nohighlight">\(\text{jvp} = (\partial y/\partial x) v\)</span></p>
<p>Forward Mode Auto-Differentiation (<code class="docutils literal notranslate"><span class="pre">Rop</span></code> in Theano). PyTorch does not natively
support this operation; this function essentially calls backward mode autodiff
twice, as described in [1].</p>
<p>See <a class="reference internal" href="#plenoptic.synthesize.autodiff.vector_jacobian_product" title="plenoptic.synthesize.autodiff.vector_jacobian_product"><code class="xref py py-meth docutils literal notranslate"><span class="pre">vector_jacobian_product()</span></code></a> docstring on why we and pass arguments for
<code class="docutils literal notranslate"><span class="pre">retain_graph</span></code> and <code class="docutils literal notranslate"><span class="pre">create_graph</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Model output with gradient attached, shape is torch.Size([m, 1])</p></li>
<li><p><strong>x</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Model input with gradient attached, shape is torch.Size([n, 1]), i.e. same dim
as input tensor</p></li>
<li><p><strong>V</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Directions in which to compute product, shape is torch.Size([n, k]) where k is
number of vectors to compute</p></li>
<li><p><strong>dummy_vec</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Vector with which to do jvp trick [1]. If argument exists, then use some
pre-allocated, cached vector, otherwise create a new one and move to device in
this method.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Jacobian-vector product, torch.Size([n, k])</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Jv</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>[1] <a class="reference external" href="https://j-towns.github.io/2017/06/12/A-new-trick.html">https://j-towns.github.io/2017/06/12/A-new-trick.html</a></p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="plenoptic.synthesize.autodiff.vector_jacobian_product">
<span class="sig-prename descclassname"><span class="pre">plenoptic.synthesize.autodiff.</span></span><span class="sig-name descname"><span class="pre">vector_jacobian_product</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">U</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retain_graph</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">create_graph</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">detach</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/autodiff.html#vector_jacobian_product"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.autodiff.vector_jacobian_product" title="Link to this definition"></a></dt>
<dd><p>Compute vector Jacobian product: <span class="math notranslate nohighlight">\(\text{vjp} = u^T(\partial y/\partial x)\)</span></p>
<p>Backward Mode Auto-Differentiation (<cite>Lop</cite> in Theano)</p>
<p>Note on efficiency: When this function is used in the context of power iteration for
computing eigenvectors, the vector output will be repeatedly fed back into :meth:
<cite>vector_jacobian_product()</cite> and <a class="reference internal" href="#plenoptic.synthesize.autodiff.jacobian_vector_product" title="plenoptic.synthesize.autodiff.jacobian_vector_product"><code class="xref py py-meth docutils literal notranslate"><span class="pre">jacobian_vector_product()</span></code></a>.
To prevent the accumulation of gradient history in this vector (especially on GPU),
we need to ensure the computation graph is not kept in memory after each iteration.
We can do this by detaching the output, as well as carefully specifying where/when
to retain the created graph.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Output with gradient attached, <code class="docutils literal notranslate"><span class="pre">torch.Size([m,</span> <span class="pre">1])</span></code>.</p></li>
<li><p><strong>x</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Input with gradient attached, <code class="docutils literal notranslate"><span class="pre">torch.Size([n,</span> <span class="pre">1])</span></code>.</p></li>
<li><p><strong>U</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Direction, shape is <code class="docutils literal notranslate"><span class="pre">torch.Size([m,</span> <span class="pre">k])</span></code>, i.e. same dim as output tensor.</p></li>
<li><p><strong>retain_graph</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></span>) – Whether or not to keep graph after doing one <a class="reference internal" href="#plenoptic.synthesize.autodiff.vector_jacobian_product" title="plenoptic.synthesize.autodiff.vector_jacobian_product"><code class="xref py py-meth docutils literal notranslate"><span class="pre">vector_jacobian_product()</span></code></a>.
Must be set to True if k&gt;1.</p></li>
<li><p><strong>create_graph</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></span>) – Whether or not to create computational graph. Usually should be set to True
unless you’re reusing the graph like in the second step
of <a class="reference internal" href="#plenoptic.synthesize.autodiff.jacobian_vector_product" title="plenoptic.synthesize.autodiff.jacobian_vector_product"><code class="xref py py-meth docutils literal notranslate"><span class="pre">jacobian_vector_product()</span></code></a>.</p></li>
<li><p><strong>detach</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></span>) – As with <code class="docutils literal notranslate"><span class="pre">create_graph</span></code>, only necessary to be True when reusing the output
like we do in the 2nd step of <a class="reference internal" href="#plenoptic.synthesize.autodiff.jacobian_vector_product" title="plenoptic.synthesize.autodiff.jacobian_vector_product"><code class="xref py py-meth docutils literal notranslate"><span class="pre">jacobian_vector_product()</span></code></a>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>vector-Jacobian product, <code class="docutils literal notranslate"><span class="pre">torch.Size([m,</span> <span class="pre">k])</span></code>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>vJ</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-plenoptic.synthesize.eigendistortion">
<span id="plenoptic-synthesize-eigendistortion-module"></span><h2>plenoptic.synthesize.eigendistortion module<a class="headerlink" href="#module-plenoptic.synthesize.eigendistortion" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="plenoptic.synthesize.eigendistortion.Eigendistortion">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">plenoptic.synthesize.eigendistortion.</span></span><span class="sig-name descname"><span class="pre">Eigendistortion</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/eigendistortion.html#Eigendistortion"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.eigendistortion.Eigendistortion" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#plenoptic.synthesize.synthesis.Synthesis" title="plenoptic.synthesize.synthesis.Synthesis"><code class="xref py py-class docutils literal notranslate"><span class="pre">Synthesis</span></code></a></p>
<p>Synthesis object to compute eigendistortions induced by a model on a given
input image.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>image</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Image. We currently do not support batches of images, as each image requires its
own optimization, so either <code class="docutils literal notranslate"><span class="pre">image.ndimension()==1</span></code> or <code class="docutils literal notranslate"><span class="pre">image.shape[0]==1</span></code></p></li>
<li><p><strong>model</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a></span>) – Torch model with defined forward and backward operations.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="plenoptic.synthesize.eigendistortion.Eigendistortion.jacobian">
<span class="sig-name descname"><span class="pre">jacobian</span></span><a class="headerlink" href="#plenoptic.synthesize.eigendistortion.Eigendistortion.jacobian" title="Link to this definition"></a></dt>
<dd><p>Is only set when <a class="reference internal" href="#plenoptic.synthesize.eigendistortion.Eigendistortion.synthesize" title="plenoptic.synthesize.eigendistortion.Eigendistortion.synthesize"><code class="xref py py-func docutils literal notranslate"><span class="pre">synthesize()</span></code></a> is run with <code class="docutils literal notranslate"><span class="pre">method='exact'</span></code>. Default to
<code class="docutils literal notranslate"><span class="pre">None</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="plenoptic.synthesize.eigendistortion.Eigendistortion.eigendistortions">
<span class="sig-name descname"><span class="pre">eigendistortions</span></span><a class="headerlink" href="#plenoptic.synthesize.eigendistortion.Eigendistortion.eigendistortions" title="Link to this definition"></a></dt>
<dd><p>Tensor of eigendistortions (eigenvectors of Fisher matrix), ordered by
eigenvalue, with Size((n_distortions, <a href="#id1"><span class="problematic" id="id2">*</span></a>image.shape[1:])).</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="plenoptic.synthesize.eigendistortion.Eigendistortion.eigenvalues">
<span class="sig-name descname"><span class="pre">eigenvalues</span></span><a class="headerlink" href="#plenoptic.synthesize.eigendistortion.Eigendistortion.eigenvalues" title="Link to this definition"></a></dt>
<dd><p>Tensor of eigenvalues corresponding to each eigendistortion, listed in
decreasing order.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="plenoptic.synthesize.eigendistortion.Eigendistortion.eigenindex">
<span class="sig-name descname"><span class="pre">eigenindex</span></span><a class="headerlink" href="#plenoptic.synthesize.eigendistortion.Eigendistortion.eigenindex" title="Link to this definition"></a></dt>
<dd><p>Index of each eigenvector/eigenvalue.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>listlike</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Notes</p>
<p>This is a method for comparing image representations in terms of their ability to
explain perceptual sensitivity in humans. It estimates eigenvectors of the FIM.
A model, <span class="math notranslate nohighlight">\(y = f(x)\)</span>, is a deterministic (and differentiable)
mapping from the input pixels <span class="math notranslate nohighlight">\(x \in \mathbb{R}^n\)</span> to a mean output
response vector <span class="math notranslate nohighlight">\(y\in \mathbb{R}^m\)</span>, where we assume additive white
Gaussian noise in the response space.
The Jacobian matrix at x is:</p>
<blockquote>
<div><p><span class="math notranslate nohighlight">\(J(x) = J = dydx\)</span>,
<span class="math notranslate nohighlight">\(J\in\mathbb{R}^{m \times n}\)</span> (ie. output_dim x input_dim)</p>
</div></blockquote>
<p>The matrix consists of all partial derivatives of the vector-valued function f.
The Fisher Information Matrix (FIM) at x, under white Gaussian noise in the
response space, is:</p>
<blockquote>
<div><p><span class="math notranslate nohighlight">\(F = J^T J\)</span></p>
</div></blockquote>
<p>It is a quadratic approximation of the discriminability of distortions
relative to <span class="math notranslate nohighlight">\(x\)</span>.</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r1708efe03b12-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>Berardino, A., Laparra, V., Ballé, J. and Simoncelli, E., 2017.
Eigen-distortions of hierarchical representations. In Advances in
neural information processing systems (pp. 3530-3539).
<a class="reference external" href="https://www.cns.nyu.edu/pub/lcv/berardino17c-final.pdf">https://www.cns.nyu.edu/pub/lcv/berardino17c-final.pdf</a>
<a class="reference external" href="https://www.cns.nyu.edu/~lcv/eigendistortions/">https://www.cns.nyu.edu/~lcv/eigendistortions/</a></p>
</div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Attributes<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><a class="reference internal" href="#id0" title="plenoptic.synthesize.eigendistortion.Eigendistortion.eigendistortions"><code class="xref py py-obj docutils literal notranslate"><span class="pre">eigendistortions</span></code></a></dt><dd><p>Tensor of eigendistortions (eigenvectors of Fisher matrix), ordered by eigenvalue.</p>
</dd>
<dt><a class="reference internal" href="#id3" title="plenoptic.synthesize.eigendistortion.Eigendistortion.eigenindex"><code class="xref py py-obj docutils literal notranslate"><span class="pre">eigenindex</span></code></a></dt><dd><p>Index of each eigenvector/eigenvalue.</p>
</dd>
<dt><a class="reference internal" href="#id4" title="plenoptic.synthesize.eigendistortion.Eigendistortion.eigenvalues"><code class="xref py py-obj docutils literal notranslate"><span class="pre">eigenvalues</span></code></a></dt><dd><p>Tensor of eigenvalues corresponding to each eigendistortion, listed in decreasing order.</p>
</dd>
<dt><strong>image</strong></dt><dd></dd>
<dt><a class="reference internal" href="#id5" title="plenoptic.synthesize.eigendistortion.Eigendistortion.jacobian"><code class="xref py py-obj docutils literal notranslate"><span class="pre">jacobian</span></code></a></dt><dd><p>Is only set when <a class="reference internal" href="#plenoptic.synthesize.eigendistortion.Eigendistortion.synthesize" title="plenoptic.synthesize.eigendistortion.Eigendistortion.synthesize"><code class="xref py py-func docutils literal notranslate"><span class="pre">synthesize()</span></code></a> is run with <code class="docutils literal notranslate"><span class="pre">method='exact'</span></code>.</p>
</dd>
<dt><strong>model</strong></dt><dd></dd>
</dl>
</dd>
</dl>
<p class="rubric">Methods</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#plenoptic.synthesize.eigendistortion.Eigendistortion.compute_jacobian" title="plenoptic.synthesize.eigendistortion.Eigendistortion.compute_jacobian"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute_jacobian</span></code></a>()</p></td>
<td><p>Calls autodiff.jacobian and returns jacobian.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#plenoptic.synthesize.eigendistortion.Eigendistortion.load" title="plenoptic.synthesize.eigendistortion.Eigendistortion.load"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load</span></code></a>(file_path[, map_location, ...])</p></td>
<td><p>Load all relevant stuff from a .pt file.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#plenoptic.synthesize.eigendistortion.Eigendistortion.save" title="plenoptic.synthesize.eigendistortion.Eigendistortion.save"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save</span></code></a>(file_path)</p></td>
<td><p>Save all relevant variables in .pt file.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#plenoptic.synthesize.eigendistortion.Eigendistortion.synthesize" title="plenoptic.synthesize.eigendistortion.Eigendistortion.synthesize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">synthesize</span></code></a>([method, k, max_iter, p, q, ...])</p></td>
<td><p>Compute eigendistortions of Fisher Information Matrix with given input image.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#id8" title="plenoptic.synthesize.eigendistortion.Eigendistortion.to"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to</span></code></a>(*args, **kwargs)</p></td>
<td><p>Moves and/or casts the parameters and buffers.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="plenoptic.synthesize.eigendistortion.Eigendistortion.compute_jacobian">
<span class="sig-name descname"><span class="pre">compute_jacobian</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/eigendistortion.html#Eigendistortion.compute_jacobian"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.eigendistortion.Eigendistortion.compute_jacobian" title="Link to this definition"></a></dt>
<dd><p>Calls autodiff.jacobian and returns jacobian. Will throw error if input too big.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Jacobian of representation wrt input.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>J</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="id0">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">eigendistortions</span></span><a class="headerlink" href="#id0" title="Link to this definition"></a></dt>
<dd><p>Tensor of eigendistortions (eigenvectors of Fisher matrix), ordered by
eigenvalue.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="id3">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">eigenindex</span></span><a class="headerlink" href="#id3" title="Link to this definition"></a></dt>
<dd><p>Index of each eigenvector/eigenvalue.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="id4">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">eigenvalues</span></span><a class="headerlink" href="#id4" title="Link to this definition"></a></dt>
<dd><p>Tensor of eigenvalues corresponding to each eigendistortion, listed in
decreasing order.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="plenoptic.synthesize.eigendistortion.Eigendistortion.image">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">image</span></span><a class="headerlink" href="#plenoptic.synthesize.eigendistortion.Eigendistortion.image" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="id5">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">jacobian</span></span><a class="headerlink" href="#id5" title="Link to this definition"></a></dt>
<dd><p>Is only set when <a class="reference internal" href="#plenoptic.synthesize.eigendistortion.Eigendistortion.synthesize" title="plenoptic.synthesize.eigendistortion.Eigendistortion.synthesize"><code class="xref py py-func docutils literal notranslate"><span class="pre">synthesize()</span></code></a> is run with <code class="docutils literal notranslate"><span class="pre">method='exact'</span></code>.
Default to <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="plenoptic.synthesize.eigendistortion.Eigendistortion.load">
<span class="sig-name descname"><span class="pre">load</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">map_location</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensor_equality_atol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-08</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensor_equality_rtol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">pickle_load_args</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/eigendistortion.html#Eigendistortion.load"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.eigendistortion.Eigendistortion.load" title="Link to this definition"></a></dt>
<dd><p>Load all relevant stuff from a .pt file.</p>
<p>This must be called by a <code class="docutils literal notranslate"><span class="pre">Eigendistortion</span></code> object initialized just like the
saved object.</p>
<p>Note this operates in place and so doesn’t return anything.</p>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 1.2: </span>load behavior changed in a backwards-incompatible manner in order to
compatible with breaking changes in torch 2.6.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>file_path</strong> (<em>str</em>) – The path to load the synthesis object from</p></li>
<li><p><strong>map_location</strong> (<em>str</em><em>, </em><em>optional</em>) – map_location argument to pass to <code class="docutils literal notranslate"><span class="pre">torch.load</span></code>. If you save
stuff that was being run on a GPU and are loading onto a
CPU, you’ll need this to make sure everything lines up
properly. This should be structured like the str you would
pass to <code class="docutils literal notranslate"><span class="pre">torch.device</span></code></p></li>
<li><p><strong>tensor_equality_atol</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></span>) – Absolute tolerance to use when checking for tensor equality during load,
passed to <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.allclose.html#torch.allclose" title="(in PyTorch v2.7)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.allclose()</span></code></a>. It may be necessary to increase if you are
saving and loading on two machines with torch built by different cuda
versions. Be careful when changing this! See
<a class="reference external" href="https://docs.pytorch.org/docs/stable/type_info.html#torch.torch.finfo" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.finfo</span></code></a> for more details about floating
point precision of different data types (especially, <code class="docutils literal notranslate"><span class="pre">eps</span></code>); if you have
to increase this by more than 1 or 2 decades, then you are probably not
dealing with a numerical issue.</p></li>
<li><p><strong>tensor_equality_rtol</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></span>) – Relative tolerance to use when checking for tensor equality during load,
passed to <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.allclose.html#torch.allclose" title="(in PyTorch v2.7)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.allclose()</span></code></a>. It may be necessary to increase if you are
saving and loading on two machines with torch built by different cuda
versions. Be careful when changing this! See
<a class="reference external" href="https://docs.pytorch.org/docs/stable/type_info.html#torch.torch.finfo" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.finfo</span></code></a> for more details about floating
point precision of different data types (especially, <code class="docutils literal notranslate"><span class="pre">eps</span></code>); if you have
to increase this by more than 1 or 2 decades, then you are probably not
dealing with a numerical issue.</p></li>
<li><p><strong>pickle_load_args</strong> – any additional kwargs will be added to <code class="docutils literal notranslate"><span class="pre">pickle_module.load</span></code> via
<code class="docutils literal notranslate"><span class="pre">torch.load</span></code>, see that function’s docstring for details.</p></li>
</ul>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">examine_saved_synthesis</span></code></dt><dd><p>Examine metadata from saved object: pytorch and plenoptic versions, name of the synthesis object, shapes of tensors, etc.</p>
</dd>
</dl>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">plenoptic</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">po</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">einstein</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">simul</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">remove_grad</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">eig</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">synth</span><span class="o">.</span><span class="n">Eigendistortion</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">eig</span><span class="o">.</span><span class="n">synthesize</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">eig</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;eig.pt&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">eig_copy</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">synth</span><span class="o">.</span><span class="n">Eigendistortion</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">eig_copy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;eig.pt&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="plenoptic.synthesize.eigendistortion.Eigendistortion.model">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model</span></span><a class="headerlink" href="#plenoptic.synthesize.eigendistortion.Eigendistortion.model" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="plenoptic.synthesize.eigendistortion.Eigendistortion.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/eigendistortion.html#Eigendistortion.save"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.eigendistortion.Eigendistortion.save" title="Link to this definition"></a></dt>
<dd><p>Save all relevant variables in .pt file.</p>
<p>See <code class="docutils literal notranslate"><span class="pre">load</span></code> docstring for an example of use.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>file_path</strong> (<em>str</em>) – The path to save the Eigendistortion object to</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="plenoptic.synthesize.eigendistortion.Eigendistortion.synthesize">
<span class="sig-name descname"><span class="pre">synthesize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'power'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop_criterion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-07</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/eigendistortion.html#Eigendistortion.synthesize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.eigendistortion.Eigendistortion.synthesize" title="Link to this definition"></a></dt>
<dd><p>Compute eigendistortions of Fisher Information Matrix with given input image.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>method</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Literal</span></code>[<code class="docutils literal notranslate"><span class="pre">'exact'</span></code>, <code class="docutils literal notranslate"><span class="pre">'power'</span></code>, <code class="docutils literal notranslate"><span class="pre">'randomized_svd'</span></code>]</span>) – Eigensolver method. ‘exact’ tries to do eigendecomposition directly (
not recommended for very large inputs). ‘power’ (default) uses the power
method to compute first and last eigendistortions, with maximum number of
iterations dictated by n_steps. ‘randomized_svd’ uses randomized SVD to
approximate the top k eigendistortions and their corresponding eigenvalues.</p></li>
<li><p><strong>k</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – How many vectors to return using block power method or svd.</p></li>
<li><p><strong>max_iter</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – Maximum number of steps to run for <code class="docutils literal notranslate"><span class="pre">method='power'</span></code> in eigenvalue
computation. Ignored for other methods.</p></li>
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – Oversampling parameter for randomized SVD. k+p vectors will be sampled,
and k will be returned. See docstring of <code class="docutils literal notranslate"><span class="pre">_synthesize_randomized_svd</span></code>
for more details including algorithm reference.</p></li>
<li><p><strong>q</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – Matrix power parameter for randomized SVD. This is an effective trick for
the algorithm to converge to the correct eigenvectors when the
eigenspectrum does not decay quickly. See <code class="docutils literal notranslate"><span class="pre">_synthesize_randomized_svd</span></code>
for more details including algorithm reference.</p></li>
<li><p><strong>stop_criterion</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></span>) – Used if <code class="docutils literal notranslate"><span class="pre">method='power'</span></code> to check for convergence. If the L2-norm
of the eigenvalues has changed by less than this value from one
iteration to the next, we terminate synthesis.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="plenoptic.synthesize.eigendistortion.Eigendistortion.to">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/eigendistortion.html#Eigendistortion.to"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.eigendistortion.Eigendistortion.to" title="Link to this definition"></a></dt>
<dd><p>Moves and/or casts the parameters and buffers.</p>
<p>This can be called as</p>
<dl class="py function">
<dt class="sig sig-object py" id="id6">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">non_blocking</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/eigendistortion.html#Eigendistortion.to"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id6" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="id7">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dtype</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">non_blocking</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/eigendistortion.html#Eigendistortion.to"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id7" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="id8">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">non_blocking</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/eigendistortion.html#Eigendistortion.to"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id8" title="Link to this definition"></a></dt>
<dd></dd></dl>

<p>Its signature is similar to <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.Tensor.to.html#torch.Tensor.to" title="(in PyTorch v2.7)"><code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.Tensor.to()</span></code></a>, but only accepts
floating point desired <code class="xref py py-attr docutils literal notranslate"><span class="pre">dtype</span></code> s. In addition, this method will
only cast the floating point parameters and buffers to <code class="xref py py-attr docutils literal notranslate"><span class="pre">dtype</span></code>
(if given). The integral parameters and buffers will be moved
<code class="xref py py-attr docutils literal notranslate"><span class="pre">device</span></code>, if that is given, but with dtypes unchanged. When
<code class="xref py py-attr docutils literal notranslate"><span class="pre">non_blocking</span></code> is set, it tries to convert/move asynchronously
with respect to the host if possible, e.g., moving CPU Tensors with
pinned memory to CUDA devices.</p>
<p>See below for examples.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt>device (<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.device</span></code></a>): the desired device of the parameters</dt><dd><p>and buffers in this module</p>
</dd>
<dt>dtype (<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensor_attributes.html#torch.dtype" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.dtype</span></code></a>): the desired floating point type of</dt><dd><p>the floating point parameters and buffers in this module</p>
</dd>
<dt>tensor (torch.Tensor): Tensor whose dtype and device are the desired</dt><dd><p>dtype and device for all parameters and buffers in this module</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="plenoptic.synthesize.eigendistortion.display_eigendistortion">
<span class="sig-prename descclassname"><span class="pre">plenoptic.synthesize.eigendistortion.</span></span><span class="sig-name descname"><span class="pre">display_eigendistortion</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">eigendistortion</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eigenindex=0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha=5.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">process_image=&lt;function</span> <span class="pre">&lt;lambda&gt;&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ax=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">plot_complex='rectangular'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">**kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/eigendistortion.html#display_eigendistortion"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.eigendistortion.display_eigendistortion" title="Link to this definition"></a></dt>
<dd><p>Displays specified eigendistortion added to the image.</p>
<p>If image or eigendistortions have 3 channels, then it is assumed to be a color
image and it is converted to grayscale. This is merely for display convenience
and may change in the future.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>eigendistortion</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="#plenoptic.synthesize.eigendistortion.Eigendistortion" title="plenoptic.synthesize.eigendistortion.Eigendistortion"><code class="xref py py-class docutils literal notranslate"><span class="pre">Eigendistortion</span></code></a></span>) – Eigendistortion object whose synthesized eigendistortion we want to display</p></li>
<li><p><strong>eigenindex</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – Index of eigendistortion to plot. E.g. If there are 10 eigenvectors, 0 will
index the first one, and -1 or 9 will index the last one.</p></li>
<li><p><strong>alpha</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></span>) – Amount by which to scale eigendistortion for <cite>image + (alpha * eigendistortion)</cite>
for display.</p></li>
<li><p><strong>process_image</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">Callable</span></code>[[<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>], <a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span>) – A function to process the image+alpha*distortion before clamping between 0,1.
E.g. multiplying by the stdev ImageNet then adding the mean of ImageNet to undo
image preprocessing.</p></li>
<li><p><strong>ax</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">Axes</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Axis handle on which to plot.</p></li>
<li><p><strong>plot_complex</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></span>) – Parameter for <code class="xref py py-meth docutils literal notranslate"><span class="pre">plenoptic.imshow()</span></code> determining how to handle complex values.
Defaults to ‘rectangular’, which plots real and complex components as separate
images. Can also be ‘polar’ or ‘logpolar’; see that method’s docstring
for details.</p></li>
<li><p><strong>kwargs</strong> – Additional arguments for <code class="xref py py-meth docutils literal notranslate"><span class="pre">po.imshow()</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>matplotlib Figure handle returned by plenoptic.imshow()</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>fig</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="plenoptic.synthesize.eigendistortion.fisher_info_matrix_eigenvalue">
<span class="sig-prename descclassname"><span class="pre">plenoptic.synthesize.eigendistortion.</span></span><span class="sig-name descname"><span class="pre">fisher_info_matrix_eigenvalue</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">v</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dummy_vec</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/eigendistortion.html#fisher_info_matrix_eigenvalue"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.eigendistortion.fisher_info_matrix_eigenvalue" title="Link to this definition"></a></dt>
<dd><p>Compute the eigenvalues of the Fisher Information Matrix corresponding to
eigenvectors in v:math:<cite>lambda= v^T F v</cite></p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="plenoptic.synthesize.eigendistortion.fisher_info_matrix_vector_product">
<span class="sig-prename descclassname"><span class="pre">plenoptic.synthesize.eigendistortion.</span></span><span class="sig-name descname"><span class="pre">fisher_info_matrix_vector_product</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">v</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dummy_vec</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/eigendistortion.html#fisher_info_matrix_vector_product"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.eigendistortion.fisher_info_matrix_vector_product" title="Link to this definition"></a></dt>
<dd><p>Compute Fisher Information Matrix Vector Product: <span class="math notranslate nohighlight">\(Fv\)</span></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Output tensor with gradient attached</p></li>
<li><p><strong>x</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Input tensor with gradient attached</p></li>
<li><p><strong>v</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – The vectors with which to compute Fisher vector products</p></li>
<li><p><strong>dummy_vec</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Dummy vector for Jacobian vector product trick</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Vector, Fisher vector product</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Fv</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>Under white Gaussian noise assumption, <span class="math notranslate nohighlight">\(F\)</span> is matrix multiplication
of Jacobian transpose and Jacobian:
<span class="math notranslate nohighlight">\(F = J^T J\)</span>. Hence:
<span class="math notranslate nohighlight">\(Fv = J^T (Jv)\)</span></p>
</dd></dl>

</section>
<section id="module-plenoptic.synthesize.mad_competition">
<span id="plenoptic-synthesize-mad-competition-module"></span><h2>plenoptic.synthesize.mad_competition module<a class="headerlink" href="#module-plenoptic.synthesize.mad_competition" title="Link to this heading"></a></h2>
<p>Run MAD Competition.</p>
<dl class="py class">
<dt class="sig sig-object py" id="plenoptic.synthesize.mad_competition.MADCompetition">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">plenoptic.synthesize.mad_competition.</span></span><span class="sig-name descname"><span class="pre">MADCompetition</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimized_metric</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reference_metric</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">minmax</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_tradeoff_lambda</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">range_penalty_lambda</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">allowed_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0,</span> <span class="pre">1)</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/mad_competition.html#MADCompetition"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.mad_competition.MADCompetition" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#plenoptic.synthesize.synthesis.OptimizedSynthesis" title="plenoptic.synthesize.synthesis.OptimizedSynthesis"><code class="xref py py-class docutils literal notranslate"><span class="pre">OptimizedSynthesis</span></code></a></p>
<p>Synthesize a single maximally-differentiating image for two metrics.</p>
<p>Following the basic idea in <a class="reference internal" href="#r457fcb70e19f-1" id="id9">[1]</a>, this class synthesizes a
maximally-differentiating image for two given metrics, based on a given
image. We start by adding noise to this image and then iteratively
adjusting its pixels so as to either minimize or maximize
<code class="docutils literal notranslate"><span class="pre">optimized_metric</span></code> while holding the value of <code class="docutils literal notranslate"><span class="pre">reference_metric</span></code> constant.</p>
<p>MADCompetiton accepts two metrics as its input. These should be callables
that take two images and return a single number, and that number should be
0 if and only if the two images are identical (thus, the larger the number,
the more different the two images).</p>
<p>Note that a full set of MAD Competition images consists of two pairs: a maximal and
a minimal image for each metric. A single instantiation of <code class="docutils literal notranslate"><span class="pre">MADCompetition</span></code> will
generate one of these four images.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>image</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – A tensor, this is the image we use as the reference point.</p></li>
<li><p><strong>optimized_metric</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a> | <code class="xref py py-class docutils literal notranslate"><span class="pre">Callable</span></code>[[<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>], <a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span>) – The metric whose value you wish to minimize or maximize, which takes
two tensors and returns a scalar.</p></li>
<li><p><strong>reference_metric</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a> | <code class="xref py py-class docutils literal notranslate"><span class="pre">Callable</span></code>[[<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>], <a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span>) – The metric whose value you wish to keep fixed, which takes two tensors
and returns a scalar.</p></li>
<li><p><strong>minmax</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Literal</span></code>[<code class="docutils literal notranslate"><span class="pre">'min'</span></code>, <code class="docutils literal notranslate"><span class="pre">'max'</span></code>]</span>) – Whether you wish to minimize or maximize <code class="docutils literal notranslate"><span class="pre">optimized_metric</span></code>.</p></li>
<li><p><strong>metric_tradeoff_lambda</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Lambda to multiply by <code class="docutils literal notranslate"><span class="pre">reference_metric</span></code> loss and add to
<code class="docutils literal notranslate"><span class="pre">optimized_metric</span></code> loss. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, we pick a value so the two
initial losses are approximately equal in magnitude.</p></li>
<li><p><strong>range_penalty_lambda</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></span>) – Lambda to multiply by range penalty and add to loss.</p></li>
<li><p><strong>allowable_range</strong> – Range (inclusive) of allowed pixel values. Any values outside this
range will be penalized.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="plenoptic.synthesize.mad_competition.MADCompetition.mad_image">
<span class="sig-name descname"><span class="pre">mad_image</span></span><a class="headerlink" href="#plenoptic.synthesize.mad_competition.MADCompetition.mad_image" title="Link to this definition"></a></dt>
<dd><p>The Maximally-Differentiating Image. This may be unfinished depending
on how many iterations we’ve run for.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.7)">torch.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="plenoptic.synthesize.mad_competition.MADCompetition.initial_image">
<span class="sig-name descname"><span class="pre">initial_image</span></span><a class="headerlink" href="#plenoptic.synthesize.mad_competition.MADCompetition.initial_image" title="Link to this definition"></a></dt>
<dd><p>The initial <code class="docutils literal notranslate"><span class="pre">mad_image</span></code>, which we obtain by adding Gaussian noise to
<code class="docutils literal notranslate"><span class="pre">image</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.7)">torch.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="plenoptic.synthesize.mad_competition.MADCompetition.losses">
<span class="sig-name descname"><span class="pre">losses</span></span><a class="headerlink" href="#plenoptic.synthesize.mad_competition.MADCompetition.losses" title="Link to this definition"></a></dt>
<dd><p>A list of the objective function’s loss over iterations.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="plenoptic.synthesize.mad_competition.MADCompetition.gradient_norm">
<span class="sig-name descname"><span class="pre">gradient_norm</span></span><a class="headerlink" href="#plenoptic.synthesize.mad_competition.MADCompetition.gradient_norm" title="Link to this definition"></a></dt>
<dd><p>A list of the gradient’s L2 norm over iterations.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="plenoptic.synthesize.mad_competition.MADCompetition.pixel_change_norm">
<span class="sig-name descname"><span class="pre">pixel_change_norm</span></span><a class="headerlink" href="#plenoptic.synthesize.mad_competition.MADCompetition.pixel_change_norm" title="Link to this definition"></a></dt>
<dd><p>A list containing the L2 norm of the pixel change over iterations
(<code class="docutils literal notranslate"><span class="pre">pixel_change_norm[i]</span></code> is the pixel change norm in
<code class="docutils literal notranslate"><span class="pre">mad_image</span></code> between iterations <code class="docutils literal notranslate"><span class="pre">i</span></code> and <code class="docutils literal notranslate"><span class="pre">i-1</span></code>).</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="plenoptic.synthesize.mad_competition.MADCompetition.optimized_metric_loss">
<span class="sig-name descname"><span class="pre">optimized_metric_loss</span></span><a class="headerlink" href="#plenoptic.synthesize.mad_competition.MADCompetition.optimized_metric_loss" title="Link to this definition"></a></dt>
<dd><p>A list of the <code class="docutils literal notranslate"><span class="pre">optimized_metric</span></code> loss over iterations.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="plenoptic.synthesize.mad_competition.MADCompetition.reference_metric_loss">
<span class="sig-name descname"><span class="pre">reference_metric_loss</span></span><a class="headerlink" href="#plenoptic.synthesize.mad_competition.MADCompetition.reference_metric_loss" title="Link to this definition"></a></dt>
<dd><p>A list of the <code class="docutils literal notranslate"><span class="pre">reference_metric</span></code> loss over iterations.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="plenoptic.synthesize.mad_competition.MADCompetition.saved_mad_image">
<span class="sig-name descname"><span class="pre">saved_mad_image</span></span><a class="headerlink" href="#plenoptic.synthesize.mad_competition.MADCompetition.saved_mad_image" title="Link to this definition"></a></dt>
<dd><p>Saved <code class="docutils literal notranslate"><span class="pre">self.mad_image</span></code> for later examination.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.7)">torch.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r457fcb70e19f-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id9">1</a><span class="fn-bracket">]</span></span>
<p>Wang, Z., &amp; Simoncelli, E. P. (2008). Maximum differentiation (MAD)
competition: A methodology for comparing computational models of
perceptual discriminability. Journal of Vision, 8(12), 1–13.
<a class="reference external" href="https://dx.doi.org/10.1167/8.12.8">https://dx.doi.org/10.1167/8.12.8</a></p>
</div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Attributes<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>allowed_range</strong></dt><dd></dd>
<dt><a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition.gradient_norm" title="plenoptic.synthesize.mad_competition.MADCompetition.gradient_norm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient_norm</span></code></a></dt><dd><p>Synthesis gradient’s L2 norm over iterations.</p>
</dd>
<dt><strong>image</strong></dt><dd></dd>
<dt><strong>initial_image</strong></dt><dd></dd>
<dt><a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition.losses" title="plenoptic.synthesize.mad_competition.MADCompetition.losses"><code class="xref py py-obj docutils literal notranslate"><span class="pre">losses</span></code></a></dt><dd><p>Synthesis loss over iterations.</p>
</dd>
<dt><strong>mad_image</strong></dt><dd></dd>
<dt><strong>metric_tradeoff_lambda</strong></dt><dd></dd>
<dt><strong>minmax</strong></dt><dd></dd>
<dt><strong>optimized_metric</strong></dt><dd></dd>
<dt><strong>optimized_metric_loss</strong></dt><dd></dd>
<dt><strong>optimizer</strong></dt><dd></dd>
<dt><a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition.pixel_change_norm" title="plenoptic.synthesize.mad_competition.MADCompetition.pixel_change_norm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">pixel_change_norm</span></code></a></dt><dd><p>L2 norm change in pixel values over iterations.</p>
</dd>
<dt><strong>range_penalty_lambda</strong></dt><dd></dd>
<dt><strong>reference_metric</strong></dt><dd></dd>
<dt><strong>reference_metric_loss</strong></dt><dd></dd>
<dt><strong>saved_mad_image</strong></dt><dd></dd>
<dt><strong>scheduler</strong></dt><dd></dd>
<dt><strong>store_progress</strong></dt><dd></dd>
</dl>
</dd>
</dl>
<p class="rubric">Methods</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition.load" title="plenoptic.synthesize.mad_competition.MADCompetition.load"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load</span></code></a>(file_path[, map_location, ...])</p></td>
<td><p>Load all relevant stuff from a .pt file.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition.objective_function" title="plenoptic.synthesize.mad_competition.MADCompetition.objective_function"><code class="xref py py-obj docutils literal notranslate"><span class="pre">objective_function</span></code></a>([mad_image, image])</p></td>
<td><p>Compute the MADCompetition synthesis loss.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition.save" title="plenoptic.synthesize.mad_competition.MADCompetition.save"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save</span></code></a>(file_path)</p></td>
<td><p>Save all relevant variables in .pt file.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition.setup" title="plenoptic.synthesize.mad_competition.MADCompetition.setup"><code class="xref py py-obj docutils literal notranslate"><span class="pre">setup</span></code></a>([initial_noise, optimizer, ...])</p></td>
<td><p>Initialize the MAD image, optimizer, and scheduler.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition.synthesize" title="plenoptic.synthesize.mad_competition.MADCompetition.synthesize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">synthesize</span></code></a>([max_iter, store_progress, ...])</p></td>
<td><p>Synthesize a MAD image.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#id17" title="plenoptic.synthesize.mad_competition.MADCompetition.to"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to</span></code></a>(*args, **kwargs)</p></td>
<td><p>Moves and/or casts the parameters and buffers.</p></td>
</tr>
</tbody>
</table>
<dl class="py property">
<dt class="sig sig-object py" id="plenoptic.synthesize.mad_competition.MADCompetition.image">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">image</span></span><a class="headerlink" href="#plenoptic.synthesize.mad_competition.MADCompetition.image" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="id10">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">initial_image</span></span><a class="headerlink" href="#id10" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="plenoptic.synthesize.mad_competition.MADCompetition.load">
<span class="sig-name descname"><span class="pre">load</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">map_location</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensor_equality_atol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-08</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensor_equality_rtol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">pickle_load_args</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/mad_competition.html#MADCompetition.load"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.mad_competition.MADCompetition.load" title="Link to this definition"></a></dt>
<dd><p>Load all relevant stuff from a .pt file.</p>
<p>This must be called by a <code class="docutils literal notranslate"><span class="pre">MADCompetition</span></code> object initialized just like the
saved object.</p>
<p>Note this operates in place and so doesn’t return anything.</p>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 1.2: </span>load behavior changed in a backwards-incompatible manner in order to
compatible with breaking changes in torch 2.6.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>file_path</strong> (<em>str</em>) – The path to load the synthesis object from</p></li>
<li><p><strong>map_location</strong> (<em>str</em><em>, </em><em>optional</em>) – map_location argument to pass to <code class="docutils literal notranslate"><span class="pre">torch.load</span></code>. If you save
stuff that was being run on a GPU and are loading onto a
CPU, you’ll need this to make sure everything lines up
properly. This should be structured like the str you would
pass to <code class="docutils literal notranslate"><span class="pre">torch.device</span></code></p></li>
<li><p><strong>tensor_equality_atol</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></span>) – Absolute tolerance to use when checking for tensor equality during load,
passed to <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.allclose.html#torch.allclose" title="(in PyTorch v2.7)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.allclose()</span></code></a>. It may be necessary to increase if you are
saving and loading on two machines with torch built by different cuda
versions. Be careful when changing this! See
<a class="reference external" href="https://docs.pytorch.org/docs/stable/type_info.html#torch.torch.finfo" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.finfo</span></code></a> for more details about floating
point precision of different data types (especially, <code class="docutils literal notranslate"><span class="pre">eps</span></code>); if you have
to increase this by more than 1 or 2 decades, then you are probably not
dealing with a numerical issue.</p></li>
<li><p><strong>tensor_equality_rtol</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></span>) – Relative tolerance to use when checking for tensor equality during load,
passed to <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.allclose.html#torch.allclose" title="(in PyTorch v2.7)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.allclose()</span></code></a>. It may be necessary to increase if you are
saving and loading on two machines with torch built by different cuda
versions. Be careful when changing this! See
<a class="reference external" href="https://docs.pytorch.org/docs/stable/type_info.html#torch.torch.finfo" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.finfo</span></code></a> for more details about floating
point precision of different data types (especially, <code class="docutils literal notranslate"><span class="pre">eps</span></code>); if you have
to increase this by more than 1 or 2 decades, then you are probably not
dealing with a numerical issue.</p></li>
<li><p><strong>pickle_load_args</strong> – any additional kwargs will be added to <code class="docutils literal notranslate"><span class="pre">pickle_module.load</span></code> via
<code class="docutils literal notranslate"><span class="pre">torch.load</span></code>, see that function’s docstring for details.</p></li>
</ul>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">examine_saved_synthesis</span></code></dt><dd><p>Examine metadata from saved object: pytorch and plenoptic versions, name of the synthesis object, shapes of tensors, etc.</p>
</dd>
</dl>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">plenoptic</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">po</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">einstein</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span><span class="w"> </span><span class="nf">ds_ssim</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="gp">... </span>   <span class="k">return</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">po</span><span class="o">.</span><span class="n">metric</span><span class="o">.</span><span class="n">ssim</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mad</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">synth</span><span class="o">.</span><span class="n">MADCompetition</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">po</span><span class="o">.</span><span class="n">metric</span><span class="o">.</span><span class="n">mse</span><span class="p">,</span> <span class="n">ds_ssim</span><span class="p">,</span> <span class="s2">&quot;min&quot;</span><span class="p">,</span>
<span class="gp">... </span>                              <span class="n">metric_tradeoff_lambda</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mad</span><span class="o">.</span><span class="n">synthesize</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">store_progress</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mad</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;mad.pt&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mad_copy</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">synth</span><span class="o">.</span><span class="n">MADCompetition</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">po</span><span class="o">.</span><span class="n">metric</span><span class="o">.</span><span class="n">mse</span><span class="p">,</span> <span class="n">ds_ssim</span><span class="p">,</span> <span class="s2">&quot;min&quot;</span><span class="p">,</span>
<span class="gp">... </span>                                   <span class="n">metric_tradeoff_lambda</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mad_copy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;mad.pt&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="id11">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">mad_image</span></span><a class="headerlink" href="#id11" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="plenoptic.synthesize.mad_competition.MADCompetition.metric_tradeoff_lambda">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">metric_tradeoff_lambda</span></span><a class="headerlink" href="#plenoptic.synthesize.mad_competition.MADCompetition.metric_tradeoff_lambda" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="plenoptic.synthesize.mad_competition.MADCompetition.minmax">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">minmax</span></span><a class="headerlink" href="#plenoptic.synthesize.mad_competition.MADCompetition.minmax" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="plenoptic.synthesize.mad_competition.MADCompetition.objective_function">
<span class="sig-name descname"><span class="pre">objective_function</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mad_image</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">image</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/mad_competition.html#MADCompetition.objective_function"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.mad_competition.MADCompetition.objective_function" title="Link to this definition"></a></dt>
<dd><p>Compute the MADCompetition synthesis loss.</p>
<p>This computes:</p>
<div class="math notranslate nohighlight">
\[\begin{split}t L_1(x, \hat{x}) &amp;+ \lambda_1 [L_2(x, x+\epsilon) - L_2(x, \hat{x})]^2 \\
                  &amp;+ \lambda_2 \mathcal{B}(\hat{x})\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(t\)</span> is 1 if <code class="docutils literal notranslate"><span class="pre">self.minmax</span></code> is <code class="docutils literal notranslate"><span class="pre">'min'</span></code> and -1
if it’s <code class="docutils literal notranslate"><span class="pre">'max'</span></code>, <span class="math notranslate nohighlight">\(L_1\)</span> is <code class="docutils literal notranslate"><span class="pre">self.optimized_metric</span></code>,
<span class="math notranslate nohighlight">\(L_2\)</span> is <code class="docutils literal notranslate"><span class="pre">self.reference_metric</span></code>, <span class="math notranslate nohighlight">\(x\)</span> is
<code class="docutils literal notranslate"><span class="pre">self.image</span></code>, <span class="math notranslate nohighlight">\(\hat{x}\)</span> is <code class="docutils literal notranslate"><span class="pre">self.mad_image</span></code>,
<span class="math notranslate nohighlight">\(\epsilon\)</span> is the initial noise, <span class="math notranslate nohighlight">\(\mathcal{B}\)</span> is the
quadratic bound penalty, <span class="math notranslate nohighlight">\(\lambda_1\)</span> is
<code class="docutils literal notranslate"><span class="pre">self.metric_tradeoff_lambda</span></code> and <span class="math notranslate nohighlight">\(\lambda_2\)</span> is
<code class="docutils literal notranslate"><span class="pre">self.range_penalty_lambda</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mad_image</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Proposed <code class="docutils literal notranslate"><span class="pre">mad_image</span></code>, <span class="math notranslate nohighlight">\(\hat{x}\)</span> in the above equation. If
None, use <code class="docutils literal notranslate"><span class="pre">self.mad_image</span></code>.</p></li>
<li><p><strong>image</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Proposed <code class="docutils literal notranslate"><span class="pre">image</span></code>, <span class="math notranslate nohighlight">\(x\)</span> in the above equation. If
None, use <code class="docutils literal notranslate"><span class="pre">self.image</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>loss</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="plenoptic.synthesize.mad_competition.MADCompetition.optimized_metric">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">optimized_metric</span></span><a class="headerlink" href="#plenoptic.synthesize.mad_competition.MADCompetition.optimized_metric" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="id12">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">optimized_metric_loss</span></span><a class="headerlink" href="#id12" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="plenoptic.synthesize.mad_competition.MADCompetition.reference_metric">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">reference_metric</span></span><a class="headerlink" href="#plenoptic.synthesize.mad_competition.MADCompetition.reference_metric" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="id13">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">reference_metric_loss</span></span><a class="headerlink" href="#id13" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="plenoptic.synthesize.mad_competition.MADCompetition.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/mad_competition.html#MADCompetition.save"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.mad_competition.MADCompetition.save" title="Link to this definition"></a></dt>
<dd><p>Save all relevant variables in .pt file.</p>
<p>Note that if store_progress is True, this will probably be very
large.</p>
<p>See <code class="docutils literal notranslate"><span class="pre">load</span></code> docstring for an example of use.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>file_path</strong> (<em>str</em>) – The path to save the MADCompetition object to</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="id14">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">saved_mad_image</span></span><a class="headerlink" href="#id14" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="plenoptic.synthesize.mad_competition.MADCompetition.setup">
<span class="sig-name descname"><span class="pre">setup</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">initial_noise</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scheduler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scheduler_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/mad_competition.html#MADCompetition.setup"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.mad_competition.MADCompetition.setup" title="Link to this definition"></a></dt>
<dd><p>Initialize the MAD image, optimizer, and scheduler.</p>
<p>Can only be called once. If <code class="docutils literal notranslate"><span class="pre">load()</span></code> has been called, <code class="docutils literal notranslate"><span class="pre">initial_noise</span></code> must
be None.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>initial_noise</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – <code class="docutils literal notranslate"><span class="pre">mad_image</span></code> is initialized to <code class="docutils literal notranslate"><span class="pre">self.image</span> <span class="pre">+</span> <span class="pre">initial_noise</span> <span class="pre">*</span>
<span class="pre">torch.randn_like(self.image)</span></code>, so this gives the standard deviation of the
Gaussian noise. If None, we use a value of 0.1.</p></li>
<li><p><strong>optimizer</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code></a> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – The un-initialized optimizer object to use. If None, we use Adam.</p></li>
<li><p><strong>optimizer_kwargs</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – The keyword arguments to pass to the optimizer on initialization. If None,
we use {“lr”: .01} and, if optimizer is None, {“amsgrad”: True}</p></li>
<li><p><strong>scheduler</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.LRScheduler.html#torch.optim.lr_scheduler.LRScheduler" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">LRScheduler</span></code></a> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – The learning rate scheduler to use. If None, we don’t use one.</p></li>
<li><p><strong>scheduler_kwargs</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – The keyword arguments to pass to the scheduler on initialization.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>Set initial noise:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">plenoptic</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">po</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">einstein</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mad</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">synth</span><span class="o">.</span><span class="n">MADCompetition</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">:</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">po</span><span class="o">.</span><span class="n">metric</span><span class="o">.</span><span class="n">ssim</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span>
<span class="gp">... </span>                              <span class="n">po</span><span class="o">.</span><span class="n">metric</span><span class="o">.</span><span class="n">mse</span><span class="p">,</span> <span class="s2">&quot;min&quot;</span><span class="p">,</span>
<span class="gp">... </span>                              <span class="n">metric_tradeoff_lambda</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mad</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mad</span><span class="o">.</span><span class="n">synthesize</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
<p>Set optimizer:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">plenoptic</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">po</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">einstein</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mad</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">synth</span><span class="o">.</span><span class="n">MADCompetition</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">:</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">po</span><span class="o">.</span><span class="n">metric</span><span class="o">.</span><span class="n">ssim</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span>
<span class="gp">... </span>                              <span class="n">po</span><span class="o">.</span><span class="n">metric</span><span class="o">.</span><span class="n">mse</span><span class="p">,</span> <span class="s2">&quot;min&quot;</span><span class="p">,</span>
<span class="gp">... </span>                              <span class="n">metric_tradeoff_lambda</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mad</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">,</span> <span class="n">optimizer_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">})</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mad</span><span class="o">.</span><span class="n">synthesize</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
<p>Use with save/load. Only the optimizer object is necessary, its kwargs and the
initial noise are handled by load.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">plenoptic</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">po</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">einstein</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mad</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">synth</span><span class="o">.</span><span class="n">MADCompetition</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">:</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">po</span><span class="o">.</span><span class="n">metric</span><span class="o">.</span><span class="n">ssim</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span>
<span class="gp">... </span>                              <span class="n">po</span><span class="o">.</span><span class="n">metric</span><span class="o">.</span><span class="n">mse</span><span class="p">,</span> <span class="s2">&quot;min&quot;</span><span class="p">,</span>
<span class="gp">... </span>                              <span class="n">metric_tradeoff_lambda</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mad</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">,</span> <span class="n">optimizer_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">})</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mad</span><span class="o">.</span><span class="n">synthesize</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mad</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;mad_setup.pt&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mad</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">synth</span><span class="o">.</span><span class="n">MADCompetition</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">:</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">po</span><span class="o">.</span><span class="n">metric</span><span class="o">.</span><span class="n">ssim</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span>
<span class="gp">... </span>                              <span class="n">po</span><span class="o">.</span><span class="n">metric</span><span class="o">.</span><span class="n">mse</span><span class="p">,</span> <span class="s2">&quot;min&quot;</span><span class="p">,</span>
<span class="gp">... </span>                              <span class="n">metric_tradeoff_lambda</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mad</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;mad_setup.pt&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mad</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mad</span><span class="o">.</span><span class="n">synthesize</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="plenoptic.synthesize.mad_competition.MADCompetition.synthesize">
<span class="sig-name descname"><span class="pre">synthesize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">store_progress</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop_criterion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop_iters_to_check</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">50</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/mad_competition.html#MADCompetition.synthesize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.mad_competition.MADCompetition.synthesize" title="Link to this definition"></a></dt>
<dd><p>Synthesize a MAD image.</p>
<p>Update the pixels of <code class="docutils literal notranslate"><span class="pre">initial_image</span></code> to maximize or minimize
(depending on the value of <code class="docutils literal notranslate"><span class="pre">minmax</span></code>) the value of
<code class="docutils literal notranslate"><span class="pre">optimized_metric(image,</span> <span class="pre">mad_image)</span></code> while keeping the value of
<code class="docutils literal notranslate"><span class="pre">reference_metric(image,</span> <span class="pre">mad_image)</span></code> constant.</p>
<p>We run this until either we reach <code class="docutils literal notranslate"><span class="pre">max_iter</span></code> or the change over the
past <code class="docutils literal notranslate"><span class="pre">stop_iters_to_check</span></code> iterations is less than
<code class="docutils literal notranslate"><span class="pre">stop_criterion</span></code>, whichever comes first</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>max_iter</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – The maximum number of iterations to run before we end synthesis
(unless we hit the stop criterion).</p></li>
<li><p><strong>store_progress</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code> | <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – Whether we should store the MAD image in progress during synthesis. If
False, we don’t save anything. If True, we save every iteration. If an int,
we save every <code class="docutils literal notranslate"><span class="pre">store_progress</span></code> iterations (note then that 0 is the same as
False and 1 the same as True).</p></li>
<li><p><strong>stop_criterion</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></span>) – If the loss over the past <code class="docutils literal notranslate"><span class="pre">stop_iters_to_check</span></code> has changed
less than <code class="docutils literal notranslate"><span class="pre">stop_criterion</span></code>, we terminate synthesis.</p></li>
<li><p><strong>stop_iters_to_check</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – How many iterations back to check in order to see if the
loss has stopped decreasing (for <code class="docutils literal notranslate"><span class="pre">stop_criterion</span></code>).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="plenoptic.synthesize.mad_competition.MADCompetition.to">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/mad_competition.html#MADCompetition.to"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.mad_competition.MADCompetition.to" title="Link to this definition"></a></dt>
<dd><p>Moves and/or casts the parameters and buffers.</p>
<p>This can be called as</p>
<dl class="py function">
<dt class="sig sig-object py" id="id15">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">non_blocking</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/mad_competition.html#MADCompetition.to"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id15" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="id16">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dtype</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">non_blocking</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/mad_competition.html#MADCompetition.to"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id16" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="id17">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">non_blocking</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/mad_competition.html#MADCompetition.to"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id17" title="Link to this definition"></a></dt>
<dd></dd></dl>

<p>Its signature is similar to <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.Tensor.to.html#torch.Tensor.to" title="(in PyTorch v2.7)"><code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.Tensor.to()</span></code></a>, but only accepts
floating point desired <code class="xref py py-attr docutils literal notranslate"><span class="pre">dtype</span></code> s. In addition, this method will
only cast the floating point parameters and buffers to <code class="xref py py-attr docutils literal notranslate"><span class="pre">dtype</span></code>
(if given). The integral parameters and buffers will be moved
<code class="xref py py-attr docutils literal notranslate"><span class="pre">device</span></code>, if that is given, but with dtypes unchanged. When
<code class="xref py py-attr docutils literal notranslate"><span class="pre">non_blocking</span></code> is set, it tries to convert/move asynchronously
with respect to the host if possible, e.g., moving CPU Tensors with
pinned memory to CUDA devices.</p>
<p>See below for examples.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt>device (<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.device</span></code></a>): the desired device of the parameters</dt><dd><p>and buffers in this module</p>
</dd>
<dt>dtype (<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensor_attributes.html#torch.dtype" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.dtype</span></code></a>): the desired floating point type of</dt><dd><p>the floating point parameters and buffers in this module</p>
</dd>
<dt>tensor (torch.Tensor): Tensor whose dtype and device are the desired</dt><dd><p>dtype and device for all parameters and buffers in this module</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="plenoptic.synthesize.mad_competition.animate">
<span class="sig-prename descclassname"><span class="pre">plenoptic.synthesize.mad_competition.</span></span><span class="sig-name descname"><span class="pre">animate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mad</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">framerate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">channel_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">zoom</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fig</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axes_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">figsize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">included_plots</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">['display_mad_image',</span> <span class="pre">'plot_loss',</span> <span class="pre">'plot_pixel_values']</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">width_ratios</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/mad_competition.html#animate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.mad_competition.animate" title="Link to this definition"></a></dt>
<dd><p>Animate synthesis progress.</p>
<p>This is essentially the figure produced by
<code class="docutils literal notranslate"><span class="pre">mad.plot_synthesis_status</span></code> animated over time, for each stored
iteration.</p>
<p>This functions returns a matplotlib FuncAnimation object. See our documentation
(e.g.,
[Quickstart](<a class="reference external" href="https://docs.plenoptic.org/docs/branch/main/tutorials/00_quickstart.html">https://docs.plenoptic.org/docs/branch/main/tutorials/00_quickstart.html</a>))
for examples on how to view it in a Jupyter notebook. In order to save, use
<code class="docutils literal notranslate"><span class="pre">anim.save(filename)</span></code>. In either case, this can take a while and you’ll need the
appropriate writer installed and on your path, e.g., ffmpeg, imagemagick, etc). See
[matplotlib documentation](<a class="reference external" href="https://matplotlib.org/stable/api/animation_api.html">https://matplotlib.org/stable/api/animation_api.html</a>) for
more details.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mad</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition" title="plenoptic.synthesize.mad_competition.MADCompetition"><code class="xref py py-class docutils literal notranslate"><span class="pre">MADCompetition</span></code></a></span>) – MADCompetition object whose synthesis we want to animate.</p></li>
<li><p><strong>framerate</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – How many frames a second to display.</p></li>
<li><p><strong>batch_idx</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – Which index to take from the batch dimension</p></li>
<li><p><strong>channel_idx</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Which index to take from the channel dimension. If None, we use all
channels (assumed use-case is RGB(A) image).</p></li>
<li><p><strong>zoom</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – How much to zoom in / enlarge the synthesized image, the ratio
of display pixels to image pixels. If None (the default), we
attempt to find the best value ourselves.</p></li>
<li><p><strong>fig</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">Figure</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – If None, create the figure from scratch. Else, should be an empty
figure with enough axes (the expected use here is have same-size
movies with different plots).</p></li>
<li><p><strong>axes_idx</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]</span>) – Dictionary specifying which axes contains which type of plot, allows
for more fine-grained control of the resulting figure. Probably only
helpful if fig is also defined. Possible keys: <code class="docutils literal notranslate"><span class="pre">'mad_image',</span>
<span class="pre">'loss',</span> <span class="pre">'pixel_values',</span> <span class="pre">'misc'</span></code>. Values should all be ints. If you
tell this function to create a plot that doesn’t have a corresponding
key, we find the lowest int that is not already in the dict, so if you
have axes that you want unchanged, place their idx in <code class="docutils literal notranslate"><span class="pre">'misc'</span></code>.</p></li>
<li><p><strong>figsize</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>] | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – The size of the figure to create. It may take a little bit of
playing around to find a reasonable value. If None, we attempt to
make our best guess, aiming to have each axis be of size (5, 5)</p></li>
<li><p><strong>width_ratios</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>]</span>) – By default, all plots axes will have the same width. To change
that, specify their relative widths using the keys:
[‘display_mad_image’, ‘plot_loss’, ‘plot_pixel_values’] and floats
specifying their relative width. Any not included will be assumed to be
1.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The animation object. In order to view, must convert to HTML
or save.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>anim</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>By default, we use the ffmpeg backend, which requires that you have
ffmpeg installed and on your path (<a class="reference external" href="https://ffmpeg.org/download.html">https://ffmpeg.org/download.html</a>).
To use a different, use the matplotlib rcParams:
<cite>matplotlib.rcParams[‘animation.writer’] = writer</cite>, see
<a class="reference external" href="https://matplotlib.org/stable/api/animation_api.html#writer-classes">https://matplotlib.org/stable/api/animation_api.html#writer-classes</a> for
more details.</p>
<p>For displaying in a jupyter notebook, ffmpeg appears to be required.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="plenoptic.synthesize.mad_competition.display_mad_image">
<span class="sig-prename descclassname"><span class="pre">plenoptic.synthesize.mad_competition.</span></span><span class="sig-name descname"><span class="pre">display_mad_image</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mad</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">channel_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">zoom</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">title</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'MADCompetition'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/mad_competition.html#display_mad_image"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.mad_competition.display_mad_image" title="Link to this definition"></a></dt>
<dd><p>Display MAD image.</p>
<p>You can specify what iteration to view by using the <code class="docutils literal notranslate"><span class="pre">iteration</span></code> arg.
The default, <code class="docutils literal notranslate"><span class="pre">None</span></code>, shows the final one.</p>
<p>We use <code class="docutils literal notranslate"><span class="pre">plenoptic.imshow</span></code> to display the synthesized image and attempt to
automatically find the most reasonable zoom value. You can override this
value using the zoom arg, but remember that <code class="docutils literal notranslate"><span class="pre">plenoptic.imshow</span></code> is
opinionated about the size of the resulting image and will throw an
Exception if the axis created is not big enough for the selected zoom.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mad</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition" title="plenoptic.synthesize.mad_competition.MADCompetition"><code class="xref py py-class docutils literal notranslate"><span class="pre">MADCompetition</span></code></a></span>) – MADCompetition object whose MAD image we want to display.</p></li>
<li><p><strong>batch_idx</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – Which index to take from the batch dimension</p></li>
<li><p><strong>channel_idx</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Which index to take from the channel dimension. If None, we assume
image is RGB(A) and show all channels.</p></li>
<li><p><strong>zoom</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – How much to zoom in / enlarge the synthesized image, the ratio
of display pixels to image pixels. If None (the default), we
attempt to find the best value ourselves.</p></li>
<li><p><strong>iteration</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Which iteration to display. If None, the default, we show
the most recent one. Negative values are also allowed.</p></li>
<li><p><strong>ax</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">Axes</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Pre-existing axes for plot. If None, we call <code class="docutils literal notranslate"><span class="pre">plt.gca()</span></code>.</p></li>
<li><p><strong>title</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></span>) – Title of the axis.</p></li>
<li><p><strong>kwargs</strong> – Passed to <code class="docutils literal notranslate"><span class="pre">plenoptic.imshow</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The matplotlib axes containing the plot.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>ax</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="plenoptic.synthesize.mad_competition.display_mad_image_all">
<span class="sig-prename descclassname"><span class="pre">plenoptic.synthesize.mad_competition.</span></span><span class="sig-name descname"><span class="pre">display_mad_image_all</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mad_metric1_min</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mad_metric2_min</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mad_metric1_max</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mad_metric2_max</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric1_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric2_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">zoom</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/mad_competition.html#display_mad_image_all"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.mad_competition.display_mad_image_all" title="Link to this definition"></a></dt>
<dd><p>Display all MAD Competition images.</p>
<p>To generate a full set of MAD Competition images, you need four instances:
one for minimizing and maximizing each metric. This helper function creates
a figure to display the full set of images.</p>
<p>In addition to the four MAD Competition images, this also plots the initial
image from <cite>mad_metric1_min</cite>, for comparison.</p>
<p>Note that all four MADCompetition instances must have the same
<cite>image</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mad_metric1_min</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition" title="plenoptic.synthesize.mad_competition.MADCompetition"><code class="xref py py-class docutils literal notranslate"><span class="pre">MADCompetition</span></code></a></span>) – MADCompetition object that minimized the first metric.</p></li>
<li><p><strong>mad_metric2_min</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition" title="plenoptic.synthesize.mad_competition.MADCompetition"><code class="xref py py-class docutils literal notranslate"><span class="pre">MADCompetition</span></code></a></span>) – MADCompetition object that minimized the second metric.</p></li>
<li><p><strong>mad_metric1_max</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition" title="plenoptic.synthesize.mad_competition.MADCompetition"><code class="xref py py-class docutils literal notranslate"><span class="pre">MADCompetition</span></code></a></span>) – MADCompetition object that maximized the first metric.</p></li>
<li><p><strong>mad_metric2_max</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition" title="plenoptic.synthesize.mad_competition.MADCompetition"><code class="xref py py-class docutils literal notranslate"><span class="pre">MADCompetition</span></code></a></span>) – MADCompetition object that maximized the second metric.</p></li>
<li><p><strong>metric1_name</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Name of the first metric. If None, we use the name of the
<cite>optimized_metric</cite> function from <cite>mad_metric1_min</cite>.</p></li>
<li><p><strong>metric2_name</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Name of the second metric. If None, we use the name of the
<cite>optimized_metric</cite> function from <cite>mad_metric2_min</cite>.</p></li>
<li><p><strong>zoom</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code> | <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></span>) – Ratio of display pixels to image pixels. See <cite>plenoptic.imshow</cite> for
details.</p></li>
<li><p><strong>kwargs</strong> – Passed to <cite>plenoptic.imshow</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Figure containing the images.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>fig</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="plenoptic.synthesize.mad_competition.plot_loss">
<span class="sig-prename descclassname"><span class="pre">plenoptic.synthesize.mad_competition.</span></span><span class="sig-name descname"><span class="pre">plot_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mad</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/mad_competition.html#plot_loss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.mad_competition.plot_loss" title="Link to this definition"></a></dt>
<dd><p>Plot metric losses.</p>
<p>Plots <code class="docutils literal notranslate"><span class="pre">mad.optimized_metric_loss</span></code> and <code class="docutils literal notranslate"><span class="pre">mad.reference_metric_loss</span></code> on two
separate axes, over all iterations. Also plots a red dot at <code class="docutils literal notranslate"><span class="pre">iteration</span></code>,
to highlight the loss there. If <code class="docutils literal notranslate"><span class="pre">iteration=None</span></code>, then the dot will be at
the final iteration.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mad</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition" title="plenoptic.synthesize.mad_competition.MADCompetition"><code class="xref py py-class docutils literal notranslate"><span class="pre">MADCompetition</span></code></a></span>) – MADCompetition object whose loss we want to plot.</p></li>
<li><p><strong>iteration</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Which iteration to display. If None, the default, we show
the most recent one. Negative values are also allowed.</p></li>
<li><p><strong>axes</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Axes</span></code>] | <code class="xref py py-class docutils literal notranslate"><span class="pre">Axes</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Pre-existing axes for plot. If a list of axes, must be the two axes to
use for this plot. If a single axis, we’ll split it in half
horizontally. If None, we call <code class="docutils literal notranslate"><span class="pre">plt.gca()</span></code>.</p></li>
<li><p><strong>kwargs</strong> – passed to plt.plot</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The matplotlib axes containing the plot.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>axes</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>We plot <code class="docutils literal notranslate"><span class="pre">abs(mad.losses)</span></code> because if we’re maximizing the synthesis
metric, we minimized its negative. By plotting the absolute value, we get
them all on the same scale.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="plenoptic.synthesize.mad_competition.plot_loss_all">
<span class="sig-prename descclassname"><span class="pre">plenoptic.synthesize.mad_competition.</span></span><span class="sig-name descname"><span class="pre">plot_loss_all</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mad_metric1_min</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mad_metric2_min</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mad_metric1_max</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mad_metric2_max</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric1_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric2_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric1_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{'c':</span> <span class="pre">'C0'}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric2_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{'c':</span> <span class="pre">'C1'}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{'linestyle':</span> <span class="pre">'--'}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{'linestyle':</span> <span class="pre">'-'}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">figsize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(10,</span> <span class="pre">5)</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/mad_competition.html#plot_loss_all"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.mad_competition.plot_loss_all" title="Link to this definition"></a></dt>
<dd><p>Plot loss for full set of MAD Competiton instances.</p>
<p>To generate a full set of MAD Competition images, you need four instances:
one for minimizing and maximizing each metric. This helper function creates
a two-axis figure to display the loss for this full set.</p>
<p>Note that all four MADCompetition instances must have the same
<cite>image</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mad_metric1_min</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition" title="plenoptic.synthesize.mad_competition.MADCompetition"><code class="xref py py-class docutils literal notranslate"><span class="pre">MADCompetition</span></code></a></span>) – MADCompetition object that minimized the first metric.</p></li>
<li><p><strong>mad_metric2_min</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition" title="plenoptic.synthesize.mad_competition.MADCompetition"><code class="xref py py-class docutils literal notranslate"><span class="pre">MADCompetition</span></code></a></span>) – MADCompetition object that minimized the second metric.</p></li>
<li><p><strong>mad_metric1_max</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition" title="plenoptic.synthesize.mad_competition.MADCompetition"><code class="xref py py-class docutils literal notranslate"><span class="pre">MADCompetition</span></code></a></span>) – MADCompetition object that maximized the first metric.</p></li>
<li><p><strong>mad_metric2_max</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition" title="plenoptic.synthesize.mad_competition.MADCompetition"><code class="xref py py-class docutils literal notranslate"><span class="pre">MADCompetition</span></code></a></span>) – MADCompetition object that maximized the second metric.</p></li>
<li><p><strong>metric1_name</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Name of the first metric. If None, we use the name of the
<cite>optimized_metric</cite> function from <cite>mad_metric1_min</cite>.</p></li>
<li><p><strong>metric2_name</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Name of the second metric. If None, we use the name of the
<cite>optimized_metric</cite> function from <cite>mad_metric2_min</cite>.</p></li>
<li><p><strong>metric1_kwargs</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></span>) – Dictionary of arguments to pass to <cite>matplotlib.pyplot.plot</cite> to identify
synthesis instance where the first metric was being optimized.</p></li>
<li><p><strong>metric2_kwargs</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></span>) – Dictionary of arguments to pass to <cite>matplotlib.pyplot.plot</cite> to identify
synthesis instance where the second metric was being optimized.</p></li>
<li><p><strong>min_kwargs</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></span>) – Dictionary of arguments to pass to <cite>matplotlib.pyplot.plot</cite> to identify
synthesis instance where <cite>optimized_metric</cite> was being minimized.</p></li>
<li><p><strong>max_kwargs</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></span>) – Dictionary of arguments to pass to <cite>matplotlib.pyplot.plot</cite> to identify
synthesis instance where <cite>optimized_metric</cite> was being maximized.</p></li>
<li><p><strong>figsize</strong> – Size of the figure we create.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Figure containing the plot.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>fig</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="plenoptic.synthesize.mad_competition.plot_pixel_values">
<span class="sig-prename descclassname"><span class="pre">plenoptic.synthesize.mad_competition.</span></span><span class="sig-name descname"><span class="pre">plot_pixel_values</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mad</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">channel_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ylim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/mad_competition.html#plot_pixel_values"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.mad_competition.plot_pixel_values" title="Link to this definition"></a></dt>
<dd><p>Plot histogram of pixel values of reference and MAD images.</p>
<p>As a way to check the distributions of pixel intensities and see
if there’s any values outside the allowed range</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mad</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition" title="plenoptic.synthesize.mad_competition.MADCompetition"><code class="xref py py-class docutils literal notranslate"><span class="pre">MADCompetition</span></code></a></span>) – MADCompetition object with the images whose pixel values we want to compare.</p></li>
<li><p><strong>batch_idx</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – Which index to take from the batch dimension</p></li>
<li><p><strong>channel_idx</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Which index to take from the channel dimension. If None, we use all
channels (assumed use-case is RGB(A) images).</p></li>
<li><p><strong>iteration</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Which iteration to display. If None, the default, we show
the most recent one. Negative values are also allowed.</p></li>
<li><p><strong>ylim</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>], <code class="xref py py-data docutils literal notranslate"><span class="pre">Literal</span></code>[<code class="docutils literal notranslate"><span class="pre">False</span></code>]]</span>) – if tuple, the ylimit to set for this axis. If False, we leave
it untouched</p></li>
<li><p><strong>ax</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">Axes</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Pre-existing axes for plot. If None, we call <code class="docutils literal notranslate"><span class="pre">plt.gca()</span></code>.</p></li>
<li><p><strong>kwargs</strong> – passed to plt.hist</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Creates axes.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>ax</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="plenoptic.synthesize.mad_competition.plot_synthesis_status">
<span class="sig-prename descclassname"><span class="pre">plenoptic.synthesize.mad_competition.</span></span><span class="sig-name descname"><span class="pre">plot_synthesis_status</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mad</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">channel_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vrange</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'indep1'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">zoom</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fig</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axes_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">figsize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">included_plots</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">['display_mad_image',</span> <span class="pre">'plot_loss',</span> <span class="pre">'plot_pixel_values']</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">width_ratios</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/mad_competition.html#plot_synthesis_status"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.mad_competition.plot_synthesis_status" title="Link to this definition"></a></dt>
<dd><p>Make a plot showing synthesis status.</p>
<p>We create several subplots to analyze this. By default, we create two
subplots on a new figure: the first one contains the MAD image and the
second contains the loss.</p>
<p>There is an optional additional plot: pixel_values, a histogram of pixel
values of the synthesized and target images.</p>
<p>All of these (including the default plots) can be toggled using their
corresponding boolean flags, and can be created separately using the
method with the name <cite>plot_{flag}</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mad</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition" title="plenoptic.synthesize.mad_competition.MADCompetition"><code class="xref py py-class docutils literal notranslate"><span class="pre">MADCompetition</span></code></a></span>) – MADCompetition object whose status we want to plot.</p></li>
<li><p><strong>batch_idx</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – Which index to take from the batch dimension</p></li>
<li><p><strong>channel_idx</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Which index to take from the channel dimension. If None, we use all
channels (assumed use-case is RGB(A) image).</p></li>
<li><p><strong>iteration</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Which iteration to display. If None, the default, we show
the most recent one. Negative values are also allowed.</p></li>
<li><p><strong>vrange</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>] | <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></span>) – The vrange option to pass to <code class="docutils literal notranslate"><span class="pre">display_mad_image()</span></code>. See
docstring of <code class="docutils literal notranslate"><span class="pre">imshow</span></code> for possible values.</p></li>
<li><p><strong>zoom</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – How much to zoom in / enlarge the synthesized image, the ratio
of display pixels to image pixels. If None (the default), we
attempt to find the best value ourselves.</p></li>
<li><p><strong>fig</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">Figure</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – if None, we create a new figure. otherwise we assume this is
an empty figure that has the appropriate size and number of
subplots</p></li>
<li><p><strong>axes_idx</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]</span>) – Dictionary specifying which axes contains which type of plot, allows
for more fine-grained control of the resulting figure. Probably only
helpful if fig is also defined. Possible keys: <code class="docutils literal notranslate"><span class="pre">'mad_image',</span>
<span class="pre">'loss',</span> <span class="pre">'pixel_values',</span> <span class="pre">'misc'</span></code>. Values should all be ints. If you
tell this function to create a plot that doesn’t have a corresponding
key, we find the lowest int that is not already in the dict, so if you
have axes that you want unchanged, place their idx in <code class="docutils literal notranslate"><span class="pre">'misc'</span></code>.</p></li>
<li><p><strong>figsize</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>] | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – The size of the figure to create. It may take a little bit of
playing around to find a reasonable value. If None, we attempt to
make our best guess, aiming to have each axis be of size (5, 5)</p></li>
<li><p><strong>included_plots</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]</span>) – Which plots to include. Must be some subset of <code class="docutils literal notranslate"><span class="pre">'display_mad_image',</span>
<span class="pre">'plot_loss',</span> <span class="pre">'plot_pixel_values'</span></code>.</p></li>
<li><p><strong>width_ratios</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>]</span>) – By default, all plots axes will have the same width. To change
that, specify their relative widths using the keys:
[‘display_mad_image’, ‘plot_loss’, ‘plot_pixel_values’] and floats
specifying their relative width. Any not included will be assumed to be
1.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Figure</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]]</span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><ul class="simple">
<li><p><em>fig</em> – The figure containing this plot</p></li>
<li><p><em>axes_idx</em> – Dictionary giving index of each plot.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-plenoptic.synthesize.metamer">
<span id="plenoptic-synthesize-metamer-module"></span><h2>plenoptic.synthesize.metamer module<a class="headerlink" href="#module-plenoptic.synthesize.metamer" title="Link to this heading"></a></h2>
<p>Synthesize model metamers.</p>
<dl class="py class">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.Metamer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">plenoptic.synthesize.metamer.</span></span><span class="sig-name descname"><span class="pre">Metamer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_function=&lt;function</span> <span class="pre">mse&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">range_penalty_lambda=0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">allowed_range=(0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">1)</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/metamer.html#Metamer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.metamer.Metamer" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#plenoptic.synthesize.synthesis.OptimizedSynthesis" title="plenoptic.synthesize.synthesis.OptimizedSynthesis"><code class="xref py py-class docutils literal notranslate"><span class="pre">OptimizedSynthesis</span></code></a></p>
<p>Synthesize metamers for image-computable differentiable models.</p>
<p>Following the basic idea in <a class="reference internal" href="#r868b9832577a-1" id="id18">[1]</a>, this class creates a metamer for a given model on
a given image. We iteratively adjust the pixel values so as to match the
representation of the <code class="docutils literal notranslate"><span class="pre">metamer</span></code> and <code class="docutils literal notranslate"><span class="pre">image</span></code>.</p>
<p>All <code class="docutils literal notranslate"><span class="pre">saved_</span></code> attributes are initialized as empty lists and will be
non-empty if the <code class="docutils literal notranslate"><span class="pre">store_progress</span></code> arg to <code class="docutils literal notranslate"><span class="pre">synthesize()</span></code> is not
<code class="docutils literal notranslate"><span class="pre">False</span></code>. They will be appended to on every iteration if
<code class="docutils literal notranslate"><span class="pre">store_progress=True</span></code> or every <code class="docutils literal notranslate"><span class="pre">store_progress</span></code> iterations if it’s an
<code class="docutils literal notranslate"><span class="pre">int</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>image</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – A tensor, this is the image whose representation we wish to
match.</p></li>
<li><p><strong>model</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a></span>) – A visual model, see <cite>Metamer</cite> notebook for more details</p></li>
<li><p><strong>loss_function</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">Callable</span></code>[[<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>], <a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span>) – the loss function to use to compare the representations of the models
in order to determine their loss.</p></li>
<li><p><strong>range_penalty_lambda</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></span>) – strength of the regularizer that enforces the allowed_range. Must be
non-negative.</p></li>
<li><p><strong>allowed_range</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>]</span>) – Range (inclusive) of allowed pixel values. Any values outside this
range will be penalized.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.Metamer.target_representation">
<span class="sig-name descname"><span class="pre">target_representation</span></span><a class="headerlink" href="#plenoptic.synthesize.metamer.Metamer.target_representation" title="Link to this definition"></a></dt>
<dd><p>Whatever is returned by <code class="docutils literal notranslate"><span class="pre">model(image)</span></code>, this is what we match
in order to create a metamer</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.7)">torch.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.Metamer.metamer">
<span class="sig-name descname"><span class="pre">metamer</span></span><a class="headerlink" href="#plenoptic.synthesize.metamer.Metamer.metamer" title="Link to this definition"></a></dt>
<dd><p>The metamer. This may be unfinished depending on how many
iterations we’ve run for.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.7)">torch.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.Metamer.losses">
<span class="sig-name descname"><span class="pre">losses</span></span><a class="headerlink" href="#plenoptic.synthesize.metamer.Metamer.losses" title="Link to this definition"></a></dt>
<dd><p>A list of our loss over iterations.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.Metamer.gradient_norm">
<span class="sig-name descname"><span class="pre">gradient_norm</span></span><a class="headerlink" href="#plenoptic.synthesize.metamer.Metamer.gradient_norm" title="Link to this definition"></a></dt>
<dd><p>A list of the gradient’s L2 norm over iterations.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.Metamer.pixel_change_norm">
<span class="sig-name descname"><span class="pre">pixel_change_norm</span></span><a class="headerlink" href="#plenoptic.synthesize.metamer.Metamer.pixel_change_norm" title="Link to this definition"></a></dt>
<dd><p>A list containing the L2 norm of the pixel change over iterations
(<code class="docutils literal notranslate"><span class="pre">pixel_change_norm[i]</span></code> is the pixel change norm in
<code class="docutils literal notranslate"><span class="pre">metamer</span></code> between iterations <code class="docutils literal notranslate"><span class="pre">i</span></code> and <code class="docutils literal notranslate"><span class="pre">i-1</span></code>).</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.Metamer.saved_metamer">
<span class="sig-name descname"><span class="pre">saved_metamer</span></span><a class="headerlink" href="#plenoptic.synthesize.metamer.Metamer.saved_metamer" title="Link to this definition"></a></dt>
<dd><p>Saved <code class="docutils literal notranslate"><span class="pre">self.metamer</span></code> for later examination.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.7)">torch.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r868b9832577a-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id18">1</a><span class="fn-bracket">]</span></span>
<p>J Portilla and E P Simoncelli. A Parametric Texture Model
based on Joint Statistics of Complex Wavelet Coefficients. Int’l
Journal of Computer Vision. 40(1):49-71, October, 2000.
<a class="reference external" href="https://www.cns.nyu.edu/~eero/ABSTRACTS/portilla99-abstract.html">https://www.cns.nyu.edu/~eero/ABSTRACTS/portilla99-abstract.html</a>
<a class="reference external" href="https://www.cns.nyu.edu/~lcv/texture/">https://www.cns.nyu.edu/~lcv/texture/</a></p>
</div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Attributes<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>allowed_range</strong></dt><dd></dd>
<dt><a class="reference internal" href="#plenoptic.synthesize.metamer.Metamer.gradient_norm" title="plenoptic.synthesize.metamer.Metamer.gradient_norm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient_norm</span></code></a></dt><dd><p>Synthesis gradient’s L2 norm over iterations.</p>
</dd>
<dt><strong>image</strong></dt><dd></dd>
<dt><a class="reference internal" href="#plenoptic.synthesize.metamer.Metamer.losses" title="plenoptic.synthesize.metamer.Metamer.losses"><code class="xref py py-obj docutils literal notranslate"><span class="pre">losses</span></code></a></dt><dd><p>Synthesis loss over iterations.</p>
</dd>
<dt><strong>metamer</strong></dt><dd></dd>
<dt><strong>model</strong></dt><dd></dd>
<dt><strong>optimizer</strong></dt><dd></dd>
<dt><a class="reference internal" href="#plenoptic.synthesize.metamer.Metamer.pixel_change_norm" title="plenoptic.synthesize.metamer.Metamer.pixel_change_norm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">pixel_change_norm</span></code></a></dt><dd><p>L2 norm change in pixel values over iterations.</p>
</dd>
<dt><strong>range_penalty_lambda</strong></dt><dd></dd>
<dt><strong>saved_metamer</strong></dt><dd></dd>
<dt><strong>scheduler</strong></dt><dd></dd>
<dt><strong>store_progress</strong></dt><dd></dd>
<dt><a class="reference internal" href="#id21" title="plenoptic.synthesize.metamer.Metamer.target_representation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">target_representation</span></code></a></dt><dd><p>Model representation of <code class="docutils literal notranslate"><span class="pre">image</span></code>, the goal of synthesis is for <code class="docutils literal notranslate"><span class="pre">model(metamer)</span></code> to match this value.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Methods</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#plenoptic.synthesize.metamer.Metamer.load" title="plenoptic.synthesize.metamer.Metamer.load"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load</span></code></a>(file_path[, map_location, ...])</p></td>
<td><p>Load all relevant stuff from a .pt file.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#plenoptic.synthesize.metamer.Metamer.objective_function" title="plenoptic.synthesize.metamer.Metamer.objective_function"><code class="xref py py-obj docutils literal notranslate"><span class="pre">objective_function</span></code></a>([metamer_representation, ...])</p></td>
<td><p>Compute the metamer synthesis loss.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#plenoptic.synthesize.metamer.Metamer.save" title="plenoptic.synthesize.metamer.Metamer.save"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save</span></code></a>(file_path)</p></td>
<td><p>Save all relevant variables in .pt file.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#plenoptic.synthesize.metamer.Metamer.setup" title="plenoptic.synthesize.metamer.Metamer.setup"><code class="xref py py-obj docutils literal notranslate"><span class="pre">setup</span></code></a>([initial_image, optimizer, ...])</p></td>
<td><p>Initialize the metamer, optimizer, and scheduler.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#plenoptic.synthesize.metamer.Metamer.synthesize" title="plenoptic.synthesize.metamer.Metamer.synthesize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">synthesize</span></code></a>([max_iter, store_progress, ...])</p></td>
<td><p>Synthesize a metamer.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#id24" title="plenoptic.synthesize.metamer.Metamer.to"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to</span></code></a>(*args, **kwargs)</p></td>
<td><p>Moves and/or casts the parameters and buffers.</p></td>
</tr>
</tbody>
</table>
<dl class="py property">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.Metamer.image">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">image</span></span><a class="headerlink" href="#plenoptic.synthesize.metamer.Metamer.image" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.Metamer.load">
<span class="sig-name descname"><span class="pre">load</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">map_location</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensor_equality_atol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-08</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensor_equality_rtol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">pickle_load_args</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/metamer.html#Metamer.load"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.metamer.Metamer.load" title="Link to this definition"></a></dt>
<dd><p>Load all relevant stuff from a .pt file.</p>
<p>This must be called by a <code class="docutils literal notranslate"><span class="pre">Metamer</span></code> object initialized just like the saved
object.</p>
<p>Note this operates in place and so doesn’t return anything.</p>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 1.2: </span>load behavior changed in a backwards-incompatible manner in order to
compatible with breaking changes in torch 2.6.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>file_path</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></span>) – The path to load the synthesis object from</p></li>
<li><p><strong>map_location</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – map_location argument to pass to <code class="docutils literal notranslate"><span class="pre">torch.load</span></code>. If you save
stuff that was being run on a GPU and are loading onto a
CPU, you’ll need this to make sure everything lines up
properly. This should be structured like the str you would
pass to <code class="docutils literal notranslate"><span class="pre">torch.device</span></code></p></li>
<li><p><strong>tensor_equality_atol</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></span>) – Absolute tolerance to use when checking for tensor equality during load,
passed to <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.allclose.html#torch.allclose" title="(in PyTorch v2.7)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.allclose()</span></code></a>. It may be necessary to increase if you are
saving and loading on two machines with torch built by different cuda
versions. Be careful when changing this! See
<a class="reference external" href="https://docs.pytorch.org/docs/stable/type_info.html#torch.torch.finfo" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.finfo</span></code></a> for more details about floating
point precision of different data types (especially, <code class="docutils literal notranslate"><span class="pre">eps</span></code>); if you have
to increase this by more than 1 or 2 decades, then you are probably not
dealing with a numerical issue.</p></li>
<li><p><strong>tensor_equality_rtol</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></span>) – Relative tolerance to use when checking for tensor equality during load,
passed to <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.allclose.html#torch.allclose" title="(in PyTorch v2.7)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.allclose()</span></code></a>. It may be necessary to increase if you are
saving and loading on two machines with torch built by different cuda
versions. Be careful when changing this! See
<a class="reference external" href="https://docs.pytorch.org/docs/stable/type_info.html#torch.torch.finfo" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.finfo</span></code></a> for more details about floating
point precision of different data types (especially, <code class="docutils literal notranslate"><span class="pre">eps</span></code>); if you have
to increase this by more than 1 or 2 decades, then you are probably not
dealing with a numerical issue.</p></li>
<li><p><strong>pickle_load_args</strong> – any additional kwargs will be added to <code class="docutils literal notranslate"><span class="pre">pickle_module.load</span></code> via
<code class="docutils literal notranslate"><span class="pre">torch.load</span></code>, see that function’s docstring for details.</p></li>
</ul>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">examine_saved_synthesis</span></code></dt><dd><p>Examine metadata from saved object: pytorch and plenoptic versions, name of the synthesis object, shapes of tensors, etc.</p>
</dd>
</dl>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">plenoptic</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">po</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">einstein</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">simul</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">remove_grad</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metamer</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">synth</span><span class="o">.</span><span class="n">Metamer</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metamer</span><span class="o">.</span><span class="n">synthesize</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">store_progress</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metamer</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;metamers.pt&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metamer_copy</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">synth</span><span class="o">.</span><span class="n">Metamer</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metamer_copy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;metamers.pt&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="id19">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">metamer</span></span><a class="headerlink" href="#id19" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.Metamer.model">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model</span></span><a class="headerlink" href="#plenoptic.synthesize.metamer.Metamer.model" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.Metamer.objective_function">
<span class="sig-name descname"><span class="pre">objective_function</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">metamer_representation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_representation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/metamer.html#Metamer.objective_function"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.metamer.Metamer.objective_function" title="Link to this definition"></a></dt>
<dd><p>Compute the metamer synthesis loss.</p>
<p>This calls self.loss_function on <code class="docutils literal notranslate"><span class="pre">metamer_representation</span></code> and
<code class="docutils literal notranslate"><span class="pre">target_representation</span></code> and then adds the weighted range penalty.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>metamer_representation</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Model response to <code class="docutils literal notranslate"><span class="pre">metamer</span></code>. If None, we use
<code class="docutils literal notranslate"><span class="pre">self.model(self.metamer)</span></code></p></li>
<li><p><strong>target_representation</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Model response to <code class="docutils literal notranslate"><span class="pre">image</span></code>. If None, we use
<code class="docutils literal notranslate"><span class="pre">self.target_representation</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>loss</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.Metamer.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/metamer.html#Metamer.save"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.metamer.Metamer.save" title="Link to this definition"></a></dt>
<dd><p>Save all relevant variables in .pt file.</p>
<p>Note that if store_progress is True, this will probably be very
large.</p>
<p>See <code class="docutils literal notranslate"><span class="pre">load</span></code> docstring for an example of use.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>file_path</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></span>) – The path to save the metamer object to</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="id20">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">saved_metamer</span></span><a class="headerlink" href="#id20" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.Metamer.setup">
<span class="sig-name descname"><span class="pre">setup</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">initial_image</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scheduler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scheduler_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/metamer.html#Metamer.setup"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.metamer.Metamer.setup" title="Link to this definition"></a></dt>
<dd><p>Initialize the metamer, optimizer, and scheduler.</p>
<p>Can only be called once. If <code class="docutils literal notranslate"><span class="pre">load()</span></code> has been called, <code class="docutils literal notranslate"><span class="pre">initial_image</span></code> must
be None.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>initial_image</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – The tensor we use to initialize the metamer. If None, we initialize with
uniformly-distributed random noise lying within <code class="docutils literal notranslate"><span class="pre">self.allowed_range</span></code>.</p></li>
<li><p><strong>optimizer</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code></a> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – The un-initialized optimizer object to use. If None, we use Adam.</p></li>
<li><p><strong>optimizer_kwargs</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – The keyword arguments to pass to the optimizer on initialization. If None,
we use {“lr”: .01} and, if optimizer is None, {“amsgrad”: True}</p></li>
<li><p><strong>scheduler</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.LRScheduler.html#torch.optim.lr_scheduler.LRScheduler" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">LRScheduler</span></code></a> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – The learning rate scheduler to use. If None, we don’t use one.</p></li>
<li><p><strong>scheduler_kwargs</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – The keyword arguments to pass to the scheduler on initialization.</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ValueError :</strong> – If <code class="docutils literal notranslate"><span class="pre">initial_image</span></code> is the wrong shape.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>Set initial image:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">plenoptic</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">po</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">einstein</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">simul</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">remove_grad</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">met</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">synth</span><span class="o">.</span><span class="n">Metamer</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">met</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="n">po</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">curie</span><span class="p">())</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">met</span><span class="o">.</span><span class="n">synthesize</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
<p>Set optimizer:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">plenoptic</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">po</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">einstein</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">simul</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">remove_grad</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">met</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">synth</span><span class="o">.</span><span class="n">Metamer</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">met</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">,</span> <span class="n">optimizer_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">})</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">met</span><span class="o">.</span><span class="n">synthesize</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
<p>Use with save/load. Only the optimizer object is necessary, its kwargs and the
initial image are handled by load.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">plenoptic</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">po</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">einstein</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">simul</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">remove_grad</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">met</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">synth</span><span class="o">.</span><span class="n">Metamer</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">met</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="n">po</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">curie</span><span class="p">(),</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">,</span>
<span class="gp">... </span>          <span class="n">optimizer_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">})</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">met</span><span class="o">.</span><span class="n">synthesize</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">met</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;metamer_setup.pt&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">met</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">synth</span><span class="o">.</span><span class="n">Metamer</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">met</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;metamer_setup.pt&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">met</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">met</span><span class="o">.</span><span class="n">synthesize</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.Metamer.synthesize">
<span class="sig-name descname"><span class="pre">synthesize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">store_progress</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop_criterion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop_iters_to_check</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">50</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/metamer.html#Metamer.synthesize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.metamer.Metamer.synthesize" title="Link to this definition"></a></dt>
<dd><p>Synthesize a metamer.</p>
<p>Update the pixels of <code class="docutils literal notranslate"><span class="pre">metamer</span></code> until its representation matches that of
<code class="docutils literal notranslate"><span class="pre">image</span></code>.</p>
<p>We run this until either we reach <code class="docutils literal notranslate"><span class="pre">max_iter</span></code> or the change over the
past <code class="docutils literal notranslate"><span class="pre">stop_iters_to_check</span></code> iterations is less than
<code class="docutils literal notranslate"><span class="pre">stop_criterion</span></code>, whichever comes first</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>max_iter</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – The maximum number of iterations to run before we end synthesis
(unless we hit the stop criterion).</p></li>
<li><p><strong>store_progress</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code> | <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – Whether we should store the metamer image in progress during
synthesis. If False, we don’t save anything. If True, we save every
iteration. If an int, we save every <code class="docutils literal notranslate"><span class="pre">store_progress</span></code> iterations
(note then that 0 is the same as False and 1 the same as True).</p></li>
<li><p><strong>stop_criterion</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></span>) – If the loss over the past <code class="docutils literal notranslate"><span class="pre">stop_iters_to_check</span></code> has changed
less than <code class="docutils literal notranslate"><span class="pre">stop_criterion</span></code>, we terminate synthesis.</p></li>
<li><p><strong>stop_iters_to_check</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – How many iterations back to check in order to see if the
loss has stopped decreasing (for <code class="docutils literal notranslate"><span class="pre">stop_criterion</span></code>).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="id21">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">target_representation</span></span><a class="headerlink" href="#id21" title="Link to this definition"></a></dt>
<dd><p>Model representation of <code class="docutils literal notranslate"><span class="pre">image</span></code>, the goal of synthesis is for
<code class="docutils literal notranslate"><span class="pre">model(metamer)</span></code> to match this value.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.Metamer.to">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/metamer.html#Metamer.to"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.metamer.Metamer.to" title="Link to this definition"></a></dt>
<dd><p>Moves and/or casts the parameters and buffers.</p>
<p>This can be called as</p>
<dl class="py function">
<dt class="sig sig-object py" id="id22">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">non_blocking</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/metamer.html#Metamer.to"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id22" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="id23">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dtype</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">non_blocking</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/metamer.html#Metamer.to"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id23" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="id24">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">non_blocking</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/metamer.html#Metamer.to"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id24" title="Link to this definition"></a></dt>
<dd></dd></dl>

<p>Its signature is similar to <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.Tensor.to.html#torch.Tensor.to" title="(in PyTorch v2.7)"><code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.Tensor.to()</span></code></a>, but only accepts
floating point desired <code class="xref py py-attr docutils literal notranslate"><span class="pre">dtype</span></code> s. In addition, this method will
only cast the floating point parameters and buffers to <code class="xref py py-attr docutils literal notranslate"><span class="pre">dtype</span></code>
(if given). The integral parameters and buffers will be moved
<code class="xref py py-attr docutils literal notranslate"><span class="pre">device</span></code>, if that is given, but with dtypes unchanged. When
<code class="xref py py-attr docutils literal notranslate"><span class="pre">non_blocking</span></code> is set, it tries to convert/move asynchronously
with respect to the host if possible, e.g., moving CPU Tensors with
pinned memory to CUDA devices.</p>
<p>See below for examples.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt>device (<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.device</span></code></a>): the desired device of the parameters</dt><dd><p>and buffers in this module</p>
</dd>
<dt>dtype (<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensor_attributes.html#torch.dtype" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.dtype</span></code></a>): the desired floating point type of</dt><dd><p>the floating point parameters and buffers in this module</p>
</dd>
<dt>tensor (torch.Tensor): Tensor whose dtype and device are the desired</dt><dd><p>dtype and device for all parameters and buffers in this module</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.MetamerCTF">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">plenoptic.synthesize.metamer.</span></span><span class="sig-name descname"><span class="pre">MetamerCTF</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_function=&lt;function</span> <span class="pre">mse&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">range_penalty_lambda=0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">allowed_range=(0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">1)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">coarse_to_fine='together'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/metamer.html#MetamerCTF"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.metamer.MetamerCTF" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#plenoptic.synthesize.metamer.Metamer" title="plenoptic.synthesize.metamer.Metamer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Metamer</span></code></a></p>
<p>Synthesize model metamers with coarse-to-fine synthesis.</p>
<p>This is a special case of <code class="docutils literal notranslate"><span class="pre">Metamer</span></code>, which uses the coarse-to-fine
synthesis procedure described in <a href="#id30"><span class="problematic" id="id25">[1]_</span></a>: we start by updating metamer with
respect to only a subset of the model’s representation (generally, that
which corresponds to the lowest spatial frequencies), and changing which
subset we consider over the course of synthesis. This is similar to
optimizing with a blurred version of the objective function and gradually
adding in finer details. It improves synthesis performance for some models.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>image</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – A tensor, this is the image whose representation we wish to
match.</p></li>
<li><p><strong>model</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a></span>) – A visual model, see <cite>Metamer</cite> notebook for more details</p></li>
<li><p><strong>loss_function</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">Callable</span></code>[[<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>], <a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span>) – the loss function to use to compare the representations of the models
in order to determine their loss.</p></li>
<li><p><strong>range_penalty_lambda</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></span>) – strength of the regularizer that enforces the allowed_range. Must be
non-negative.</p></li>
<li><p><strong>allowed_range</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>]</span>) – Range (inclusive) of allowed pixel values. Any values outside this
range will be penalized.</p></li>
<li><p><strong>coarse_to_fine</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Literal</span></code>[<code class="docutils literal notranslate"><span class="pre">'together'</span></code>, <code class="docutils literal notranslate"><span class="pre">'separate'</span></code>]</span>) – <ul>
<li><p>‘together’: start with the coarsest scale, then gradually
add each finer scale.</p></li>
<li><p>’separate’: compute the gradient with respect to each
scale separately (ignoring the others), then with respect
to all of them at the end.</p></li>
</ul>
<p>(see <code class="docutils literal notranslate"><span class="pre">Metamer</span></code> tutorial for more details).</p>
</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.MetamerCTF.target_representation">
<span class="sig-name descname"><span class="pre">target_representation</span></span><a class="headerlink" href="#plenoptic.synthesize.metamer.MetamerCTF.target_representation" title="Link to this definition"></a></dt>
<dd><p>Whatever is returned by <code class="docutils literal notranslate"><span class="pre">model(image)</span></code>, this is what we match
in order to create a metamer</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.7)">torch.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.MetamerCTF.metamer">
<span class="sig-name descname"><span class="pre">metamer</span></span><a class="headerlink" href="#plenoptic.synthesize.metamer.MetamerCTF.metamer" title="Link to this definition"></a></dt>
<dd><p>The metamer. This may be unfinished depending on how many
iterations we’ve run for.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.7)">torch.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.MetamerCTF.losses">
<span class="sig-name descname"><span class="pre">losses</span></span><a class="headerlink" href="#plenoptic.synthesize.metamer.MetamerCTF.losses" title="Link to this definition"></a></dt>
<dd><p>A list of our loss over iterations.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.MetamerCTF.gradient_norm">
<span class="sig-name descname"><span class="pre">gradient_norm</span></span><a class="headerlink" href="#plenoptic.synthesize.metamer.MetamerCTF.gradient_norm" title="Link to this definition"></a></dt>
<dd><p>A list of the gradient’s L2 norm over iterations.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.MetamerCTF.pixel_change_norm">
<span class="sig-name descname"><span class="pre">pixel_change_norm</span></span><a class="headerlink" href="#plenoptic.synthesize.metamer.MetamerCTF.pixel_change_norm" title="Link to this definition"></a></dt>
<dd><p>A list containing the L2 norm of the pixel change over iterations
(<code class="docutils literal notranslate"><span class="pre">pixel_change_norm[i]</span></code> is the pixel change norm in
<code class="docutils literal notranslate"><span class="pre">metamer</span></code> between iterations <code class="docutils literal notranslate"><span class="pre">i</span></code> and <code class="docutils literal notranslate"><span class="pre">i-1</span></code>).</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.MetamerCTF.saved_metamer">
<span class="sig-name descname"><span class="pre">saved_metamer</span></span><a class="headerlink" href="#plenoptic.synthesize.metamer.MetamerCTF.saved_metamer" title="Link to this definition"></a></dt>
<dd><p>Saved <code class="docutils literal notranslate"><span class="pre">self.metamer</span></code> for later examination.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.7)">torch.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.MetamerCTF.scales">
<span class="sig-name descname"><span class="pre">scales</span></span><a class="headerlink" href="#plenoptic.synthesize.metamer.MetamerCTF.scales" title="Link to this definition"></a></dt>
<dd><p>The list of scales in optimization order (i.e., from coarse to fine).
Will be modified during the course of optimization.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list or None</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.MetamerCTF.scales_loss">
<span class="sig-name descname"><span class="pre">scales_loss</span></span><a class="headerlink" href="#plenoptic.synthesize.metamer.MetamerCTF.scales_loss" title="Link to this definition"></a></dt>
<dd><p>The scale-specific loss at each iteration</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list or None</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.MetamerCTF.scales_timing">
<span class="sig-name descname"><span class="pre">scales_timing</span></span><a class="headerlink" href="#plenoptic.synthesize.metamer.MetamerCTF.scales_timing" title="Link to this definition"></a></dt>
<dd><p>Keys are the values found in <code class="docutils literal notranslate"><span class="pre">scales</span></code>, values are lists, specifying
the iteration where we started and stopped optimizing this scale.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dict or None</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.MetamerCTF.scales_finished">
<span class="sig-name descname"><span class="pre">scales_finished</span></span><a class="headerlink" href="#plenoptic.synthesize.metamer.MetamerCTF.scales_finished" title="Link to this definition"></a></dt>
<dd><p>List of scales that we’ve finished optimizing.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list or None</p>
</dd>
</dl>
</dd></dl>

<dl class="field-list simple">
<dt class="field-odd">Attributes<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>allowed_range</strong></dt><dd></dd>
<dt><strong>coarse_to_fine</strong></dt><dd></dd>
<dt><a class="reference internal" href="#plenoptic.synthesize.metamer.MetamerCTF.gradient_norm" title="plenoptic.synthesize.metamer.MetamerCTF.gradient_norm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient_norm</span></code></a></dt><dd><p>Synthesis gradient’s L2 norm over iterations.</p>
</dd>
<dt><strong>image</strong></dt><dd></dd>
<dt><a class="reference internal" href="#plenoptic.synthesize.metamer.MetamerCTF.losses" title="plenoptic.synthesize.metamer.MetamerCTF.losses"><code class="xref py py-obj docutils literal notranslate"><span class="pre">losses</span></code></a></dt><dd><p>Synthesis loss over iterations.</p>
</dd>
<dt><strong>metamer</strong></dt><dd></dd>
<dt><strong>model</strong></dt><dd></dd>
<dt><strong>optimizer</strong></dt><dd></dd>
<dt><a class="reference internal" href="#plenoptic.synthesize.metamer.MetamerCTF.pixel_change_norm" title="plenoptic.synthesize.metamer.MetamerCTF.pixel_change_norm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">pixel_change_norm</span></code></a></dt><dd><p>L2 norm change in pixel values over iterations.</p>
</dd>
<dt><strong>range_penalty_lambda</strong></dt><dd></dd>
<dt><strong>saved_metamer</strong></dt><dd></dd>
<dt><strong>scales</strong></dt><dd></dd>
<dt><strong>scales_finished</strong></dt><dd></dd>
<dt><strong>scales_loss</strong></dt><dd></dd>
<dt><strong>scales_timing</strong></dt><dd></dd>
<dt><strong>scheduler</strong></dt><dd></dd>
<dt><strong>store_progress</strong></dt><dd></dd>
<dt><a class="reference internal" href="#plenoptic.synthesize.metamer.MetamerCTF.target_representation" title="plenoptic.synthesize.metamer.MetamerCTF.target_representation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">target_representation</span></code></a></dt><dd><p>Model representation of <code class="docutils literal notranslate"><span class="pre">image</span></code>, the goal of synthesis is for <code class="docutils literal notranslate"><span class="pre">model(metamer)</span></code> to match this value.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Methods</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#plenoptic.synthesize.metamer.MetamerCTF.load" title="plenoptic.synthesize.metamer.MetamerCTF.load"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load</span></code></a>(file_path[, map_location, ...])</p></td>
<td><p>Load all relevant stuff from a .pt file.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">objective_function</span></code>([metamer_representation, ...])</p></td>
<td><p>Compute the metamer synthesis loss.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">save</span></code>(file_path)</p></td>
<td><p>Save all relevant variables in .pt file.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">setup</span></code>([initial_image, optimizer, ...])</p></td>
<td><p>Initialize the metamer, optimizer, and scheduler.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#plenoptic.synthesize.metamer.MetamerCTF.synthesize" title="plenoptic.synthesize.metamer.MetamerCTF.synthesize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">synthesize</span></code></a>([max_iter, store_progress, ...])</p></td>
<td><p>Synthesize a metamer.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">to</span></code>(*args, **kwargs)</p></td>
<td><p>Moves and/or casts the parameters and buffers.</p></td>
</tr>
</tbody>
</table>
<dl class="py property">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.MetamerCTF.coarse_to_fine">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">coarse_to_fine</span></span><a class="headerlink" href="#plenoptic.synthesize.metamer.MetamerCTF.coarse_to_fine" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.MetamerCTF.load">
<span class="sig-name descname"><span class="pre">load</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">map_location</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensor_equality_atol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-08</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensor_equality_rtol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">pickle_load_args</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/metamer.html#MetamerCTF.load"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.metamer.MetamerCTF.load" title="Link to this definition"></a></dt>
<dd><p>Load all relevant stuff from a .pt file.</p>
<p>This should be called by an initialized <code class="docutils literal notranslate"><span class="pre">Metamer</span></code> object – we will
ensure that <code class="docutils literal notranslate"><span class="pre">image</span></code>, <code class="docutils literal notranslate"><span class="pre">target_representation</span></code> (and thus
<code class="docutils literal notranslate"><span class="pre">model</span></code>), and <code class="docutils literal notranslate"><span class="pre">loss_function</span></code> are all identical.</p>
<p>Note this operates in place and so doesn’t return anything.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>file_path</strong> (<em>str</em>) – The path to load the synthesis object from</p></li>
<li><p><strong>map_location</strong> (<em>str</em><em>, </em><em>optional</em>) – map_location argument to pass to <code class="docutils literal notranslate"><span class="pre">torch.load</span></code>. If you save
stuff that was being run on a GPU and are loading onto a
CPU, you’ll need this to make sure everything lines up
properly. This should be structured like the str you would
pass to <code class="docutils literal notranslate"><span class="pre">torch.device</span></code></p></li>
<li><p><strong>tensor_equality_atol</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></span>) – Absolute tolerance to use when checking for tensor equality during load,
passed to <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.allclose.html#torch.allclose" title="(in PyTorch v2.7)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.allclose()</span></code></a>. It may be necessary to increase if you are
saving and loading on two machines with torch built by different cuda
versions. Be careful when changing this! See
<a class="reference external" href="https://docs.pytorch.org/docs/stable/type_info.html#torch.torch.finfo" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.finfo</span></code></a> for more details about floating
point precision of different data types (especially, <code class="docutils literal notranslate"><span class="pre">eps</span></code>); if you have
to increase this by more than 1 or 2 decades, then you are probably not
dealing with a numerical issue.</p></li>
<li><p><strong>tensor_equality_rtol</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></span>) – Relative tolerance to use when checking for tensor equality during load,
passed to <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.allclose.html#torch.allclose" title="(in PyTorch v2.7)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.allclose()</span></code></a>. It may be necessary to increase if you are
saving and loading on two machines with torch built by different cuda
versions. Be careful when changing this! See
<a class="reference external" href="https://docs.pytorch.org/docs/stable/type_info.html#torch.torch.finfo" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.finfo</span></code></a> for more details about floating
point precision of different data types (especially, <code class="docutils literal notranslate"><span class="pre">eps</span></code>); if you have
to increase this by more than 1 or 2 decades, then you are probably not
dealing with a numerical issue.</p></li>
<li><p><strong>pickle_load_args</strong> – any additional kwargs will be added to <code class="docutils literal notranslate"><span class="pre">pickle_module.load</span></code> via
<code class="docutils literal notranslate"><span class="pre">torch.load</span></code>, see that function’s docstring for details.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">plenoptic</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">po</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">einstein</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">simul</span><span class="o">.</span><span class="n">PortillaSimoncelli</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metamer</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">synth</span><span class="o">.</span><span class="n">MetamerCTF</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metamer</span><span class="o">.</span><span class="n">synthesize</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">store_progress</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metamer</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;metamers.pt&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metamer_copy</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">synth</span><span class="o">.</span><span class="n">MetamerCTF</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metamer_copy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;metamers.pt&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="id26">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">scales</span></span><a class="headerlink" href="#id26" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="id27">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">scales_finished</span></span><a class="headerlink" href="#id27" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="id28">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">scales_loss</span></span><a class="headerlink" href="#id28" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="id29">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">scales_timing</span></span><a class="headerlink" href="#id29" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.MetamerCTF.synthesize">
<span class="sig-name descname"><span class="pre">synthesize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">store_progress</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop_criterion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop_iters_to_check</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">50</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">change_scale_criterion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctf_iters_to_check</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">50</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/metamer.html#MetamerCTF.synthesize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.metamer.MetamerCTF.synthesize" title="Link to this definition"></a></dt>
<dd><p>Synthesize a metamer.</p>
<p>Update the pixels of <code class="docutils literal notranslate"><span class="pre">metamer</span></code> until its representation matches
that of <code class="docutils literal notranslate"><span class="pre">image</span></code>.</p>
<p>We run this until either we reach <code class="docutils literal notranslate"><span class="pre">max_iter</span></code> or the change over the
past <code class="docutils literal notranslate"><span class="pre">stop_iters_to_check</span></code> iterations is less than
<code class="docutils literal notranslate"><span class="pre">stop_criterion</span></code>, whichever comes first</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>max_iter</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – The maximum number of iterations to run before we end synthesis
(unless we hit the stop criterion).</p></li>
<li><p><strong>store_progress</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code> | <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – Whether we should store the metamer image in progress on every
iteration. If False, we don’t save anything. If True, we save every
iteration. If an int, we save every <code class="docutils literal notranslate"><span class="pre">store_progress</span></code> iterations
(note then that 0 is the same as False and 1 the same as True).</p></li>
<li><p><strong>stop_criterion</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></span>) – If the loss over the past <code class="docutils literal notranslate"><span class="pre">stop_iters_to_check</span></code> has changed
less than <code class="docutils literal notranslate"><span class="pre">stop_criterion</span></code>, we terminate synthesis.</p></li>
<li><p><strong>stop_iters_to_check</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – How many iterations back to check in order to see if the
loss has stopped decreasing (for <code class="docutils literal notranslate"><span class="pre">stop_criterion</span></code>).</p></li>
<li><p><strong>change_scale_criterion</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Scale-specific analogue of <code class="docutils literal notranslate"><span class="pre">change_scale_criterion</span></code>: we consider
a given scale finished (and move onto the next) if the loss has
changed less than this in the past <code class="docutils literal notranslate"><span class="pre">ctf_iters_to_check</span></code>
iterations. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, we’ll change scales as soon as we’ve spent
<code class="docutils literal notranslate"><span class="pre">ctf_iters_to_check</span></code> on a given scale</p></li>
<li><p><strong>ctf_iters_to_check</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – Scale-specific analogue of <code class="docutils literal notranslate"><span class="pre">stop_iters_to_check</span></code>: how many
iterations back in order to check in order to see if we should
switch scales.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.animate">
<span class="sig-prename descclassname"><span class="pre">plenoptic.synthesize.metamer.</span></span><span class="sig-name descname"><span class="pre">animate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">metamer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">framerate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">channel_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ylim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vrange</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0,</span> <span class="pre">1)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">zoom</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">plot_representation_error_as_rgb</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fig</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axes_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">figsize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">included_plots</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">['display_metamer',</span> <span class="pre">'plot_loss',</span> <span class="pre">'plot_representation_error']</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">width_ratios</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/metamer.html#animate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.metamer.animate" title="Link to this definition"></a></dt>
<dd><p>Animate synthesis progress.</p>
<p>This is essentially the figure produced by
<code class="docutils literal notranslate"><span class="pre">metamer.plot_synthesis_status</span></code> animated over time, for each stored
iteration.</p>
<p>This functions returns a matplotlib FuncAnimation object. See our documentation
(e.g.,
[Quickstart](<a class="reference external" href="https://docs.plenoptic.org/docs/branch/main/tutorials/00_quickstart.html">https://docs.plenoptic.org/docs/branch/main/tutorials/00_quickstart.html</a>))
for examples on how to view it in a Jupyter notebook. In order to save, use
<code class="docutils literal notranslate"><span class="pre">anim.save(filename)</span></code>. In either case, this can take a while and you’ll need the
appropriate writer installed and on your path, e.g., ffmpeg, imagemagick, etc). See
[matplotlib documentation](<a class="reference external" href="https://matplotlib.org/stable/api/animation_api.html">https://matplotlib.org/stable/api/animation_api.html</a>) for
more details.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>metamer</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="#plenoptic.synthesize.metamer.Metamer" title="plenoptic.synthesize.metamer.Metamer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Metamer</span></code></a></span>) – Metamer object whose synthesis we want to animate.</p></li>
<li><p><strong>framerate</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – How many frames a second to display.</p></li>
<li><p><strong>batch_idx</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – Which index to take from the batch dimension</p></li>
<li><p><strong>channel_idx</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Which index to take from the channel dimension. If None, we use all
channels (assumed use-case is RGB(A) image).</p></li>
<li><p><strong>ylim</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>], <code class="xref py py-data docutils literal notranslate"><span class="pre">Literal</span></code>[<code class="docutils literal notranslate"><span class="pre">False</span></code>]]</span>) – <p>The y-limits of the representation_error plot:</p>
<ul>
<li><p>If a tuple, then this is the ylim of all plots</p></li>
<li><p>If None, then all plots have the same limits, all
symmetric about 0 with a limit of
<code class="docutils literal notranslate"><span class="pre">np.abs(representation_error).max()</span></code> (for the initial
representation_error)</p></li>
<li><p>If False, don’t modify limits.</p></li>
<li><p>If a string, must be ‘rescale’ or of the form ‘rescaleN’,
where N can be any integer. If ‘rescaleN’, we rescale the
limits every N frames (we rescale as if ylim = None). If
‘rescale’, then we do this 10 times over the course of the
animation</p></li>
</ul>
</p></li>
<li><p><strong>vrange</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>] | <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></span>) – The vrange option to pass to <code class="docutils literal notranslate"><span class="pre">display_metamer()</span></code>. See
docstring of <code class="docutils literal notranslate"><span class="pre">imshow</span></code> for possible values.</p></li>
<li><p><strong>zoom</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – How much to zoom in / enlarge the metamer, the ratio
of display pixels to image pixels. If None (the default), we
attempt to find the best value ourselves.</p></li>
<li><p><strong>plot_representation_error_as_rgb</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></span>) – The representation can be image-like with multiple channels, and we
have no way to determine whether it should be represented as an RGB
image or not, so the user must set this flag to tell us. It will be
ignored if the representation doesn’t look image-like or if the
model has its own plot_representation_error() method. Else, it will
be passed to <cite>po.imshow()</cite>, see that methods docstring for details.
since plot_synthesis_status normally sets it up for us</p></li>
<li><p><strong>fig</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">Figure</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – If None, create the figure from scratch. Else, should be an empty
figure with enough axes (the expected use here is have same-size
movies with different plots).</p></li>
<li><p><strong>axes_idx</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]</span>) – Dictionary specifying which axes contains which type of plot, allows
for more fine-grained control of the resulting figure. Probably only
helpful if fig is also defined. Possible keys: <code class="docutils literal notranslate"><span class="pre">'display_metamer',</span>
<span class="pre">'plot_loss',</span> <span class="pre">'plot_representation_error',</span> <span class="pre">'plot_pixel_values',</span>
<span class="pre">'misc'</span></code>. Values should all be ints. If you tell this function to
create a plot that doesn’t have a corresponding key, we find the lowest
int that is not already in the dict, so if you have axes that you want
unchanged, place their idx in <code class="docutils literal notranslate"><span class="pre">'misc'</span></code>.</p></li>
<li><p><strong>figsize</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>] | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – The size of the figure to create. It may take a little bit of
playing around to find a reasonable value. If None, we attempt to
make our best guess, aiming to have each axis be of size (5, 5)</p></li>
<li><p><strong>included_plots</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]</span>) – Which plots to include. Must be some subset of <code class="docutils literal notranslate"><span class="pre">'display_metamer',</span>
<span class="pre">'plot_loss',</span> <span class="pre">'plot_representation_error',</span> <span class="pre">'plot_pixel_values'</span></code>.</p></li>
<li><p><strong>width_ratios</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>]</span>) – By default, all plots axes will have the same width. To change
that, specify their relative widths using the keys: <code class="docutils literal notranslate"><span class="pre">'display_metamer',</span>
<span class="pre">'plot_loss',</span> <span class="pre">'plot_representation_error',</span> <span class="pre">'plot_pixel_values'</span></code> and floats
specifying their relative width. Any not included will be assumed to be
1.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The animation object. In order to view, must convert to HTML
or save.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>anim</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>By default, we use the ffmpeg backend, which requires that you have
ffmpeg installed and on your path (<a class="reference external" href="https://ffmpeg.org/download.html">https://ffmpeg.org/download.html</a>).
To use a different, use the matplotlib rcParams:
<cite>matplotlib.rcParams[‘animation.writer’] = writer</cite>, see
<a class="reference external" href="https://matplotlib.org/stable/api/animation_api.html#writer-classes">https://matplotlib.org/stable/api/animation_api.html#writer-classes</a> for
more details.</p>
<p>For displaying in a jupyter notebook, ffmpeg appears to be required.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.display_metamer">
<span class="sig-prename descclassname"><span class="pre">plenoptic.synthesize.metamer.</span></span><span class="sig-name descname"><span class="pre">display_metamer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">metamer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">channel_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">zoom</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/metamer.html#display_metamer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.metamer.display_metamer" title="Link to this definition"></a></dt>
<dd><p>Display metamer.</p>
<p>You can specify what iteration to view by using the <code class="docutils literal notranslate"><span class="pre">iteration</span></code> arg.
The default, <code class="docutils literal notranslate"><span class="pre">None</span></code>, shows the final one.</p>
<p>We use <code class="docutils literal notranslate"><span class="pre">plenoptic.imshow</span></code> to display the metamer and attempt to
automatically find the most reasonable zoom value. You can override this
value using the zoom arg, but remember that <code class="docutils literal notranslate"><span class="pre">plenoptic.imshow</span></code> is
opinionated about the size of the resulting image and will throw an
Exception if the axis created is not big enough for the selected zoom.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>metamer</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="#plenoptic.synthesize.metamer.Metamer" title="plenoptic.synthesize.metamer.Metamer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Metamer</span></code></a></span>) – Metamer object whose synthesized metamer we want to display.</p></li>
<li><p><strong>batch_idx</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – Which index to take from the batch dimension</p></li>
<li><p><strong>channel_idx</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Which index to take from the channel dimension. If None, we assume
image is RGB(A) and show all channels.</p></li>
<li><p><strong>iteration</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Which iteration to display. If None, the default, we show
the most recent one. Negative values are also allowed.</p></li>
<li><p><strong>ax</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">Axes</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Pre-existing axes for plot. If None, we call <code class="docutils literal notranslate"><span class="pre">plt.gca()</span></code>.</p></li>
<li><p><strong>zoom</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – How much to zoom in / enlarge the metamer, the ratio of display pixels
to image pixels. If None (the default), we attempt to find the best
value ourselves.</p></li>
<li><p><strong>kwargs</strong> – Passed to <code class="docutils literal notranslate"><span class="pre">plenoptic.imshow</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The matplotlib axes containing the plot.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>ax</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.plot_loss">
<span class="sig-prename descclassname"><span class="pre">plenoptic.synthesize.metamer.</span></span><span class="sig-name descname"><span class="pre">plot_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">metamer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/metamer.html#plot_loss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.metamer.plot_loss" title="Link to this definition"></a></dt>
<dd><p>Plot synthesis loss with log-scaled y axis.</p>
<p>Plots <code class="docutils literal notranslate"><span class="pre">metamer.losses</span></code> over all iterations. Also plots a red dot at
<code class="docutils literal notranslate"><span class="pre">iteration</span></code>, to highlight the loss there. If <code class="docutils literal notranslate"><span class="pre">iteration=None</span></code>, then the
dot will be at the final iteration.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>metamer</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="#plenoptic.synthesize.metamer.Metamer" title="plenoptic.synthesize.metamer.Metamer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Metamer</span></code></a></span>) – Metamer object whose loss we want to plot.</p></li>
<li><p><strong>iteration</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Which iteration to display. If None, the default, we show
the most recent one. Negative values are also allowed.</p></li>
<li><p><strong>ax</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">Axes</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Pre-existing axes for plot. If None, we call <code class="docutils literal notranslate"><span class="pre">plt.gca()</span></code>.</p></li>
<li><p><strong>kwargs</strong> – passed to plt.semilogy</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The matplotlib axes containing the plot.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>ax</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.plot_pixel_values">
<span class="sig-prename descclassname"><span class="pre">plenoptic.synthesize.metamer.</span></span><span class="sig-name descname"><span class="pre">plot_pixel_values</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">metamer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">channel_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ylim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/metamer.html#plot_pixel_values"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.metamer.plot_pixel_values" title="Link to this definition"></a></dt>
<dd><p>Plot histogram of pixel values of target image and its metamer.</p>
<p>As a way to check the distributions of pixel intensities and see
if there’s any values outside the allowed range</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>metamer</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="#plenoptic.synthesize.metamer.Metamer" title="plenoptic.synthesize.metamer.Metamer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Metamer</span></code></a></span>) – Metamer object with the images whose pixel values we want to compare.</p></li>
<li><p><strong>batch_idx</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – Which index to take from the batch dimension</p></li>
<li><p><strong>channel_idx</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Which index to take from the channel dimension. If None, we use all
channels (assumed use-case is RGB(A) images).</p></li>
<li><p><strong>iteration</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Which iteration to display. If None, the default, we show
the most recent one. Negative values are also allowed.</p></li>
<li><p><strong>ylim</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>], <code class="xref py py-data docutils literal notranslate"><span class="pre">Literal</span></code>[<code class="docutils literal notranslate"><span class="pre">False</span></code>]]</span>) – if tuple, the ylimit to set for this axis. If False, we leave
it untouched</p></li>
<li><p><strong>ax</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">Axes</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Pre-existing axes for plot. If None, we call <code class="docutils literal notranslate"><span class="pre">plt.gca()</span></code>.</p></li>
<li><p><strong>kwargs</strong> – passed to plt.hist</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Created axes.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>ax</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.plot_representation_error">
<span class="sig-prename descclassname"><span class="pre">plenoptic.synthesize.metamer.</span></span><span class="sig-name descname"><span class="pre">plot_representation_error</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">metamer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ylim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">as_rgb</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/metamer.html#plot_representation_error"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.metamer.plot_representation_error" title="Link to this definition"></a></dt>
<dd><p>Plot distance ratio showing how close we are to convergence.</p>
<p>We plot <code class="docutils literal notranslate"><span class="pre">_representation_error(metamer,</span> <span class="pre">iteration)</span></code>. For more details, see
<code class="docutils literal notranslate"><span class="pre">plenoptic.tools.display.plot_representation</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>metamer</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="#plenoptic.synthesize.metamer.Metamer" title="plenoptic.synthesize.metamer.Metamer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Metamer</span></code></a></span>) – Metamer object whose synthesized metamer we want to display.</p></li>
<li><p><strong>batch_idx</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – Which index to take from the batch dimension</p></li>
<li><p><strong>iteration</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Which iteration to display. If None, the default, we show
the most recent one. Negative values are also allowed.</p></li>
<li><p><strong>ylim</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Literal</span></code>[<code class="docutils literal notranslate"><span class="pre">False</span></code>]]</span>) – If <code class="docutils literal notranslate"><span class="pre">ylim</span></code> is <code class="docutils literal notranslate"><span class="pre">None</span></code>, we sets the axes’ y-limits to be <code class="docutils literal notranslate"><span class="pre">(-y_max,</span>
<span class="pre">y_max)</span></code>, where <code class="docutils literal notranslate"><span class="pre">y_max=np.abs(data).max()</span></code>. If it’s <code class="docutils literal notranslate"><span class="pre">False</span></code>, we do
nothing. If a tuple, we use that range.</p></li>
<li><p><strong>ax</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">Axes</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Pre-existing axes for plot. If None, we call <code class="docutils literal notranslate"><span class="pre">plt.gca()</span></code>.</p></li>
<li><p><strong>as_rgb</strong> (<em>bool</em><em>, </em><em>optional</em>) – The representation can be image-like with multiple channels, and we
have no way to determine whether it should be represented as an RGB
image or not, so the user must set this flag to tell us. It will be
ignored if the response doesn’t look image-like or if the model has its
own plot_representation_error() method. Else, it will be passed to
<cite>po.imshow()</cite>, see that methods docstring for details.</p></li>
<li><p><strong>kwargs</strong> – Passed to <code class="docutils literal notranslate"><span class="pre">metamer.model.forward</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>List of created axes</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>axes</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.plot_synthesis_status">
<span class="sig-prename descclassname"><span class="pre">plenoptic.synthesize.metamer.</span></span><span class="sig-name descname"><span class="pre">plot_synthesis_status</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">metamer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">channel_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ylim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vrange</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'indep1'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">zoom</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">plot_representation_error_as_rgb</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fig</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axes_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">figsize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">included_plots</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">['display_metamer',</span> <span class="pre">'plot_loss',</span> <span class="pre">'plot_representation_error']</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">width_ratios</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/metamer.html#plot_synthesis_status"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.metamer.plot_synthesis_status" title="Link to this definition"></a></dt>
<dd><p>Make a plot showing synthesis status.</p>
<p>We create several subplots to analyze this. By default, we create three
subplots on a new figure: the first one contains the synthesized metamer,
the second contains the loss, and the third contains the representation
error.</p>
<p>There is an optional additional plot: <code class="docutils literal notranslate"><span class="pre">plot_pixel_values</span></code>, a histogram of
pixel values of the metamer and target image.</p>
<p>The plots to include are specified by including their name in the
<code class="docutils literal notranslate"><span class="pre">included_plots</span></code> list. All plots can be created separately using the
method with the same name.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>metamer</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="#plenoptic.synthesize.metamer.Metamer" title="plenoptic.synthesize.metamer.Metamer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Metamer</span></code></a></span>) – Metamer object whose status we want to plot.</p></li>
<li><p><strong>batch_idx</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – Which index to take from the batch dimension</p></li>
<li><p><strong>channel_idx</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Which index to take from the channel dimension. If None, we use all
channels (assumed use-case is RGB(A) image).</p></li>
<li><p><strong>iteration</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Which iteration to display. If None, the default, we show
the most recent one. Negative values are also allowed.</p></li>
<li><p><strong>ylim</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Literal</span></code>[<code class="docutils literal notranslate"><span class="pre">False</span></code>]]</span>) – The ylimit to use for the representation_error plot. We pass
this value directly to <code class="docutils literal notranslate"><span class="pre">plot_representation_error</span></code></p></li>
<li><p><strong>vrange</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>] | <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></span>) – The vrange option to pass to <code class="docutils literal notranslate"><span class="pre">display_metamer()</span></code>. See
docstring of <code class="docutils literal notranslate"><span class="pre">imshow</span></code> for possible values.</p></li>
<li><p><strong>zoom</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – How much to zoom in / enlarge the metamer, the ratio
of display pixels to image pixels. If None (the default), we
attempt to find the best value ourselves.</p></li>
<li><p><strong>plot_representation_error_as_rgb</strong> (<em>bool</em><em>, </em><em>optional</em>) – The representation can be image-like with multiple channels, and we
have no way to determine whether it should be represented as an RGB
image or not, so the user must set this flag to tell us. It will be
ignored if the response doesn’t look image-like or if the
model has its own plot_representation_error() method. Else, it will
be passed to <cite>po.imshow()</cite>, see that methods docstring for details.</p></li>
<li><p><strong>fig</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">Figure</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – if None, we create a new figure. otherwise we assume this is
an empty figure that has the appropriate size and number of
subplots</p></li>
<li><p><strong>axes_idx</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]</span>) – Dictionary specifying which axes contains which type of plot, allows
for more fine-grained control of the resulting figure. Probably only
helpful if fig is also defined. Possible keys: <code class="docutils literal notranslate"><span class="pre">'display_metamer',</span>
<span class="pre">'plot_loss',</span> <span class="pre">'plot_representation_error',</span> <span class="pre">'plot_pixel_values',</span>
<span class="pre">'misc'</span></code>. Values should all be ints. If you tell this function to
create a plot that doesn’t have a corresponding key, we find the lowest
int that is not already in the dict, so if you have axes that you want
unchanged, place their idx in <code class="docutils literal notranslate"><span class="pre">'misc'</span></code>.</p></li>
<li><p><strong>figsize</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>] | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – The size of the figure to create. It may take a little bit of
playing around to find a reasonable value. If None, we attempt to
make our best guess, aiming to have each axis be of size (5, 5)</p></li>
<li><p><strong>included_plots</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]</span>) – Which plots to include. Must be some subset of <code class="docutils literal notranslate"><span class="pre">'display_metamer',</span>
<span class="pre">'plot_loss',</span> <span class="pre">'plot_representation_error',</span> <span class="pre">'plot_pixel_values'</span></code>.</p></li>
<li><p><strong>width_ratios</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>]</span>) – By default, all plots axes will have the same width. To change
that, specify their relative widths using the keys: <code class="docutils literal notranslate"><span class="pre">'display_metamer',</span>
<span class="pre">'plot_loss',</span> <span class="pre">'plot_representation_error',</span> <span class="pre">'plot_pixel_values'</span></code> and floats
specifying their relative width. Any not included will be assumed to be
1.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Figure</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]]</span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><ul class="simple">
<li><p><em>fig</em> – The figure containing this plot</p></li>
<li><p><em>axes_idx</em> – Dictionary giving index of each plot.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-plenoptic.synthesize.synthesis">
<span id="plenoptic-synthesize-synthesis-module"></span><h2>plenoptic.synthesize.synthesis module<a class="headerlink" href="#module-plenoptic.synthesize.synthesis" title="Link to this heading"></a></h2>
<p>abstract synthesis super-class.</p>
<dl class="py class">
<dt class="sig sig-object py" id="plenoptic.synthesize.synthesis.OptimizedSynthesis">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">plenoptic.synthesize.synthesis.</span></span><span class="sig-name descname"><span class="pre">OptimizedSynthesis</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">range_penalty_lambda</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">allowed_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0,</span> <span class="pre">1)</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/synthesis.html#OptimizedSynthesis"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.synthesis.OptimizedSynthesis" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#plenoptic.synthesize.synthesis.Synthesis" title="plenoptic.synthesize.synthesis.Synthesis"><code class="xref py py-class docutils literal notranslate"><span class="pre">Synthesis</span></code></a></p>
<p>Abstract super-class for synthesis objects that use optimization.</p>
<p>The primary difference between this and the generic Synthesis class is that
these will use an optimizer object to iteratively update their output.</p>
<dl class="field-list simple">
<dt class="field-odd">Attributes<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>allowed_range</strong></dt><dd></dd>
<dt><a class="reference internal" href="#plenoptic.synthesize.synthesis.OptimizedSynthesis.gradient_norm" title="plenoptic.synthesize.synthesis.OptimizedSynthesis.gradient_norm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient_norm</span></code></a></dt><dd><p>Synthesis gradient’s L2 norm over iterations.</p>
</dd>
<dt><a class="reference internal" href="#plenoptic.synthesize.synthesis.OptimizedSynthesis.losses" title="plenoptic.synthesize.synthesis.OptimizedSynthesis.losses"><code class="xref py py-obj docutils literal notranslate"><span class="pre">losses</span></code></a></dt><dd><p>Synthesis loss over iterations.</p>
</dd>
<dt><strong>optimizer</strong></dt><dd></dd>
<dt><a class="reference internal" href="#plenoptic.synthesize.synthesis.OptimizedSynthesis.pixel_change_norm" title="plenoptic.synthesize.synthesis.OptimizedSynthesis.pixel_change_norm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">pixel_change_norm</span></code></a></dt><dd><p>L2 norm change in pixel values over iterations.</p>
</dd>
<dt><strong>range_penalty_lambda</strong></dt><dd></dd>
<dt><strong>scheduler</strong></dt><dd></dd>
<dt><strong>store_progress</strong></dt><dd></dd>
</dl>
</dd>
</dl>
<p class="rubric">Methods</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">load</span></code>(file_path, empty_on_init_attr[, ...])</p></td>
<td><p>Load all relevant attributes from a .pt file.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#plenoptic.synthesize.synthesis.OptimizedSynthesis.objective_function" title="plenoptic.synthesize.synthesis.OptimizedSynthesis.objective_function"><code class="xref py py-obj docutils literal notranslate"><span class="pre">objective_function</span></code></a>()</p></td>
<td><p>How good is the current synthesized object.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">save</span></code>(file_path[, save_io_attrs, ...])</p></td>
<td><p>Save all attributes in .pt file.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#plenoptic.synthesize.synthesis.OptimizedSynthesis.setup" title="plenoptic.synthesize.synthesis.OptimizedSynthesis.setup"><code class="xref py py-obj docutils literal notranslate"><span class="pre">setup</span></code></a>()</p></td>
<td><p>What to start synthesis with.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">synthesize</span></code>()</p></td>
<td><p>Synthesize something.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">to</span></code>(*args[, attrs])</p></td>
<td><p>Moves and/or casts the parameters and buffers.</p></td>
</tr>
</tbody>
</table>
<dl class="py property">
<dt class="sig sig-object py" id="plenoptic.synthesize.synthesis.OptimizedSynthesis.allowed_range">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">allowed_range</span></span><a class="headerlink" href="#plenoptic.synthesize.synthesis.OptimizedSynthesis.allowed_range" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="plenoptic.synthesize.synthesis.OptimizedSynthesis.gradient_norm">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">gradient_norm</span></span><a class="headerlink" href="#plenoptic.synthesize.synthesis.OptimizedSynthesis.gradient_norm" title="Link to this definition"></a></dt>
<dd><p>Synthesis gradient’s L2 norm over iterations.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="plenoptic.synthesize.synthesis.OptimizedSynthesis.losses">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">losses</span></span><a class="headerlink" href="#plenoptic.synthesize.synthesis.OptimizedSynthesis.losses" title="Link to this definition"></a></dt>
<dd><p>Synthesis loss over iterations.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="plenoptic.synthesize.synthesis.OptimizedSynthesis.objective_function">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">objective_function</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/synthesis.html#OptimizedSynthesis.objective_function"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.synthesis.OptimizedSynthesis.objective_function" title="Link to this definition"></a></dt>
<dd><p>How good is the current synthesized object.</p>
<p>See <code class="docutils literal notranslate"><span class="pre">plenoptic.tools.optim</span></code> for some examples.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="plenoptic.synthesize.synthesis.OptimizedSynthesis.optimizer">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">optimizer</span></span><a class="headerlink" href="#plenoptic.synthesize.synthesis.OptimizedSynthesis.optimizer" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="plenoptic.synthesize.synthesis.OptimizedSynthesis.pixel_change_norm">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">pixel_change_norm</span></span><a class="headerlink" href="#plenoptic.synthesize.synthesis.OptimizedSynthesis.pixel_change_norm" title="Link to this definition"></a></dt>
<dd><p>L2 norm change in pixel values over iterations.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="plenoptic.synthesize.synthesis.OptimizedSynthesis.range_penalty_lambda">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">range_penalty_lambda</span></span><a class="headerlink" href="#plenoptic.synthesize.synthesis.OptimizedSynthesis.range_penalty_lambda" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="plenoptic.synthesize.synthesis.OptimizedSynthesis.scheduler">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">scheduler</span></span><a class="headerlink" href="#plenoptic.synthesize.synthesis.OptimizedSynthesis.scheduler" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="plenoptic.synthesize.synthesis.OptimizedSynthesis.setup">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">setup</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/synthesis.html#OptimizedSynthesis.setup"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.synthesis.OptimizedSynthesis.setup" title="Link to this definition"></a></dt>
<dd><p>What to start synthesis with.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="plenoptic.synthesize.synthesis.OptimizedSynthesis.store_progress">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">store_progress</span></span><a class="headerlink" href="#plenoptic.synthesize.synthesis.OptimizedSynthesis.store_progress" title="Link to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="plenoptic.synthesize.synthesis.Synthesis">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">plenoptic.synthesize.synthesis.</span></span><span class="sig-name descname"><span class="pre">Synthesis</span></span><a class="reference internal" href="../_modules/plenoptic/synthesize/synthesis.html#Synthesis"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.synthesis.Synthesis" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">ABC</span></code></p>
<p>Abstract super-class for synthesis objects.</p>
<p>All synthesis objects share a variety of similarities and thus need
to have similar methods. Some of these can be implemented here and
simply inherited, some of them will need to be different for each
sub-class and thus are marked as abstract methods here</p>
<p class="rubric">Methods</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#plenoptic.synthesize.synthesis.Synthesis.load" title="plenoptic.synthesize.synthesis.Synthesis.load"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load</span></code></a>(file_path, empty_on_init_attr[, ...])</p></td>
<td><p>Load all relevant attributes from a .pt file.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#plenoptic.synthesize.synthesis.Synthesis.save" title="plenoptic.synthesize.synthesis.Synthesis.save"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save</span></code></a>(file_path[, save_io_attrs, ...])</p></td>
<td><p>Save all attributes in .pt file.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#plenoptic.synthesize.synthesis.Synthesis.synthesize" title="plenoptic.synthesize.synthesis.Synthesis.synthesize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">synthesize</span></code></a>()</p></td>
<td><p>Synthesize something.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#plenoptic.synthesize.synthesis.Synthesis.to" title="plenoptic.synthesize.synthesis.Synthesis.to"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to</span></code></a>(*args[, attrs])</p></td>
<td><p>Moves and/or casts the parameters and buffers.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="plenoptic.synthesize.synthesis.Synthesis.load">
<span class="sig-name descname"><span class="pre">load</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">empty_on_init_attr</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">map_location</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">check_attributes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">check_io_attributes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">state_dict_attributes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensor_equality_atol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-08</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensor_equality_rtol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">pickle_load_args</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/synthesis.html#Synthesis.load"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.synthesis.Synthesis.load" title="Link to this definition"></a></dt>
<dd><p>Load all relevant attributes from a .pt file.</p>
<p>This should be called by <code class="docutils literal notranslate"><span class="pre">Synthesis</span></code> object that has just been initialized.</p>
<p>Note this operates in place and so doesn’t return anything.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>file_path</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></span>) – The path to load the synthesis object from</p></li>
<li><p><strong>empty_on_init_attr</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></span>) – The name of an attribute that will either be None or have length 0 if the
Synthesis object has just been initialized.</p></li>
<li><p><strong>map_location</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – map_location argument to pass to <code class="docutils literal notranslate"><span class="pre">torch.load</span></code>. If you save
stuff that was being run on a GPU and are loading onto a
CPU, you’ll need this to make sure everything lines up
properly. This should be structured like the str you would
pass to <code class="docutils literal notranslate"><span class="pre">torch.device</span></code></p></li>
<li><p><strong>check_attributes</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]</span>) – List of strings we ensure are identical in the current <code class="docutils literal notranslate"><span class="pre">Synthesis</span></code> object
and the loaded one.</p></li>
<li><p><strong>check_io_attributes</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]</span>) – Names of attributes whose input/output behavior we should check (i.e., if we
call them on identical inputs, do we get identical outputs). In the loaded
dictionary, these are a tuple of three values: the name of the callable, the
name of the attribute to use as input, and the output we expect.</p></li>
<li><p><strong>state_dict_attributes</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]</span>) – Names of attributes that were callables, saved as a tuple with the name of
the callable and their state_dict. We will ensure the name of the attributes
are identical and then load the state_dict. If the attribute is None on the
initialized Synthesis object, then we set the tuple, and count on the
Synthesis object to properly handle it when needed.</p></li>
<li><p><strong>tensor_equality_atol</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></span>) – Absolute tolerance to use when checking for tensor equality during load,
passed to <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.allclose.html#torch.allclose" title="(in PyTorch v2.7)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.allclose()</span></code></a>. It may be necessary to increase if you are
saving and loading on two machines with torch built by different cuda
versions. Be careful when changing this! See
<a class="reference external" href="https://docs.pytorch.org/docs/stable/type_info.html#torch.torch.finfo" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.finfo</span></code></a> for more details about floating
point precision of different data types (especially, <code class="docutils literal notranslate"><span class="pre">eps</span></code>); if you have
to increase this by more than 1 or 2 decades, then you are probably not
dealing with a numerical issue.</p></li>
<li><p><strong>tensor_equality_rtol</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></span>) – Relative tolerance to use when checking for tensor equality during load,
passed to <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.allclose.html#torch.allclose" title="(in PyTorch v2.7)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.allclose()</span></code></a>. It may be necessary to increase if you are
saving and loading on two machines with torch built by different cuda
versions. Be careful when changing this! See
<a class="reference external" href="https://docs.pytorch.org/docs/stable/type_info.html#torch.torch.finfo" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.finfo</span></code></a> for more details about floating
point precision of different data types (especially, <code class="docutils literal notranslate"><span class="pre">eps</span></code>); if you have
to increase this by more than 1 or 2 decades, then you are probably not
dealing with a numerical issue.</p></li>
<li><p><strong>pickle_load_args</strong> – any additional kwargs will be added to <code class="docutils literal notranslate"><span class="pre">pickle_module.load</span></code> via
<code class="docutils literal notranslate"><span class="pre">torch.load</span></code>, see that function’s docstring for details.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="plenoptic.synthesize.synthesis.Synthesis.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_io_attrs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_state_dict_attrs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/synthesis.html#Synthesis.save"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.synthesis.Synthesis.save" title="Link to this definition"></a></dt>
<dd><p>Save all attributes in .pt file.</p>
<p>Note that there are two special categories of attributes, as described below.
All other attributes will be pickled directly and so should be either tensors or
primitives (e.g., not a function or callable torch object). We do not check this
explicitly, but load will fail if that’s not the case.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>file_path</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></span>) – The path to save the synthesis object to</p></li>
<li><p><strong>save_io_attrs</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]]</span>) – List with tuples of form (str, (str, …)). The first element is the name of
the attribute to we save, and the second element is a tuple of attributes of
the Synthesis object, which we can pass as inputs to the attribute. We save
them as tuples of (name, input_names, outputs). On load, we check that the
initialized object’s name hasn’t changed, and that when called on the same
inputs, we get the same outputs. Intended for models, metrics, loss
functions. Used to avoid saving callables, which is brittle and unsafe.</p></li>
<li><p><strong>save_state_dict_attrs</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]</span>) – Names of attributes that we save as tuples of (name, state_dict).
Corresponding attribute can be None, in which case we save an empty
dictionary as state_dict. On load, we check that the initialized object’s
name hasn’t changed, and load the state_dict. Intended for optimizers,
schedulers. Used to avoid saving callables, which is brittle and unsafe.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="plenoptic.synthesize.synthesis.Synthesis.synthesize">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">synthesize</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/synthesis.html#Synthesis.synthesize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.synthesis.Synthesis.synthesize" title="Link to this definition"></a></dt>
<dd><p>Synthesize something.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="plenoptic.synthesize.synthesis.Synthesis.to">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attrs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/synthesis.html#Synthesis.to"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.synthesis.Synthesis.to" title="Link to this definition"></a></dt>
<dd><p>Moves and/or casts the parameters and buffers.
Similar to <code class="docutils literal notranslate"><span class="pre">save</span></code>, this is an abstract method only because you
need to define the attributes to call to on.</p>
<p>This can be called as
.. function:: to(device=None, dtype=None, non_blocking=False)
.. function:: to(dtype, non_blocking=False)
.. function:: to(tensor, non_blocking=False)
Its signature is similar to <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.Tensor.to.html#torch.Tensor.to" title="(in PyTorch v2.7)"><code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.Tensor.to()</span></code></a>, but only accepts
floating point desired <code class="xref py py-attr docutils literal notranslate"><span class="pre">dtype</span></code> s. In addition, this method will
only cast the floating point parameters and buffers to <code class="xref py py-attr docutils literal notranslate"><span class="pre">dtype</span></code>
(if given). The integral parameters and buffers will be moved
<code class="xref py py-attr docutils literal notranslate"><span class="pre">device</span></code>, if that is given, but with dtypes unchanged. When
<code class="xref py py-attr docutils literal notranslate"><span class="pre">non_blocking</span></code> is set, it tries to convert/move asynchronously
with respect to the host if possible, e.g., moving CPU Tensors with
pinned memory to CUDA devices. When calling this method to move tensors
to a CUDA device, items in <code class="docutils literal notranslate"><span class="pre">attrs</span></code> that start with “<a href="#id31"><span class="problematic" id="id32">saved_</span></a>” will not
be moved.
.. note:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">This</span> <span class="n">method</span> <span class="n">modifies</span> <span class="n">the</span> <span class="n">module</span> <span class="ow">in</span><span class="o">-</span><span class="n">place</span><span class="o">.</span>
</pre></div>
</div>
<dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt>device (<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.device</span></code></a>): the desired device of the parameters</dt><dd><p>and buffers in this module</p>
</dd>
<dt>dtype (<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensor_attributes.html#torch.dtype" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.dtype</span></code></a>): the desired floating point type of</dt><dd><p>the floating point parameters and buffers in this module</p>
</dd>
<dt>tensor (torch.Tensor): Tensor whose dtype and device are the desired</dt><dd><p>dtype and device for all parameters and buffers in this module</p>
</dd>
<dt>attrs (<code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>): list of strs containing the attributes of</dt><dd><p>this object to move to the specified device/dtype</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-plenoptic.synthesize">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-plenoptic.synthesize" title="Link to this heading"></a></h2>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="plenoptic.simulate.models.html" class="btn btn-neutral float-left" title="plenoptic.simulate.models package" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="plenoptic.tools.html" class="btn btn-neutral float-right" title="plenoptic.tools package" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2019, Plenoptic authors.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>