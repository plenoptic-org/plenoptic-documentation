

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>plenoptic.simulate.models.portilla_simoncelli &mdash; plenoptic 1.3.2.dev90 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../../../_static/plot_directive.css" />
      <link rel="stylesheet" type="text/css" href="../../../../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../../../../_static/togglebutton.css?v=13237357" />
      <link rel="stylesheet" type="text/css" href="../../../../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
      <link rel="stylesheet" type="text/css" href="../../../../_static/sphinx-design.min.css?v=95c83b7e" />
      <link rel="stylesheet" type="text/css" href="../../../../_static/custom.css?v=a2d047e6" />

  
      <script src="../../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../../../_static/documentation_options.js?v=5f0d2a28"></script>
      <script src="../../../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../../../../_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="../../../../_static/copybutton.js?v=35a8b989"></script>
      <script>let toggleHintShow = 'Click to show';</script>
      <script>let toggleHintHide = 'Click to hide';</script>
      <script>let toggleOpenOnPrint = 'true';</script>
      <script src="../../../../_static/togglebutton.js?v=4a39c7ea"></script>
      <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
      <script src="../../../../_static/design-tabs.js?v=f930bc37"></script>
    <script src="../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../../index.html" class="icon icon-home">
            plenoptic
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Basic concepts</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../install.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../jupyter.html">Using Jupyter to Run Example Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../conceptual_intro.html">Conceptual Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../models.html">Model requirements</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/quickstart.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../citation.html">Citation Guide and Bibliography</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Synthesis method introductions</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/intro/Eigendistortions.html">Eigendistortions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/intro/MAD_Competition_1.html">MAD Competition Conceptual Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/intro/MAD_Competition_2.html">MAD Competition Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/intro/Metamer.html">Metamers</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Models and metrics</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/models/Perceptual_distance.html">Perceptual distance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/models/Steerable_Pyramid.html">Steerable Pyramid</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/models/portilla_simoncelli/ps_index.html">Portilla-Simoncelli Texture Model</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Synthesis method examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/applications/Demo_Eigendistortion.html">Reproducing Berardino et al., 2017 (Eigendistortions)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/applications/Original_MAD.html">Reproducing Wang and Simoncelli, 2008 (MAD Competition)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced usage</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../synthesis.html">Synthesis object design</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tips.html">Tips and Tricks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../reproducibility.html">Reproducibility and Compatibility</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api/modules.html">API Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/advanced/Display.html">Display and animate functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/advanced/Synthesis_extensions.html">Extending existing synthesis objects</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">plenoptic</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">plenoptic.simulate.models.portilla_simoncelli</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for plenoptic.simulate.models.portilla_simoncelli</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Portilla-Simoncelli texture statistics.</span>

<span class="sd">The Portilla-Simoncelli (PS) texture statistics are a set of image</span>
<span class="sd">statistics, first described in [1]_, that are proposed as a sufficient set</span>
<span class="sd">of measurements for describing visual textures. That is, if two texture</span>
<span class="sd">images have the same values for all PS texture stats, humans should</span>
<span class="sd">consider them as members of the same family of textures.</span>

<span class="sd">References</span>
<span class="sd">----------</span>
<span class="sd">.. [1] J Portilla and E P Simoncelli. A Parametric Texture Model based on</span>
<span class="sd">   Joint Statistics of Complex Wavelet Coefficients. Int&#39;l Journal of</span>
<span class="sd">   Computer Vision. 40(1):49-71, October, 2000.</span>
<span class="sd">   https://www.cns.nyu.edu/~eero/ABSTRACTS/portilla99-abstract.html</span>
<span class="sd">   https://www.cns.nyu.edu/~lcv/texture/</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">collections</span><span class="w"> </span><span class="kn">import</span> <span class="n">OrderedDict</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Literal</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">einops</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">mpl</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.fft</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">Tensor</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">...tools</span><span class="w"> </span><span class="kn">import</span> <span class="n">signal</span><span class="p">,</span> <span class="n">stats</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">...tools.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">to_numpy</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">...tools.display</span><span class="w"> </span><span class="kn">import</span> <span class="n">clean_stem_plot</span><span class="p">,</span> <span class="n">clean_up_axes</span><span class="p">,</span> <span class="n">update_stem</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">...tools.validate</span><span class="w"> </span><span class="kn">import</span> <span class="n">validate_input</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">..canonical_computations.steerable_pyramid_freq</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">SCALES_TYPE</span> <span class="k">as</span> <span class="n">PYR_SCALES_TYPE</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">..canonical_computations.steerable_pyramid_freq</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">SteerablePyramidFreq</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">SCALES_TYPE</span> <span class="o">=</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;pixel_statistics&quot;</span><span class="p">]</span> <span class="o">|</span> <span class="n">PYR_SCALES_TYPE</span>


<div class="viewcode-block" id="PortillaSimoncelli">
<a class="viewcode-back" href="../../../../api/plenoptic.simulate.models.html#plenoptic.simulate.models.portilla_simoncelli.PortillaSimoncelli">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">PortillaSimoncelli</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Portila-Simoncelli texture statistics.</span>

<span class="sd">    The Portilla-Simoncelli (PS) texture statistics are a set of image</span>
<span class="sd">    statistics, first described in [1]_, that are proposed as a sufficient set</span>
<span class="sd">    of measurements for describing visual textures. That is, if two texture</span>
<span class="sd">    images have the same values for all PS texture stats, humans should</span>
<span class="sd">    consider them as members of the same family of textures.</span>

<span class="sd">    The PS stats are computed based on the</span>
<span class="sd">    :class:`~plenoptic.simulate.canonical_computations.steerable_pyramid_freq.SteerablePyramidFreq`</span>
<span class="sd">    [2]_. They consist of the local auto-correlations, cross-scale</span>
<span class="sd">    (within-orientation) correlations, and cross-orientation (within-scale)</span>
<span class="sd">    correlations of both the pyramid coefficients and the local energy (as</span>
<span class="sd">    computed by those coefficients). Additionally, they include the first four</span>
<span class="sd">    global moments (mean, variance, skew, and kurtosis) of the image and</span>
<span class="sd">    down-sampled versions of that image. See the paper and notebook for more</span>
<span class="sd">    description.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    image_shape</span>
<span class="sd">        Shape of input image.</span>
<span class="sd">    n_scales</span>
<span class="sd">        The number of pyramid scales used to measure the statistics.</span>
<span class="sd">    n_orientations</span>
<span class="sd">        The number of orientations used to measure the statistics.</span>
<span class="sd">    spatial_corr_width</span>
<span class="sd">        The width of the spatial cross- and auto-correlation statistics.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    scales: list</span>
<span class="sd">        The names of the unique scales of coefficients in the pyramid, used for</span>
<span class="sd">        coarse-to-fine metamer synthesis.</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        If the height or width of ``image`` cannot be divided by 2 ``n_scales``</span>
<span class="sd">        times. This is necessary because of how the model handles multiscale</span>
<span class="sd">        representations.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] J Portilla and E P Simoncelli. A Parametric Texture Model based on</span>
<span class="sd">       Joint Statistics of Complex Wavelet Coefficients. Int&#39;l Journal of</span>
<span class="sd">       Computer Vision. 40(1):49-71, October, 2000.</span>
<span class="sd">       https://www.cns.nyu.edu/~eero/ABSTRACTS/portilla99-abstract.html</span>
<span class="sd">       https://www.cns.nyu.edu/~lcv/texture/</span>
<span class="sd">    .. [2] E P Simoncelli and W T Freeman, &quot;The Steerable Pyramid: A Flexible</span>
<span class="sd">       Architecture for Multi-Scale Derivative Computation,&quot; Second Int&#39;l Conf</span>
<span class="sd">       on Image Processing, Washington, DC, Oct 1995.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">image_shape</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span>
        <span class="n">n_scales</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
        <span class="n">n_orientations</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
        <span class="n">spatial_corr_width</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">9</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">image_shape</span> <span class="o">=</span> <span class="n">image_shape</span>
        <span class="k">if</span> <span class="nb">any</span><span class="p">([(</span><span class="n">image_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="mi">2</span><span class="o">**</span><span class="n">i</span><span class="p">)</span> <span class="o">%</span> <span class="mi">2</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_scales</span><span class="p">)])</span> <span class="ow">or</span> <span class="nb">any</span><span class="p">(</span>
            <span class="p">[(</span><span class="n">image_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">/</span> <span class="mi">2</span><span class="o">**</span><span class="n">i</span><span class="p">)</span> <span class="o">%</span> <span class="mi">2</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_scales</span><span class="p">)]</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Because of how the Portilla-Simoncelli model handles &quot;</span>
                <span class="s2">&quot;multiscale representations, it only works with images&quot;</span>
                <span class="s2">&quot; whose shape can be divided by 2 `n_scales` times.&quot;</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">spatial_corr_width</span> <span class="o">=</span> <span class="n">spatial_corr_width</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span> <span class="o">=</span> <span class="n">n_scales</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_orientations</span> <span class="o">=</span> <span class="n">n_orientations</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_pyr</span> <span class="o">=</span> <span class="n">SteerablePyramidFreq</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">image_shape</span><span class="p">,</span>
            <span class="n">height</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span><span class="p">,</span>
            <span class="n">order</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_orientations</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span>
            <span class="n">is_complex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">tight_frame</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">scales</span> <span class="o">=</span> <span class="p">(</span>
            <span class="p">[</span><span class="s2">&quot;pixel_statistics&quot;</span><span class="p">,</span> <span class="s2">&quot;residual_lowpass&quot;</span><span class="p">]</span>
            <span class="o">+</span> <span class="p">[</span><span class="n">ii</span> <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_scales</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)]</span>
            <span class="o">+</span> <span class="p">[</span><span class="s2">&quot;residual_highpass&quot;</span><span class="p">]</span>
        <span class="p">)</span>

        <span class="c1"># Dictionary defining shape of the statistics and which scale they&#39;re</span>
        <span class="c1"># associated with</span>
        <span class="n">scales_shape_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_scales_shape_dict</span><span class="p">()</span>

        <span class="c1"># Dictionary defining necessary statistics, that is, those that are not</span>
        <span class="c1"># redundant</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_necessary_stats_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_necessary_stats_dict</span><span class="p">(</span>
            <span class="n">scales_shape_dict</span>
        <span class="p">)</span>
        <span class="c1"># turn this into tensor we can use in forward pass. first into a</span>
        <span class="c1"># boolean mask...</span>
        <span class="n">_necessary_stats_mask</span> <span class="o">=</span> <span class="n">einops</span><span class="o">.</span><span class="n">pack</span><span class="p">(</span>
            <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_necessary_stats_dict</span><span class="o">.</span><span class="n">values</span><span class="p">()),</span> <span class="s2">&quot;*&quot;</span>
        <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="c1"># then into a tensor of indices</span>
        <span class="n">_necessary_stats_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">_necessary_stats_mask</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;_necessary_stats_mask&quot;</span><span class="p">,</span> <span class="n">_necessary_stats_mask</span><span class="p">)</span>

        <span class="c1"># This array is composed of the following values: &#39;pixel_statistics&#39;,</span>
        <span class="c1"># &#39;residual_lowpass&#39;, &#39;residual_highpass&#39; and integer values from 0 to</span>
        <span class="c1"># self.n_scales-1. It is the same size as the representation tensor</span>
        <span class="c1"># returned by this object&#39;s forward method. It must be a numpy array so</span>
        <span class="c1"># we can have a mixture of ints and strs (and so we can use np.isin</span>
        <span class="c1"># later)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_representation_scales</span> <span class="o">=</span> <span class="n">einops</span><span class="o">.</span><span class="n">pack</span><span class="p">(</span>
            <span class="nb">list</span><span class="p">(</span><span class="n">scales_shape_dict</span><span class="o">.</span><span class="n">values</span><span class="p">()),</span> <span class="s2">&quot;*&quot;</span>
        <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="c1"># just select the scales of the necessary stats.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_representation_scales</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_representation_scales</span><span class="p">[</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_necessary_stats_mask</span>
        <span class="p">]</span>
        <span class="c1"># This model has no trainable parameters, so it&#39;s always in eval mode</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_create_scales_shape_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">OrderedDict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create dictionary defining scales and shape of each stat.</span>

<span class="sd">        This dictionary functions as metadata which is used for two main</span>
<span class="sd">        purposes:</span>

<span class="sd">        - Scale assignment. In order for optimization to work well, we proceed</span>
<span class="sd">          in a &quot;coarse-to-fine&quot; manner. That is, we start optimization by only</span>
<span class="sd">          considering the statistics related to the lowest frequencies, and</span>
<span class="sd">          gradually add in those related to higher and higher frequencies. This</span>
<span class="sd">          is similar to blurring the objective function and then gradually</span>
<span class="sd">          adding in finer and finer details. The numbers in this dictionary map</span>
<span class="sd">          the computed statistics to their corresponding scales, which we use</span>
<span class="sd">          in remove_scales to throw away some stats as needed.</span>

<span class="sd">        - Redundant stat identification. As described at the bottom of the</span>
<span class="sd">          notebook, the model incidentally computes a whole bunch of redundant</span>
<span class="sd">          stats, because auto- and cross-correlation matrices have certain</span>
<span class="sd">          symmetries. the _create_necessary_stats_dict method accepts the</span>
<span class="sd">          dictionary created here as input and uses the values to get the</span>
<span class="sd">          shapes of these and insert True/False as necessary.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        scales_shape_dict</span>
<span class="sd">           Dictionary defining shape and associated scales of each computed</span>
<span class="sd">           statistic. The keys name each statistic, with dummy arrays as</span>
<span class="sd">           values. These arrays have the same shape as the stat (excluding</span>
<span class="sd">           batch and channel), with values defining which scale they correspond</span>
<span class="sd">           to.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">shape_dict</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
        <span class="c1"># There are 6 pixel statistics</span>
        <span class="n">shape_dict</span><span class="p">[</span><span class="s2">&quot;pixel_statistics&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="mi">6</span> <span class="o">*</span> <span class="p">[</span><span class="s2">&quot;pixel_statistics&quot;</span><span class="p">])</span>

        <span class="c1"># These are the basic building blocks of the scale assignments for many</span>
        <span class="c1"># of the statistics calculated by the PortillaSimoncelli model.</span>
        <span class="n">scales</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span><span class="p">)</span>
        <span class="c1"># the cross-scale correlations exclude the coarsest scale</span>
        <span class="n">scales_without_coarsest</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="c1"># the statistics computed on the reconstructed bandpass images have an</span>
        <span class="c1"># extra scale corresponding to the lowpass residual</span>
        <span class="n">scales_with_lowpass</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
            <span class="n">scales</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="o">+</span> <span class="p">[</span><span class="s2">&quot;residual_lowpass&quot;</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">object</span>
        <span class="p">)</span>

        <span class="c1"># now we go through each statistic in order and create a dummy array</span>
        <span class="c1"># full of 1s with the same shape as the actual statistic (excluding the</span>
        <span class="c1"># batch and channel dimensions, as each stat is computed independently</span>
        <span class="c1"># across those dimensions). We then multiply it by one of the scales</span>
        <span class="c1"># arrays above to turn those 1s into values describing the</span>
        <span class="c1"># corresponding scale.</span>

        <span class="n">auto_corr_mag</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span>
            <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">spatial_corr_width</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">spatial_corr_width</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">n_orientations</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span><span class="p">,</span>
            <span class="p">),</span>
            <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1"># this rearrange call is turning scales from 1d with shape (n_scales, )</span>
        <span class="c1"># to 4d with shape (1, 1, n_scales, 1), so that it matches</span>
        <span class="c1"># auto_corr_mag. the following rearrange calls do similar.</span>
        <span class="n">auto_corr_mag</span> <span class="o">*=</span> <span class="n">einops</span><span class="o">.</span><span class="n">rearrange</span><span class="p">(</span><span class="n">scales</span><span class="p">,</span> <span class="s2">&quot;s -&gt; 1 1 1 s&quot;</span><span class="p">)</span>
        <span class="n">shape_dict</span><span class="p">[</span><span class="s2">&quot;auto_correlation_magnitude&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">auto_corr_mag</span>

        <span class="n">shape_dict</span><span class="p">[</span><span class="s2">&quot;skew_reconstructed&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">scales_with_lowpass</span>

        <span class="n">shape_dict</span><span class="p">[</span><span class="s2">&quot;kurtosis_reconstructed&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">scales_with_lowpass</span>

        <span class="n">auto_corr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span>
            <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">spatial_corr_width</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">spatial_corr_width</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
            <span class="p">),</span>
            <span class="n">dtype</span><span class="o">=</span><span class="nb">object</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">auto_corr</span> <span class="o">*=</span> <span class="n">einops</span><span class="o">.</span><span class="n">rearrange</span><span class="p">(</span><span class="n">scales_with_lowpass</span><span class="p">,</span> <span class="s2">&quot;s -&gt; 1 1 s&quot;</span><span class="p">)</span>
        <span class="n">shape_dict</span><span class="p">[</span><span class="s2">&quot;auto_correlation_reconstructed&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">auto_corr</span>

        <span class="n">shape_dict</span><span class="p">[</span><span class="s2">&quot;std_reconstructed&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">scales_with_lowpass</span>

        <span class="n">cross_orientation_corr_mag</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span>
            <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_orientations</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_orientations</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span><span class="p">),</span>
            <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">cross_orientation_corr_mag</span> <span class="o">*=</span> <span class="n">einops</span><span class="o">.</span><span class="n">rearrange</span><span class="p">(</span><span class="n">scales</span><span class="p">,</span> <span class="s2">&quot;s -&gt; 1 1 s&quot;</span><span class="p">)</span>
        <span class="n">shape_dict</span><span class="p">[</span><span class="s2">&quot;cross_orientation_correlation_magnitude&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">cross_orientation_corr_mag</span>
        <span class="p">)</span>

        <span class="n">mags_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">n_orientations</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
        <span class="n">mags_std</span> <span class="o">*=</span> <span class="n">einops</span><span class="o">.</span><span class="n">rearrange</span><span class="p">(</span><span class="n">scales</span><span class="p">,</span> <span class="s2">&quot;s -&gt; 1 s&quot;</span><span class="p">)</span>
        <span class="n">shape_dict</span><span class="p">[</span><span class="s2">&quot;magnitude_std&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">mags_std</span>

        <span class="n">cross_scale_corr_mag</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span>
            <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_orientations</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_orientations</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">cross_scale_corr_mag</span> <span class="o">*=</span> <span class="n">einops</span><span class="o">.</span><span class="n">rearrange</span><span class="p">(</span><span class="n">scales_without_coarsest</span><span class="p">,</span> <span class="s2">&quot;s -&gt; 1 1 s&quot;</span><span class="p">)</span>
        <span class="n">shape_dict</span><span class="p">[</span><span class="s2">&quot;cross_scale_correlation_magnitude&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">cross_scale_corr_mag</span>

        <span class="n">cross_scale_corr_real</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span>
            <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_orientations</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_orientations</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">cross_scale_corr_real</span> <span class="o">*=</span> <span class="n">einops</span><span class="o">.</span><span class="n">rearrange</span><span class="p">(</span><span class="n">scales_without_coarsest</span><span class="p">,</span> <span class="s2">&quot;s -&gt; 1 1 s&quot;</span><span class="p">)</span>
        <span class="n">shape_dict</span><span class="p">[</span><span class="s2">&quot;cross_scale_correlation_real&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">cross_scale_corr_real</span>

        <span class="n">shape_dict</span><span class="p">[</span><span class="s2">&quot;var_highpass_residual&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="s2">&quot;residual_highpass&quot;</span><span class="p">])</span>

        <span class="k">return</span> <span class="n">shape_dict</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_create_necessary_stats_dict</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">scales_shape_dict</span><span class="p">:</span> <span class="n">OrderedDict</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">OrderedDict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create mask specifying the necessary statistics.</span>

<span class="sd">        Some of the statistics computed by the model are redundant, due to</span>
<span class="sd">        symmetries. For example, about half of the values in the</span>
<span class="sd">        autocorrelation matrices are duplicates. See the Portilla-Simoncelli</span>
<span class="sd">        notebook for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        scales_shape_dict</span>
<span class="sd">            Dictionary defining shape and associated scales of each computed</span>
<span class="sd">            statistic.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        necessary_stats_dict</span>
<span class="sd">            Dictionary defining which statistics are necessary (i.e., not</span>
<span class="sd">            redundant). Will have the same keys as scales_shape_dict, with the</span>
<span class="sd">            values being boolean tensors of the same shape as</span>
<span class="sd">            scales_shape_dict&#39;s corresponding values. True denotes the</span>
<span class="sd">            statistics that will be included in the model&#39;s output, while False</span>
<span class="sd">            denotes the redundant ones we will toss.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">mask_dict</span> <span class="o">=</span> <span class="n">scales_shape_dict</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="c1"># Pre-compute some necessary indices.</span>
        <span class="c1"># Lower triangular indices (including diagonal), for auto correlations</span>
        <span class="n">tril_inds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tril_indices</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">spatial_corr_width</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">spatial_corr_width</span><span class="p">)</span>
        <span class="c1"># Get the second half of the diagonal, i.e., everything from the center</span>
        <span class="c1"># element on. These are all repeated for the auto correlations. (As</span>
        <span class="c1"># these are autocorrelations (rather than auto-covariance) matrices,</span>
        <span class="c1"># they&#39;ve been normalized by the variance and so the center element is</span>
        <span class="c1"># always 1, and thus uninformative)</span>
        <span class="n">diag_repeated</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span>
            <span class="n">start</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">spatial_corr_width</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">spatial_corr_width</span>
        <span class="p">)</span>
        <span class="c1"># Upper triangle indices, including diagonal. These are redundant stats</span>
        <span class="c1"># for cross_orientation_correlation_magnitude (because we&#39;ve normalized</span>
        <span class="c1"># this matrix to be true cross-correlations, the diagonals are all 1,</span>
        <span class="c1"># like for the auto-correlations)</span>
        <span class="n">triu_inds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">triu_indices</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_orientations</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_orientations</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">mask_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="p">[</span>
                <span class="s2">&quot;auto_correlation_magnitude&quot;</span><span class="p">,</span>
                <span class="s2">&quot;auto_correlation_reconstructed&quot;</span><span class="p">,</span>
            <span class="p">]:</span>
                <span class="c1"># Symmetry M_{i,j} = M_{n-i+1, n-j+1}</span>
                <span class="c1"># Start with all False, then place True in necessary stats.</span>
                <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
                <span class="n">mask</span><span class="p">[</span><span class="n">tril_inds</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">tril_inds</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="c1"># if spatial_corr_width is even, then the first row is not</span>
                <span class="c1"># redundant with anything either</span>
                <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">mod</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">spatial_corr_width</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">mask</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="n">mask</span><span class="p">[</span><span class="n">diag_repeated</span><span class="p">,</span> <span class="n">diag_repeated</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">elif</span> <span class="n">k</span> <span class="o">==</span> <span class="s2">&quot;cross_orientation_correlation_magnitude&quot;</span><span class="p">:</span>
                <span class="c1"># Symmetry M_{i,j} = M_{j,i}.</span>
                <span class="c1"># Start with all True, then place False in redundant stats.</span>
                <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
                <span class="n">mask</span><span class="p">[</span><span class="n">triu_inds</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">triu_inds</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># all of the other stats have no redundancies</span>
                <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
            <span class="n">mask_dict</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">mask</span>
        <span class="k">return</span> <span class="n">mask_dict</span>

<div class="viewcode-block" id="PortillaSimoncelli.forward">
<a class="viewcode-back" href="../../../../api/plenoptic.simulate.models.html#plenoptic.simulate.models.portilla_simoncelli.PortillaSimoncelli.forward">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">scales</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">SCALES_TYPE</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generate Texture Statistics representation of an image.</span>

<span class="sd">        Note that separate batches and channels are analyzed in parallel.</span>

<span class="sd">        For any representation that contains info across scales, the scales always run</span>
<span class="sd">        from fine to coarse, representing all orientations at a given scale before</span>
<span class="sd">        moving on.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        image</span>
<span class="sd">            A 4d tensor (batch, channel, height, width) containing the image(s) to</span>
<span class="sd">            analyze.</span>
<span class="sd">        scales</span>
<span class="sd">            Which scales to include in the returned representation. If None, we</span>
<span class="sd">            include all scales. Otherwise, can contain subset of values present</span>
<span class="sd">            in this model&#39;s ``scales`` attribute, and the returned tensor will</span>
<span class="sd">            then contain the subset corresponding to those scales.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        representation_tensor</span>
<span class="sd">            3d tensor of shape (batch, channel, stats) containing the measured</span>
<span class="sd">            texture statistics.</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If ``image`` is not 4d or has a dtype other than float or complex.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; import plenoptic as po</span>
<span class="sd">        &gt;&gt;&gt; img = po.data.curie()</span>
<span class="sd">        &gt;&gt;&gt; portilla_simoncelli_model = po.simul.PortillaSimoncelli(img.shape[2:])</span>
<span class="sd">        &gt;&gt;&gt; representation_tensor = portilla_simoncelli_model(img)</span>
<span class="sd">        &gt;&gt;&gt; representation_tensor.shape</span>
<span class="sd">        torch.Size([1, 1, 1046])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">validate_input</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

        <span class="c1"># pyr_dict is the dictionary of complex-valued tensors returned by the</span>
        <span class="c1"># steerable pyramid. pyr_coeffs is a list (length n_scales) of 5d</span>
        <span class="c1"># tensors, each of shape (batch, channel, scales, n_orientations,</span>
        <span class="c1"># height, width) containing the complex-valued oriented bands, while</span>
        <span class="c1"># highpass is a real-valued 4d tensor of shape (batch, channel, height,</span>
        <span class="c1"># width). Note that the residual lowpass in pyr_dict has been demeaned.</span>
        <span class="c1"># We keep both the dict and list of pyramid coefficients because we</span>
        <span class="c1"># need the dictionary for reconstructing the image done later on.</span>
        <span class="n">pyr_dict</span><span class="p">,</span> <span class="n">pyr_coeffs</span><span class="p">,</span> <span class="n">highpass</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_pyr_coeffs</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

        <span class="c1"># Now, we create several intermediate representations that we&#39;ll use to</span>
        <span class="c1"># compute the texture statistics later.</span>

        <span class="c1"># First, two intermediate dictionaries: magnitude_pyr_coeffs and</span>
        <span class="c1"># real_pyr_coeffs, which contain the demeaned magnitude of the pyramid</span>
        <span class="c1"># coefficients and the real part of the pyramid coefficients</span>
        <span class="c1"># respectively.</span>
        <span class="p">(</span>
            <span class="n">mag_pyr_coeffs</span><span class="p">,</span>
            <span class="n">real_pyr_coeffs</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_intermediate_representations</span><span class="p">(</span><span class="n">pyr_coeffs</span><span class="p">)</span>

        <span class="c1"># Then, the reconstructed lowpass image at each scale. (this is a list</span>
        <span class="c1"># of length n_scales+1 containing tensors of shape (batch, channel,</span>
        <span class="c1"># height, width))</span>
        <span class="n">reconstructed_images</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_reconstruct_lowpass_at_each_scale</span><span class="p">(</span><span class="n">pyr_dict</span><span class="p">)</span>
        <span class="c1"># the reconstructed_images list goes from coarse-to-fine, but we want</span>
        <span class="c1"># each of the stats computed from it to go from fine-to-coarse, so we</span>
        <span class="c1"># reverse its direction.</span>
        <span class="n">reconstructed_images</span> <span class="o">=</span> <span class="n">reconstructed_images</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="c1"># Now, start calculating the PS texture stats.</span>

        <span class="c1"># Calculate pixel statistics (mean, variance, skew, kurtosis, min,</span>
        <span class="c1"># max).</span>
        <span class="n">pixel_stats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_pixel_stats</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

        <span class="c1"># Compute the central autocorrelation of the coefficient magnitudes. This is a</span>
        <span class="c1"># tensor of shape: (batch, channel, spatial_corr_width, spatial_corr_width,</span>
        <span class="c1"># n_orientations, n_scales). var_mags is a tensor of shape (batch, channel,</span>
        <span class="c1"># n_orientations, n_scales)</span>
        <span class="n">autocorr_mags</span><span class="p">,</span> <span class="n">mags_var</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_autocorr</span><span class="p">(</span><span class="n">mag_pyr_coeffs</span><span class="p">)</span>
        <span class="c1"># mags_var is the variance of the magnitude coefficients at each scale (it&#39;s an</span>
        <span class="c1"># intermediary of the computation of the auto-correlations). We take the square</span>
        <span class="c1"># root to get the standard deviation.</span>
        <span class="n">mags_std</span> <span class="o">=</span> <span class="n">mags_var</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>

        <span class="c1"># Compute the central autocorrelation of the reconstructed lowpass</span>
        <span class="c1"># images at each scale (and their variances). autocorr_recon is a</span>
        <span class="c1"># tensor of shape (batch, channel, spatial_corr_width,</span>
        <span class="c1"># spatial_corr_width, n_scales+1), and var_recon is a tensor of shape</span>
        <span class="c1"># (batch, channel, n_scales+1)</span>
        <span class="n">autocorr_recon</span><span class="p">,</span> <span class="n">var_recon</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_autocorr</span><span class="p">(</span><span class="n">reconstructed_images</span><span class="p">)</span>
        <span class="c1"># Compute the standard deviation, skew, and kurtosis of each</span>
        <span class="c1"># reconstructed lowpass image. std_recon, skew_recon, and</span>
        <span class="c1"># kurtosis_recon will all end up as tensors of shape (batch, channel,</span>
        <span class="c1"># n_scales+1)</span>
        <span class="n">std_recon</span> <span class="o">=</span> <span class="n">var_recon</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>
        <span class="n">skew_recon</span><span class="p">,</span> <span class="n">kurtosis_recon</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_skew_kurtosis_recon</span><span class="p">(</span>
            <span class="n">reconstructed_images</span><span class="p">,</span> <span class="n">var_recon</span><span class="p">,</span> <span class="n">pixel_stats</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
        <span class="p">)</span>

        <span class="c1"># Compute the cross-orientation correlations between the magnitude</span>
        <span class="c1"># coefficients at each scale. this will be a tensor of shape (batch,</span>
        <span class="c1"># channel, n_orientations, n_orientations, n_scales)</span>
        <span class="n">cross_ori_corr_mags</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_cross_correlation</span><span class="p">(</span>
            <span class="n">mag_pyr_coeffs</span><span class="p">,</span> <span class="n">mag_pyr_coeffs</span><span class="p">,</span> <span class="n">mags_var</span><span class="p">,</span> <span class="n">mags_var</span>
        <span class="p">)</span>

        <span class="c1"># If we have more than one scale, compute the cross-scale correlations</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># First, double the phase the coefficients, so we can correctly</span>
            <span class="c1"># compute correlations across scales.</span>
            <span class="p">(</span>
                <span class="n">phase_doubled_mags</span><span class="p">,</span>
                <span class="n">phase_doubled_sep</span><span class="p">,</span>
            <span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_double_phase_pyr_coeffs</span><span class="p">(</span><span class="n">pyr_coeffs</span><span class="p">)</span>
            <span class="c1"># Compute the cross-scale correlations between the magnitude</span>
            <span class="c1"># coefficients. For each coefficient, we&#39;re correlating it with the</span>
            <span class="c1"># coefficients at the next-coarsest scale. this will be a tensor of</span>
            <span class="c1"># shape (batch, channel, n_orientations, n_orientations,</span>
            <span class="c1"># n_scales-1)</span>
            <span class="n">cross_scale_corr_mags</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_cross_correlation</span><span class="p">(</span>
                <span class="n">mag_pyr_coeffs</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">phase_doubled_mags</span><span class="p">,</span> <span class="n">mags_var</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="p">)</span>
            <span class="c1"># Compute the cross-scale correlations between the real</span>
            <span class="c1"># coefficients and the real and imaginary coefficients at the next</span>
            <span class="c1"># coarsest scale. this will be a tensor of shape (batch, channel,</span>
            <span class="c1"># n_orientations, 2*n_orientations, n_scales-1)</span>
            <span class="n">cross_scale_corr_real</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_cross_correlation</span><span class="p">(</span>
                <span class="n">real_pyr_coeffs</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">phase_doubled_sep</span>
            <span class="p">)</span>

        <span class="c1"># Compute the variance of the highpass residual</span>
        <span class="n">var_highpass_residual</span> <span class="o">=</span> <span class="n">highpass</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>

        <span class="c1"># Now, combine all these stats together, first into a list</span>
        <span class="n">all_stats</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">pixel_stats</span><span class="p">,</span>
            <span class="n">autocorr_mags</span><span class="p">,</span>
            <span class="n">skew_recon</span><span class="p">,</span>
            <span class="n">kurtosis_recon</span><span class="p">,</span>
            <span class="n">autocorr_recon</span><span class="p">,</span>
            <span class="n">std_recon</span><span class="p">,</span>
            <span class="n">cross_ori_corr_mags</span><span class="p">,</span>
            <span class="n">mags_std</span><span class="p">,</span>
        <span class="p">]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">all_stats</span> <span class="o">+=</span> <span class="p">[</span><span class="n">cross_scale_corr_mags</span><span class="p">,</span> <span class="n">cross_scale_corr_real</span><span class="p">]</span>
        <span class="n">all_stats</span> <span class="o">+=</span> <span class="p">[</span><span class="n">var_highpass_residual</span><span class="p">]</span>
        <span class="c1"># And then pack them into a 3d tensor</span>
        <span class="n">representation_tensor</span><span class="p">,</span> <span class="n">pack_info</span> <span class="o">=</span> <span class="n">einops</span><span class="o">.</span><span class="n">pack</span><span class="p">(</span><span class="n">all_stats</span><span class="p">,</span> <span class="s2">&quot;b c *&quot;</span><span class="p">)</span>

        <span class="c1"># the only time when this is None is during testing, when we make sure</span>
        <span class="c1"># that our assumptions are all valid.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_necessary_stats_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># store this so we can unpack this info (only possible when we&#39;ve</span>
            <span class="c1"># discarded no stats)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_pack_info</span> <span class="o">=</span> <span class="n">pack_info</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Throw away all redundant statistics</span>
            <span class="n">representation_tensor</span> <span class="o">=</span> <span class="n">representation_tensor</span><span class="o">.</span><span class="n">index_select</span><span class="p">(</span>
                <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_necessary_stats_mask</span>
            <span class="p">)</span>

        <span class="c1"># Return the subset of stats corresponding to the specified scale.</span>
        <span class="k">if</span> <span class="n">scales</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">representation_tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">remove_scales</span><span class="p">(</span><span class="n">representation_tensor</span><span class="p">,</span> <span class="n">scales</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">representation_tensor</span></div>


<div class="viewcode-block" id="PortillaSimoncelli.remove_scales">
<a class="viewcode-back" href="../../../../api/plenoptic.simulate.models.html#plenoptic.simulate.models.portilla_simoncelli.PortillaSimoncelli.remove_scales">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">remove_scales</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">representation_tensor</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">scales_to_keep</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">SCALES_TYPE</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Remove statistics not associated with scales.</span>

<span class="sd">        For a given representation_tensor and a list of scales_to_keep, this</span>
<span class="sd">        attribute removes all statistics *not* associated with those scales.</span>

<span class="sd">        Note that calling this method will always remove statistics.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        representation_tensor</span>
<span class="sd">            3d tensor containing the measured representation statistics.</span>
<span class="sd">        scales_to_keep</span>
<span class="sd">            Which scales to include in the returned representation. Can contain</span>
<span class="sd">            subset of values present in this model&#39;s ``scales`` attribute, and</span>
<span class="sd">            the returned tensor will then contain the subset of the full</span>
<span class="sd">            representation corresponding to those scales.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        limited_representation_tensor</span>
<span class="sd">            Representation tensor with some statistics removed.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; import plenoptic as po</span>
<span class="sd">        &gt;&gt;&gt; img = po.data.curie()</span>
<span class="sd">        &gt;&gt;&gt; portilla_simoncelli_model = po.simul.PortillaSimoncelli(img.shape[2:])</span>
<span class="sd">        &gt;&gt;&gt; representation_tensor = portilla_simoncelli_model(img)</span>
<span class="sd">        &gt;&gt;&gt; representation_tensor.shape</span>
<span class="sd">        torch.Size([1, 1, 1046])</span>
<span class="sd">        &gt;&gt;&gt; limited_representation_tensor = portilla_simoncelli_model.remove_scales(</span>
<span class="sd">        ...     representation_tensor, scales_to_keep=[0]</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; limited_representation_tensor.shape</span>
<span class="sd">        torch.Size([1, 1, 261])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># this is necessary because object is the dtype of</span>
        <span class="c1"># self._representation_scales</span>
        <span class="n">scales_to_keep</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">scales_to_keep</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">object</span><span class="p">)</span>
        <span class="c1"># np.isin returns a 1d boolean array of the same shape as</span>
        <span class="c1"># self._representation_scales with True at each location where that</span>
        <span class="c1"># value appears in scales_to_keep. where then converts this boolean</span>
        <span class="c1"># array into indices</span>
        <span class="n">ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_representation_scales</span><span class="p">,</span> <span class="n">scales_to_keep</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">ind</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">ind</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">representation_tensor</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">representation_tensor</span><span class="o">.</span><span class="n">index_select</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">ind</span><span class="p">)</span></div>


<div class="viewcode-block" id="PortillaSimoncelli.convert_to_tensor">
<a class="viewcode-back" href="../../../../api/plenoptic.simulate.models.html#plenoptic.simulate.models.portilla_simoncelli.PortillaSimoncelli.convert_to_tensor">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">convert_to_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">representation_dict</span><span class="p">:</span> <span class="n">OrderedDict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Convert dictionary of statistics to a tensor.</span>

<span class="sd">        The output has shape (batch, channel, n_statistics), flattening and</span>
<span class="sd">        concatenating across all statistic classes. The dictionary representation</span>
<span class="sd">        may be easier to make sense of.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        representation_dict</span>
<span class="sd">             Dictionary of representation.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        rep</span>
<span class="sd">            3d tensor of statistics.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        convert_to_dict</span>
<span class="sd">            Convert tensor representation to dictionary.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; import plenoptic as po</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>
<span class="sd">        &gt;&gt;&gt; img = po.data.curie()</span>
<span class="sd">        &gt;&gt;&gt; portilla_simoncelli_model = po.simul.PortillaSimoncelli(img.shape[2:])</span>
<span class="sd">        &gt;&gt;&gt; representation_tensor = portilla_simoncelli_model(img)</span>
<span class="sd">        &gt;&gt;&gt; representation_dict = portilla_simoncelli_model.convert_to_dict(</span>
<span class="sd">        ...     representation_tensor</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; representation_tensor_new = portilla_simoncelli_model.convert_to_tensor(</span>
<span class="sd">        ...     representation_dict</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; torch.equal(representation_tensor, representation_tensor_new)</span>
<span class="sd">        True</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">rep</span> <span class="o">=</span> <span class="n">einops</span><span class="o">.</span><span class="n">pack</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">representation_dict</span><span class="o">.</span><span class="n">values</span><span class="p">()),</span> <span class="s2">&quot;b c *&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="c1"># then get rid of all the nans / unnecessary stats</span>
        <span class="k">return</span> <span class="n">rep</span><span class="o">.</span><span class="n">index_select</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_necessary_stats_mask</span><span class="p">)</span></div>


<div class="viewcode-block" id="PortillaSimoncelli.convert_to_dict">
<a class="viewcode-back" href="../../../../api/plenoptic.simulate.models.html#plenoptic.simulate.models.portilla_simoncelli.PortillaSimoncelli.convert_to_dict">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">convert_to_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">representation_tensor</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">OrderedDict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Convert tensor of statistics to a dictionary.</span>

<span class="sd">        While the tensor representation is required by plenoptic&#39;s synthesis</span>
<span class="sd">        objects, the dictionary representation is easier to manually inspect.</span>

<span class="sd">        This dictionary will contain NaNs in its values: these are placeholders</span>
<span class="sd">        for the redundant statistics.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        representation_tensor</span>
<span class="sd">            3d tensor of statistics.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        rep</span>
<span class="sd">            Dictionary of representation, with informative keys.</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If ``representation_tensor`` has an unexpected number of elements. This can</span>
<span class="sd">            happen if some elements were manually removed from</span>
<span class="sd">            ``representation_tensor``, if a non-``None`` value was passed to ``forward``</span>
<span class="sd">            when computing it, or if it was computed using a different instantiation of</span>
<span class="sd">            the model.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        convert_to_tensor:</span>
<span class="sd">            Convert dictionary representation to tensor.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; import plenoptic as po</span>
<span class="sd">        &gt;&gt;&gt; img = po.data.curie()</span>
<span class="sd">        &gt;&gt;&gt; portilla_simoncelli_model = po.simul.PortillaSimoncelli(</span>
<span class="sd">        ...     img.shape[2:], n_scales=3</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; representation_tensor = portilla_simoncelli_model(img)</span>
<span class="sd">        &gt;&gt;&gt; representation_dict = portilla_simoncelli_model.convert_to_dict(</span>
<span class="sd">        ...     representation_tensor</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; # We will go through and examine each of these keys individually</span>
<span class="sd">        &gt;&gt;&gt; # Shape is (batch, channel, 6): first four moments plus min and max</span>
<span class="sd">        &gt;&gt;&gt; # of input image</span>
<span class="sd">        &gt;&gt;&gt; representation_dict[&quot;pixel_statistics&quot;].shape</span>
<span class="sd">        torch.Size([1, 1, 6])</span>
<span class="sd">        &gt;&gt;&gt; # Shape is (batch, channel, spatial_corr_width, spatial_corr_width,</span>
<span class="sd">        &gt;&gt;&gt; # n_orientations, n_scales)</span>
<span class="sd">        &gt;&gt;&gt; representation_dict[&quot;auto_correlation_magnitude&quot;].shape</span>
<span class="sd">        torch.Size([1, 1, 9, 9, 4, 3])</span>
<span class="sd">        &gt;&gt;&gt; # Shape is (batch, channel, n_scales+1)</span>
<span class="sd">        &gt;&gt;&gt; representation_dict[&quot;skew_reconstructed&quot;].shape</span>
<span class="sd">        torch.Size([1, 1, 4])</span>
<span class="sd">        &gt;&gt;&gt; # Shape is (batch, channel, n_scales+1)</span>
<span class="sd">        &gt;&gt;&gt; representation_dict[&quot;kurtosis_reconstructed&quot;].shape</span>
<span class="sd">        torch.Size([1, 1, 4])</span>
<span class="sd">        &gt;&gt;&gt; # Shape is (batch, channel, spatial_corr_width, spatial_corr_width,</span>
<span class="sd">        &gt;&gt;&gt; # n_scales+1)</span>
<span class="sd">        &gt;&gt;&gt; representation_dict[&quot;auto_correlation_reconstructed&quot;].shape</span>
<span class="sd">        torch.Size([1, 1, 9, 9, 4])</span>
<span class="sd">        &gt;&gt;&gt; # Shape is (batch, channel, n_scales+1)</span>
<span class="sd">        &gt;&gt;&gt; representation_dict[&quot;std_reconstructed&quot;].shape</span>
<span class="sd">        torch.Size([1, 1, 4])</span>
<span class="sd">        &gt;&gt;&gt; # Shape is (batch, channel, n_orientations, n_orientations, n_scales)</span>
<span class="sd">        &gt;&gt;&gt; representation_dict[&quot;cross_orientation_correlation_magnitude&quot;].shape</span>
<span class="sd">        torch.Size([1, 1, 4, 4, 3])</span>
<span class="sd">        &gt;&gt;&gt; # Shape is (batch, channel, n_orientations, n_scales)</span>
<span class="sd">        &gt;&gt;&gt; representation_dict[&quot;magnitude_std&quot;].shape</span>
<span class="sd">        torch.Size([1, 1, 4, 3])</span>
<span class="sd">        &gt;&gt;&gt; # Shape is (batch, channel, n_orientations, n_orientations, n_scales-1)</span>
<span class="sd">        &gt;&gt;&gt; representation_dict[&quot;cross_scale_correlation_magnitude&quot;].shape</span>
<span class="sd">        torch.Size([1, 1, 4, 4, 2])</span>
<span class="sd">        &gt;&gt;&gt; # Shape is (batch, channel, n_orientations, 2*n_orientations, n_scales-1)</span>
<span class="sd">        &gt;&gt;&gt; representation_dict[&quot;cross_scale_correlation_real&quot;].shape</span>
<span class="sd">        torch.Size([1, 1, 4, 8, 2])</span>
<span class="sd">        &gt;&gt;&gt; # Shape is (batch, channel, 1)</span>
<span class="sd">        &gt;&gt;&gt; representation_dict[&quot;var_highpass_residual&quot;].shape</span>
<span class="sd">        torch.Size([1, 1, 1])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">representation_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_representation_scales</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;representation tensor is the wrong length (expected&quot;</span>
                <span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_representation_scales</span><span class="p">)</span><span class="si">}</span><span class="s2"> but got&quot;</span>
                <span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="n">representation_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">)! Did you remove some of&quot;</span>
                <span class="s2">&quot; the scales? (i.e., by setting scales in the forward pass)?&quot;</span>
                <span class="s2">&quot; convert_to_dict does not support such tensors.&quot;</span>
            <span class="p">)</span>

        <span class="n">rep</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_necessary_stats_dict</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">n_filled</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">rep</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="c1"># each statistic is a tensor with batch and channel dimensions as</span>
            <span class="c1"># found in representation_tensor and all the other dimensions</span>
            <span class="c1"># determined by the values in necessary_stats_dict.</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="o">*</span><span class="n">representation_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">],</span> <span class="o">*</span><span class="n">v</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
            <span class="n">new_v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nan</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span>
                <span class="n">shape</span><span class="p">,</span>
                <span class="n">dtype</span><span class="o">=</span><span class="n">representation_tensor</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                <span class="n">device</span><span class="o">=</span><span class="n">representation_tensor</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="c1"># v.sum() gives the number of necessary elements from this stat</span>
            <span class="n">this_stat_vec</span> <span class="o">=</span> <span class="n">representation_tensor</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">n_filled</span> <span class="p">:</span> <span class="n">n_filled</span> <span class="o">+</span> <span class="n">v</span><span class="o">.</span><span class="n">sum</span><span class="p">()]</span>
            <span class="c1"># use boolean indexing to put the values from new_stat_vec in the</span>
            <span class="c1"># appropriate place</span>
            <span class="n">new_v</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">v</span><span class="p">]</span> <span class="o">=</span> <span class="n">this_stat_vec</span>
            <span class="n">rep</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_v</span>
            <span class="n">n_filled</span> <span class="o">+=</span> <span class="n">v</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">rep</span></div>


    <span class="k">def</span><span class="w"> </span><span class="nf">_compute_pyr_coeffs</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">image</span><span class="p">:</span> <span class="n">Tensor</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">OrderedDict</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute pyramid coefficients of image.</span>

<span class="sd">        Note that the residual lowpass has been demeaned independently for each</span>
<span class="sd">        batch and channel (and this is true of the lowpass returned separately</span>
<span class="sd">        as well as the one included in pyr_coeffs_dict).</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        image</span>
<span class="sd">            4d tensor of shape (batch, channel, height, width) containing the</span>
<span class="sd">            image.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        pyr_coeffs_dict</span>
<span class="sd">            OrderedDict of containing all pyramid coefficients.</span>
<span class="sd">        pyr_coeffs</span>
<span class="sd">            List of length n_scales, containing 5d tensors of shape (batch,</span>
<span class="sd">            channel, n_orientations, height, width) containing the complex-valued</span>
<span class="sd">            oriented bands (note that height and width shrink by half on each</span>
<span class="sd">            scale). This excludes the residual highpass and lowpass bands.</span>
<span class="sd">        highpass</span>
<span class="sd">            The residual highpass as a real-valued 4d tensor (batch, channel,</span>
<span class="sd">            height, width).</span>
<span class="sd">        lowpass</span>
<span class="sd">            The residual lowpass as a real-valued 4d tensor (batch, channel,</span>
<span class="sd">            height, width). This tensor has been demeaned (independently for</span>
<span class="sd">            each batch and channel).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">pyr_coeffs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pyr</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
        <span class="c1"># separate out the residuals and demean the residual lowpass</span>
        <span class="n">lowpass</span> <span class="o">=</span> <span class="n">pyr_coeffs</span><span class="p">[</span><span class="s2">&quot;residual_lowpass&quot;</span><span class="p">]</span>
        <span class="n">lowpass</span> <span class="o">=</span> <span class="n">lowpass</span> <span class="o">-</span> <span class="n">lowpass</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">pyr_coeffs</span><span class="p">[</span><span class="s2">&quot;residual_lowpass&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">lowpass</span>
        <span class="n">highpass</span> <span class="o">=</span> <span class="n">pyr_coeffs</span><span class="p">[</span><span class="s2">&quot;residual_highpass&quot;</span><span class="p">]</span>

        <span class="c1"># This is a list of tensors, one for each scale, where each tensor is</span>
        <span class="c1"># of shape (batch, channel, n_orientations, height, width) (note that</span>
        <span class="c1"># height and width halves on each scale)</span>
        <span class="n">coeffs_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">pyr_coeffs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span><span class="p">)]</span>
        <span class="k">return</span> <span class="n">pyr_coeffs</span><span class="p">,</span> <span class="n">coeffs_list</span><span class="p">,</span> <span class="n">highpass</span><span class="p">,</span> <span class="n">lowpass</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_compute_pixel_stats</span><span class="p">(</span><span class="n">image</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the PS pixel stats: first four moments, min, and max.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        image</span>
<span class="sd">            4d tensor of shape (batch, channel, height, width) containing input</span>
<span class="sd">            image. Stats are computed independently for each batch and channel.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        pixel_stats</span>
<span class="sd">            3d tensor of shape (batch, channel, 6) containing the mean,</span>
<span class="sd">            variance, skew, kurtosis, minimum pixel value, and maximum pixel</span>
<span class="sd">            value (in that order).</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># numpydoc ignore=ES01</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="c1"># we use torch.var instead of plenoptic.tools.variance, because our</span>
        <span class="c1"># variance is the uncorrected (or sample) variance and we want the</span>
        <span class="c1"># corrected one here.</span>
        <span class="n">var</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">skew</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">skew</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">var</span><span class="o">=</span><span class="n">var</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">kurtosis</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">kurtosis</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">var</span><span class="o">=</span><span class="n">var</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="c1"># can&#39;t compute min/max over two dims simultaneously with</span>
        <span class="c1"># torch.min/max, so use einops</span>
        <span class="n">img_min</span> <span class="o">=</span> <span class="n">einops</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="s2">&quot;b c h w -&gt; b c&quot;</span><span class="p">,</span> <span class="s2">&quot;min&quot;</span><span class="p">)</span>
        <span class="n">img_max</span> <span class="o">=</span> <span class="n">einops</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="s2">&quot;b c h w -&gt; b c&quot;</span><span class="p">,</span> <span class="s2">&quot;max&quot;</span><span class="p">)</span>
        <span class="c1"># mean needed to be unflattened to be used by skew and kurtosis</span>
        <span class="c1"># correctly, but we&#39;ll want it to be flattened like this in the final</span>
        <span class="c1"># representation tensor</span>
        <span class="k">return</span> <span class="n">einops</span><span class="o">.</span><span class="n">pack</span><span class="p">([</span><span class="n">mean</span><span class="p">,</span> <span class="n">var</span><span class="p">,</span> <span class="n">skew</span><span class="p">,</span> <span class="n">kurtosis</span><span class="p">,</span> <span class="n">img_min</span><span class="p">,</span> <span class="n">img_max</span><span class="p">],</span> <span class="s2">&quot;b c *&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_compute_intermediate_representations</span><span class="p">(</span>
        <span class="n">pyr_coeffs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Tensor</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="n">Tensor</span><span class="p">],</span> <span class="nb">list</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute useful intermediate representations.</span>

<span class="sd">        These representations are:</span>
<span class="sd">          1) demeaned magnitude of the pyramid coefficients,</span>
<span class="sd">          2) real part of the pyramid coefficients</span>

<span class="sd">        These two are used in computing some of the texture representation.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        pyr_coeffs</span>
<span class="sd">            Complex steerable pyramid coefficients (without residuals), as list</span>
<span class="sd">            of length n_scales, containing 5d tensors of shape (batch, channel,</span>
<span class="sd">            n_orientations, height, width).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        magnitude_pyr_coeffs</span>
<span class="sd">           List of length n_scales, containing 5d tensors of shape (batch,</span>
<span class="sd">           channel, n_orientations, height, width) (same as ``pyr_coeffs``),</span>
<span class="sd">           containing the demeaned magnitude of the steerable pyramid</span>
<span class="sd">           coefficients (i.e., ``coeffs.abs() - coeffs.abs().mean((-2, -1))``).</span>
<span class="sd">        real_pyr_coeffs :</span>
<span class="sd">           List of length n_scales, containing 5d tensors of shape (batch,</span>
<span class="sd">           channel, n_orientations, height, width) (same as ``pyr_coeffs``),</span>
<span class="sd">           containing the real components of the coefficients (i.e.</span>
<span class="sd">           ``coeffs.real``).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">magnitude_pyr_coeffs</span> <span class="o">=</span> <span class="p">[</span><span class="n">coeff</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span> <span class="k">for</span> <span class="n">coeff</span> <span class="ow">in</span> <span class="n">pyr_coeffs</span><span class="p">]</span>
        <span class="n">magnitude_means</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">mag</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">for</span> <span class="n">mag</span> <span class="ow">in</span> <span class="n">magnitude_pyr_coeffs</span>
        <span class="p">]</span>
        <span class="n">magnitude_pyr_coeffs</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">mag</span> <span class="o">-</span> <span class="n">mn</span> <span class="k">for</span> <span class="n">mag</span><span class="p">,</span> <span class="n">mn</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">magnitude_pyr_coeffs</span><span class="p">,</span> <span class="n">magnitude_means</span><span class="p">)</span>
        <span class="p">]</span>
        <span class="n">real_pyr_coeffs</span> <span class="o">=</span> <span class="p">[</span><span class="n">coeff</span><span class="o">.</span><span class="n">real</span> <span class="k">for</span> <span class="n">coeff</span> <span class="ow">in</span> <span class="n">pyr_coeffs</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">magnitude_pyr_coeffs</span><span class="p">,</span> <span class="n">real_pyr_coeffs</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reconstruct_lowpass_at_each_scale</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">pyr_coeffs_dict</span><span class="p">:</span> <span class="n">OrderedDict</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Reconstruct the lowpass unoriented image at each scale.</span>

<span class="sd">        The autocorrelation, standard deviation, skew, and kurtosis of each of</span>
<span class="sd">        these images is part of the texture representation.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        pyr_coeffs_dict</span>
<span class="sd">            Dictionary containing the steerable pyramid coefficients, with the</span>
<span class="sd">            lowpass residual demeaned.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        reconstructed_images</span>
<span class="sd">            List of length n_scales+1 containing the reconstructed unoriented</span>
<span class="sd">            image at each scale, from fine to coarse. The final image is</span>
<span class="sd">            reconstructed just from the residual lowpass image. Each is a 4d</span>
<span class="sd">            tensor, this is a list because they are all different heights and</span>
<span class="sd">            widths.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">reconstructed_images</span> <span class="o">=</span> <span class="p">[</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_pyr</span><span class="o">.</span><span class="n">recon_pyr</span><span class="p">(</span><span class="n">pyr_coeffs_dict</span><span class="p">,</span> <span class="n">levels</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;residual_lowpass&quot;</span><span class="p">])</span>
        <span class="p">]</span>
        <span class="c1"># go through scales backwards</span>
        <span class="k">for</span> <span class="n">lev</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">recon</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pyr</span><span class="o">.</span><span class="n">recon_pyr</span><span class="p">(</span><span class="n">pyr_coeffs_dict</span><span class="p">,</span> <span class="n">levels</span><span class="o">=</span><span class="p">[</span><span class="n">lev</span><span class="p">])</span>
            <span class="n">reconstructed_images</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">recon</span> <span class="o">+</span> <span class="n">reconstructed_images</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="c1"># now downsample as necessary, so that these end up the same size as</span>
        <span class="c1"># their corresponding coefficients. We multiply by the factor of 4 here</span>
        <span class="c1"># in order to approximately equalize the steerable pyramid coefficient</span>
        <span class="c1"># values across scales. This could also be handled by making the</span>
        <span class="c1"># pyramid tight frame</span>
        <span class="n">reconstructed_images</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">signal</span><span class="o">.</span><span class="n">shrink</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="mi">2</span> <span class="o">**</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span> <span class="o">-</span> <span class="n">i</span><span class="p">))</span> <span class="o">*</span> <span class="mi">4</span> <span class="o">**</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span> <span class="o">-</span> <span class="n">i</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">reconstructed_images</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="p">]</span>
        <span class="k">return</span> <span class="n">reconstructed_images</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_compute_autocorr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">coeffs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Tensor</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the autocorrelation of some statistics.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        coeffs_list</span>
<span class="sd">            List (of length s) of tensors of shape (batch, channel, *, height,</span>
<span class="sd">            width), where * is zero or one additional dimensions. Intended use</span>
<span class="sd">            case: ``magnitude_pyr_coeffs`` (which is list of length ``n_scales`` of 5d</span>
<span class="sd">            tensors, with * containing ``n_orientations``) or ``reconstructed_images``</span>
<span class="sd">            (which is a list of length ``n_scales+1`` of 4d tensors).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        autocorrs</span>
<span class="sd">            Tensor of shape (batch, channel, spatial_corr_width,</span>
<span class="sd">            spatial_corr_width, *, s) containing the autocorrelation (up to</span>
<span class="sd">            distance ``spatial_corr_width//2``) of each element in</span>
<span class="sd">            ``coeffs_list``, computed independently over all but the final two</span>
<span class="sd">            dimensions.</span>
<span class="sd">        vars</span>
<span class="sd">            3d Tensor of shape (batch, channel, *, s) containing the variance</span>
<span class="sd">            of each element in ``coeffs_list``, computed independently over all</span>
<span class="sd">            but the final two dimensions.</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If ``coeffs_list`` contains tensors that have other than 4 or 5 dimensions.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># numpydoc ignore=ES01</span>
        <span class="k">if</span> <span class="n">coeffs_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">5</span><span class="p">:</span>
            <span class="n">dims</span> <span class="o">=</span> <span class="s2">&quot;o&quot;</span>
        <span class="k">elif</span> <span class="n">coeffs_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
            <span class="n">dims</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;coeffs_list must contain tensors of either 4 or 5 dimensions!&quot;</span>
            <span class="p">)</span>
        <span class="n">acs</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">signal</span><span class="o">.</span><span class="n">center_crop</span><span class="p">(</span><span class="n">signal</span><span class="o">.</span><span class="n">autocorrelation</span><span class="p">(</span><span class="n">coeff</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">spatial_corr_width</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">coeff</span> <span class="ow">in</span> <span class="n">coeffs_list</span>
        <span class="p">]</span>
        <span class="n">acs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">acs</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">var</span> <span class="o">=</span> <span class="n">signal</span><span class="o">.</span><span class="n">center_crop</span><span class="p">(</span><span class="n">acs</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">acs</span> <span class="o">=</span> <span class="n">acs</span> <span class="o">/</span> <span class="n">var</span>
        <span class="n">var</span> <span class="o">=</span> <span class="n">einops</span><span class="o">.</span><span class="n">rearrange</span><span class="p">(</span><span class="n">var</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;b c s </span><span class="si">{</span><span class="n">dims</span><span class="si">}</span><span class="s2"> 1 1 -&gt; b c </span><span class="si">{</span><span class="n">dims</span><span class="si">}</span><span class="s2"> s&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">einops</span><span class="o">.</span><span class="n">rearrange</span><span class="p">(</span><span class="n">acs</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;b c s </span><span class="si">{</span><span class="n">dims</span><span class="si">}</span><span class="s2"> a1 a2 -&gt; b c a1 a2 </span><span class="si">{</span><span class="n">dims</span><span class="si">}</span><span class="s2"> s&quot;</span><span class="p">),</span> <span class="n">var</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_compute_skew_kurtosis_recon</span><span class="p">(</span>
        <span class="n">reconstructed_images</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">var_recon</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">img_var</span><span class="p">:</span> <span class="n">Tensor</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the skew and kurtosis of each lowpass reconstructed image.</span>

<span class="sd">        For each scale, if the ratio of its variance to the original image&#39;s</span>
<span class="sd">        pixel variance is below a threshold of</span>
<span class="sd">        ``torch.finfo(img_var.dtype).resolution`` (``1e-6`` for ``float32``,</span>
<span class="sd">        ``1e-15`` for ``float64``), skew and kurtosis are assigned default</span>
<span class="sd">        values of ``0`` or ``3``, respectively.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        reconstructed_images</span>
<span class="sd">            List of length ``n_scales+1`` containing the reconstructed unoriented</span>
<span class="sd">            image at each scale, from fine to coarse. The final image is</span>
<span class="sd">            reconstructed just from the residual lowpass image.</span>
<span class="sd">        var_recon</span>
<span class="sd">            Tensor of shape (batch, channel, n_scales+1) containing the</span>
<span class="sd">            variance of each tensor in reconstruced_images.</span>
<span class="sd">        img_var</span>
<span class="sd">            Tensor of shape (batch, channel) containing the pixel variance</span>
<span class="sd">            (from ``pixel_stats`` tensor).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        skew_recon, kurtosis_recon</span>
<span class="sd">            Tensors of shape (batch, channel, n_scales+1) containing the skew</span>
<span class="sd">            and kurtosis, respectively, of each tensor in</span>
<span class="sd">            ``reconstructed_images``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">skew_recon</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">stats</span><span class="o">.</span><span class="n">skew</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">var</span><span class="o">=</span><span class="n">var_recon</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">i</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">im</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">reconstructed_images</span><span class="p">)</span>
        <span class="p">]</span>
        <span class="n">skew_recon</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">skew_recon</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">kurtosis_recon</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">stats</span><span class="o">.</span><span class="n">kurtosis</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">var</span><span class="o">=</span><span class="n">var_recon</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">i</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">im</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">reconstructed_images</span><span class="p">)</span>
        <span class="p">]</span>
        <span class="n">kurtosis_recon</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">kurtosis_recon</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">skew_default</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">skew_recon</span><span class="p">)</span>
        <span class="n">kurtosis_default</span> <span class="o">=</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">kurtosis_recon</span><span class="p">)</span>
        <span class="c1"># if this variance ratio is too small, then use the default values</span>
        <span class="c1"># instead. unsqueeze is used here because var_recon is shape (batch,</span>
        <span class="c1"># channel, scales+1), whereas img_var is just (batch, channel)</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">img_var</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">resolution</span>
        <span class="n">unstable_locs</span> <span class="o">=</span> <span class="n">var_recon</span> <span class="o">/</span> <span class="n">img_var</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">res</span>
        <span class="n">skew_recon</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">unstable_locs</span><span class="p">,</span> <span class="n">skew_default</span><span class="p">,</span> <span class="n">skew_recon</span><span class="p">)</span>
        <span class="n">kurtosis_recon</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">unstable_locs</span><span class="p">,</span> <span class="n">kurtosis_default</span><span class="p">,</span> <span class="n">kurtosis_recon</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">skew_recon</span><span class="p">,</span> <span class="n">kurtosis_recon</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_compute_cross_correlation</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">coeffs_tensor</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Tensor</span><span class="p">],</span>
        <span class="n">coeffs_tensor_other</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Tensor</span><span class="p">],</span>
        <span class="n">coeffs_var</span><span class="p">:</span> <span class="kc">None</span> <span class="o">|</span> <span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">coeffs_other_var</span><span class="p">:</span> <span class="kc">None</span> <span class="o">|</span> <span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute cross-correlations.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        coeffs_tensor, coeffs_tensor_other</span>
<span class="sd">            The two lists of length scales, each containing 5d tensors of shape</span>
<span class="sd">            (batch, channel, n_orientations, height, width) to be correlated.</span>
<span class="sd">        coeffs_var, coeffs_other_var</span>
<span class="sd">            Two optional tensors containing the variances of coeffs_tensor and</span>
<span class="sd">            coeffs_tensor_other, respectively, in case they&#39;ve already been computed.</span>
<span class="sd">            Should be of shape (batch, channel, n_orientations, n_scales). Used to</span>
<span class="sd">            normalize the covariances into cross-correlations.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        cross_corrs</span>
<span class="sd">            Tensor of shape (batch, channel, n_orientations, n_orientations,</span>
<span class="sd">            scales) containing the cross-correlations at each</span>
<span class="sd">            scale.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># numpydoc ignore=ES01</span>
        <span class="n">covars</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">coeff</span><span class="p">,</span> <span class="n">coeff_other</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span>
            <span class="nb">zip</span><span class="p">(</span><span class="n">coeffs_tensor</span><span class="p">,</span> <span class="n">coeffs_tensor_other</span><span class="p">)</span>
        <span class="p">):</span>
            <span class="c1"># precompute this, which we&#39;ll use for normalization</span>
            <span class="n">numel</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="o">*</span><span class="n">coeff</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:])</span>
            <span class="c1"># compute the covariance</span>
            <span class="n">covar</span> <span class="o">=</span> <span class="n">einops</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span>
                <span class="n">coeff</span><span class="p">,</span> <span class="n">coeff_other</span><span class="p">,</span> <span class="s2">&quot;b c o1 h w, b c o2 h w -&gt; b c o1 o2&quot;</span>
            <span class="p">)</span>
            <span class="n">covar</span> <span class="o">=</span> <span class="n">covar</span> <span class="o">/</span> <span class="n">numel</span>
            <span class="c1"># Then normalize it to get the Pearson product-moment correlation</span>
            <span class="c1"># coefficient, see</span>
            <span class="c1"># https://numpy.org/doc/stable/reference/generated/numpy.corrcoef.html.</span>
            <span class="k">if</span> <span class="n">coeffs_var</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># First, compute the variances of each coeff</span>
                <span class="n">coeff_var</span> <span class="o">=</span> <span class="n">einops</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span>
                    <span class="n">coeff</span><span class="p">,</span> <span class="n">coeff</span><span class="p">,</span> <span class="s2">&quot;b c o1 h w, b c o1 h w -&gt; b c o1&quot;</span>
                <span class="p">)</span>
                <span class="n">coeff_var</span> <span class="o">=</span> <span class="n">coeff_var</span> <span class="o">/</span> <span class="n">numel</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">coeff_var</span> <span class="o">=</span> <span class="n">coeffs_var</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">coeffs_other_var</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># First, compute the variances of each coeff</span>
                <span class="n">coeff_other_var</span> <span class="o">=</span> <span class="n">einops</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span>
                    <span class="n">coeff_other</span><span class="p">,</span> <span class="n">coeff_other</span><span class="p">,</span> <span class="s2">&quot;b c o1 h w, b c o1 h w -&gt; b c o1&quot;</span>
                <span class="p">)</span>
                <span class="n">coeff_other_var</span> <span class="o">=</span> <span class="n">coeff_other_var</span> <span class="o">/</span> <span class="n">numel</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">coeff_other_var</span> <span class="o">=</span> <span class="n">coeffs_other_var</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span>
            <span class="c1"># Then compute the outer product of those variances.</span>
            <span class="n">var_outer_prod</span> <span class="o">=</span> <span class="n">einops</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span>
                <span class="n">coeff_var</span><span class="p">,</span> <span class="n">coeff_other_var</span><span class="p">,</span> <span class="s2">&quot;b c o1, b c o2 -&gt; b c o1 o2&quot;</span>
            <span class="p">)</span>
            <span class="c1"># And the sqrt of this is what we use to normalize the covariance</span>
            <span class="c1"># into the cross-correlation</span>
            <span class="n">covars</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">covar</span> <span class="o">/</span> <span class="n">var_outer_prod</span><span class="o">.</span><span class="n">sqrt</span><span class="p">())</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">covars</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_double_phase_pyr_coeffs</span><span class="p">(</span>
        <span class="n">pyr_coeffs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Tensor</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="n">Tensor</span><span class="p">],</span> <span class="nb">list</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Upsample and double the phase of pyramid coefficients.</span>

<span class="sd">        This is trick is key to correctly computing the correlation between</span>
<span class="sd">        coefficients at different spatial scales.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        pyr_coeffs</span>
<span class="sd">            Complex steerable pyramid coefficients (without residuals), as list</span>
<span class="sd">            of length n_scales, containing 5d tensors of shape (batch, channel,</span>
<span class="sd">            n_orientations, height, width).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        doubled_phase_mags</span>
<span class="sd">            The demeaned magnitude (i.e., pyr_coeffs.abs()) of each upsampled</span>
<span class="sd">            double-phased coefficient. List of length n_scales-1 containing</span>
<span class="sd">            tensors of same shape the input (the finest scale has been</span>
<span class="sd">            removed).</span>
<span class="sd">        doubled_phase_separate</span>
<span class="sd">            The real and imaginary parts of each double-phased coefficient.</span>
<span class="sd">            List of length n_scales-1, containing tensors of shape (batch,</span>
<span class="sd">            channel, 2*n_orientations, height, width), with the real component</span>
<span class="sd">            found at the same orientation index as the input, and the imaginary</span>
<span class="sd">            at orientation+self.n_orientations. (The finest scale has been</span>
<span class="sd">            removed).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">doubled_phase_mags</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">doubled_phase_sep</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="c1"># don&#39;t do this for the finest scale</span>
        <span class="k">for</span> <span class="n">coeff</span> <span class="ow">in</span> <span class="n">pyr_coeffs</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span>
            <span class="c1"># We divide by the factor of 4 here in order to approximately</span>
            <span class="c1"># equalize the steerable pyramid coefficient values across scales.</span>
            <span class="c1"># This could also be handled by making the pyramid tight frame</span>
            <span class="n">doubled_phase</span> <span class="o">=</span> <span class="n">signal</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">coeff</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="mf">4.0</span>
            <span class="n">doubled_phase</span> <span class="o">=</span> <span class="n">signal</span><span class="o">.</span><span class="n">modulate_phase</span><span class="p">(</span><span class="n">doubled_phase</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
            <span class="n">doubled_phase_mag</span> <span class="o">=</span> <span class="n">doubled_phase</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span>
            <span class="n">doubled_phase_mag</span> <span class="o">=</span> <span class="n">doubled_phase_mag</span> <span class="o">-</span> <span class="n">doubled_phase_mag</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span>
                <span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)</span>
            <span class="n">doubled_phase_mags</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">doubled_phase_mag</span><span class="p">)</span>
            <span class="n">doubled_phase_sep</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">einops</span><span class="o">.</span><span class="n">pack</span><span class="p">([</span><span class="n">doubled_phase</span><span class="o">.</span><span class="n">real</span><span class="p">,</span> <span class="n">doubled_phase</span><span class="o">.</span><span class="n">imag</span><span class="p">],</span> <span class="s2">&quot;b c * h w&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">doubled_phase_mags</span><span class="p">,</span> <span class="n">doubled_phase_sep</span>

<div class="viewcode-block" id="PortillaSimoncelli.plot_representation">
<a class="viewcode-back" href="../../../../api/plenoptic.simulate.models.html#plenoptic.simulate.models.portilla_simoncelli.PortillaSimoncelli.plot_representation">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">plot_representation</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">data</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">ax</span><span class="p">:</span> <span class="n">plt</span><span class="o">.</span><span class="n">Axes</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">figsize</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">ylim</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">|</span> <span class="n">Literal</span><span class="p">[</span><span class="kc">False</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">batch_idx</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">title</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">plt</span><span class="o">.</span><span class="n">Figure</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="n">plt</span><span class="o">.</span><span class="n">Axes</span><span class="p">]]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Plot the representation in a human viewable format.</span>

<span class="sd">        We plot the representation as stem plots with data separated out by</span>
<span class="sd">        statistic type.</span>

<span class="sd">        This plots the representation of a single batch and averages over all</span>
<span class="sd">        channels in the representation.</span>

<span class="sd">        We create the following axes:</span>

<span class="sd">        - pixels+var_highpass: marginal pixel statistics (first four moments,</span>
<span class="sd">          min, max) and variance of the residual highpass.</span>

<span class="sd">        - std+skew+kurtosis recon: the standard deviation, skew, and kurtosis</span>
<span class="sd">          of the reconstructed lowpass image at each scale</span>

<span class="sd">        - magnitude_std: the standard deviation of the steerable pyramid</span>
<span class="sd">          coefficient magnitudes at each orientation and scale.</span>

<span class="sd">        - auto_correlation_reconstructed: the auto-correlation of the</span>
<span class="sd">          reconstructed lowpass image at each scale (summarized using Euclidean</span>
<span class="sd">          norm).</span>

<span class="sd">        - auto_correlation_magnitude: the auto-correlation of the pyramid</span>
<span class="sd">          coefficient magnitudes at each scale and orientation (summarized</span>
<span class="sd">          using Euclidean norm).</span>

<span class="sd">        - cross_orientation_correlation_magnitude: the cross-correlations</span>
<span class="sd">          between each orientation at each scale (summarized using Euclidean</span>
<span class="sd">          norm)</span>

<span class="sd">        If ``self.n_scales &gt; 1``, we also have combination of the following, where</span>
<span class="sd">        all cross-correlations are summarized using Euclidean norm over the</span>
<span class="sd">        channel dimension:</span>

<span class="sd">        - cross_scale_correlation_magnitude: the cross-correlations between the</span>
<span class="sd">          pyramid coefficient magnitude at one scale and the same orientation</span>
<span class="sd">          at the next-coarsest scale.</span>

<span class="sd">        - cross_scale_correlation_real: the cross-correlations between the real</span>
<span class="sd">          component of the pyramid coefficients and the real and imaginary</span>
<span class="sd">          components (at the same orientation) at the next-coarsest scale.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data</span>
<span class="sd">            The data to show on the plot. Else, should look like the output of</span>
<span class="sd">            ``self.forward(img)``, with the exact same structure (e.g., as</span>
<span class="sd">            returned by ``metamer.representation_error()`` or another instance</span>
<span class="sd">            of this class).</span>
<span class="sd">        ax</span>
<span class="sd">            Axes where we will plot the data. If a ``plt.Axes`` instance, will</span>
<span class="sd">            subdivide into 6 or 8 new axes (depending on self.n_scales). If</span>
<span class="sd">            None, we create a new figure.</span>
<span class="sd">        figsize</span>
<span class="sd">            The size of the figure to create. Must be ``None`` if ax is not ``None``. If</span>
<span class="sd">            both figsize and ax are ``None``, then we set ``figsize=(15, 15)``.</span>
<span class="sd">        ylim</span>
<span class="sd">            If not None, the y-limits to use for this plot. If None, we use the</span>
<span class="sd">            default, slightly adjusted so that the minimum is 0. If False, do not</span>
<span class="sd">            change y-limits.</span>
<span class="sd">        batch_idx</span>
<span class="sd">            Which index to take from the batch dimension (the first one).</span>
<span class="sd">        title</span>
<span class="sd">            Title for the plot.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        fig</span>
<span class="sd">            Figure containing the plot.</span>
<span class="sd">        axes</span>
<span class="sd">            List of 6 or 8 axes containing the plot (depending on ``self.n_scales``).</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If both ``figsize`` and ``ax`` are not ``None``.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        .. plot::</span>

<span class="sd">          &gt;&gt;&gt; import plenoptic as po</span>
<span class="sd">          &gt;&gt;&gt; img = po.data.curie()</span>
<span class="sd">          &gt;&gt;&gt; portilla_simoncelli_model = po.simul.PortillaSimoncelli(img.shape[2:])</span>
<span class="sd">          &gt;&gt;&gt; representation_tensor = portilla_simoncelli_model(img)</span>
<span class="sd">          &gt;&gt;&gt; fig, axes = portilla_simoncelli_model.plot_representation(</span>
<span class="sd">          ...     representation_tensor, figsize=(13, 6)</span>
<span class="sd">          ... )</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">ax</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">figsize</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">15</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">ax</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">figsize</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;figsize can&#39;t be set if ax is not None&quot;</span><span class="p">)</span>
        <span class="c1"># pick the batch_idx we want (but keep the data 3d), and average over</span>
        <span class="c1"># channels (but keep the data 3d). We keep data 3d because</span>
        <span class="c1"># convert_to_dict relies on it.</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">batch_idx</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="c1"># each of these values should now be a 3d tensor with 1 element in each</span>
        <span class="c1"># of the first two dims</span>
        <span class="n">rep</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">convert_to_dict</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
        <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_representation_for_plotting</span><span class="p">(</span><span class="n">rep</span><span class="p">)</span>

        <span class="c1"># Determine plot grid layout</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">n_rows</span> <span class="o">=</span> <span class="mi">3</span>
            <span class="n">n_cols</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_rows</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># then we don&#39;t have any cross-scale correlations, so fewer axes.</span>
            <span class="n">n_rows</span> <span class="o">=</span> <span class="mi">2</span>
            <span class="n">n_cols</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_rows</span><span class="p">))</span>

        <span class="c1"># Set up grid spec</span>
        <span class="k">if</span> <span class="n">ax</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># we add 2 to order because we&#39;re adding one to get the</span>
            <span class="c1"># number of orientations and then another one to add an</span>
            <span class="c1"># extra column for the mean luminance plot</span>
            <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">)</span>
            <span class="n">gs</span> <span class="o">=</span> <span class="n">mpl</span><span class="o">.</span><span class="n">gridspec</span><span class="o">.</span><span class="n">GridSpec</span><span class="p">(</span><span class="n">n_rows</span><span class="p">,</span> <span class="n">n_cols</span><span class="p">,</span> <span class="n">fig</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># want to make sure the axis we&#39;re taking over is basically invisible.</span>
            <span class="n">ax</span> <span class="o">=</span> <span class="n">clean_up_axes</span><span class="p">(</span>
                <span class="n">ax</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;top&quot;</span><span class="p">,</span> <span class="s2">&quot;right&quot;</span><span class="p">,</span> <span class="s2">&quot;bottom&quot;</span><span class="p">,</span> <span class="s2">&quot;left&quot;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">]</span>
            <span class="p">)</span>
            <span class="n">gs</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">get_subplotspec</span><span class="p">()</span><span class="o">.</span><span class="n">subgridspec</span><span class="p">(</span><span class="n">n_rows</span><span class="p">,</span> <span class="n">n_cols</span><span class="p">)</span>
            <span class="n">fig</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">figure</span>

        <span class="c1"># plot data</span>
        <span class="n">axes</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
            <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="n">gs</span><span class="p">[</span><span class="n">i</span> <span class="o">//</span> <span class="n">n_cols</span><span class="p">,</span> <span class="n">i</span> <span class="o">%</span> <span class="n">n_cols</span><span class="p">])</span>
            <span class="n">ax</span> <span class="o">=</span> <span class="n">clean_stem_plot</span><span class="p">(</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">v</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">ax</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">ylim</span><span class="o">=</span><span class="n">ylim</span><span class="p">)</span>
            <span class="n">axes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ax</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">title</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span></div>


    <span class="k">def</span><span class="w"> </span><span class="nf">_representation_for_plotting</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rep</span><span class="p">:</span> <span class="n">OrderedDict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">OrderedDict</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Convert into a representation that is more convenient for plotting.</span>

<span class="sd">        Intended as a helper function for plot_representation.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        rep</span>
<span class="sd">            Dictionary of representation, with informative keys.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        plot_rep</span>
<span class="sd">            Dictionary of representation summarized for plotting.</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If the tensors in ``rep`` looks like they have more than one batch</span>
<span class="sd">            or channel. Should select or average over those dimensions.</span>
<span class="sd">        ValueError</span>
<span class="sd">            If ``rep`` contains unexpected keys.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">rep</span><span class="p">[</span><span class="s2">&quot;skew_reconstructed&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Currently, only know how to plot single batch and channel at&quot;</span>
                <span class="s2">&quot; a time! Select and/or average over those dimensions&quot;</span>
            <span class="p">)</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
        <span class="n">data</span><span class="p">[</span><span class="s2">&quot;pixels+var_highpass&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
            <span class="p">[</span><span class="n">rep</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;pixel_statistics&quot;</span><span class="p">),</span> <span class="n">rep</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;var_highpass_residual&quot;</span><span class="p">)]</span>
        <span class="p">)</span>
        <span class="n">data</span><span class="p">[</span><span class="s2">&quot;std+skew+kurtosis recon&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
            <span class="p">(</span>
                <span class="n">rep</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;std_reconstructed&quot;</span><span class="p">),</span>
                <span class="n">rep</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;skew_reconstructed&quot;</span><span class="p">),</span>
                <span class="n">rep</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;kurtosis_reconstructed&quot;</span><span class="p">),</span>
            <span class="p">)</span>
        <span class="p">)</span>

        <span class="n">data</span><span class="p">[</span><span class="s2">&quot;magnitude_std&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">rep</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;magnitude_std&quot;</span><span class="p">)</span>

        <span class="c1"># want to plot these in a specific order</span>
        <span class="n">all_keys</span> <span class="o">=</span> <span class="p">[</span>
            <span class="s2">&quot;auto_correlation_reconstructed&quot;</span><span class="p">,</span>
            <span class="s2">&quot;auto_correlation_magnitude&quot;</span><span class="p">,</span>
            <span class="s2">&quot;cross_orientation_correlation_magnitude&quot;</span><span class="p">,</span>
            <span class="s2">&quot;cross_scale_correlation_magnitude&quot;</span><span class="p">,</span>
            <span class="s2">&quot;cross_scale_correlation_real&quot;</span><span class="p">,</span>
        <span class="p">]</span>
        <span class="k">if</span> <span class="nb">set</span><span class="p">(</span><span class="n">rep</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span> <span class="o">!=</span> <span class="nb">set</span><span class="p">(</span><span class="n">all_keys</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;representation has unexpected keys!&quot;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">all_keys</span><span class="p">:</span>
            <span class="c1"># if we only have one scale, no cross-scale stats</span>
            <span class="k">if</span> <span class="n">k</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;cross_scale&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="c1"># we compute L2 norm manually, since there are NaNs (marking</span>
            <span class="c1"># redundant stats)</span>
            <span class="n">data</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">rep</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">nansum</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">data</span>

<div class="viewcode-block" id="PortillaSimoncelli.update_plot">
<a class="viewcode-back" href="../../../../api/plenoptic.simulate.models.html#plenoptic.simulate.models.portilla_simoncelli.PortillaSimoncelli.update_plot">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">update_plot</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">axes</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">plt</span><span class="o">.</span><span class="n">Axes</span><span class="p">],</span>
        <span class="n">data</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">batch_idx</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">plt</span><span class="o">.</span><span class="n">Artist</span><span class="p">]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Update the information in our representation plot.</span>

<span class="sd">        This is used for creating an animation of the representation</span>
<span class="sd">        over time. In order to create the animation, we need to know how</span>
<span class="sd">        to update the matplotlib Artists, and this provides a simple way</span>
<span class="sd">        of doing that. It relies on the fact that we&#39;ve used</span>
<span class="sd">        ``plot_representation`` to create the plots we want to update</span>
<span class="sd">        and so know that they&#39;re stem plots.</span>

<span class="sd">        We take the axes containing the representation information (note that</span>
<span class="sd">        this is probably a subset of the total number of axes in the figure, if</span>
<span class="sd">        we&#39;re showing other information, as done by ``Metamer.animate``), grab</span>
<span class="sd">        the representation from plotting and, since these are both lists,</span>
<span class="sd">        iterate through them, updating them to the values in ``data`` as we go.</span>

<span class="sd">        In order for this to be used by ``FuncAnimation``, we need to</span>
<span class="sd">        return Artists, so we return a list of the relevant artists, the</span>
<span class="sd">        ``markerline`` and ``stemlines`` from the ``StemContainer``.</span>

<span class="sd">        Currently, this averages over all channels in the representation.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        axes</span>
<span class="sd">            A list of axes to update. We assume that these are the axes</span>
<span class="sd">            created by ``plot_representation`` and so contain stem plots</span>
<span class="sd">            in the correct order.</span>
<span class="sd">        data</span>
<span class="sd">            The data to show on the plot. Else, should look like the output of</span>
<span class="sd">            ``self.forward(img)``, with the exact same structure (e.g., as</span>
<span class="sd">            returned by ``metamer.representation_error()`` or another instance</span>
<span class="sd">            of this class).</span>
<span class="sd">        batch_idx</span>
<span class="sd">            Which index to take from the batch dimension (the first one).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        stem_artists</span>
<span class="sd">            A list of the artists used to update the information on the</span>
<span class="sd">            stem plots.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        This method is meant to be used by animation functions, so users won&#39;t</span>
<span class="sd">        typically use this directly.</span>

<span class="sd">        &gt;&gt;&gt; import plenoptic as po</span>
<span class="sd">        &gt;&gt;&gt; img = po.data.curie()</span>
<span class="sd">        &gt;&gt;&gt; portilla_simoncelli_model = po.simul.PortillaSimoncelli(img.shape[2:])</span>
<span class="sd">        &gt;&gt;&gt; representation_tensor = portilla_simoncelli_model.forward(img)</span>
<span class="sd">        &gt;&gt;&gt; fig, axes = portilla_simoncelli_model.plot_representation(</span>
<span class="sd">        ...     representation_tensor</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; new_img = po.data.einstein()</span>
<span class="sd">        &gt;&gt;&gt; new_representation_tensor = portilla_simoncelli_model.forward(new_img)</span>
<span class="sd">        &gt;&gt;&gt; stem_artists = portilla_simoncelli_model.update_plot(</span>
<span class="sd">        ...     axes, new_representation_tensor</span>
<span class="sd">        ... )</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">stem_artists</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">axes</span> <span class="o">=</span> <span class="p">[</span><span class="n">ax</span> <span class="k">for</span> <span class="n">ax</span> <span class="ow">in</span> <span class="n">axes</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">ax</span><span class="o">.</span><span class="n">containers</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span>
        <span class="c1"># pick the batch_idx we want (but keep the data 3d), and average over</span>
        <span class="c1"># channels (but keep the data 3d). We keep data 3d because</span>
        <span class="c1"># convert_to_dict relies on it.</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">batch_idx</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="c1"># each of these values should now be a 3d tensor with 1 element in each</span>
        <span class="c1"># of the first two dims</span>
        <span class="n">rep</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">convert_to_dict</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
        <span class="n">rep</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_representation_for_plotting</span><span class="p">(</span><span class="n">rep</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axes</span><span class="p">,</span> <span class="n">rep</span><span class="o">.</span><span class="n">values</span><span class="p">()):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
                <span class="n">vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">dd</span><span class="p">)</span> <span class="k">for</span> <span class="n">dd</span> <span class="ow">in</span> <span class="n">d</span><span class="o">.</span><span class="n">values</span><span class="p">()])</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">vals</span> <span class="o">=</span> <span class="n">to_numpy</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>

            <span class="n">sc</span> <span class="o">=</span> <span class="n">update_stem</span><span class="p">(</span><span class="n">ax</span><span class="o">.</span><span class="n">containers</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">vals</span><span class="p">)</span>
            <span class="n">stem_artists</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="n">sc</span><span class="o">.</span><span class="n">markerline</span><span class="p">,</span> <span class="n">sc</span><span class="o">.</span><span class="n">stemlines</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">stem_artists</span></div>
</div>

</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2019-2025, Plenoptic authors.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>