
<!DOCTYPE html>


<html lang="en" data-content_root="../../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>plenoptic.synthesize.metamer &#8212; plenoptic 1.3.2.dev302 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css?v=9c3e77be" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../../_static/custom.css?v=d54d67fd" />
  
  <!-- So that users can add custom icons -->
  <script src="../../../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../../../_static/documentation_options.js?v=06b62906"></script>
    <script src="../../../_static/doctools.js?v=fd6eb6e6"></script>
    <script src="../../../_static/sphinx_highlight.js?v=6ffebe34"></script>
    <script src="../../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../../_static/copybutton.js?v=6dbb43f8"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js?v=1ae7504c"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../../_static/design-tabs.js?v=f930bc37"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_modules/plenoptic/synthesize/metamer';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_version = '0.16.1';
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = 'https://docs.plenoptic.org/docs/branch/main/_static/version_switcher.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = '1.3.2';
        DOCUMENTATION_OPTIONS.show_version_warning_banner =
            true;
        </script>
    <script src="../../../_static/custom-icon.js?v=0bae05a2"></script>
    <link rel="icon" href="../../../_static/plenoptic.ico"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="1.3.2" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../../_static/Plenoptic_Logo_CMYK_Full_Wide.svg" class="logo__image only-light" alt="plenoptic 1.3.2.dev302 documentation - Home"/>
    <img src="../../../_static/Plenoptic_Logo_CMYK_Full_DarkMode_Wide.svg" class="logo__image only-dark pst-js-only" alt="plenoptic 1.3.2.dev302 documentation - Home"/>
  
  
</a></div>
    
      <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-2"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-2"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-2"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-2">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../getting_started/index.html">
    Getting started
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../user_guide/index.html">
    User Guide
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../api.html">
    API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../reference/index.html">
    Reference
  </a>
</li>

            <li class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button"
                data-bs-toggle="dropdown" aria-expanded="false"
                aria-controls="pst-nav-more-links">
                    More
                </button>
                <ul id="pst-nav-more-links" class="dropdown-menu">
                    
<li class=" ">
  <a class="nav-link dropdown-item nav-external" href="https://github.com/plenoptic-org/plenoptic/releases">
    Changelog
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../../developers/index.html">
    For developers
  </a>
</li>

                </ul>
            </li>
            
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://plenoptic.org" title="Home" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-solid fa-house fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Home</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/plenoptic-org/plenoptic" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fab fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/plenoptic" title="PyPI" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-custom fa-pypi fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPI</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar hide-on-wide">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../getting_started/index.html">
    Getting started
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../user_guide/index.html">
    User Guide
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../api.html">
    API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../reference/index.html">
    Reference
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://github.com/plenoptic-org/plenoptic/releases">
    Changelog
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../developers/index.html">
    For developers
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://plenoptic.org" title="Home" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-solid fa-house fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Home</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/plenoptic-org/plenoptic" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fab fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/plenoptic" title="PyPI" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-custom fa-pypi fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPI</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../../index.html" class="nav-link">Module code</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">plenoptic.synthesize.metamer</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <h1>Source code for plenoptic.synthesize.metamer</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Model metamers.</span>

<span class="sd">Model metamers are images whose pixel values differ but whose model outputs are</span>
<span class="sd">identical. They allow researchers to better understand the information which have no</span>
<span class="sd">effect on a model&#39;s output, also known as their invariances.</span>
<span class="sd">&quot;&quot;&quot;</span>  <span class="c1"># numpydoc ignore=EX01</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">re</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">collections</span><span class="w"> </span><span class="kn">import</span> <span class="n">OrderedDict</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">collections.abc</span><span class="w"> </span><span class="kn">import</span> <span class="n">Callable</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Literal</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">mpl</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tqdm.auto</span><span class="w"> </span><span class="kn">import</span> <span class="n">tqdm</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">..tools</span><span class="w"> </span><span class="kn">import</span> <span class="n">data</span><span class="p">,</span> <span class="n">display</span><span class="p">,</span> <span class="n">optim</span><span class="p">,</span> <span class="n">signal</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">..tools.convergence</span><span class="w"> </span><span class="kn">import</span> <span class="n">_coarse_to_fine_enough</span><span class="p">,</span> <span class="n">_loss_convergence</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">..tools.validate</span><span class="w"> </span><span class="kn">import</span> <span class="n">validate_coarse_to_fine</span><span class="p">,</span> <span class="n">validate_input</span><span class="p">,</span> <span class="n">validate_model</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.synthesis</span><span class="w"> </span><span class="kn">import</span> <span class="n">OptimizedSynthesis</span>


<div class="viewcode-block" id="Metamer">
<a class="viewcode-back" href="../../../generated/plenoptic.synthesize.metamer.Metamer.html#plenoptic.synthesize.metamer.Metamer">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">Metamer</span><span class="p">(</span><span class="n">OptimizedSynthesis</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Synthesize metamers for image-computable differentiable models.</span>

<span class="sd">    Following the basic idea in [1]_, this class creates a metamer for a given model on</span>
<span class="sd">    a given image. We iteratively adjust the pixel values so as to match the</span>
<span class="sd">    representation of the :attr:`metamer` and :attr:`image`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    image</span>
<span class="sd">        A tensor, this is the image whose representation we wish to</span>
<span class="sd">        match.</span>
<span class="sd">    model</span>
<span class="sd">        A visual model.</span>
<span class="sd">    loss_function</span>
<span class="sd">        The loss function to use to compare the representations of the models</span>
<span class="sd">        in order to determine their loss.</span>
<span class="sd">    range_penalty_lambda</span>
<span class="sd">        Strength of the regularizer that enforces the allowed_range. Must be</span>
<span class="sd">        non-negative.</span>
<span class="sd">    allowed_range</span>
<span class="sd">        Range (inclusive) of allowed pixel values. Any values outside this</span>
<span class="sd">        range will be penalized.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] J Portilla and E P Simoncelli. A Parametric Texture Model</span>
<span class="sd">       based on Joint Statistics of Complex Wavelet Coefficients. Int&#39;l</span>
<span class="sd">       Journal of Computer Vision. 40(1):49-71, October, 2000.</span>
<span class="sd">       https://www.cns.nyu.edu/~eero/ABSTRACTS/portilla99-abstract.html</span>
<span class="sd">       https://www.cns.nyu.edu/~lcv/texture/</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    Synthesize and visualize a metamer for a simple model:</span>

<span class="sd">    .. plot::</span>
<span class="sd">      :context: reset</span>

<span class="sd">      &gt;&gt;&gt; import plenoptic as po</span>
<span class="sd">      &gt;&gt;&gt; import matplotlib.pyplot as plt</span>
<span class="sd">      &gt;&gt;&gt; img = po.data.einstein()</span>
<span class="sd">      &gt;&gt;&gt; model = po.simul.Gaussian(30).eval()</span>
<span class="sd">      &gt;&gt;&gt; po.tools.remove_grad(model)</span>
<span class="sd">      &gt;&gt;&gt; met = po.synth.Metamer(img, model)</span>
<span class="sd">      &gt;&gt;&gt; met.synthesize(110)</span>
<span class="sd">      &gt;&gt;&gt; fig, axes = plt.subplots(1, 4, figsize=(16, 4))</span>
<span class="sd">      &gt;&gt;&gt; po.imshow(img, ax=axes[0], title=&quot;Target image&quot;)</span>
<span class="sd">      &lt;Figure size ... with 4 Axes&gt;</span>
<span class="sd">      &gt;&gt;&gt; axes[0].xaxis.set_visible(False)</span>
<span class="sd">      &gt;&gt;&gt; axes[0].yaxis.set_visible(False)</span>
<span class="sd">      &gt;&gt;&gt; po.synth.metamer.plot_synthesis_status(met, fig=fig, axes_idx={&quot;misc&quot;: 0})[0]</span>
<span class="sd">      &lt;Figure size ...&gt;</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">loss_function</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">]</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Callable which specifies how close metamer representation is to target.&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">image</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
        <span class="n">loss_function</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">mse</span><span class="p">,</span>
        <span class="n">range_penalty_lambda</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
        <span class="n">allowed_range</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">range_penalty_lambda</span><span class="p">,</span> <span class="n">allowed_range</span><span class="p">)</span>
        <span class="n">validate_input</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">allowed_range</span><span class="o">=</span><span class="n">allowed_range</span><span class="p">)</span>
        <span class="n">validate_model</span><span class="p">(</span>
            <span class="n">model</span><span class="p">,</span>
            <span class="n">image_shape</span><span class="o">=</span><span class="n">image</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
            <span class="n">image_dtype</span><span class="o">=</span><span class="n">image</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="n">image</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_image</span> <span class="o">=</span> <span class="n">image</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_image_shape</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">shape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_target_representation</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">image</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_scheduler</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_scheduler_step_arg</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_function</span> <span class="o">=</span> <span class="n">loss_function</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_saved_metamer</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_store_progress</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_metamer</span> <span class="o">=</span> <span class="kc">None</span>

<div class="viewcode-block" id="Metamer.setup">
<a class="viewcode-back" href="../../../generated/plenoptic.synthesize.metamer.Metamer.html#plenoptic.synthesize.metamer.Metamer.setup">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">setup</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">initial_image</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">optimizer</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">optimizer_kwargs</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">scheduler</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">LRScheduler</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">scheduler_kwargs</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize the metamer, optimizer, and scheduler.</span>

<span class="sd">        Can only be called once. If ``load()`` has been called, ``initial_image`` must</span>
<span class="sd">        be ``None``.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        initial_image</span>
<span class="sd">            The tensor we use to initialize the metamer. If ``None``, we initialize with</span>
<span class="sd">            uniformly-distributed random noise lying within ``self.allowed_range``.</span>
<span class="sd">        optimizer</span>
<span class="sd">            The un-initialized optimizer object to use. If ``None``, we use</span>
<span class="sd">            :class:`torch.optim.Adam`.</span>
<span class="sd">        optimizer_kwargs</span>
<span class="sd">            The keyword arguments to pass to the optimizer on initialization. If</span>
<span class="sd">            ``None``, we use ``{&quot;lr&quot;: .01}`` and, if optimizer is ``None``,</span>
<span class="sd">            ``{&quot;amsgrad&quot;: True}``.</span>
<span class="sd">        scheduler</span>
<span class="sd">            The un-initialized learning rate scheduler object to use. If ``None``, we</span>
<span class="sd">            don&#39;t use one.</span>
<span class="sd">        scheduler_kwargs</span>
<span class="sd">            The keyword arguments to pass to the scheduler on initialization.</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If you try to set ``initial_image`` after calling :func:`load`.</span>
<span class="sd">        ValueError</span>
<span class="sd">            If ``setup`` is called more than once or after :func:`synthesize`.</span>
<span class="sd">        ValueError</span>
<span class="sd">            If you try to set ``optimizer_kwargs`` after calling :func:`load`.</span>
<span class="sd">        TypeError</span>
<span class="sd">            If the loaded object had a non-Adam optimizer, but the ``optimizer`` arg</span>
<span class="sd">            is not specified.</span>
<span class="sd">        ValueError</span>
<span class="sd">            If the loaded object had an optimizer, and the ``optimizer`` arg is</span>
<span class="sd">            a different type.</span>
<span class="sd">        ValueError</span>
<span class="sd">            If you try to set ``scheduler_kwargs`` after calling :func:`load`.</span>
<span class="sd">        TypeError</span>
<span class="sd">            If the loaded object had a scheduler, but the ``scheduler`` arg is not</span>
<span class="sd">            specified.</span>
<span class="sd">        ValueError</span>
<span class="sd">            If the loaded object had a scheduler, but the ``scheduler`` arg is</span>
<span class="sd">            a different type.</span>

<span class="sd">        Warns</span>
<span class="sd">        -----</span>
<span class="sd">        UserWarning</span>
<span class="sd">            If ``initial_image`` is a different shape than ``self.image``.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        Set initial image:</span>

<span class="sd">        &gt;&gt;&gt; import plenoptic as po</span>
<span class="sd">        &gt;&gt;&gt; img = po.data.einstein()</span>
<span class="sd">        &gt;&gt;&gt; model = po.simul.Gaussian(30).eval()</span>
<span class="sd">        &gt;&gt;&gt; po.tools.remove_grad(model)</span>
<span class="sd">        &gt;&gt;&gt; met = po.synth.Metamer(img, model)</span>
<span class="sd">        &gt;&gt;&gt; met.setup(po.data.curie())</span>

<span class="sd">        Set optimizer:</span>

<span class="sd">        &gt;&gt;&gt; met = po.synth.Metamer(img, model)</span>
<span class="sd">        &gt;&gt;&gt; met.setup(optimizer=torch.optim.SGD, optimizer_kwargs={&quot;lr&quot;: 0.01})</span>

<span class="sd">        Set optimizer and scheduler:</span>

<span class="sd">        &gt;&gt;&gt; met = po.synth.Metamer(img, model)</span>
<span class="sd">        &gt;&gt;&gt; met.setup(</span>
<span class="sd">        ...     optimizer=torch.optim.SGD,</span>
<span class="sd">        ...     optimizer_kwargs={&quot;lr&quot;: 0.01},</span>
<span class="sd">        ...     scheduler=torch.optim.lr_scheduler.ReduceLROnPlateau,</span>
<span class="sd">        ... )</span>

<span class="sd">        Use with save/load. We only pass the optimizer/scheduler objects when calling</span>
<span class="sd">        setup after load, their kwargs and the initial image are handled during the</span>
<span class="sd">        load.</span>

<span class="sd">        &gt;&gt;&gt; met = po.synth.Metamer(img, model)</span>
<span class="sd">        &gt;&gt;&gt; met.setup(</span>
<span class="sd">        ...     po.data.curie(),</span>
<span class="sd">        ...     optimizer=torch.optim.SGD,</span>
<span class="sd">        ...     optimizer_kwargs={&quot;lr&quot;: 0.01},</span>
<span class="sd">        ...     scheduler=torch.optim.lr_scheduler.ReduceLROnPlateau,</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; met.synthesize(5)</span>
<span class="sd">        &gt;&gt;&gt; met.save(&quot;metamer_setup.pt&quot;)</span>
<span class="sd">        &gt;&gt;&gt; met = po.synth.Metamer(img, model)</span>
<span class="sd">        &gt;&gt;&gt; met.load(&quot;metamer_setup.pt&quot;)</span>
<span class="sd">        &gt;&gt;&gt; met.setup(</span>
<span class="sd">        ...     optimizer=torch.optim.SGD,</span>
<span class="sd">        ...     scheduler=torch.optim.lr_scheduler.ReduceLROnPlateau,</span>
<span class="sd">        ... )</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_metamer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">initial_image</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">metamer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">image</span><span class="p">)</span>
                <span class="c1"># rescale metamer to lie within the interval</span>
                <span class="c1"># self.allowed_range</span>
                <span class="n">metamer</span> <span class="o">=</span> <span class="n">signal</span><span class="o">.</span><span class="n">rescale</span><span class="p">(</span><span class="n">metamer</span><span class="p">,</span> <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">allowed_range</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">validate_input</span><span class="p">(</span><span class="n">initial_image</span><span class="p">,</span> <span class="n">allowed_range</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">allowed_range</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">initial_image</span><span class="o">.</span><span class="n">size</span><span class="p">()</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">size</span><span class="p">():</span>
                    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                        <span class="s2">&quot;initial_image and image are different sizes! This &quot;</span>
                        <span class="s2">&quot;has not been tested as much, open an issue if you have &quot;</span>
                        <span class="s2">&quot;any problems! https://github.com/plenoptic-org/plenoptic/&quot;</span>
                        <span class="s2">&quot;issues/new?template=bug_report.md&quot;</span>
                    <span class="p">)</span>
                <span class="n">metamer</span> <span class="o">=</span> <span class="n">initial_image</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
                <span class="n">metamer</span> <span class="o">=</span> <span class="n">metamer</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">metamer</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_metamer</span> <span class="o">=</span> <span class="n">metamer</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loaded</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">initial_image</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Cannot set initial_image after calling load()!&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;setup() can only be called once and must be called&quot;</span>
                    <span class="s2">&quot; before synthesize()!&quot;</span>
                <span class="p">)</span>

        <span class="c1"># initialize the optimizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_initialize_optimizer</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">metamer</span><span class="p">,</span> <span class="n">optimizer_kwargs</span><span class="p">)</span>
        <span class="c1"># and scheduler</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_initialize_scheduler</span><span class="p">(</span><span class="n">scheduler</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">scheduler_kwargs</span><span class="p">)</span>
        <span class="c1"># reset _loaded, if everything ran successfully</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_loaded</span> <span class="o">=</span> <span class="kc">False</span></div>


<div class="viewcode-block" id="Metamer.synthesize">
<a class="viewcode-back" href="../../../generated/plenoptic.synthesize.metamer.Metamer.html#plenoptic.synthesize.metamer.Metamer.synthesize">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">synthesize</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">max_iter</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
        <span class="n">store_progress</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">stop_criterion</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-4</span><span class="p">,</span>
        <span class="n">stop_iters_to_check</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Synthesize a metamer.</span>

<span class="sd">        Update the pixels of :attr:`metamer` until its representation matches that of</span>
<span class="sd">        :attr:`image`.</span>

<span class="sd">        We run this until either we reach ``max_iter`` or the loss changes less than</span>
<span class="sd">        ``stop_criterion`` over the past ``stop_iters_to_check`` iterations,</span>
<span class="sd">        whichever comes first.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        max_iter</span>
<span class="sd">            The maximum number of iterations to run before we end synthesis</span>
<span class="sd">            (unless we hit the stop criterion).</span>
<span class="sd">        store_progress</span>
<span class="sd">            Whether we should store the metamer image in progress during</span>
<span class="sd">            synthesis. If ``False``, we don&#39;t save anything. If True, we save every</span>
<span class="sd">            iteration. If an int, we save every ``store_progress`` iterations</span>
<span class="sd">            (note then that 0 is the same as False and 1 the same as True). This is</span>
<span class="sd">            primarily useful for using</span>
<span class="sd">            :func:`~plenoptic.synthesize.metamer.animate` to create a video of the</span>
<span class="sd">            course of synthesis.</span>
<span class="sd">        stop_criterion</span>
<span class="sd">            If the loss over the past ``stop_iters_to_check`` has changed</span>
<span class="sd">            less than ``stop_criterion``, we terminate synthesis.</span>
<span class="sd">        stop_iters_to_check</span>
<span class="sd">            How many iterations back to check in order to see if the</span>
<span class="sd">            loss has stopped decreasing (for ``stop_criterion``).</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If we find a NaN during optimization.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        :func:`~plenoptic.synthesize.metamer.plot_synthesis_status`</span>
<span class="sd">            Create a plot summarizing synthesis status at a given iteration.</span>
<span class="sd">        :func:`~plenoptic.synthesize.metamer.animate`</span>
<span class="sd">            Create a video of the metamer changing over the course of</span>
<span class="sd">            synthesis.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; import plenoptic as po</span>
<span class="sd">        &gt;&gt;&gt; po.tools.set_seed(0)</span>
<span class="sd">        &gt;&gt;&gt; img = po.data.einstein()</span>
<span class="sd">        &gt;&gt;&gt; model = po.simul.Gaussian(30).eval()</span>
<span class="sd">        &gt;&gt;&gt; po.tools.remove_grad(model)</span>
<span class="sd">        &gt;&gt;&gt; met = po.synth.Metamer(img, model)</span>
<span class="sd">        &gt;&gt;&gt; # this isn&#39;t enough to run synthesis to completion, just an example</span>
<span class="sd">        &gt;&gt;&gt; met.synthesize(5)</span>
<span class="sd">        &gt;&gt;&gt; met.losses</span>
<span class="sd">        tensor([0.0194, 0.0198, 0.0179, 0.0160, 0.0145, 0.0132])</span>

<span class="sd">        Synthesize a metamer, using ``store_progress`` so we can examine progress</span>
<span class="sd">        later. (This also enables us to create a video of the metamer changing over</span>
<span class="sd">        the course of synthesis, see</span>
<span class="sd">        :func:`~plenoptic.synthesize.metamer.animate`.)</span>

<span class="sd">        &gt;&gt;&gt; met = po.synth.Metamer(img, model)</span>
<span class="sd">        &gt;&gt;&gt; # this isn&#39;t enough to run synthesis to completion, just an example</span>
<span class="sd">        &gt;&gt;&gt; met.synthesize(5, store_progress=2)</span>
<span class="sd">        &gt;&gt;&gt; met.saved_metamer.shape</span>
<span class="sd">        torch.Size([4, 1, 1, 256, 256])</span>
<span class="sd">        &gt;&gt;&gt; # see loss, etc on the 4th iteration</span>
<span class="sd">        &gt;&gt;&gt; progress = met.get_progress(4)</span>
<span class="sd">        &gt;&gt;&gt; progress.keys()</span>
<span class="sd">        dict_keys([&#39;losses&#39;, ..., &#39;saved_metamer&#39;, &#39;store_progress_iteration&#39;])</span>
<span class="sd">        &gt;&gt;&gt; progress[&quot;losses&quot;]</span>
<span class="sd">        tensor(0.0139)</span>

<span class="sd">        Adjust ``stop_criterion`` and ``stop_iters_to_check`` to change how convergence</span>
<span class="sd">        is determined. In this case, we stop early by making ``stop_criterion`` fairly</span>
<span class="sd">        large. In practice, you&#39;re more likely to make ``stop_criterion`` smaller to let</span>
<span class="sd">        synthesis run for longer.</span>

<span class="sd">        &gt;&gt;&gt; met = po.synth.Metamer(img, model)</span>
<span class="sd">        &gt;&gt;&gt; # this isn&#39;t enough to run synthesis to completion, just an example</span>
<span class="sd">        &gt;&gt;&gt; met.synthesize(12, stop_criterion=0.001, stop_iters_to_check=2)</span>
<span class="sd">        &gt;&gt;&gt; len(met.losses)</span>
<span class="sd">        9</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># if setup hasn&#39;t been called manually, call it now.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_metamer</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_scheduler</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">setup</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_current_loss</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># get ready to store progress</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">store_progress</span> <span class="o">=</span> <span class="n">store_progress</span>

        <span class="n">pbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">max_iter</span><span class="p">))</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">pbar</span><span class="p">:</span>
            <span class="c1"># update saved_* attrs. len(_losses) gives the total number of</span>
            <span class="c1"># iterations and will be correct across calls to `synthesize`</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_store</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_losses</span><span class="p">))</span>

            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer_step</span><span class="p">(</span><span class="n">pbar</span><span class="p">)</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">loss</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Found a NaN in loss during optimization.&quot;</span><span class="p">)</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_convergence</span><span class="p">(</span><span class="n">stop_criterion</span><span class="p">,</span> <span class="n">stop_iters_to_check</span><span class="p">):</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;Loss has converged, stopping synthesis&quot;</span><span class="p">)</span>
                <span class="k">break</span>

        <span class="c1"># compute current loss, no need to compute gradient</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_current_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">objective_function</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

        <span class="n">pbar</span><span class="o">.</span><span class="n">close</span><span class="p">()</span></div>


<div class="viewcode-block" id="Metamer.objective_function">
<a class="viewcode-back" href="../../../generated/plenoptic.synthesize.metamer.Metamer.html#plenoptic.synthesize.metamer.Metamer.objective_function">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">objective_function</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">metamer</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">target_representation</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">analyze_kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the metamer synthesis loss.</span>

<span class="sd">        This calls self.loss_function on</span>
<span class="sd">        ``self.model(metamer, **analyze_kwargs)`` and</span>
<span class="sd">        ``target_representation`` and then adds the weighted range penalty</span>
<span class="sd">        on ``metamer``.</span>

<span class="sd">        Its output over time is stored in :attr:`losses`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        metamer</span>
<span class="sd">            Current ``metamer``. If ``None``, we use ``self.metamer``.</span>
<span class="sd">        target_representation</span>
<span class="sd">            Model response to ``image``. If ``None``, we use</span>
<span class="sd">            ``self.target_representation``.</span>
<span class="sd">        **analyze_kwargs</span>
<span class="sd">            Additional kwargs to pass to ``self.model(metamer)``.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        loss</span>
<span class="sd">            1-element tensor containing the loss on this step.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; import plenoptic as po</span>
<span class="sd">        &gt;&gt;&gt; po.tools.set_seed(0)</span>
<span class="sd">        &gt;&gt;&gt; img = po.data.einstein()</span>
<span class="sd">        &gt;&gt;&gt; model = po.simul.Gaussian(30).eval()</span>
<span class="sd">        &gt;&gt;&gt; po.tools.remove_grad(model)</span>
<span class="sd">        &gt;&gt;&gt; met = po.synth.Metamer(img, model)</span>

<span class="sd">        Before :meth:`setup` or :meth:`synthesize` is called, this returns an</span>
<span class="sd">        empty tensor because the metamer attribute hasn&#39;t been initialized:</span>

<span class="sd">        &gt;&gt;&gt; met.objective_function()</span>
<span class="sd">        tensor([])</span>
<span class="sd">        &gt;&gt;&gt; met.synthesize(5, store_progress=True)</span>

<span class="sd">        When called without any arguments, this returns the current loss:</span>

<span class="sd">        &gt;&gt;&gt; met.objective_function()</span>
<span class="sd">        tensor(0.0132, grad_fn=&lt;AddBackward0&gt;)</span>
<span class="sd">        &gt;&gt;&gt; met.losses[-1]</span>
<span class="sd">        tensor(0.0132)</span>

<span class="sd">        Can be called with a different image. (Note that, because we called</span>
<span class="sd">        :meth:`synthesize` with ``store_progress=True``, we cached the metamer</span>
<span class="sd">        over the course of synthesis):</span>

<span class="sd">        &gt;&gt;&gt; met.objective_function(met.saved_metamer[0])</span>
<span class="sd">        tensor(0.0194, grad_fn=&lt;AddBackward0&gt;)</span>
<span class="sd">        &gt;&gt;&gt; met.losses[0]</span>
<span class="sd">        tensor(0.0194)</span>

<span class="sd">        This method differs from the :attr:`loss_function` attribute because of its</span>
<span class="sd">        inclusion of the penalty. In the following block, the pixels of</span>
<span class="sd">        ``rand_img`` all lie within $[0, 1]$, and so the outputs of</span>
<span class="sd">        :attr:`objective_function` and :attr:`loss_function` are the same:</span>

<span class="sd">        &gt;&gt;&gt; rand_img = torch.rand_like(img)</span>
<span class="sd">        &gt;&gt;&gt; rand_img.min(), rand_img.max()</span>
<span class="sd">        (tensor(7.9870e-06), tensor(1.0000))</span>
<span class="sd">        &gt;&gt;&gt; met.objective_function(rand_img)</span>
<span class="sd">        tensor(0.0190)</span>
<span class="sd">        &gt;&gt;&gt; met.loss_function(model(img), model(rand_img))</span>
<span class="sd">        tensor(0.0190)</span>

<span class="sd">        In this block, the image&#39;s lie outside $[0, 1]$, and so the outputs of</span>
<span class="sd">        :attr:`objective_function` and :attr:`loss_function` are different:</span>

<span class="sd">        &gt;&gt;&gt; rand_img *= 2</span>
<span class="sd">        &gt;&gt;&gt; rand_img.min(), rand_img.max()</span>
<span class="sd">        (tensor(0.0001), tensor(2.0000))</span>
<span class="sd">        &gt;&gt;&gt; met.objective_function(rand_img)</span>
<span class="sd">        tensor(1100.9663)</span>
<span class="sd">        &gt;&gt;&gt; met.loss_function(model(img), model(rand_img))</span>
<span class="sd">        tensor(0.3133)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">metamer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">metamer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">metamer</span>
            <span class="c1"># if this is empty, then self.metamer hasn&#39;t been initialized</span>
            <span class="k">if</span> <span class="n">metamer</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">target_representation</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">target_representation</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_representation</span>
        <span class="n">metamer_representation</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">metamer</span><span class="p">,</span> <span class="o">**</span><span class="n">analyze_kwargs</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_function</span><span class="p">(</span><span class="n">metamer_representation</span><span class="p">,</span> <span class="n">target_representation</span><span class="p">)</span>
        <span class="n">range_penalty</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">penalize_range</span><span class="p">(</span><span class="n">metamer</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">allowed_range</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">range_penalty_lambda</span> <span class="o">*</span> <span class="n">range_penalty</span></div>


<div class="viewcode-block" id="Metamer.get_progress">
<a class="viewcode-back" href="../../../generated/plenoptic.synthesize.metamer.Metamer.html#plenoptic.synthesize.metamer.Metamer.get_progress">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_progress</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">iteration</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">iteration_selection</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;floor&quot;</span><span class="p">,</span> <span class="s2">&quot;ceiling&quot;</span><span class="p">,</span> <span class="s2">&quot;round&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;round&quot;</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return dictionary summarizing synthesis progress at ``iteration``.</span>

<span class="sd">        This returns a dictionary containing info from :attr:`losses`,</span>
<span class="sd">        :attr:`pixel_change_norm`, :attr:`gradient_norm`, and</span>
<span class="sd">        :attr:`saved_metamer` corresponding to ``iteration``. If synthesis was</span>
<span class="sd">        run with ``store_progress=False`` (and so we did not cache anything in</span>
<span class="sd">        :attr:`saved_metamer`), then that key will be missing. If synthesis was</span>
<span class="sd">        run with ``store_progress&gt;1``, we will grab the corresponding tensor</span>
<span class="sd">        from :attr:`saved_metamer`, with behavior determined by</span>
<span class="sd">        ``iteration_selection``.</span>

<span class="sd">        The returned dictionary will additionally contain the keys:</span>

<span class="sd">        - ``&quot;iteration&quot;``: the (0-indexed positive) synthesis iteration that the</span>
<span class="sd">          values for :attr:`losses`, :attr:`pixel_change_norm`, and</span>
<span class="sd">          :attr:`gradient_norm` come from.</span>

<span class="sd">        - If ``self.store_progress``, ``&quot;store_progress_iteration&quot;``: the (0-indexed</span>
<span class="sd">          positive) synthesis iteration that the value for :attr:`saved_metamer` comes</span>
<span class="sd">          from.</span>

<span class="sd">        Note that for the most recent iteration (``iteration=-1`` or ``iteration=None``</span>
<span class="sd">        or ``iteration==len(self.losses)-1``), we do not have values for</span>
<span class="sd">        :attr:`pixel_change_norm` or :attr:`gradient_norm`, since in this case we are</span>
<span class="sd">        showing the loss and value for the current metamer.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        iteration</span>
<span class="sd">            Synthesis iteration to summarize. If ``None``, grab the most recent.</span>
<span class="sd">            Negative values are allowed.</span>
<span class="sd">        iteration_selection</span>

<span class="sd">            How to select the relevant iteration from :attr:`saved_metamer`</span>
<span class="sd">            when the request iteration wasn&#39;t stored.</span>

<span class="sd">            When synthesis was run with ``store_progress=n`` (where ``n&gt;1``),</span>
<span class="sd">            metamers are only saved every ``n`` iterations. If you request an</span>
<span class="sd">            iteration where a metamer wasn&#39;t saved, this determines which available</span>
<span class="sd">            iteration is used instead:</span>

<span class="sd">            * ``&quot;floor&quot;``: use the closest saved iteration **before** the</span>
<span class="sd">              requested one.</span>

<span class="sd">            * ``&quot;ceiling&quot;``: use the closest saved iteration **after** the</span>
<span class="sd">              requested one.</span>

<span class="sd">            * ``&quot;round&quot;``: use the closest saved iteration.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        progress_info</span>
<span class="sd">            Dictionary summarizing synthesis progress.</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        IndexError</span>
<span class="sd">            If ``iteration`` takes an illegal value.</span>

<span class="sd">        Warns</span>
<span class="sd">        -----</span>
<span class="sd">        UserWarning</span>
<span class="sd">            If the iteration used for ``saved_metamer`` is not the same as the argument</span>
<span class="sd">            ``iteration`` (because e.g., you set ``iteration=3`` but</span>
<span class="sd">            ``self.store_progress=2``).</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        :func:`~plenoptic.synthesize.metamer.plot_synthesis_status`</span>
<span class="sd">            Create a plot summarizing synthesis status at a given iteration.</span>
<span class="sd">        :func:`~plenoptic.synthesize.metamer.animate`</span>
<span class="sd">            Create a video of the metamer changing over the course of</span>
<span class="sd">            synthesis.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; import plenoptic as po</span>
<span class="sd">        &gt;&gt;&gt; po.tools.set_seed(0)</span>
<span class="sd">        &gt;&gt;&gt; img = po.data.einstein()</span>
<span class="sd">        &gt;&gt;&gt; model = po.simul.Gaussian(30).eval()</span>
<span class="sd">        &gt;&gt;&gt; po.tools.remove_grad(model)</span>
<span class="sd">        &gt;&gt;&gt; met = po.synth.Metamer(img, model)</span>
<span class="sd">        &gt;&gt;&gt; met.synthesize(5)</span>

<span class="sd">        Get values from the first iteration:</span>

<span class="sd">        &gt;&gt;&gt; met.get_progress(0)</span>
<span class="sd">        {&#39;losses&#39;: tensor(0.0194),</span>
<span class="sd">        &#39;iteration&#39;: 0,</span>
<span class="sd">        &#39;pixel_change_norm&#39;: tensor(2.5326),</span>
<span class="sd">        &#39;gradient_norm&#39;: tensor(0.0010)}</span>

<span class="sd">        Get values from most last iteration of synthesis:</span>

<span class="sd">        &gt;&gt;&gt; print(met.get_progress(-2))</span>
<span class="sd">        {&#39;losses&#39;: tensor(0.0145),</span>
<span class="sd">        &#39;iteration&#39;: 4,</span>
<span class="sd">        &#39;pixel_change_norm&#39;: tensor(2.2698),</span>
<span class="sd">        &#39;gradient_norm&#39;: tensor(0.0268)}</span>

<span class="sd">        Get current values:</span>

<span class="sd">        &gt;&gt;&gt; print(met.get_progress(-1))</span>
<span class="sd">        {&#39;losses&#39;: tensor(0.0132),</span>
<span class="sd">        &#39;iteration&#39;: 5,</span>
<span class="sd">        &#39;pixel_change_norm&#39;: None,</span>
<span class="sd">        &#39;gradient_norm&#39;: None}</span>

<span class="sd">        When synthesis is run with ``store_progress=True``, this function also</span>
<span class="sd">        returns the metamer from the corresponding iteration:</span>

<span class="sd">        &gt;&gt;&gt; met = po.synth.Metamer(img, model)</span>
<span class="sd">        &gt;&gt;&gt; met.synthesize(5, store_progress=True)</span>
<span class="sd">        &gt;&gt;&gt; print(met.get_progress(-1))</span>
<span class="sd">        {&#39;losses&#39;: tensor(0.0124),</span>
<span class="sd">        &#39;iteration&#39;: 5,</span>
<span class="sd">        &#39;pixel_change_norm&#39;: None,</span>
<span class="sd">        &#39;gradient_norm&#39;: None,</span>
<span class="sd">        &#39;saved_metamer&#39;: tensor([[[[0.4554, ...]]]], grad_fn=&lt;SelectBackward0&gt;),</span>
<span class="sd">        &#39;store_progress_iteration&#39;: 5}</span>
<span class="sd">        &gt;&gt;&gt; torch.equal(met.saved_metamer[-1], met.get_progress(-1)[&quot;saved_metamer&quot;])</span>
<span class="sd">        True</span>

<span class="sd">        When synthesis is run with ``store_progress&gt;1``, this function returns the</span>
<span class="sd">        metamer from the closest iteration:</span>

<span class="sd">        &gt;&gt;&gt; met = po.synth.Metamer(img, model)</span>
<span class="sd">        &gt;&gt;&gt; met.synthesize(5, store_progress=2)</span>
<span class="sd">        &gt;&gt;&gt; print(met.get_progress(-3))</span>
<span class="sd">        {&#39;losses&#39;: tensor(0.0152),</span>
<span class="sd">        &#39;iteration&#39;: 3,</span>
<span class="sd">        &#39;pixel_change_norm&#39;: tensor(2.3592),</span>
<span class="sd">        &#39;gradient_norm&#39;: tensor(0.0269),</span>
<span class="sd">        &#39;saved_metamer&#39;: tensor([[[[0.8532, ...]]]], grad_fn=&lt;SelectBackward0&gt;),</span>
<span class="sd">        &#39;store_progress_iteration&#39;: 4}</span>

<span class="sd">        When we cannot grab the saved metamer corresponding to the requested</span>
<span class="sd">        iteration, ``iteration_selection`` controls how we determine &quot;closest&quot;:</span>

<span class="sd">        &gt;&gt;&gt; print(met.get_progress(-3, iteration_selection=&quot;floor&quot;))</span>
<span class="sd">        {&#39;losses&#39;: tensor(0.0152),</span>
<span class="sd">        &#39;iteration&#39;: 3,</span>
<span class="sd">        &#39;pixel_change_norm&#39;: tensor(2.3592),</span>
<span class="sd">        &#39;gradient_norm&#39;: tensor(0.0269),</span>
<span class="sd">        &#39;saved_metamer&#39;: tensor([[[[ 0.8730, ...]]]], grad_fn=&lt;SelectBackward0&gt;),</span>
<span class="sd">        &#39;store_progress_iteration&#39;: 2}</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_progress</span><span class="p">(</span>
            <span class="n">iteration</span><span class="p">,</span>
            <span class="n">iteration_selection</span><span class="p">,</span>
            <span class="n">store_progress_attributes</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;saved_metamer&quot;</span><span class="p">],</span>
        <span class="p">)</span></div>


    <span class="k">def</span><span class="w"> </span><span class="nf">_optimizer_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pbar</span><span class="p">:</span> <span class="n">tqdm</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute and propagate gradients, then step the optimizer to update metamer.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        pbar</span>
<span class="sd">            A tqdm progress-bar, which we update with a postfix</span>
<span class="sd">            describing the current loss, gradient norm, and learning</span>
<span class="sd">            rate (it already tells us which iteration and the time</span>
<span class="sd">            elapsed).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        loss</span>
<span class="sd">            1-element tensor containing the loss on this step.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># numpydoc ignore=ES01,EX01</span>
        <span class="n">last_iter_metamer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">metamer</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_closure</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

        <span class="n">grad_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">vector_norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">metamer</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="nb">ord</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_gradient_norm</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">grad_norm</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

        <span class="c1"># optionally step the scheduler, passing loss if needed</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_scheduler_step_arg</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="n">pixel_change_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">vector_norm</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">metamer</span> <span class="o">-</span> <span class="n">last_iter_metamer</span><span class="p">,</span> <span class="nb">ord</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_pixel_change_norm</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pixel_change_norm</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
        <span class="c1"># add extra info here if you want it to show up in progress bar</span>
        <span class="n">pbar</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">(</span>
            <span class="n">OrderedDict</span><span class="p">(</span>
                <span class="n">loss</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="s2">.04e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="n">learning_rate</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;lr&quot;</span><span class="p">],</span>
                <span class="n">gradient_norm</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">grad_norm</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.04e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="n">pixel_change_norm</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">pixel_change_norm</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.04e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_check_convergence</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">stop_criterion</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">stop_iters_to_check</span><span class="p">:</span> <span class="nb">int</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Check whether the loss has stabilized and, if so, return True.</span>

<span class="sd">        Uses :func:`~plenoptic.tools.convergence._loss_convergence`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        stop_criterion</span>
<span class="sd">            If the loss over the past ``stop_iters_to_check`` has changed</span>
<span class="sd">            less than ``stop_criterion``, we terminate synthesis.</span>
<span class="sd">        stop_iters_to_check</span>
<span class="sd">            How many iterations back to check in order to see if the</span>
<span class="sd">            loss has stopped decreasing (for ``stop_criterion``).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        loss_stabilized</span>
<span class="sd">            Whether the loss has stabilized or not.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># numpydoc ignore=EX01</span>
        <span class="k">return</span> <span class="n">_loss_convergence</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stop_criterion</span><span class="p">,</span> <span class="n">stop_iters_to_check</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_store</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Store metamer, if appropriate.</span>

<span class="sd">        If it&#39;s the right iteration, we update :attr:`saved_metamer`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        i</span>
<span class="sd">            The current iteration.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        stored</span>
<span class="sd">            True if we stored this iteration, False if not.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># numpydoc ignore=EX01</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">store_progress</span> <span class="ow">and</span> <span class="p">(</span><span class="n">i</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">store_progress</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
            <span class="c1"># want these to always be on cpu, to reduce memory use for GPUs</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_saved_metamer</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">metamer</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">))</span>
            <span class="n">stored</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">stored</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">return</span> <span class="n">stored</span>

<div class="viewcode-block" id="Metamer.save">
<a class="viewcode-back" href="../../../generated/plenoptic.synthesize.metamer.Metamer.html#plenoptic.synthesize.metamer.Metamer.save">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">file_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Save all relevant variables in .pt file.</span>

<span class="sd">        Note that if ``store_progress`` is True, this will probably be very</span>
<span class="sd">        large.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        file_path :</span>
<span class="sd">            The path to save the metamer object to.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        load</span>
<span class="sd">            Method to load in saved ``Metamer`` objects.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; import plenoptic as po</span>
<span class="sd">        &gt;&gt;&gt; img = po.data.einstein()</span>
<span class="sd">        &gt;&gt;&gt; model = po.simul.Gaussian(30).eval()</span>
<span class="sd">        &gt;&gt;&gt; po.tools.remove_grad(model)</span>
<span class="sd">        &gt;&gt;&gt; met = po.synth.Metamer(img, model)</span>
<span class="sd">        &gt;&gt;&gt; met.synthesize(max_iter=5, store_progress=True)</span>
<span class="sd">        &gt;&gt;&gt; met.save(&quot;metamers.pt&quot;)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">save_io_attrs</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">(</span><span class="s2">&quot;loss_function&quot;</span><span class="p">,</span> <span class="p">(</span><span class="s2">&quot;_target_representation&quot;</span><span class="p">,</span> <span class="s2">&quot;2 * _target_representation&quot;</span><span class="p">)),</span>
            <span class="p">(</span><span class="s2">&quot;_model&quot;</span><span class="p">,</span> <span class="p">(</span><span class="s2">&quot;_image&quot;</span><span class="p">,)),</span>
        <span class="p">]</span>
        <span class="n">save_state_dict_attrs</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;_optimizer&quot;</span><span class="p">,</span> <span class="s2">&quot;_scheduler&quot;</span><span class="p">]</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="n">save_io_attrs</span><span class="p">,</span> <span class="n">save_state_dict_attrs</span><span class="p">)</span></div>


<div class="viewcode-block" id="Metamer.to">
<a class="viewcode-back" href="../../../generated/plenoptic.synthesize.metamer.Metamer.html#plenoptic.synthesize.metamer.Metamer.to">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">to</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Move and/or cast the parameters and buffers.</span>

<span class="sd">        This can be called as</span>

<span class="sd">        .. code:: python</span>

<span class="sd">            to(device=None, dtype=None, non_blocking=False)</span>

<span class="sd">        .. code:: python</span>

<span class="sd">            to(dtype, non_blocking=False)</span>

<span class="sd">        .. code:: python</span>

<span class="sd">            to(tensor, non_blocking=False)</span>

<span class="sd">        Its signature is similar to :meth:`torch.Tensor.to`, but only accepts</span>
<span class="sd">        floating point desired ``dtype``. In addition, this method will</span>
<span class="sd">        only cast the floating point parameters and buffers to ``dtype``</span>
<span class="sd">        (if given). The integral parameters and buffers will be moved</span>
<span class="sd">        ``device``, if that is given, but with dtypes unchanged. When</span>
<span class="sd">        `on_blocking`` is set, it tries to convert/move asynchronously</span>
<span class="sd">        with respect to the host if possible, e.g., moving CPU Tensors with</span>
<span class="sd">        pinned memory to CUDA devices.</span>

<span class="sd">        See :meth:`torch.nn.Module.to` for examples.</span>

<span class="sd">        .. note::</span>
<span class="sd">            This method modifies the module in-place.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        device : torch.device</span>
<span class="sd">            The desired device of the parameters and buffers in this module.</span>
<span class="sd">        dtype : torch.dtype</span>
<span class="sd">            The desired floating point type of the floating point parameters and</span>
<span class="sd">            buffers in this module.</span>
<span class="sd">        tensor : torch.Tensor</span>
<span class="sd">            Tensor whose dtype and device are the desired dtype and device for</span>
<span class="sd">            all parameters and buffers in this module.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; import plenoptic as po</span>
<span class="sd">        &gt;&gt;&gt; img = po.data.einstein()</span>
<span class="sd">        &gt;&gt;&gt; model = po.simul.Gaussian(30).eval()</span>
<span class="sd">        &gt;&gt;&gt; po.tools.remove_grad(model)</span>
<span class="sd">        &gt;&gt;&gt; met = po.synth.Metamer(img, model)</span>
<span class="sd">        &gt;&gt;&gt; met.image.dtype</span>
<span class="sd">        torch.float32</span>
<span class="sd">        &gt;&gt;&gt; met.model(met.image).dtype</span>
<span class="sd">        torch.float32</span>
<span class="sd">        &gt;&gt;&gt; met.to(torch.float64)</span>
<span class="sd">        &gt;&gt;&gt; met.image.dtype</span>
<span class="sd">        torch.float64</span>
<span class="sd">        &gt;&gt;&gt; met.model(met.image).dtype</span>
<span class="sd">        torch.float64</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># numpydoc ignore=PR01,PR02</span>
        <span class="n">attrs</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;_image&quot;</span><span class="p">,</span> <span class="s2">&quot;_target_representation&quot;</span><span class="p">,</span> <span class="s2">&quot;_metamer&quot;</span><span class="p">,</span> <span class="s2">&quot;_saved_metamer&quot;</span><span class="p">]</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">attrs</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="c1"># try to call .to() on model. this should work, but it might fail if e.g., this</span>
        <span class="c1"># a custom model that doesn&#39;t inherit torch.nn.Module</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;Unable to call model.to(), so we leave it as is.&quot;</span><span class="p">)</span></div>


<div class="viewcode-block" id="Metamer.load">
<a class="viewcode-back" href="../../../generated/plenoptic.synthesize.metamer.Metamer.html#plenoptic.synthesize.metamer.Metamer.load">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">load</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">file_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">map_location</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">tensor_equality_atol</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-8</span><span class="p">,</span>
        <span class="n">tensor_equality_rtol</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-5</span><span class="p">,</span>
        <span class="o">**</span><span class="n">pickle_load_args</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Load all relevant stuff from a .pt file.</span>

<span class="sd">        This must be called by a ``Metamer`` object initialized just like the saved</span>
<span class="sd">        object.</span>

<span class="sd">        Note this operates in place and so doesn&#39;t return anything.</span>

<span class="sd">        .. versionchanged:: 1.2</span>
<span class="sd">           load behavior changed in a backwards-incompatible manner in order to</span>
<span class="sd">           compatible with breaking changes in torch 2.6.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        file_path</span>
<span class="sd">            The path to load the synthesis object from.</span>
<span class="sd">        map_location</span>
<span class="sd">            Argument to pass to :func:`torch.load` as ``map_location``. If you</span>
<span class="sd">            save stuff that was being run on a GPU and are loading onto a</span>
<span class="sd">            CPU, you&#39;ll need this to make sure everything lines up</span>
<span class="sd">            properly. This should be structured like the str you would</span>
<span class="sd">            pass to :class:`torch.device`.</span>
<span class="sd">        tensor_equality_atol</span>
<span class="sd">            Absolute tolerance to use when checking for tensor equality during load,</span>
<span class="sd">            passed to :func:`torch.allclose`. It may be necessary to increase if you are</span>
<span class="sd">            saving and loading on two machines with torch built by different cuda</span>
<span class="sd">            versions. Be careful when changing this! See</span>
<span class="sd">            :class:`torch.finfo&lt;torch.torch.finfo&gt;` for more details about floating</span>
<span class="sd">            point precision of different data types (especially, ``eps``); if you have</span>
<span class="sd">            to increase this by more than 1 or 2 decades, then you are probably not</span>
<span class="sd">            dealing with a numerical issue.</span>
<span class="sd">        tensor_equality_rtol</span>
<span class="sd">            Relative tolerance to use when checking for tensor equality during load,</span>
<span class="sd">            passed to :func:`torch.allclose`. It may be necessary to increase if you are</span>
<span class="sd">            saving and loading on two machines with torch built by different cuda</span>
<span class="sd">            versions. Be careful when changing this! See</span>
<span class="sd">            :class:`torch.finfo&lt;torch.torch.finfo&gt;` for more details about floating</span>
<span class="sd">            point precision of different data types (especially, ``eps``); if you have</span>
<span class="sd">            to increase this by more than 1 or 2 decades, then you are probably not</span>
<span class="sd">            dealing with a numerical issue.</span>
<span class="sd">        **pickle_load_args</span>
<span class="sd">            Any additional kwargs will be added to ``pickle_module.load`` via</span>
<span class="sd">            :func:`torch.load`, see that function&#39;s docstring for details.</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If :func:`setup` or :func:`synthesize` has been called before this call</span>
<span class="sd">            to ``load``.</span>
<span class="sd">        ValueError</span>
<span class="sd">            If the object saved at ``file_path`` is not a ``Metamer`` object.</span>
<span class="sd">        ValueError</span>
<span class="sd">            If the saved and loading ``Metamer`` objects have a different value</span>
<span class="sd">            for any of :attr:`image`, :attr:`range_penalty_lambda`,</span>
<span class="sd">            or :attr:`allowed_range`.</span>
<span class="sd">        ValueError</span>
<span class="sd">            If the behavior of :attr:`loss_function` or :attr:`model` is different</span>
<span class="sd">            between the saved and loading objects.</span>

<span class="sd">        Warns</span>
<span class="sd">        -----</span>
<span class="sd">        UserWarning</span>
<span class="sd">            If :func:`setup` will need to be called after load, to finish initializing</span>
<span class="sd">            :attr:`optimizer` or :attr:`scheduler`.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        :func:`~plenoptic.tools.io.examine_saved_synthesis`</span>
<span class="sd">            Examine metadata from saved object: pytorch and plenoptic versions, name of</span>
<span class="sd">            the synthesis object, shapes of tensors, etc.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        In order to load a saved ``Metamer`` object, we must first initialize</span>
<span class="sd">        one using the same arguments. (We use float64 / &quot;double&quot; precision rather than</span>
<span class="sd">        torch&#39;s default float32 because it increases reproducibility, see the</span>
<span class="sd">        :ref:`Reproducibility &lt;reproduce&gt;` page of our documentations for more details.)</span>
<span class="sd">        Here, we load in a cached example:</span>

<span class="sd">        &gt;&gt;&gt; import plenoptic as po</span>
<span class="sd">        &gt;&gt;&gt; img = po.data.einstein().to(torch.float64)</span>
<span class="sd">        &gt;&gt;&gt; model = po.simul.Gaussian(30).eval().to(torch.float64)</span>
<span class="sd">        &gt;&gt;&gt; po.tools.remove_grad(model)</span>
<span class="sd">        &gt;&gt;&gt; met = po.synth.Metamer(img, model)</span>
<span class="sd">        &gt;&gt;&gt; print(met.metamer)</span>
<span class="sd">        tensor([])</span>
<span class="sd">        &gt;&gt;&gt; met.load(po.data.fetch_data(&quot;example_metamer_gaussian.pt&quot;))</span>
<span class="sd">        &gt;&gt;&gt; print(met.metamer)</span>
<span class="sd">        tensor([[[[0.0692, ...]]]], dtype=torch.float64, requires_grad=True)</span>

<span class="sd">        If the saved ``Metamer`` object lived on a CUDA device and you do not have</span>
<span class="sd">        CUDA on the loading machine, use ``map_location`` to change device:</span>

<span class="sd">        &gt;&gt;&gt; met = po.synth.Metamer(img, model)</span>
<span class="sd">        &gt;&gt;&gt; met.image.device</span>
<span class="sd">        device(type=&#39;cpu&#39;)</span>
<span class="sd">        &gt;&gt;&gt; met.load(po.data.fetch_data(&quot;example_metamer_gaussian-cuda.pt&quot;))</span>
<span class="sd">        Traceback (most recent call last):</span>
<span class="sd">        RuntimeError: Attempting to deserialize object on a CUDA device but</span>
<span class="sd">        torch.cuda.is_available() is False...</span>
<span class="sd">        &gt;&gt;&gt; met.load(</span>
<span class="sd">        ...     po.data.fetch_data(&quot;example_metamer_gaussian-cuda.pt&quot;),</span>
<span class="sd">        ...     map_location=&quot;cpu&quot;,</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; print(met.metamer)</span>
<span class="sd">        tensor([[[[0.0692, ...]]]], dtype=torch.float64, requires_grad=True)</span>

<span class="sd">        If the loading ``Metamer`` object was not initialized with same values</span>
<span class="sd">        as the saved object, an error will be raised:</span>

<span class="sd">        &gt;&gt;&gt; met = po.synth.Metamer(torch.rand_like(img), model)</span>
<span class="sd">        &gt;&gt;&gt; met.load(po.data.fetch_data(&quot;example_metamer_gaussian.pt&quot;))</span>
<span class="sd">        Traceback (most recent call last):</span>
<span class="sd">        ValueError: Saved and initialized attribute image have different values...</span>

<span class="sd">        If the loading ``Metamer`` object has a different data type than the saved</span>
<span class="sd">        object, an error will be raised:</span>

<span class="sd">        &gt;&gt;&gt; met = po.synth.Metamer(img, model)</span>
<span class="sd">        &gt;&gt;&gt; met.to(torch.float32)</span>
<span class="sd">        &gt;&gt;&gt; met.load(po.data.fetch_data(&quot;example_metamer_gaussian.pt&quot;))</span>
<span class="sd">        Traceback (most recent call last):</span>
<span class="sd">        ValueError: Saved and initialized attribute image have different dtype...</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_load</span><span class="p">(</span>
            <span class="n">file_path</span><span class="p">,</span>
            <span class="n">map_location</span><span class="p">,</span>
            <span class="n">tensor_equality_atol</span><span class="o">=</span><span class="n">tensor_equality_atol</span><span class="p">,</span>
            <span class="n">tensor_equality_rtol</span><span class="o">=</span><span class="n">tensor_equality_rtol</span><span class="p">,</span>
            <span class="o">**</span><span class="n">pickle_load_args</span><span class="p">,</span>
        <span class="p">)</span></div>


    <span class="k">def</span><span class="w"> </span><span class="nf">_load</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">file_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">map_location</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">additional_check_attributes</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[],</span>
        <span class="n">additional_check_io_attributes</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[],</span>
        <span class="n">tensor_equality_atol</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-8</span><span class="p">,</span>
        <span class="n">tensor_equality_rtol</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-5</span><span class="p">,</span>
        <span class="o">**</span><span class="n">pickle_load_args</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Load from a file.</span>

<span class="sd">        This is a helper function for loading.</span>

<span class="sd">        Users interact with ``load`` (without the underscore), this is to allow</span>
<span class="sd">        subclasses to specify additional attributes or loss functions to check.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        file_path</span>
<span class="sd">            The path to load the synthesis object from.</span>
<span class="sd">        map_location</span>
<span class="sd">            Argument to pass to :func:`torch.load` as ``map_location``. If you</span>
<span class="sd">            save stuff that was being run on a GPU and are loading onto a</span>
<span class="sd">            CPU, you&#39;ll need this to make sure everything lines up</span>
<span class="sd">            properly. This should be structured like the str you would</span>
<span class="sd">            pass to :class:`torch.device`.</span>
<span class="sd">        additional_check_attributes</span>
<span class="sd">            Any additional attributes to check for equality. Intended for use by any</span>
<span class="sd">            subclasses, to add other attributes set at initialization.</span>
<span class="sd">        additional_check_io_attributes</span>
<span class="sd">            Any additional attributes whose input/output behavior we should check.</span>
<span class="sd">            Intended for use by any subclasses.</span>
<span class="sd">        tensor_equality_atol</span>
<span class="sd">            Absolute tolerance to use when checking for tensor equality during load,</span>
<span class="sd">            passed to :func:`torch.allclose`. It may be necessary to increase if you are</span>
<span class="sd">            saving and loading on two machines with torch built by different cuda</span>
<span class="sd">            versions. Be careful when changing this! See</span>
<span class="sd">            :class:`torch.finfo&lt;torch.torch.finfo&gt;` for more details about floating</span>
<span class="sd">            point precision of different data types (especially, ``eps``); if you have</span>
<span class="sd">            to increase this by more than 1 or 2 decades, then you are probably not</span>
<span class="sd">            dealing with a numerical issue.</span>
<span class="sd">        tensor_equality_rtol</span>
<span class="sd">            Relative tolerance to use when checking for tensor equality during load,</span>
<span class="sd">            passed to :func:`torch.allclose`. It may be necessary to increase if you are</span>
<span class="sd">            saving and loading on two machines with torch built by different cuda</span>
<span class="sd">            versions. Be careful when changing this! See</span>
<span class="sd">            :class:`torch.finfo&lt;torch.torch.finfo&gt;` for more details about floating</span>
<span class="sd">            point precision of different data types (especially, ``eps``); if you have</span>
<span class="sd">            to increase this by more than 1 or 2 decades, then you are probably not</span>
<span class="sd">            dealing with a numerical issue.</span>
<span class="sd">        **pickle_load_args</span>
<span class="sd">            Any additional kwargs will be added to ``pickle_module.load`` via</span>
<span class="sd">            :func:`torch.load`, see that function&#39;s docstring for details.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># numpydoc ignore=EX01</span>
        <span class="n">check_attributes</span> <span class="o">=</span> <span class="p">[</span>
            <span class="s2">&quot;_image&quot;</span><span class="p">,</span>
            <span class="s2">&quot;_range_penalty_lambda&quot;</span><span class="p">,</span>
            <span class="s2">&quot;_allowed_range&quot;</span><span class="p">,</span>
        <span class="p">]</span>
        <span class="n">check_attributes</span> <span class="o">+=</span> <span class="n">additional_check_attributes</span>
        <span class="n">check_io_attrs</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">(</span><span class="s2">&quot;loss_function&quot;</span><span class="p">,</span> <span class="p">(</span><span class="s2">&quot;_target_representation&quot;</span><span class="p">,</span> <span class="s2">&quot;2 * _target_representation&quot;</span><span class="p">)),</span>
            <span class="p">(</span><span class="s2">&quot;_model&quot;</span><span class="p">,</span> <span class="p">(</span><span class="s2">&quot;_image&quot;</span><span class="p">,)),</span>
        <span class="p">]</span>
        <span class="n">check_io_attrs</span> <span class="o">+=</span> <span class="n">additional_check_io_attributes</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">load</span><span class="p">(</span>
            <span class="n">file_path</span><span class="p">,</span>
            <span class="s2">&quot;_metamer&quot;</span><span class="p">,</span>
            <span class="n">map_location</span><span class="o">=</span><span class="n">map_location</span><span class="p">,</span>
            <span class="n">check_attributes</span><span class="o">=</span><span class="n">check_attributes</span><span class="p">,</span>
            <span class="n">check_io_attributes</span><span class="o">=</span><span class="n">check_io_attrs</span><span class="p">,</span>
            <span class="n">state_dict_attributes</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;_optimizer&quot;</span><span class="p">,</span> <span class="s2">&quot;_scheduler&quot;</span><span class="p">],</span>
            <span class="n">tensor_equality_atol</span><span class="o">=</span><span class="n">tensor_equality_atol</span><span class="p">,</span>
            <span class="n">tensor_equality_rtol</span><span class="o">=</span><span class="n">tensor_equality_rtol</span><span class="p">,</span>
            <span class="o">**</span><span class="n">pickle_load_args</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1"># make this require a grad again</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metamer</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>
        <span class="c1"># these are always supposed to be on cpu, but may get copied over to</span>
        <span class="c1"># gpu on load (which can cause problems when resuming synthesis), so</span>
        <span class="c1"># fix that.</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_saved_metamer</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_saved_metamer</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">!=</span> <span class="s2">&quot;cpu&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_saved_metamer</span> <span class="o">=</span> <span class="p">[</span><span class="n">met</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">met</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_saved_metamer</span><span class="p">]</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The model for which the metamer is synthesized.&quot;&quot;&quot;</span>
        <span class="c1"># numpydoc ignore=RT01,ES01,EX01</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">image</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Target image of metamer optimization.&quot;&quot;&quot;</span>
        <span class="c1"># numpydoc ignore=RT01,ES01,EX01</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_image</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">target_representation</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :attr:`model` representation of :attr:`image`.</span>

<span class="sd">        The goal of synthesis is for ``model(metamer)`` to match this value.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; import plenoptic as po</span>
<span class="sd">        &gt;&gt;&gt; img = po.data.einstein()</span>
<span class="sd">        &gt;&gt;&gt; model = po.simul.Gaussian(30).eval()</span>
<span class="sd">        &gt;&gt;&gt; po.tools.remove_grad(model)</span>
<span class="sd">        &gt;&gt;&gt; met = po.synth.Metamer(img, model)</span>
<span class="sd">        &gt;&gt;&gt; torch.equal(model(img), met.target_representation)</span>
<span class="sd">        True</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># numpydoc ignore=RT01</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_target_representation</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">metamer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Model metamer, the parameter we are optimizing.&quot;&quot;&quot;</span>
        <span class="c1"># numpydoc ignore=RT01,ES01,EX01</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_metamer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_metamer</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">saved_metamer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :attr:`metamer`, cached over time for later examination.</span>

<span class="sd">        How often the metamer is cached is determined by the ``store_progress`` argument</span>
<span class="sd">        to the :func:`synthesize` function.</span>

<span class="sd">        The last entry will always be the current :attr:`metamer`.</span>

<span class="sd">        If ``store_progress==1``, then this corresponds directly to :attr:`losses`:</span>
<span class="sd">        ``losses[i]`` is the error for ``saved_metamer[i]``</span>

<span class="sd">        This tensor always lives on the CPU, regardless of the device of the ``Metamer``</span>
<span class="sd">        object.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        If synthesize is called without ``store_progress``, then this attribute</span>
<span class="sd">        just contains the metamer, though the number of dimensions is different:</span>

<span class="sd">        &gt;&gt;&gt; import plenoptic as po</span>
<span class="sd">        &gt;&gt;&gt; po.tools.set_seed(0)</span>
<span class="sd">        &gt;&gt;&gt; img = po.data.einstein()</span>
<span class="sd">        &gt;&gt;&gt; model = po.simul.Gaussian(30).eval()</span>
<span class="sd">        &gt;&gt;&gt; po.tools.remove_grad(model)</span>
<span class="sd">        &gt;&gt;&gt; met = po.synth.Metamer(img, model)</span>
<span class="sd">        &gt;&gt;&gt; met.saved_metamer</span>
<span class="sd">        tensor([])</span>
<span class="sd">        &gt;&gt;&gt; met.synthesize(5)</span>
<span class="sd">        &gt;&gt;&gt; met.saved_metamer</span>
<span class="sd">        tensor([[[[[ 0.0098, ...]]]]], grad_fn=&lt;StackBackward0&gt;)</span>
<span class="sd">        &gt;&gt;&gt; met.metamer</span>
<span class="sd">        tensor([[[[ 0.0098, ...]]]], requires_grad=True)</span>
<span class="sd">        &gt;&gt;&gt; met.saved_metamer.shape</span>
<span class="sd">        torch.Size([1, 1, 1, 256, 256])</span>
<span class="sd">        &gt;&gt;&gt; met.metamer.shape</span>
<span class="sd">        torch.Size([1, 1, 256, 256])</span>

<span class="sd">        If synthesize is called with ``store_progress=1``, then this attribute</span>
<span class="sd">        contains the metamer at each iteration, and ``losses[i]`` contains the error</span>
<span class="sd">        for ``saved_metamer[i]``.</span>

<span class="sd">        &gt;&gt;&gt; met = po.synth.Metamer(img, model)</span>
<span class="sd">        &gt;&gt;&gt; met.synthesize(5, store_progress=True)</span>
<span class="sd">        &gt;&gt;&gt; met.saved_metamer.shape</span>
<span class="sd">        torch.Size([6, 1, 1, 256, 256])</span>
<span class="sd">        &gt;&gt;&gt; met.objective_function(met.saved_metamer[2])</span>
<span class="sd">        tensor(0.0169, grad_fn=&lt;AddBackward0&gt;)</span>
<span class="sd">        &gt;&gt;&gt; met.losses[2]</span>
<span class="sd">        tensor(0.0169)</span>

<span class="sd">        (In the above example, ``saved_metamer`` has 6 elements because it includes the</span>
<span class="sd">        metamer at the start of each of the 5 synthesis iterations, plus the current</span>
<span class="sd">        one.)</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># numpydoc ignore=RT01,EX01</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_metamer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># for memory purposes, always on CPU</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">_saved_metamer</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">metamer</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)])</span></div>



<div class="viewcode-block" id="MetamerCTF">
<a class="viewcode-back" href="../../../generated/plenoptic.synthesize.metamer.MetamerCTF.html#plenoptic.synthesize.metamer.MetamerCTF">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">MetamerCTF</span><span class="p">(</span><span class="n">Metamer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Synthesize model metamers with coarse-to-fine synthesis.</span>

<span class="sd">    This is a special case of ``Metamer``, which uses the coarse-to-fine</span>
<span class="sd">    synthesis procedure described in [1]_: we start by updating metamer with</span>
<span class="sd">    respect to only a subset of the model&#39;s representation (generally, that</span>
<span class="sd">    which corresponds to the lowest spatial frequencies), and changing which</span>
<span class="sd">    subset we consider over the course of synthesis. This is similar to</span>
<span class="sd">    optimizing with a blurred version of the objective function and gradually</span>
<span class="sd">    adding in finer details. It improves synthesis performance for some models.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    image</span>
<span class="sd">        A tensor, this is the image whose representation we wish to</span>
<span class="sd">        match.</span>
<span class="sd">    model</span>
<span class="sd">        A visual model.</span>
<span class="sd">    loss_function</span>
<span class="sd">        The loss function to use to compare the representations of the models</span>
<span class="sd">        in order to determine their loss.</span>
<span class="sd">    range_penalty_lambda</span>
<span class="sd">        Strength of the regularizer that enforces the allowed_range. Must be</span>
<span class="sd">        non-negative.</span>
<span class="sd">    allowed_range</span>
<span class="sd">        Range (inclusive) of allowed pixel values. Any values outside this</span>
<span class="sd">        range will be penalized.</span>
<span class="sd">    coarse_to_fine</span>
<span class="sd">        - ``&quot;together&quot;``: start with the coarsest scale, then gradually</span>
<span class="sd">          add each finer scale.</span>
<span class="sd">        - ``&quot;separate&quot;``: compute the gradient with respect to each</span>
<span class="sd">          scale separately (ignoring the others), then with respect</span>
<span class="sd">          to all of them at the end.</span>

<span class="sd">        (see :ref:`Metamer tutorial &lt;metamer-nb&gt;` for more details).</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] J Portilla and E P Simoncelli. A Parametric Texture Model</span>
<span class="sd">       based on Joint Statistics of Complex Wavelet Coefficients. Int&#39;l</span>
<span class="sd">       Journal of Computer Vision. 40(1):49-71, October, 2000.</span>
<span class="sd">       https://www.cns.nyu.edu/~eero/ABSTRACTS/portilla99-abstract.html</span>
<span class="sd">       https://www.cns.nyu.edu/~lcv/texture/</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    Synthesize and visualize a metamer using coarse-to-fine synthesis:</span>

<span class="sd">    .. plot::</span>
<span class="sd">      :context: reset</span>

<span class="sd">      &gt;&gt;&gt; import plenoptic as po</span>
<span class="sd">      &gt;&gt;&gt; import matplotlib.pyplot as plt</span>
<span class="sd">      &gt;&gt;&gt; import torch</span>
<span class="sd">      &gt;&gt;&gt; img = po.data.reptile_skin()</span>
<span class="sd">      &gt;&gt;&gt; model = po.simul.PortillaSimoncelli(img.shape[-2:])</span>
<span class="sd">      &gt;&gt;&gt; # to work with MetamerCTF, models must have a scales attribute</span>
<span class="sd">      &gt;&gt;&gt; model.scales</span>
<span class="sd">      [&#39;pixel_statistics&#39;, &#39;residual_lowpass&#39;, 3, 2, 1, 0, &#39;residual_highpass&#39;]</span>
<span class="sd">      &gt;&gt;&gt; met = po.synth.MetamerCTF(img, model, loss_function=po.tools.optim.l2_norm)</span>
<span class="sd">      &gt;&gt;&gt; # initialize with an image that has a comparable mean and standard deviation</span>
<span class="sd">      &gt;&gt;&gt; init_img = (torch.rand_like(img) - 0.5) * 0.1 + img.mean()</span>
<span class="sd">      &gt;&gt;&gt; met.setup(init_img)</span>
<span class="sd">      &gt;&gt;&gt; met.synthesize(150, change_scale_criterion=None, ctf_iters_to_check=7)</span>
<span class="sd">      &gt;&gt;&gt; fig, axes = plt.subplots(1, 4, figsize=(25, 4), width_ratios=[1, 1, 1, 3])</span>
<span class="sd">      &gt;&gt;&gt; po.imshow(img, ax=axes[0], title=&quot;Target image&quot;)</span>
<span class="sd">      &lt;Figure size ... with 4 Axes&gt;</span>
<span class="sd">      &gt;&gt;&gt; axes[0].xaxis.set_visible(False)</span>
<span class="sd">      &gt;&gt;&gt; axes[0].yaxis.set_visible(False)</span>
<span class="sd">      &gt;&gt;&gt; po.synth.metamer.plot_synthesis_status(met, fig=fig, axes_idx={&quot;misc&quot;: 0})[0]</span>
<span class="sd">      &lt;Figure size ...&gt;</span>

<span class="sd">    Not all models work with ``MetamerCTF``:</span>

<span class="sd">    &gt;&gt;&gt; import plenoptic as po</span>
<span class="sd">    &gt;&gt;&gt; img = po.data.einstein()</span>
<span class="sd">    &gt;&gt;&gt; model = po.simul.Gaussian(30).eval()</span>
<span class="sd">    &gt;&gt;&gt; po.tools.remove_grad(model)</span>
<span class="sd">    &gt;&gt;&gt; met = po.synth.MetamerCTF(img, model)</span>
<span class="sd">    Traceback (most recent call last):</span>
<span class="sd">    AttributeError: model has no scales attribute ...</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">image</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
        <span class="n">loss_function</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">mse</span><span class="p">,</span>
        <span class="n">range_penalty_lambda</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
        <span class="n">allowed_range</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
        <span class="n">coarse_to_fine</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;together&quot;</span><span class="p">,</span> <span class="s2">&quot;separate&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;together&quot;</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">image</span><span class="p">,</span>
            <span class="n">model</span><span class="p">,</span>
            <span class="n">loss_function</span><span class="p">,</span>
            <span class="n">range_penalty_lambda</span><span class="p">,</span>
            <span class="n">allowed_range</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_init_ctf</span><span class="p">(</span><span class="n">coarse_to_fine</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_init_ctf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">coarse_to_fine</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;together&quot;</span><span class="p">,</span> <span class="s2">&quot;separate&quot;</span><span class="p">]):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize stuff related to coarse-to-fine.</span>

<span class="sd">        - Validates value of ``coarse_to_fine``</span>

<span class="sd">        - Validates ``self.model`` for coarse-to-fine synthesis (calls</span>
<span class="sd">          :func:`validate_coarse_to_fine`).</span>

<span class="sd">        - Initializes attributes for coarse-to-fine synthesis.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        coarse_to_fine</span>
<span class="sd">            Which mode of coarse-to-fine to use, see initial docstring for details.</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If ``coarse_to_fine`` takes an illegal value.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># numpydoc ignore=EX01</span>
        <span class="c1"># this will hold the reduced representation of the target image.</span>
        <span class="k">if</span> <span class="n">coarse_to_fine</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;separate&quot;</span><span class="p">,</span> <span class="s2">&quot;together&quot;</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Don&#39;t know how to handle value </span><span class="si">{</span><span class="n">coarse_to_fine</span><span class="si">}</span><span class="s2">!&quot;</span>
                <span class="s2">&quot; Must be one of: &#39;separate&#39;, &#39;together&#39;&quot;</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_ctf_target_representation</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">validate_coarse_to_fine</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">image_shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">device</span>
        <span class="p">)</span>
        <span class="c1"># if self.scales is not None, we&#39;re continuing a previous version</span>
        <span class="c1"># and want to continue. this list comprehension creates a new</span>
        <span class="c1"># object, so we don&#39;t modify model.scales</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_scales</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">scales</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span>
        <span class="k">if</span> <span class="n">coarse_to_fine</span> <span class="o">==</span> <span class="s2">&quot;separate&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_scales</span> <span class="o">+=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">scales</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_scales</span> <span class="o">+=</span> <span class="p">[</span><span class="s2">&quot;all&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_scales_timing</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">((</span><span class="n">k</span><span class="p">,</span> <span class="p">[])</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">scales</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_scales_timing</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">scales</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_scales_loss</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_scales_finished</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_coarse_to_fine</span> <span class="o">=</span> <span class="n">coarse_to_fine</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_initial_lr</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_initialize_optimizer</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">optimizer</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">synth_attr</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">optimizer_kwargs</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize optimizer.</span>

<span class="sd">        Calls ``super._initialize_optimizer()``, passing all arguments through, and also</span>
<span class="sd">        caches the initial learning rate (``self._initial_lr``), which we use when</span>
<span class="sd">        switching scales.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        optimizer</span>
<span class="sd">            The (un-initialized) optimizer object to use. If ``None``, we use</span>
<span class="sd">            :class:`torch.optim.Adam`.</span>
<span class="sd">        synth_attr</span>
<span class="sd">            The tensor we will optimize.</span>
<span class="sd">        optimizer_kwargs</span>
<span class="sd">            The keyword arguments to pass to the optimizer on initialization. If</span>
<span class="sd">            ``None``, we use ``{&quot;lr&quot;: .01}`` and, if optimizer is ``None``,</span>
<span class="sd">            ``{&quot;amsgrad&quot;: True}``.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># numpydoc ignore=EX01</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_initialize_optimizer</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">synth_attr</span><span class="p">,</span> <span class="n">optimizer_kwargs</span><span class="p">)</span>
        <span class="c1"># save the initial learning rate so we can reset it when we change scales</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_initial_lr</span> <span class="o">=</span> <span class="p">[</span><span class="n">pg</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">pg</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">]</span>

<div class="viewcode-block" id="MetamerCTF.synthesize">
<a class="viewcode-back" href="../../../generated/plenoptic.synthesize.metamer.MetamerCTF.html#plenoptic.synthesize.metamer.MetamerCTF.synthesize">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">synthesize</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">max_iter</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
        <span class="n">store_progress</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">stop_criterion</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-4</span><span class="p">,</span>
        <span class="n">stop_iters_to_check</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span>
        <span class="n">change_scale_criterion</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="mf">1e-2</span><span class="p">,</span>
        <span class="n">ctf_iters_to_check</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Synthesize a metamer.</span>

<span class="sd">        Update the pixels of ``metamer`` until its representation matches</span>
<span class="sd">        that of ``image``.</span>

<span class="sd">        We run this until either we reach ``max_iter`` or the change over the</span>
<span class="sd">        past ``stop_iters_to_check`` iterations is less than</span>
<span class="sd">        ``stop_criterion``, whichever comes first.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        max_iter</span>
<span class="sd">            The maximum number of iterations to run before we end synthesis</span>
<span class="sd">            (unless we hit the stop criterion).</span>
<span class="sd">        store_progress</span>
<span class="sd">            Whether we should store the metamer image in progress on every</span>
<span class="sd">            iteration. If ``False``, we don&#39;t save anything. If True, we save every</span>
<span class="sd">            iteration. If an int, we save every ``store_progress`` iterations</span>
<span class="sd">            (note then that 0 is the same as False and 1 the same as True). This is</span>
<span class="sd">            primarily useful for using</span>
<span class="sd">            :func:`~plenoptic.synthesize.metamer.animate` to create a video of the</span>
<span class="sd">            course of synthesis.</span>
<span class="sd">        stop_criterion</span>
<span class="sd">            If the loss over the past ``stop_iters_to_check`` has changed</span>
<span class="sd">            less than ``stop_criterion``, we terminate synthesis.</span>
<span class="sd">        stop_iters_to_check</span>
<span class="sd">            How many iterations back to check in order to see if the</span>
<span class="sd">            loss has stopped decreasing (for ``stop_criterion``).</span>
<span class="sd">        change_scale_criterion</span>
<span class="sd">            Scale-specific analogue of ``change_scale_criterion``: we consider</span>
<span class="sd">            a given scale finished (and move onto the next) if the loss has</span>
<span class="sd">            changed less than this in the past ``ctf_iters_to_check``</span>
<span class="sd">            iterations. If ``None``, we&#39;ll change scales as soon as we&#39;ve spent</span>
<span class="sd">            ``ctf_iters_to_check`` on a given scale.</span>
<span class="sd">        ctf_iters_to_check</span>
<span class="sd">            Scale-specific analogue of ``stop_iters_to_check``: how many</span>
<span class="sd">            iterations back in order to check in order to see if we should</span>
<span class="sd">            switch scales.</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If ``stop_criterion &gt;= change_scale_criterion`` -- behavior is strange</span>
<span class="sd">            otherwise.</span>
<span class="sd">        ValueError</span>
<span class="sd">            If we find a NaN during optimization.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        :func:`~plenoptic.synthesize.metamer.plot_synthesis_status`</span>
<span class="sd">            Create a plot summarizing synthesis status at a given iteration.</span>
<span class="sd">        :func:`~plenoptic.synthesize.metamer.animate`</span>
<span class="sd">            Create a video of the metamer changing over the course of</span>
<span class="sd">            synthesis.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; import plenoptic as po</span>
<span class="sd">        &gt;&gt;&gt; po.tools.set_seed(0)</span>
<span class="sd">        &gt;&gt;&gt; img = po.data.reptile_skin()</span>
<span class="sd">        &gt;&gt;&gt; model = po.simul.PortillaSimoncelli(img.shape[-2:])</span>
<span class="sd">        &gt;&gt;&gt; met = po.synth.MetamerCTF(img, model)</span>
<span class="sd">        &gt;&gt;&gt; # this isn&#39;t enough to run synthesis to completion, just an example</span>
<span class="sd">        &gt;&gt;&gt; met.synthesize(5)</span>
<span class="sd">        &gt;&gt;&gt; met.losses</span>
<span class="sd">        tensor([0.0821, ..., 0.0805])</span>

<span class="sd">        You can examine scales_timing attribute to see when MetamerCTF started and</span>
<span class="sd">        stopped optimizing each scale:</span>

<span class="sd">        &gt;&gt;&gt; met.scales_timing</span>
<span class="sd">        {&#39;pixel_statistics&#39;: [0],</span>
<span class="sd">         &#39;residual_lowpass&#39;: [],</span>
<span class="sd">         3: [],</span>
<span class="sd">         2: [],</span>
<span class="sd">         1: [],</span>
<span class="sd">         0: [],</span>
<span class="sd">         &#39;all&#39;: []}</span>

<span class="sd">        Synthesize a metamer, using ``store_progress`` so we can examine progress</span>
<span class="sd">        later. (This also enables us to create a video of the metamer changing over</span>
<span class="sd">        the course of synthesis, see</span>
<span class="sd">        :func:`~plenoptic.synthesize.metamer.animate`.)</span>

<span class="sd">        &gt;&gt;&gt; met = po.synth.MetamerCTF(img, model)</span>
<span class="sd">        &gt;&gt;&gt; # this isn&#39;t enough to run synthesis to completion, just an example</span>
<span class="sd">        &gt;&gt;&gt; met.synthesize(5, store_progress=2)</span>
<span class="sd">        &gt;&gt;&gt; met.saved_metamer.shape</span>
<span class="sd">        torch.Size([4, 1, 1, 256, 256])</span>
<span class="sd">        &gt;&gt;&gt; # see loss, etc on the 4th iteration</span>
<span class="sd">        &gt;&gt;&gt; progress = met.get_progress(4)</span>
<span class="sd">        &gt;&gt;&gt; progress.keys()</span>
<span class="sd">        dict_keys([&#39;losses&#39;, ..., &#39;saved_metamer&#39;, &#39;store_progress_iteration&#39;])</span>
<span class="sd">        &gt;&gt;&gt; progress[&quot;losses&quot;]</span>
<span class="sd">        tensor(0.0850)</span>

<span class="sd">        Set ``change_scale_criterion`` and ``ctf_iters_to_check`` to change</span>
<span class="sd">        scale-switching behavior.</span>

<span class="sd">        &gt;&gt;&gt; met = po.synth.MetamerCTF(img, model)</span>
<span class="sd">        &gt;&gt;&gt; # this isn&#39;t enough to run synthesis to completion, just an example</span>
<span class="sd">        &gt;&gt;&gt; met.synthesize(5, change_scale_criterion=None, ctf_iters_to_check=2)</span>
<span class="sd">        &gt;&gt;&gt; met.losses</span>
<span class="sd">        tensor([0.0863, ..., 0.0569])</span>
<span class="sd">        &gt;&gt;&gt; met.scales_timing</span>
<span class="sd">        {&#39;pixel_statistics&#39;: [0, 1],</span>
<span class="sd">         &#39;residual_lowpass&#39;: [2, 3],</span>
<span class="sd">         3: [4],</span>
<span class="sd">         2: [],</span>
<span class="sd">         1: [],</span>
<span class="sd">         0: [],</span>
<span class="sd">         &#39;all&#39;: []}</span>

<span class="sd">        Adjust ``stop_criterion`` and ``stop_iters_to_check`` to change how convergence</span>
<span class="sd">        is determined. In this case, we stop early by making ``stop_criterion`` fairly</span>
<span class="sd">        large. In practice, you&#39;re more likely to make ``stop_criterion`` smaller to let</span>
<span class="sd">        synthesis run for longer.</span>

<span class="sd">        &gt;&gt;&gt; met = po.synth.MetamerCTF(img, model)</span>
<span class="sd">        &gt;&gt;&gt; # this isn&#39;t enough to run synthesis to completion, just an example</span>
<span class="sd">        &gt;&gt;&gt; met.synthesize(10, stop_criterion=0.001, stop_iters_to_check=2)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">change_scale_criterion</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span>
            <span class="n">stop_criterion</span> <span class="o">&gt;=</span> <span class="n">change_scale_criterion</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;stop_criterion must be strictly less than &quot;</span>
                <span class="s2">&quot;change_scale_criterion, or things get weird!&quot;</span>
            <span class="p">)</span>

        <span class="c1"># if setup hasn&#39;t been called manually, call it now.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_metamer</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_scheduler</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">setup</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_current_loss</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># get ready to store progress</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">store_progress</span> <span class="o">=</span> <span class="n">store_progress</span>

        <span class="n">pbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">max_iter</span><span class="p">))</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">pbar</span><span class="p">:</span>
            <span class="c1"># update saved_* attrs. len(_losses) gives the total number of</span>
            <span class="c1"># iterations and will be correct across calls to `synthesize`</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_store</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_losses</span><span class="p">))</span>

            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer_step</span><span class="p">(</span>
                <span class="n">pbar</span><span class="p">,</span> <span class="n">change_scale_criterion</span><span class="p">,</span> <span class="n">ctf_iters_to_check</span>
            <span class="p">)</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">loss</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Found a NaN in loss during optimization.&quot;</span><span class="p">)</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_convergence</span><span class="p">(</span>
                <span class="n">i</span><span class="p">,</span> <span class="n">stop_criterion</span><span class="p">,</span> <span class="n">stop_iters_to_check</span><span class="p">,</span> <span class="n">ctf_iters_to_check</span>
            <span class="p">):</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;Loss has converged, stopping synthesis&quot;</span><span class="p">)</span>
                <span class="k">break</span>

        <span class="c1"># compute current loss, no need to compute gradient</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_current_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">objective_function</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

        <span class="n">pbar</span><span class="o">.</span><span class="n">close</span><span class="p">()</span></div>


    <span class="k">def</span><span class="w"> </span><span class="nf">_optimizer_step</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">pbar</span><span class="p">:</span> <span class="n">tqdm</span><span class="p">,</span>
        <span class="n">change_scale_criterion</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">ctf_iters_to_check</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute and propagate gradients, then step the optimizer to update metamer.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        pbar</span>
<span class="sd">            A tqdm progress-bar, which we update with a postfix</span>
<span class="sd">            describing the current loss, gradient norm, and learning</span>
<span class="sd">            rate (it already tells us which iteration and the time</span>
<span class="sd">            elapsed).</span>
<span class="sd">        change_scale_criterion</span>
<span class="sd">            How many iterations back to check to see if the loss has stopped</span>
<span class="sd">            decreasing and we should thus move to the next scale in</span>
<span class="sd">            coarse-to-fine optimization.</span>
<span class="sd">        ctf_iters_to_check</span>
<span class="sd">            Minimum number of iterations coarse-to-fine must run at each scale.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        loss</span>
<span class="sd">            1-element tensor containing the loss on this step.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># numpydoc ignore=ES01,EX01</span>
        <span class="n">last_iter_metamer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">metamer</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>

        <span class="c1"># Check if conditions hold for switching scales:</span>
        <span class="c1"># - Check if loss has decreased below the change_scale_criterion and</span>
        <span class="c1"># - if we&#39;ve been optimizing this scale for the required number of iterations</span>
        <span class="c1"># - The first check here is because the last scale will be &#39;all&#39;, and</span>
        <span class="c1">#   we never remove it</span>

        <span class="k">if</span> <span class="p">(</span>
            <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scales</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span>
            <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scales_loss</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">ctf_iters_to_check</span>
            <span class="ow">and</span> <span class="p">(</span>
                <span class="n">change_scale_criterion</span> <span class="ow">is</span> <span class="kc">None</span>
                <span class="ow">or</span> <span class="nb">abs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scales_loss</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">scales_loss</span><span class="p">[</span><span class="o">-</span><span class="n">ctf_iters_to_check</span><span class="p">])</span>
                <span class="o">&lt;</span> <span class="n">change_scale_criterion</span>
            <span class="p">)</span>
            <span class="ow">and</span> <span class="p">(</span>
                <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_losses</span><span class="p">)</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">scales_timing</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">scales</span><span class="p">[</span><span class="mi">0</span><span class="p">]][</span><span class="mi">0</span><span class="p">]</span>
                <span class="o">&gt;=</span> <span class="n">ctf_iters_to_check</span>
            <span class="p">)</span>
        <span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_scales_timing</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">scales</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_losses</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_scales_finished</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_scales</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>

            <span class="c1"># Only append if scales list is still non-empty after the pop</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">scales</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_scales_timing</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">scales</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_losses</span><span class="p">))</span>

            <span class="c1"># Reset optimizer&#39;s learning rate</span>
            <span class="k">for</span> <span class="n">pg</span><span class="p">,</span> <span class="n">lr</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initial_lr</span><span class="p">):</span>
                <span class="n">pg</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">lr</span>

            <span class="c1"># Reset ctf target representation for the next update</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_ctf_target_representation</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># the loss returned by objective_function is from *before* updating the metamer,</span>
        <span class="c1"># so to compute the equivalent for display purposes, we need to call this before</span>
        <span class="c1"># calling step()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">scales</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="s2">&quot;all&quot;</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">overall_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">objective_function</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_closure</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">scales</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;all&quot;</span><span class="p">:</span>
            <span class="c1"># then the loss computed above includes all scales</span>
            <span class="n">overall_loss</span> <span class="o">=</span> <span class="n">loss</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_scales_loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">overall_loss</span><span class="p">)</span>

        <span class="n">grad_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">vector_norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">metamer</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="nb">ord</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_gradient_norm</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">grad_norm</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

        <span class="c1"># optionally step the scheduler, passing loss if needed</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_scheduler_step_arg</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="n">pixel_change_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">vector_norm</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">metamer</span> <span class="o">-</span> <span class="n">last_iter_metamer</span><span class="p">,</span> <span class="nb">ord</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_pixel_change_norm</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pixel_change_norm</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
        <span class="c1"># add extra info here if you want it to show up in progress bar</span>
        <span class="n">pbar</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">(</span>
            <span class="n">OrderedDict</span><span class="p">(</span>
                <span class="n">loss</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">overall_loss</span><span class="si">:</span><span class="s2">.04e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="n">learning_rate</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;lr&quot;</span><span class="p">],</span>
                <span class="n">gradient_norm</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">grad_norm</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.04e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="n">pixel_change_norm</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">pixel_change_norm</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.04e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="n">current_scale</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">scales</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                <span class="n">current_scale_loss</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="s2">.04e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">overall_loss</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_closure</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculate the gradient, before the optimization step.</span>

<span class="sd">        This enables optimization algorithms that perform several evaluations</span>
<span class="sd">        of the gradient before taking a step (ie. second order methods like</span>
<span class="sd">        LBFGS).</span>

<span class="sd">        Additionally, this is where:</span>

<span class="sd">        - ``metamer_representation`` is calculated, and thus any modifications</span>
<span class="sd">          to the model&#39;s forward call (e.g., specifying ``scale`` kwarg for</span>
<span class="sd">          coarse-to-fine) should happen.</span>

<span class="sd">        - ``loss`` is calculated and ``loss.backward()`` is called.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        loss</span>
<span class="sd">            Loss of the current objective function.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># numpydoc ignore=EX01</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">analyze_kwargs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="c1"># if we&#39;ve reached &#39;all&#39;, we use the full model</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">scales</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="s2">&quot;all&quot;</span><span class="p">:</span>
            <span class="n">analyze_kwargs</span><span class="p">[</span><span class="s2">&quot;scales&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">scales</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
            <span class="c1"># if &#39;together&#39;, then we also want all the coarser</span>
            <span class="c1"># scales</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">coarse_to_fine</span> <span class="o">==</span> <span class="s2">&quot;together&quot;</span><span class="p">:</span>
                <span class="n">analyze_kwargs</span><span class="p">[</span><span class="s2">&quot;scales&quot;</span><span class="p">]</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scales_finished</span>
        <span class="c1"># if analyze_kwargs is empty, we can just compare</span>
        <span class="c1"># metamer_representation against our cached target_representation</span>
        <span class="k">if</span> <span class="n">analyze_kwargs</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ctf_target_representation</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">target_rep</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">image</span><span class="p">,</span> <span class="o">**</span><span class="n">analyze_kwargs</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_ctf_target_representation</span> <span class="o">=</span> <span class="n">target_rep</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">target_rep</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ctf_target_representation</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">target_rep</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">objective_function</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">metamer</span><span class="p">,</span> <span class="n">target_rep</span><span class="p">,</span> <span class="o">**</span><span class="n">analyze_kwargs</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">retain_graph</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_check_convergence</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">i</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">stop_criterion</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">stop_iters_to_check</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">ctf_iters_to_check</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Check whether the loss has stabilized and whether we&#39;ve synthesized all scales.</span>

<span class="sd">        We check whether:</span>

<span class="sd">        - We have been synthesizing for ``stop_iters_to_check`` iterations,</span>
<span class="sd">          i.e. ``len(synth.losses) &gt; stop_iters_to_check``.</span>

<span class="sd">        - Loss has decreased by less than ``stop_criterion`` over the past</span>
<span class="sd">          ``stop_iters_to_check`` iterations.</span>

<span class="sd">        - We have finished synthesizing each individual scale, i.e. ``synth.scales[0] ==</span>
<span class="sd">          &quot;all&quot;``.</span>

<span class="sd">        - We have been synthesizing all scales for more than ``ctf_iters_to_check``</span>
<span class="sd">          iterations, i.e. ``i - synth.scales_timing[&quot;all&quot;][0]) &gt; ctf_iters_to_check``.</span>

<span class="sd">        If all conditions are met, we return ``True``. Else, we return ``False``.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        i</span>
<span class="sd">            The current iteration (0-indexed).</span>
<span class="sd">        stop_criterion</span>
<span class="sd">            If the loss over the past ``stop_iters_to_check`` has changed</span>
<span class="sd">            less than ``stop_criterion``, we terminate synthesis.</span>
<span class="sd">        stop_iters_to_check</span>
<span class="sd">            How many iterations back to check in order to see if the</span>
<span class="sd">            loss has stopped decreasing (for ``stop_criterion``).</span>
<span class="sd">        ctf_iters_to_check</span>
<span class="sd">            Minimum number of iterations coarse-to-fine must run at each scale.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        loss_stabilized</span>
<span class="sd">            Whether the loss has stabilized and we&#39;ve synthesized all scales.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>
        <span class="c1"># numpydoc ignore=EX01</span>
        <span class="n">loss_conv</span> <span class="o">=</span> <span class="n">_loss_convergence</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stop_criterion</span><span class="p">,</span> <span class="n">stop_iters_to_check</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss_conv</span> <span class="ow">and</span> <span class="n">_coarse_to_fine_enough</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">ctf_iters_to_check</span><span class="p">)</span>

<div class="viewcode-block" id="MetamerCTF.to">
<a class="viewcode-back" href="../../../generated/plenoptic.synthesize.metamer.MetamerCTF.html#plenoptic.synthesize.metamer.MetamerCTF.to">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">to</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Move and/or cast the parameters and buffers.</span>

<span class="sd">        This can be called as</span>

<span class="sd">        .. code:: python</span>

<span class="sd">            to(device=None, dtype=None, non_blocking=False)</span>

<span class="sd">        .. code:: python</span>

<span class="sd">            to(dtype, non_blocking=False)</span>

<span class="sd">        .. code:: python</span>

<span class="sd">            to(tensor, non_blocking=False)</span>

<span class="sd">        Its signature is similar to :meth:`torch.Tensor.to`, but only accepts</span>
<span class="sd">        floating point desired ``dtype``. In addition, this method will</span>
<span class="sd">        only cast the floating point parameters and buffers to ``dtype``</span>
<span class="sd">        (if given). The integral parameters and buffers will be moved</span>
<span class="sd">        ``device``, if that is given, but with dtypes unchanged. When</span>
<span class="sd">        `on_blocking`` is set, it tries to convert/move asynchronously</span>
<span class="sd">        with respect to the host if possible, e.g., moving CPU Tensors with</span>
<span class="sd">        pinned memory to CUDA devices.</span>

<span class="sd">        See :meth:`torch.nn.Module.to` for examples.</span>

<span class="sd">        .. note::</span>
<span class="sd">            This method modifies the module in-place.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        device : torch.device</span>
<span class="sd">            The desired device of the parameters and buffers in this module.</span>
<span class="sd">        dtype : torch.dtype</span>
<span class="sd">            The desired floating point type of the floating point parameters and</span>
<span class="sd">            buffers in this module.</span>
<span class="sd">        tensor : torch.Tensor</span>
<span class="sd">            Tensor whose dtype and device are the desired dtype and device for</span>
<span class="sd">            all parameters and buffers in this module.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; import plenoptic as po</span>
<span class="sd">        &gt;&gt;&gt; img = po.data.reptile_skin()</span>
<span class="sd">        &gt;&gt;&gt; model = po.simul.PortillaSimoncelli(img.shape[-2:])</span>
<span class="sd">        &gt;&gt;&gt; met = po.synth.MetamerCTF(img, model)</span>
<span class="sd">        &gt;&gt;&gt; met.image.dtype</span>
<span class="sd">        torch.float32</span>
<span class="sd">        &gt;&gt;&gt; met.model(met.image).dtype</span>
<span class="sd">        torch.float32</span>
<span class="sd">        &gt;&gt;&gt; met.to(torch.float64)</span>
<span class="sd">        &gt;&gt;&gt; met.image.dtype</span>
<span class="sd">        torch.float64</span>
<span class="sd">        &gt;&gt;&gt; met.model(met.image).dtype</span>
<span class="sd">        torch.float64</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># numpydoc ignore=PR01,PR02</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="c1"># if synthesize has been called at least once and we have not finished moving</span>
        <span class="c1"># through all scales, _ctf_target_representation will be a Tensor which get</span>
        <span class="c1"># passed to objective_function at some point. thus, need to make sure it&#39;s also</span>
        <span class="c1"># updated.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ctf_target_representation</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_ctf_target_representation</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ctf_target_representation</span><span class="o">.</span><span class="n">to</span><span class="p">(</span>
                <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
            <span class="p">)</span></div>


<div class="viewcode-block" id="MetamerCTF.load">
<a class="viewcode-back" href="../../../generated/plenoptic.synthesize.metamer.MetamerCTF.html#plenoptic.synthesize.metamer.MetamerCTF.load">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">load</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">file_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">map_location</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">tensor_equality_atol</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-8</span><span class="p">,</span>
        <span class="n">tensor_equality_rtol</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-5</span><span class="p">,</span>
        <span class="o">**</span><span class="n">pickle_load_args</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Load all relevant stuff from a .pt file.</span>

<span class="sd">        This should be called by an initialized ``Metamer`` object -- we will</span>
<span class="sd">        ensure that ``image``, ``target_representation`` (and thus</span>
<span class="sd">        ``model``), and ``loss_function`` are all identical.</span>

<span class="sd">        Note this operates in place and so doesn&#39;t return anything.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        file_path</span>
<span class="sd">            The path to load the synthesis object from.</span>
<span class="sd">        map_location</span>
<span class="sd">            Argument to pass to :func:`torch.load` as ``map_location``. If you</span>
<span class="sd">            save stuff that was being run on a GPU and are loading onto a</span>
<span class="sd">            CPU, you&#39;ll need this to make sure everything lines up</span>
<span class="sd">            properly. This should be structured like the str you would</span>
<span class="sd">            pass to :class:`torch.device`.</span>
<span class="sd">        tensor_equality_atol</span>
<span class="sd">            Absolute tolerance to use when checking for tensor equality during load,</span>
<span class="sd">            passed to :func:`torch.allclose`. It may be necessary to increase if you are</span>
<span class="sd">            saving and loading on two machines with torch built by different cuda</span>
<span class="sd">            versions. Be careful when changing this! See</span>
<span class="sd">            :class:`torch.finfo&lt;torch.torch.finfo&gt;` for more details about floating</span>
<span class="sd">            point precision of different data types (especially, ``eps``); if you have</span>
<span class="sd">            to increase this by more than 1 or 2 decades, then you are probably not</span>
<span class="sd">            dealing with a numerical issue.</span>
<span class="sd">        tensor_equality_rtol</span>
<span class="sd">            Relative tolerance to use when checking for tensor equality during load,</span>
<span class="sd">            passed to :func:`torch.allclose`. It may be necessary to increase if you are</span>
<span class="sd">            saving and loading on two machines with torch built by different cuda</span>
<span class="sd">            versions. Be careful when changing this! See</span>
<span class="sd">            :class:`torch.finfo&lt;torch.torch.finfo&gt;` for more details about floating</span>
<span class="sd">            point precision of different data types (especially, ``eps``); if you have</span>
<span class="sd">            to increase this by more than 1 or 2 decades, then you are probably not</span>
<span class="sd">            dealing with a numerical issue.</span>
<span class="sd">        **pickle_load_args</span>
<span class="sd">            Any additional kwargs will be added to ``pickle_module.load`` via</span>
<span class="sd">            :func:`torch.load`, see that function&#39;s docstring for details.</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If :func:`setup` or :func:`synthesize` has been called before this call</span>
<span class="sd">            to ``load``.</span>
<span class="sd">        ValueError</span>
<span class="sd">            If the object saved at ``file_path`` is not a ``MetamerCTF`` object.</span>
<span class="sd">        ValueError</span>
<span class="sd">            If the saved and loading ``MetamerCTF`` objects have a different value</span>
<span class="sd">            for any of :attr:`image`, :attr:`range_penalty_lambda`,</span>
<span class="sd">            :attr:`allowed_range`, or :attr:`coarse_to_fine`.</span>
<span class="sd">        ValueError</span>
<span class="sd">            If the behavior of :attr:`loss_function` or :attr:`model` is different</span>
<span class="sd">            between the saved and loading objects.</span>

<span class="sd">        Warns</span>
<span class="sd">        -----</span>
<span class="sd">        UserWarning</span>
<span class="sd">            If :func:`setup` will need to be called after load, to finish initializing</span>
<span class="sd">            :attr:`optimizer` or :attr:`scheduler`.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        In order to load a saved ``MetamerCTF`` object, we must first initialize one</span>
<span class="sd">        using the same arguments. (We use float64 / &quot;double&quot; precision rather than</span>
<span class="sd">        torch&#39;s default float32 because it increases reproducibility, see the</span>
<span class="sd">        :ref:`Reproducibility &lt;reproduce&gt;` page of our documentations for more details.)</span>
<span class="sd">        Here, we load in a cached example:</span>

<span class="sd">        &gt;&gt;&gt; import plenoptic as po</span>
<span class="sd">        &gt;&gt;&gt; img = po.data.reptile_skin().to(torch.float64)</span>
<span class="sd">        &gt;&gt;&gt; model = po.simul.PortillaSimoncelli(img.shape[-2:])</span>
<span class="sd">        &gt;&gt;&gt; met = po.synth.MetamerCTF(img, model, po.tools.optim.l2_norm)</span>
<span class="sd">        &gt;&gt;&gt; print(met.metamer)</span>
<span class="sd">        tensor([])</span>
<span class="sd">        &gt;&gt;&gt; met.load(po.data.fetch_data(&quot;example_metamerCTF_ps.pt&quot;))</span>
<span class="sd">        &gt;&gt;&gt; print(met.metamer)</span>
<span class="sd">        tensor([[[[0.3016, ...]]]], dtype=torch.float64, requires_grad=True)</span>

<span class="sd">        If the saved ``MetamerCTF`` object lived on a CUDA device and you do not have</span>
<span class="sd">        CUDA on the loading machine, use ``map_location`` to change device:</span>

<span class="sd">        &gt;&gt;&gt; met = po.synth.MetamerCTF(img, model, po.tools.optim.l2_norm)</span>
<span class="sd">        &gt;&gt;&gt; met.image.device</span>
<span class="sd">        device(type=&#39;cpu&#39;)</span>
<span class="sd">        &gt;&gt;&gt; met.load(po.data.fetch_data(&quot;example_metamerCTF_ps-cuda.pt&quot;))</span>
<span class="sd">        Traceback (most recent call last):</span>
<span class="sd">        RuntimeError: Attempting to deserialize object on a CUDA device but</span>
<span class="sd">        torch.cuda.is_available() is False...</span>
<span class="sd">        &gt;&gt;&gt; met.load(</span>
<span class="sd">        ...     po.data.fetch_data(&quot;example_metamerCTF_ps-cuda.pt&quot;), map_location=&quot;cpu&quot;</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; print(met.metamer)</span>
<span class="sd">        tensor([[[[0.3016, ...]]]], dtype=torch.float64, requires_grad=True)</span>

<span class="sd">        Loading and saving must both be done with ``MetamerCTF``:</span>

<span class="sd">        &gt;&gt;&gt; met = po.synth.Metamer(img, model)</span>
<span class="sd">        &gt;&gt;&gt; met.load(po.data.fetch_data(&quot;example_metamerCTF_ps.pt&quot;))</span>
<span class="sd">        Traceback (most recent call last):</span>
<span class="sd">        ValueError: Saved object was a plenoptic.synthesize.metamer.MetamerCTF...</span>

<span class="sd">        If the loading ``MetamerCTF`` object was not initialized with same values</span>
<span class="sd">        as the saved object, an error will be raised:</span>

<span class="sd">        &gt;&gt;&gt; met = po.synth.MetamerCTF(</span>
<span class="sd">        ...     torch.rand_like(img), model, po.tools.optim.l2_norm</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; met.load(po.data.fetch_data(&quot;example_metamerCTF_ps.pt&quot;))</span>
<span class="sd">        Traceback (most recent call last):</span>
<span class="sd">        ValueError: Saved and initialized attribute image have different values...</span>

<span class="sd">        If the loading ``MetamerCTF`` object has a different data type than the saved</span>
<span class="sd">        object, an error will be raised:</span>

<span class="sd">        &gt;&gt;&gt; met = po.synth.MetamerCTF(img, model, po.tools.optim.l2_norm)</span>
<span class="sd">        &gt;&gt;&gt; met.to(torch.float32)</span>
<span class="sd">        &gt;&gt;&gt; met.load(po.data.fetch_data(&quot;example_metamerCTF_ps.pt&quot;))</span>
<span class="sd">        Traceback (most recent call last):</span>
<span class="sd">        ValueError: Saved and initialized attribute image have different dtype...</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_load</span><span class="p">(</span>
            <span class="n">file_path</span><span class="p">,</span>
            <span class="n">map_location</span><span class="p">,</span>
            <span class="p">[</span><span class="s2">&quot;_coarse_to_fine&quot;</span><span class="p">],</span>
            <span class="n">tensor_equality_atol</span><span class="o">=</span><span class="n">tensor_equality_atol</span><span class="p">,</span>
            <span class="n">tensor_equality_rtol</span><span class="o">=</span><span class="n">tensor_equality_rtol</span><span class="p">,</span>
            <span class="o">**</span><span class="n">pickle_load_args</span><span class="p">,</span>
        <span class="p">)</span></div>


    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">coarse_to_fine</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;How we scales are handled, see :class:`MetamerCTF` for details.&quot;&quot;&quot;</span>
        <span class="c1"># numpydoc ignore=RT01,ES01,EX01</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_coarse_to_fine</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">scales</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Model scales that we&#39;ve yet to optimize, modified during optimization.&quot;&quot;&quot;</span>
        <span class="c1"># numpydoc ignore=RT01,ES01,EX01</span>
        <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_scales</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">scales_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Scale-specific loss at each iteration.&quot;&quot;&quot;</span>
        <span class="c1"># numpydoc ignore=RT01,ES01,EX01</span>
        <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_scales_loss</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">scales_timing</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Information about when each scale was started and stopped.</span>

<span class="sd">        Keys are the values found in :attr:`scales`, and values are lists specifying</span>
<span class="sd">        the iteration where we started and stopped optimizing this scale, which are</span>
<span class="sd">        modified during optimization.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># numpydoc ignore=RT01,EX01</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_scales_timing</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">scales_finished</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Model scales that we&#39;ve finished optimizing, modified during optimization.&quot;&quot;&quot;</span>
        <span class="c1"># numpydoc ignore=RT01,ES01,EX01</span>
        <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_scales_finished</span><span class="p">)</span></div>



<div class="viewcode-block" id="plot_loss">
<a class="viewcode-back" href="../../../generated/plenoptic.synthesize.metamer.html#plenoptic.synthesize.metamer.plot_loss">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">plot_loss</span><span class="p">(</span>
    <span class="n">metamer</span><span class="p">:</span> <span class="n">Metamer</span><span class="p">,</span>
    <span class="n">iteration</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">ax</span><span class="p">:</span> <span class="n">mpl</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">Axes</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">mpl</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">Axes</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Plot synthesis loss with log-scaled y axis.</span>

<span class="sd">    Plots ``metamer.losses`` over all iterations. Also plots a red dot at</span>
<span class="sd">    ``iteration``, to highlight the loss there. If ``iteration=None``, then the</span>
<span class="sd">    dot will be at the final iteration.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    metamer</span>
<span class="sd">        Metamer object whose loss we want to plot.</span>
<span class="sd">    iteration</span>
<span class="sd">        Which iteration to display. If ``None``,  we show</span>
<span class="sd">        the most recent one. Negative values are also allowed.</span>
<span class="sd">    ax</span>
<span class="sd">        Pre-existing axes for plot. If ``None``, we call</span>
<span class="sd">        :func:`matplotlib.pyplot.gca()`.</span>
<span class="sd">    **kwargs</span>
<span class="sd">        Passed to :func:`matplotlib.pyplot.semilogy`.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    ax</span>
<span class="sd">        The matplotlib axes containing the plot.</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    IndexError</span>
<span class="sd">        If ``iteration`` takes an illegal value.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    plot_synthesis_status</span>
<span class="sd">        Create a figure combining this with other axis-level plots to summarize</span>
<span class="sd">        synthesis status at a given iteration.</span>
<span class="sd">    animate</span>
<span class="sd">        Create a video animating this and other axis-level plots changing over</span>
<span class="sd">        the course of synthesis.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    .. plot::</span>
<span class="sd">      :context: reset</span>

<span class="sd">      &gt;&gt;&gt; import plenoptic as po</span>
<span class="sd">      &gt;&gt;&gt; import torch</span>
<span class="sd">      &gt;&gt;&gt; img = po.data.einstein()</span>
<span class="sd">      &gt;&gt;&gt; model = po.simul.Gaussian(30).eval()</span>
<span class="sd">      &gt;&gt;&gt; po.tools.remove_grad(model)</span>
<span class="sd">      &gt;&gt;&gt; met = po.synth.Metamer(img, model)</span>
<span class="sd">      &gt;&gt;&gt; met.to(torch.float64)</span>
<span class="sd">      &gt;&gt;&gt; met.load(po.data.fetch_data(&quot;example_metamer_gaussian.pt&quot;))</span>
<span class="sd">      &gt;&gt;&gt; po.synth.metamer.plot_loss(met)</span>
<span class="sd">      &lt;Axes: ... ylabel=&#39;Loss&#39;&gt;</span>

<span class="sd">    Specify an iteration:</span>

<span class="sd">    .. plot::</span>
<span class="sd">      :context: close-figs</span>

<span class="sd">      &gt;&gt;&gt; po.synth.metamer.plot_loss(met, iteration=10)</span>
<span class="sd">      &lt;Axes: ... ylabel=&#39;Loss&#39;&gt;</span>

<span class="sd">    Plot on an axis in an existing figure:</span>

<span class="sd">    .. plot::</span>
<span class="sd">      :context: close-figs</span>

<span class="sd">      &gt;&gt;&gt; fig, axes = plt.subplots(1, 2)</span>
<span class="sd">      &gt;&gt;&gt; po.synth.metamer.plot_loss(met, ax=axes[1])</span>
<span class="sd">      &lt;Axes: ... ylabel=&#39;Loss&#39;&gt;</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># this warning is not relevant for this plotting function</span>
    <span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">():</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="s2">&quot;loss iteration and iteration for&quot;</span><span class="p">)</span>
        <span class="n">progress</span> <span class="o">=</span> <span class="n">metamer</span><span class="o">.</span><span class="n">get_progress</span><span class="p">(</span><span class="n">iteration</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">ax</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span><span class="n">metamer</span><span class="o">.</span><span class="n">losses</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">progress</span><span class="p">[</span><span class="s2">&quot;iteration&quot;</span><span class="p">],</span> <span class="n">progress</span><span class="p">[</span><span class="s2">&quot;losses&quot;</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;r&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;Synthesis iteration&quot;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;Loss&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ax</span></div>



<div class="viewcode-block" id="display_metamer">
<a class="viewcode-back" href="../../../generated/plenoptic.synthesize.metamer.html#plenoptic.synthesize.metamer.display_metamer">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">display_metamer</span><span class="p">(</span>
    <span class="n">metamer</span><span class="p">:</span> <span class="n">Metamer</span><span class="p">,</span>
    <span class="n">batch_idx</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">channel_idx</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">zoom</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">iteration</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">ax</span><span class="p">:</span> <span class="n">mpl</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">Axes</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">mpl</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">Axes</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Display metamer.</span>

<span class="sd">    We use :func:`~plenoptic.tools.display.imshow` to display the metamer and attempt to</span>
<span class="sd">    automatically find the most reasonable zoom value. You can override this</span>
<span class="sd">    value using the zoom arg, but remember that :func:`~plenoptic.tools.display.imshow`</span>
<span class="sd">    is opinionated about the size of the resulting image and will throw an</span>
<span class="sd">    exception if the axis created is not big enough for the selected zoom.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    metamer</span>
<span class="sd">        Metamer object whose synthesized metamer we want to display.</span>
<span class="sd">    batch_idx</span>
<span class="sd">        Which index to take from the batch dimension.</span>
<span class="sd">    channel_idx</span>
<span class="sd">        Which index to take from the channel dimension. If ``None``, we assume</span>
<span class="sd">        image is RGB(A) and show all channels.</span>
<span class="sd">    zoom</span>
<span class="sd">        How much to zoom in / enlarge the metamer, the ratio of display pixels</span>
<span class="sd">        to image pixels. If ``None``, we attempt to find the best</span>
<span class="sd">        value ourselves.</span>
<span class="sd">    iteration</span>
<span class="sd">        Which iteration to display. If ``None``, we show the most recent one.</span>
<span class="sd">        Negative values are also allowed. If ``iteration!=None`` and</span>
<span class="sd">        ``metamer.store_progress&gt;1`` (that is, the metamer was not cached on every</span>
<span class="sd">        iteration), then we show the cached metamer from the nearest iteration.</span>
<span class="sd">    ax</span>
<span class="sd">        Pre-existing axes for plot. If ``None``, we call :func:`matplotlib.pyplot.gca`.</span>
<span class="sd">    **kwargs</span>
<span class="sd">        Passed to :func:`~plenoptic.tools.display.imshow`.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    ax</span>
<span class="sd">        The matplotlib axes containing the plot.</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        If ``batch_idx`` is not an int.</span>
<span class="sd">    IndexError</span>
<span class="sd">        If ``iteration`` takes an illegal value.</span>
<span class="sd">    IndexError</span>
<span class="sd">        If ``iteration`` is not ``None`` and</span>
<span class="sd">        :meth:`~plenoptic.synthesize.metamer.Metamer.synthesize` was called with</span>
<span class="sd">        ``store_progress=False``.</span>

<span class="sd">    Warns</span>
<span class="sd">    -----</span>
<span class="sd">    UserWarning</span>
<span class="sd">        If the iteration for the displayed metamer is not the same as the argument</span>
<span class="sd">        ``iteration`` (because e.g., you set ``iteration=3`` but</span>
<span class="sd">        ``metamer.store_progress=2``).</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    plot_synthesis_status</span>
<span class="sd">        Create a figure combining this with other axis-level plots to summarize</span>
<span class="sd">        synthesis status at a given iteration.</span>
<span class="sd">    animate</span>
<span class="sd">        Create a video animating this and other axis-level plots changing over</span>
<span class="sd">        the course of synthesis.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    If a matplotlib figure exists, this function will use it (using</span>
<span class="sd">    :func:`matplotlib.pyplot.gca`):</span>

<span class="sd">    .. plot::</span>
<span class="sd">      :context: reset</span>

<span class="sd">      &gt;&gt;&gt; import plenoptic as po</span>
<span class="sd">      &gt;&gt;&gt; import matplotlib.pyplot as plt</span>
<span class="sd">      &gt;&gt;&gt; import torch</span>
<span class="sd">      &gt;&gt;&gt; plt.figure()</span>
<span class="sd">      &lt;Figure size ...&gt;</span>
<span class="sd">      &gt;&gt;&gt; img = po.data.einstein()</span>
<span class="sd">      &gt;&gt;&gt; model = po.simul.Gaussian(30).eval()</span>
<span class="sd">      &gt;&gt;&gt; po.tools.remove_grad(model)</span>
<span class="sd">      &gt;&gt;&gt; met = po.synth.Metamer(img, model)</span>
<span class="sd">      &gt;&gt;&gt; met.to(torch.float64)</span>
<span class="sd">      &gt;&gt;&gt; met.load(po.data.fetch_data(&quot;example_metamer_gaussian.pt&quot;))</span>
<span class="sd">      &gt;&gt;&gt; po.synth.metamer.display_metamer(met)</span>
<span class="sd">      &lt;Axes: title=...Metamer [iteration=107]...&gt;</span>

<span class="sd">    If no matplotlib figure exists, this function will create a new one:</span>

<span class="sd">    .. plot::</span>
<span class="sd">      :context: close-figs</span>

<span class="sd">      &gt;&gt;&gt; # close all open figures to ensure none exist</span>
<span class="sd">      &gt;&gt;&gt; plt.close(&quot;all&quot;)</span>
<span class="sd">      &gt;&gt;&gt; po.synth.metamer.display_metamer(met)</span>
<span class="sd">      &lt;Axes: title=...Metamer [iteration=107]...&gt;</span>

<span class="sd">    Display metamer from a specified iteration (requires setting ``store_progress``</span>
<span class="sd">    when :meth:`~plenoptic.synthesize.metamer.Metamer.synthesize` was called):</span>

<span class="sd">    .. plot::</span>
<span class="sd">      :context: close-figs</span>

<span class="sd">      &gt;&gt;&gt; po.synth.metamer.display_metamer(met, iteration=10)</span>
<span class="sd">      &lt;Axes: title=...Metamer [iteration=10]...&gt;</span>

<span class="sd">    Explicitly define the axis to use:</span>

<span class="sd">    .. plot::</span>
<span class="sd">      :context: close-figs</span>

<span class="sd">      &gt;&gt;&gt; fig, axes = plt.subplots(1, 2, figsize=(8, 4))</span>
<span class="sd">      &gt;&gt;&gt; po.synth.metamer.display_metamer(met, ax=axes[1])</span>
<span class="sd">      &lt;Axes: title=...Metamer [iteration=107]...&gt;</span>

<span class="sd">    When plotting on an existing axis, if ``zoom=None``, this function will determine</span>
<span class="sd">    the best zoom level for the axis size.</span>

<span class="sd">    .. plot::</span>
<span class="sd">      :context: close-figs</span>

<span class="sd">      &gt;&gt;&gt; fig, axes = plt.subplots(1, 1, figsize=(8, 8))</span>
<span class="sd">      &gt;&gt;&gt; po.synth.metamer.display_metamer(met, ax=axes)</span>
<span class="sd">      &lt;Axes: title=...Metamer [iteration=107]...dims: [256, 256] * 2.0&#39;}&gt;</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">progress</span> <span class="o">=</span> <span class="n">metamer</span><span class="o">.</span><span class="n">get_progress</span><span class="p">(</span><span class="n">iteration</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">progress</span><span class="p">[</span><span class="s2">&quot;saved_metamer&quot;</span><span class="p">]</span>
        <span class="nb">iter</span> <span class="o">=</span> <span class="n">progress</span><span class="p">[</span><span class="s2">&quot;store_progress_iteration&quot;</span><span class="p">]</span>
    <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">iteration</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">IndexError</span><span class="p">(</span>
                <span class="s2">&quot;When metamer.store_progress=False, iteration must be None!&quot;</span>
            <span class="p">)</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">metamer</span><span class="o">.</span><span class="n">metamer</span>
        <span class="c1"># losses will always have one extra value, the current loss.</span>
        <span class="nb">iter</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">metamer</span><span class="o">.</span><span class="n">losses</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batch_idx</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;batch_idx must be an integer!&quot;</span><span class="p">)</span>
    <span class="c1"># we&#39;re only plotting one image here, so if the user wants multiple</span>
    <span class="c1"># channels, they must be RGB</span>
    <span class="n">as_rgb</span> <span class="o">=</span> <span class="nb">bool</span><span class="p">(</span><span class="n">channel_idx</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">image</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">ax</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
    <span class="n">display</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span>
        <span class="n">image</span><span class="p">,</span>
        <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span>
        <span class="n">title</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Metamer [iteration=</span><span class="si">{</span><span class="nb">iter</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">,</span>
        <span class="n">zoom</span><span class="o">=</span><span class="n">zoom</span><span class="p">,</span>
        <span class="n">batch_idx</span><span class="o">=</span><span class="n">batch_idx</span><span class="p">,</span>
        <span class="n">channel_idx</span><span class="o">=</span><span class="n">channel_idx</span><span class="p">,</span>
        <span class="n">as_rgb</span><span class="o">=</span><span class="n">as_rgb</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ax</span></div>



<span class="k">def</span><span class="w"> </span><span class="nf">_representation_error</span><span class="p">(</span>
    <span class="n">metamer</span><span class="p">:</span> <span class="n">Metamer</span><span class="p">,</span>
    <span class="n">iteration</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">iteration_selection</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;floor&quot;</span><span class="p">,</span> <span class="s2">&quot;ceiling&quot;</span><span class="p">,</span> <span class="s2">&quot;round&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;round&quot;</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Get the representation error.</span>

<span class="sd">    This is ``metamer.model(metamer) - target_representation)``. If</span>
<span class="sd">    ``iteration`` is not ``None``, we use</span>
<span class="sd">    ``metamer.model(saved_metamer[iteration])`` instead.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    metamer</span>
<span class="sd">        Metamer object whose representation error we want to compute.</span>
<span class="sd">    iteration</span>
<span class="sd">        Which iteration to display. If ``None``, we show the most recent one.</span>
<span class="sd">        Negative values are also allowed. If ``iteration!=None`` and</span>
<span class="sd">        ``metamer.store_progress&gt;1`` (that is, the metamer was not cached on every</span>
<span class="sd">        iteration), then we show the cached metamer from the nearest iteration.</span>
<span class="sd">    iteration_selection</span>

<span class="sd">        How to select the relevant iteration from :attr:`saved_metamer`</span>
<span class="sd">        when the request iteration wasn&#39;t stored.</span>

<span class="sd">        When synthesis was run with ``store_progress=n`` (where ``n&gt;1``),</span>
<span class="sd">        metamers are only saved every ``n`` iterations. If you request an</span>
<span class="sd">        iteration where a metamer wasn&#39;t saved, this determines which available</span>
<span class="sd">        iteration is used instead:</span>

<span class="sd">        * ``&quot;floor&quot;``: use the closest saved iteration **before** the</span>
<span class="sd">          requested one.</span>

<span class="sd">        * ``&quot;ceiling&quot;``: use the closest saved iteration **after** the</span>
<span class="sd">          requested one.</span>

<span class="sd">        * ``&quot;round&quot;``: use the closest saved iteration.</span>

<span class="sd">    **kwargs</span>
<span class="sd">        Passed to ``metamer.model.forward``.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    representation_error</span>
<span class="sd">        The representation error at the specified iteration, for displaying.</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    IndexError</span>
<span class="sd">        If ``iteration`` takes an illegal value.</span>

<span class="sd">    Warns</span>
<span class="sd">    -----</span>
<span class="sd">    UserWarning</span>
<span class="sd">        If the iteration for the used metamer is not the same as the argument</span>
<span class="sd">        ``iteration`` (because e.g., you set ``iteration=3`` but</span>
<span class="sd">        ``metamer.store_progress=2``).</span>
<span class="sd">    &quot;&quot;&quot;</span>  <span class="c1"># numpydoc ignore=EX01</span>
    <span class="k">if</span> <span class="n">iteration</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">progress</span> <span class="o">=</span> <span class="n">metamer</span><span class="o">.</span><span class="n">get_progress</span><span class="p">(</span><span class="n">iteration</span><span class="p">)</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">progress</span><span class="p">[</span><span class="s2">&quot;saved_metamer&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">metamer</span><span class="o">.</span><span class="n">target_representation</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">metamer_rep</span> <span class="o">=</span> <span class="n">metamer</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">metamer_rep</span> <span class="o">=</span> <span class="n">metamer</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">metamer</span><span class="o">.</span><span class="n">metamer</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">metamer_rep</span> <span class="o">-</span> <span class="n">metamer</span><span class="o">.</span><span class="n">target_representation</span>


<div class="viewcode-block" id="plot_representation_error">
<a class="viewcode-back" href="../../../generated/plenoptic.synthesize.metamer.html#plenoptic.synthesize.metamer.plot_representation_error">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">plot_representation_error</span><span class="p">(</span>
    <span class="n">metamer</span><span class="p">:</span> <span class="n">Metamer</span><span class="p">,</span>
    <span class="n">batch_idx</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">iteration</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">ylim</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">|</span> <span class="n">Literal</span><span class="p">[</span><span class="kc">False</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">ax</span><span class="p">:</span> <span class="n">mpl</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">Axes</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">as_rgb</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">mpl</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">Axes</span><span class="p">]:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Plot distance ratio showing how close we are to convergence.</span>

<span class="sd">    We plot ``_representation_error(metamer, iteration)``. For more details, see</span>
<span class="sd">    :func:`plenoptic.tools.display.plot_representation`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    metamer</span>
<span class="sd">        Metamer object whose synthesized metamer we want to display.</span>
<span class="sd">    batch_idx</span>
<span class="sd">        Which index to take from the batch dimension.</span>
<span class="sd">    iteration</span>
<span class="sd">        Which iteration to display. If ``None``, we show the most recent one.</span>
<span class="sd">        Negative values are also allowed. If ``iteration!=None`` and</span>
<span class="sd">        ``metamer.store_progress&gt;1`` (that is, the metamer was not cached on every</span>
<span class="sd">        iteration), then we show the cached metamer from the nearest iteration.</span>
<span class="sd">    ylim</span>
<span class="sd">        If ``ylim`` is ``None``, we sets the axes&#39; y-limits to be ``(-y_max,</span>
<span class="sd">        y_max)``, where ``y_max=np.abs(data).max()``. If it&#39;s ``False``, we do</span>
<span class="sd">        nothing. If a tuple, we use that range.</span>
<span class="sd">    ax</span>
<span class="sd">        Pre-existing axes for plot. If ``None``, we call :func:`matplotlib.pyplot.gca`.</span>
<span class="sd">    as_rgb</span>
<span class="sd">        The representation can be image-like with multiple channels, and we</span>
<span class="sd">        have no way to determine whether it should be represented as an RGB</span>
<span class="sd">        image or not, so the user must set this flag to tell us. It will be</span>
<span class="sd">        ignored if the response doesn&#39;t look image-like or if the model has its</span>
<span class="sd">        own ``plot_representation_error()`` method. Else, it will be passed to</span>
<span class="sd">        :func:`~plenoptic.tools.display.imshow`, see that methods docstring for details.</span>
<span class="sd">    **kwargs</span>
<span class="sd">        Passed to ``metamer.model.forward``.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    axes :</span>
<span class="sd">        List of created axes.</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    IndexError</span>
<span class="sd">        If ``iteration`` takes an illegal value.</span>

<span class="sd">    Warns</span>
<span class="sd">    -----</span>
<span class="sd">    UserWarning</span>
<span class="sd">        If the iteration for the metamer used to compute the error is not the same as</span>
<span class="sd">        the argument ``iteration`` (because e.g., you set ``iteration=3`` but</span>
<span class="sd">        ``metamer.store_progress=2``).</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    plot_synthesis_status</span>
<span class="sd">        Create a figure combining this with other axis-level plots to summarize</span>
<span class="sd">        synthesis status at a given iteration.</span>
<span class="sd">    animate</span>
<span class="sd">        Create a video animating this and other axis-level plots changing over</span>
<span class="sd">        the course of synthesis.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    .. plot::</span>
<span class="sd">      :context: reset</span>

<span class="sd">      &gt;&gt;&gt; import plenoptic as po</span>
<span class="sd">      &gt;&gt;&gt; import torch</span>
<span class="sd">      &gt;&gt;&gt; img = po.data.einstein()</span>
<span class="sd">      &gt;&gt;&gt; model = po.simul.Gaussian(30).eval()</span>
<span class="sd">      &gt;&gt;&gt; po.tools.remove_grad(model)</span>
<span class="sd">      &gt;&gt;&gt; met = po.synth.Metamer(img, model)</span>
<span class="sd">      &gt;&gt;&gt; met.to(torch.float64)</span>
<span class="sd">      &gt;&gt;&gt; met.load(po.data.fetch_data(&quot;example_metamer_gaussian.pt&quot;))</span>
<span class="sd">      &gt;&gt;&gt; po.synth.metamer.plot_representation_error(met)</span>
<span class="sd">      [&lt;Axes: title=...Representation error...&gt;]</span>

<span class="sd">    Plot on an existing axis:</span>

<span class="sd">    .. plot::</span>
<span class="sd">      :context: close-figs</span>

<span class="sd">      &gt;&gt;&gt; import matplotlib.pyplot</span>
<span class="sd">      &gt;&gt;&gt; fig, axes = plt.subplots(1, 2, figsize=(8, 4))</span>
<span class="sd">      &gt;&gt;&gt; po.synth.metamer.plot_representation_error(met, ax=axes[1])</span>
<span class="sd">      [&lt;Axes: title=...Representation error...&gt;]</span>

<span class="sd">    The function uses :func:`~plenoptic.tools.display.plot_representation`,</span>
<span class="sd">    which switches between :func:`~plenoptic.tools.display.imshow` and</span>
<span class="sd">    :func:`~plenoptic.tools.display.clean_stem_plot` based on the shape of the</span>
<span class="sd">    model&#39;s output:</span>

<span class="sd">    .. plot::</span>
<span class="sd">      :context: close-figs</span>

<span class="sd">      &gt;&gt;&gt; # Flatten the last two dimensions of the output, so it looks like a vector.</span>
<span class="sd">      &gt;&gt;&gt; class TestModel(po.simul.Gaussian):</span>
<span class="sd">      ...     def __init__(self, *args, **kwargs):</span>
<span class="sd">      ...         super().__init__(*args, **kwargs)</span>
<span class="sd">      ...</span>
<span class="sd">      ...     def forward(self, x):</span>
<span class="sd">      ...         return super().forward(x).flatten(-2)</span>
<span class="sd">      &gt;&gt;&gt; model = TestModel(30).eval()</span>
<span class="sd">      &gt;&gt;&gt; po.tools.remove_grad(model)</span>
<span class="sd">      &gt;&gt;&gt; met = po.synth.Metamer(img, model)</span>
<span class="sd">      &gt;&gt;&gt; met.to(torch.float64)</span>
<span class="sd">      &gt;&gt;&gt; met.synthesize(5)</span>
<span class="sd">      &gt;&gt;&gt; po.synth.metamer.plot_representation_error(met)</span>
<span class="sd">      [&lt;Axes: title=...Representation error...&gt;]</span>

<span class="sd">    If model has its own ``plot_representation`` method, this function will use it,</span>
<span class="sd">    potentially creating multiple axes (see</span>
<span class="sd">    :func:`~plenoptic.simulate.models.portilla_simoncelli.PortillaSimoncelli.plot_representation`</span>
<span class="sd">    ):</span>

<span class="sd">    .. plot::</span>
<span class="sd">      :context: close-figs</span>

<span class="sd">      &gt;&gt;&gt; img = po.data.reptile_skin()</span>
<span class="sd">      &gt;&gt;&gt; model = po.simul.PortillaSimoncelli(img.shape[-2:])</span>
<span class="sd">      &gt;&gt;&gt; met = po.synth.MetamerCTF(img, model, po.tools.optim.l2_norm)</span>
<span class="sd">      &gt;&gt;&gt; met.to(torch.float64)</span>
<span class="sd">      &gt;&gt;&gt; met.load(po.data.fetch_data(&quot;example_metamerCTF_ps.pt&quot;))</span>
<span class="sd">      &gt;&gt;&gt; po.synth.metamer.plot_representation_error(met)</span>
<span class="sd">      [&lt;Axes: ...&gt;, ..., &lt;Axes: ...&gt;]</span>

<span class="sd">    If plotting on an existing axis, this function will sub-divide that axis as</span>
<span class="sd">    needed:</span>

<span class="sd">    .. plot::</span>
<span class="sd">      :context: close-figs</span>

<span class="sd">      &gt;&gt;&gt; fig, axes = plt.subplots(1, 2, figsize=(8, 4))</span>
<span class="sd">      &gt;&gt;&gt; po.synth.metamer.display_metamer(met, ax=axes[0])</span>
<span class="sd">      &lt;Axes: title=...Metamer [iteration=150]...&gt;</span>
<span class="sd">      &gt;&gt;&gt; po.synth.metamer.plot_representation_error(met, ax=axes[1])</span>
<span class="sd">      [&lt;Axes: ...&gt;, ..., &lt;Axes: ...&gt;]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">representation_error</span> <span class="o">=</span> <span class="n">_representation_error</span><span class="p">(</span>
        <span class="n">metamer</span><span class="o">=</span><span class="n">metamer</span><span class="p">,</span> <span class="n">iteration</span><span class="o">=</span><span class="n">iteration</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">ax</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">display</span><span class="o">.</span><span class="n">plot_representation</span><span class="p">(</span>
        <span class="n">metamer</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
        <span class="n">representation_error</span><span class="p">,</span>
        <span class="n">ax</span><span class="p">,</span>
        <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Representation error&quot;</span><span class="p">,</span>
        <span class="n">ylim</span><span class="o">=</span><span class="n">ylim</span><span class="p">,</span>
        <span class="n">batch_idx</span><span class="o">=</span><span class="n">batch_idx</span><span class="p">,</span>
        <span class="n">as_rgb</span><span class="o">=</span><span class="n">as_rgb</span><span class="p">,</span>
    <span class="p">)</span></div>



<div class="viewcode-block" id="plot_pixel_values">
<a class="viewcode-back" href="../../../generated/plenoptic.synthesize.metamer.html#plenoptic.synthesize.metamer.plot_pixel_values">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">plot_pixel_values</span><span class="p">(</span>
    <span class="n">metamer</span><span class="p">:</span> <span class="n">Metamer</span><span class="p">,</span>
    <span class="n">batch_idx</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">channel_idx</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">iteration</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">ylim</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">|</span> <span class="n">Literal</span><span class="p">[</span><span class="kc">False</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">ax</span><span class="p">:</span> <span class="n">mpl</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">Axes</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">mpl</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">Axes</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Plot histogram of pixel values of target image and its metamer.</span>

<span class="sd">    As a way to check the distributions of pixel intensities and see</span>
<span class="sd">    if there&#39;s any values outside the allowed range</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    metamer</span>
<span class="sd">        Metamer object with the images whose pixel values we want to compare.</span>
<span class="sd">    batch_idx</span>
<span class="sd">        Which index to take from the batch dimension.</span>
<span class="sd">    channel_idx</span>
<span class="sd">        Which index to take from the channel dimension. If ``None``, we use all</span>
<span class="sd">        channels (assumed use-case is RGB(A) images).</span>
<span class="sd">    iteration</span>
<span class="sd">        Which iteration to display. If ``None``, we show the most recent one.</span>
<span class="sd">        Negative values are also allowed. If ``iteration!=None`` and</span>
<span class="sd">        ``metamer.store_progress&gt;1`` (that is, the metamer was not cached on every</span>
<span class="sd">        iteration), then we show the cached metamer from the nearest iteration.</span>
<span class="sd">    ylim</span>
<span class="sd">        If tuple, the ylimit to set for this axis. If ``False``, we leave</span>
<span class="sd">        it untouched.</span>
<span class="sd">    ax</span>
<span class="sd">        Pre-existing axes for plot. If ``None``, we call</span>
<span class="sd">        :func:`matplotlib.pyplot.gca()`.</span>
<span class="sd">    **kwargs</span>
<span class="sd">        Passed to :func:`matplotlib.pyplot.hist`.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    ax</span>
<span class="sd">        Created axes.</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    IndexError</span>
<span class="sd">        If ``iteration`` takes an illegal value.</span>

<span class="sd">    Warns</span>
<span class="sd">    -----</span>
<span class="sd">    UserWarning</span>
<span class="sd">        If the iteration used for ``saved_metamer`` is not the same as the argument</span>
<span class="sd">        ``iteration`` (because e.g., you set ``iteration=3`` but</span>
<span class="sd">        ``metamer.store_progress=2``).</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    plot_synthesis_status</span>
<span class="sd">        Create a figure combining this with other axis-level plots to summarize</span>
<span class="sd">        synthesis status at a given iteration.</span>
<span class="sd">    animate</span>
<span class="sd">        Create a video animating this and other axis-level plots changing over</span>
<span class="sd">        the course of synthesis.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    .. plot::</span>
<span class="sd">      :context: reset</span>

<span class="sd">      &gt;&gt;&gt; import plenoptic as po</span>
<span class="sd">      &gt;&gt;&gt; import torch</span>
<span class="sd">      &gt;&gt;&gt; img = po.data.einstein()</span>
<span class="sd">      &gt;&gt;&gt; model = po.simul.Gaussian(30).eval()</span>
<span class="sd">      &gt;&gt;&gt; po.tools.remove_grad(model)</span>
<span class="sd">      &gt;&gt;&gt; met = po.synth.Metamer(img, model)</span>
<span class="sd">      &gt;&gt;&gt; met.to(torch.float64)</span>
<span class="sd">      &gt;&gt;&gt; met.load(po.data.fetch_data(&quot;example_metamer_gaussian.pt&quot;))</span>
<span class="sd">      &gt;&gt;&gt; po.synth.metamer.plot_pixel_values(met)</span>
<span class="sd">      &lt;Axes: ... &#39;Histogram of pixel values&#39;...&gt;</span>

<span class="sd">    Plot pixel values from a specified iteration (requires setting ``store_progress``</span>
<span class="sd">    when :meth:`~plenoptic.synthesize.metamer.Metamer.synthesize` was called):</span>

<span class="sd">    .. plot::</span>
<span class="sd">      :context: close-figs</span>

<span class="sd">      &gt;&gt;&gt; po.synth.metamer.plot_pixel_values(met, iteration=10)</span>
<span class="sd">      &lt;Axes: ... &#39;Histogram of pixel values&#39;...&gt;</span>

<span class="sd">    Plot on an existing axis:</span>

<span class="sd">    .. plot::</span>
<span class="sd">      :context: close-figs</span>

<span class="sd">      &gt;&gt;&gt; fig, axes = plt.subplots(1, 2, figsize=(8, 4))</span>
<span class="sd">      &gt;&gt;&gt; po.synth.metamer.plot_pixel_values(met, ax=axes[1])</span>
<span class="sd">      &lt;Axes: ... &#39;Histogram of pixel values&#39;...&gt;</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_freedman_diaconis_bins</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculate number of hist bins using Freedman-Diaconis rule.</span>

<span class="sd">        Copied from seaborn.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        a</span>
<span class="sd">            The array to histogram.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        n_bins</span>
<span class="sd">            Number of bins to use for histogram.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># numpydoc ignore=EX01</span>
        <span class="c1"># From https://stats.stackexchange.com/questions/798/</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
        <span class="n">iqr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">]))[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">return</span> <span class="mi">1</span>
        <span class="n">h</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">iqr</span> <span class="o">/</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="o">**</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="mi">3</span><span class="p">))</span>
        <span class="c1"># fall back to sqrt(a) bins if iqr is 0</span>
        <span class="k">if</span> <span class="n">h</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">size</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">((</span><span class="n">a</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">-</span> <span class="n">a</span><span class="o">.</span><span class="n">min</span><span class="p">())</span> <span class="o">/</span> <span class="n">h</span><span class="p">))</span>

    <span class="n">kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;alpha&quot;</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">)</span>
    <span class="n">progress</span> <span class="o">=</span> <span class="n">metamer</span><span class="o">.</span><span class="n">get_progress</span><span class="p">(</span><span class="n">iteration</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">met</span> <span class="o">=</span> <span class="n">progress</span><span class="p">[</span><span class="s2">&quot;saved_metamer&quot;</span><span class="p">]</span>
        <span class="nb">iter</span> <span class="o">=</span> <span class="n">progress</span><span class="p">[</span><span class="s2">&quot;store_progress_iteration&quot;</span><span class="p">]</span>
    <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">iteration</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">IndexError</span><span class="p">(</span>
                <span class="s2">&quot;When metamer.store_progress=False, iteration must be None!&quot;</span>
            <span class="p">)</span>
        <span class="n">met</span> <span class="o">=</span> <span class="n">metamer</span><span class="o">.</span><span class="n">metamer</span>
        <span class="c1"># losses will always have one extra value, the current loss.</span>
        <span class="nb">iter</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">metamer</span><span class="o">.</span><span class="n">losses</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">metamer</span><span class="o">.</span><span class="n">image</span><span class="p">[</span><span class="n">batch_idx</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">channel_idx</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="p">[</span><span class="n">channel_idx</span><span class="p">]</span>
        <span class="n">met</span> <span class="o">=</span> <span class="n">met</span><span class="p">[</span><span class="n">channel_idx</span><span class="p">]</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">image</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="n">met</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">met</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">ax</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span>
        <span class="n">met</span><span class="p">,</span>
        <span class="n">bins</span><span class="o">=</span><span class="nb">min</span><span class="p">(</span><span class="n">_freedman_diaconis_bins</span><span class="p">(</span><span class="n">image</span><span class="p">),</span> <span class="mi">50</span><span class="p">),</span>
        <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Metamer [iteration=</span><span class="si">{</span><span class="nb">iter</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span>
        <span class="n">image</span><span class="p">,</span>
        <span class="n">bins</span><span class="o">=</span><span class="nb">min</span><span class="p">(</span><span class="n">_freedman_diaconis_bins</span><span class="p">(</span><span class="n">image</span><span class="p">),</span> <span class="mi">50</span><span class="p">),</span>
        <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Target image&quot;</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">ylim</span><span class="p">:</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="n">ylim</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Histogram of pixel values&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ax</span></div>



<span class="k">def</span><span class="w"> </span><span class="nf">_check_included_plots</span><span class="p">(</span><span class="n">to_check</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span> <span class="n">to_check_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Check whether the user wanted us to create plots that we can&#39;t.</span>

<span class="sd">    Helper function for :func:`plot_synthesis_status` and :func:`animate`.</span>

<span class="sd">    Raises a ``ValueError`` if ``to_check`` contains any values that are not allowed.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    to_check</span>
<span class="sd">        The variable to check. We ensure that it doesn&#39;t contain any extra (not</span>
<span class="sd">        allowed) values. If a list, we check its contents. If a dict, we check</span>
<span class="sd">        its keys.</span>
<span class="sd">    to_check_name</span>
<span class="sd">        Name of the ``to_check`` variable, used in the error message.</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        If ``to_check`` takes an illegal value.</span>
<span class="sd">    &quot;&quot;&quot;</span>  <span class="c1"># numpydoc ignore=EX01</span>
    <span class="n">allowed_vals</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s2">&quot;display_metamer&quot;</span><span class="p">,</span>
        <span class="s2">&quot;plot_loss&quot;</span><span class="p">,</span>
        <span class="s2">&quot;plot_representation_error&quot;</span><span class="p">,</span>
        <span class="s2">&quot;plot_pixel_values&quot;</span><span class="p">,</span>
        <span class="s2">&quot;misc&quot;</span><span class="p">,</span>
    <span class="p">]</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">vals</span> <span class="o">=</span> <span class="n">to_check</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
    <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
        <span class="n">vals</span> <span class="o">=</span> <span class="n">to_check</span>
    <span class="n">not_allowed</span> <span class="o">=</span> <span class="p">[</span><span class="n">v</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">vals</span> <span class="k">if</span> <span class="n">v</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">allowed_vals</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">not_allowed</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">to_check_name</span><span class="si">}</span><span class="s2"> contained value(s) </span><span class="si">{</span><span class="n">not_allowed</span><span class="si">}</span><span class="s2">! &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;Only </span><span class="si">{</span><span class="n">allowed_vals</span><span class="si">}</span><span class="s2"> are permissible!&quot;</span>
        <span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_setup_synthesis_fig</span><span class="p">(</span>
    <span class="n">fig</span><span class="p">:</span> <span class="n">mpl</span><span class="o">.</span><span class="n">figure</span><span class="o">.</span><span class="n">Figure</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">axes_idx</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">{},</span>
    <span class="n">figsize</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">included_plots</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s2">&quot;display_metamer&quot;</span><span class="p">,</span>
        <span class="s2">&quot;plot_loss&quot;</span><span class="p">,</span>
        <span class="s2">&quot;plot_representation_error&quot;</span><span class="p">,</span>
    <span class="p">],</span>
    <span class="n">display_metamer_width</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">plot_loss_width</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">plot_representation_error_width</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">plot_pixel_values_width</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">mpl</span><span class="o">.</span><span class="n">figure</span><span class="o">.</span><span class="n">Figure</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="n">mpl</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">Axes</span><span class="p">],</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Set up figure for :func:`plot_synthesis_status`.</span>

<span class="sd">    Creates figure with enough axes for the all the plots you want. Will</span>
<span class="sd">    also create index in ``axes_idx`` for them if you haven&#39;t done so already.</span>

<span class="sd">    If ``fig=None``, all axes will be on the same row and have the same width.</span>
<span class="sd">    If you want them to be on different rows, will need to initialize ``fig``</span>
<span class="sd">    yourself and pass that in. For changing width, change the corresponding</span>
<span class="sd">    ``*_width`` arg, which gives width relative to other axes. So if you want</span>
<span class="sd">    the axis for the ``representation_error`` plot to be twice as wide as the</span>
<span class="sd">    others, set ``representation_error_width=2``.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    fig</span>
<span class="sd">        The figure to plot on or ``None``. If ``None``, we create a new figure.</span>
<span class="sd">    axes_idx</span>
<span class="sd">        Dictionary specifying which axes contains which type of plot, allows for more</span>
<span class="sd">        fine-grained control of the resulting figure. Probably only helpful if fig is</span>
<span class="sd">        also defined. Possible keys: ``&quot;loss&quot;``, ``&quot;representation_error&quot;``,</span>
<span class="sd">        ``&quot;pixel_values&quot;``, ``&quot;misc&quot;``. Values should all be ints. If you tell this</span>
<span class="sd">        function to create a plot that doesn&#39;t have a corresponding key, we find the</span>
<span class="sd">        lowest int that is not already in the dict, so if you have</span>
<span class="sd">        axes that you want unchanged, place their idx in ``&quot;misc&quot;``.</span>
<span class="sd">    figsize</span>
<span class="sd">        The size of the figure to create. It may take a little bit of</span>
<span class="sd">        playing around to find a reasonable value. If ``None``, we attempt to</span>
<span class="sd">        make our best guess, aiming to have relative width=1 correspond to 5.</span>
<span class="sd">    included_plots</span>
<span class="sd">        Which plots to include. Must be some subset of ``&#39;display_metamer&#39;,</span>
<span class="sd">        &#39;plot_loss&#39;, &#39;plot_representation_error&#39;, &#39;plot_pixel_values&#39;``.</span>
<span class="sd">    display_metamer_width</span>
<span class="sd">        Relative width of the axis for the synthesized metamer.</span>
<span class="sd">    plot_loss_width</span>
<span class="sd">        Relative width of the axis for loss plot.</span>
<span class="sd">    plot_representation_error_width</span>
<span class="sd">        Relative width of the axis for representation error plot.</span>
<span class="sd">    plot_pixel_values_width</span>
<span class="sd">        Relative width of the axis for image pixel intensities histograms.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    fig</span>
<span class="sd">        The figure to plot on.</span>
<span class="sd">    axes</span>
<span class="sd">        List or array of axes contained in fig.</span>
<span class="sd">    axes_idx</span>
<span class="sd">        Dictionary identifying the idx for each plot type.</span>
<span class="sd">    &quot;&quot;&quot;</span>  <span class="c1"># numpydoc ignore=EX01</span>
    <span class="n">n_subplots</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">axes_idx</span> <span class="o">=</span> <span class="n">axes_idx</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">width_ratios</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">if</span> <span class="s2">&quot;display_metamer&quot;</span> <span class="ow">in</span> <span class="n">included_plots</span><span class="p">:</span>
        <span class="n">n_subplots</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">width_ratios</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">display_metamer_width</span><span class="p">)</span>
        <span class="k">if</span> <span class="s2">&quot;display_metamer&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">axes_idx</span><span class="p">:</span>
            <span class="n">axes_idx</span><span class="p">[</span><span class="s2">&quot;display_metamer&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">_find_min_int</span><span class="p">(</span><span class="n">axes_idx</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
    <span class="k">if</span> <span class="s2">&quot;plot_loss&quot;</span> <span class="ow">in</span> <span class="n">included_plots</span><span class="p">:</span>
        <span class="n">n_subplots</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">width_ratios</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">plot_loss_width</span><span class="p">)</span>
        <span class="k">if</span> <span class="s2">&quot;plot_loss&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">axes_idx</span><span class="p">:</span>
            <span class="n">axes_idx</span><span class="p">[</span><span class="s2">&quot;plot_loss&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">_find_min_int</span><span class="p">(</span><span class="n">axes_idx</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
    <span class="k">if</span> <span class="s2">&quot;plot_representation_error&quot;</span> <span class="ow">in</span> <span class="n">included_plots</span><span class="p">:</span>
        <span class="n">n_subplots</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">width_ratios</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">plot_representation_error_width</span><span class="p">)</span>
        <span class="k">if</span> <span class="s2">&quot;plot_representation_error&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">axes_idx</span><span class="p">:</span>
            <span class="n">axes_idx</span><span class="p">[</span><span class="s2">&quot;plot_representation_error&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">_find_min_int</span><span class="p">(</span>
                <span class="n">axes_idx</span><span class="o">.</span><span class="n">values</span><span class="p">()</span>
            <span class="p">)</span>
    <span class="k">if</span> <span class="s2">&quot;plot_pixel_values&quot;</span> <span class="ow">in</span> <span class="n">included_plots</span><span class="p">:</span>
        <span class="n">n_subplots</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">width_ratios</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">plot_pixel_values_width</span><span class="p">)</span>
        <span class="k">if</span> <span class="s2">&quot;plot_pixel_values&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">axes_idx</span><span class="p">:</span>
            <span class="n">axes_idx</span><span class="p">[</span><span class="s2">&quot;plot_pixel_values&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">_find_min_int</span><span class="p">(</span><span class="n">axes_idx</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
    <span class="k">if</span> <span class="n">fig</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">width_ratios</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">width_ratios</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">figsize</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># we want (5, 5) for each subplot, with a bit of room between</span>
            <span class="c1"># each subplot</span>
            <span class="n">figsize</span> <span class="o">=</span> <span class="p">((</span><span class="n">width_ratios</span> <span class="o">*</span> <span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">+</span> <span class="n">width_ratios</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="n">width_ratios</span> <span class="o">=</span> <span class="n">width_ratios</span> <span class="o">/</span> <span class="n">width_ratios</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span>
            <span class="mi">1</span><span class="p">,</span>
            <span class="n">n_subplots</span><span class="p">,</span>
            <span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">,</span>
            <span class="n">gridspec_kw</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;width_ratios&quot;</span><span class="p">:</span> <span class="n">width_ratios</span><span class="p">},</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">n_subplots</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">axes</span> <span class="o">=</span> <span class="p">[</span><span class="n">axes</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">axes</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">axes</span>
    <span class="c1"># make sure misc contains all the empty axes</span>
    <span class="n">misc_axes</span> <span class="o">=</span> <span class="n">axes_idx</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;misc&quot;</span><span class="p">,</span> <span class="p">[])</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">misc_axes</span><span class="p">,</span> <span class="s2">&quot;__iter__&quot;</span><span class="p">):</span>
        <span class="n">misc_axes</span> <span class="o">=</span> <span class="p">[</span><span class="n">misc_axes</span><span class="p">]</span>
    <span class="n">all_axes</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">axes_idx</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
        <span class="c1"># so if it&#39;s a list of ints</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="s2">&quot;__iter__&quot;</span><span class="p">):</span>
            <span class="n">all_axes</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">all_axes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
    <span class="n">misc_axes</span> <span class="o">+=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">fig</span><span class="o">.</span><span class="n">axes</span><span class="p">)</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">all_axes</span><span class="p">]</span>
    <span class="n">axes_idx</span><span class="p">[</span><span class="s2">&quot;misc&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">misc_axes</span>
    <span class="k">return</span> <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span><span class="p">,</span> <span class="n">axes_idx</span>


<div class="viewcode-block" id="plot_synthesis_status">
<a class="viewcode-back" href="../../../generated/plenoptic.synthesize.metamer.html#plenoptic.synthesize.metamer.plot_synthesis_status">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">plot_synthesis_status</span><span class="p">(</span>
    <span class="n">metamer</span><span class="p">:</span> <span class="n">Metamer</span><span class="p">,</span>
    <span class="n">batch_idx</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">channel_idx</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">iteration</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">ylim</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">|</span> <span class="n">Literal</span><span class="p">[</span><span class="kc">False</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">vrange</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;indep1&quot;</span><span class="p">,</span>
    <span class="n">zoom</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">plot_representation_error_as_rgb</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">fig</span><span class="p">:</span> <span class="n">mpl</span><span class="o">.</span><span class="n">figure</span><span class="o">.</span><span class="n">Figure</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">axes_idx</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">{},</span>
    <span class="n">figsize</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">included_plots</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s2">&quot;display_metamer&quot;</span><span class="p">,</span>
        <span class="s2">&quot;plot_loss&quot;</span><span class="p">,</span>
        <span class="s2">&quot;plot_representation_error&quot;</span><span class="p">,</span>
    <span class="p">],</span>
    <span class="n">width_ratios</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="p">{},</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">mpl</span><span class="o">.</span><span class="n">figure</span><span class="o">.</span><span class="n">Figure</span><span class="p">,</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Make a plot showing synthesis status.</span>

<span class="sd">    We create several subplots to analyze this. The plots to include are</span>
<span class="sd">    specified by including their name in the ``included_plots`` list. All plots</span>
<span class="sd">    can be created separately using the method with the same name.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    metamer</span>
<span class="sd">        Metamer object whose status we want to plot.</span>
<span class="sd">    batch_idx</span>
<span class="sd">        Which index to take from the batch dimension.</span>
<span class="sd">    channel_idx</span>
<span class="sd">        Which index to take from the channel dimension. If ``None``, we use all</span>
<span class="sd">        channels (assumed use-case is RGB(A) image).</span>
<span class="sd">    iteration</span>
<span class="sd">        Which iteration to display. If ``None``, we show the most recent one.</span>
<span class="sd">        Negative values are also allowed. If ``iteration!=None`` and</span>
<span class="sd">        ``metamer.store_progress&gt;1`` (that is, the metamer was not cached on every</span>
<span class="sd">        iteration), then we show the cached metamer from the nearest iteration.</span>
<span class="sd">    ylim</span>
<span class="sd">        The ylimit to use for the representation_error plot. We pass</span>
<span class="sd">        this value directly to ``plot_representation_error``.</span>
<span class="sd">    vrange</span>
<span class="sd">        The vrange option to pass to :func:`display_metamer()`. See</span>
<span class="sd">        docstring of :func:`~plenoptic.tools.display.imshow` for possible values.</span>
<span class="sd">    zoom</span>
<span class="sd">        How much to zoom in / enlarge the metamer, the ratio</span>
<span class="sd">        of display pixels to image pixels. If ``None``, we</span>
<span class="sd">        attempt to find the best value ourselves.</span>
<span class="sd">    plot_representation_error_as_rgb</span>
<span class="sd">        The representation can be image-like with multiple channels, and we</span>
<span class="sd">        have no way to determine whether it should be represented as an RGB</span>
<span class="sd">        image or not, so the user must set this flag to tell us. It will be</span>
<span class="sd">        ignored if the response doesn&#39;t look image-like or if the</span>
<span class="sd">        model has its own plot_representation_error() method. Else, it will</span>
<span class="sd">        be passed to :func:`~plenoptic.tools.display.imshow`, see that method&#39;s</span>
<span class="sd">        docstring for details.</span>
<span class="sd">    fig</span>
<span class="sd">        If ``None``, we create a new figure. otherwise we assume this is</span>
<span class="sd">        an empty figure that has the appropriate size and number of</span>
<span class="sd">        subplots.</span>
<span class="sd">    axes_idx</span>
<span class="sd">        Dictionary specifying which axes contains which type of plot, allows</span>
<span class="sd">        for more fine-grained control of the resulting figure. Probably only</span>
<span class="sd">        helpful if fig is also defined. Possible keys: ``&#39;display_metamer&#39;,</span>
<span class="sd">        &#39;plot_loss&#39;, &#39;plot_representation_error&#39;, &#39;plot_pixel_values&#39;,</span>
<span class="sd">        &#39;misc&#39;``. Values should all be ints. If you tell this function to</span>
<span class="sd">        create a plot that doesn&#39;t have a corresponding key, we find the lowest</span>
<span class="sd">        int that is not already in the dict, so if you have axes that you want</span>
<span class="sd">        unchanged, place their idx in ``&#39;misc&#39;``.</span>
<span class="sd">    figsize</span>
<span class="sd">        The size of the figure to create. It may take a little bit of</span>
<span class="sd">        playing around to find a reasonable value. If ``None``, we attempt to</span>
<span class="sd">        make our best guess, aiming to have each axis be of size ``(5, 5)``.</span>
<span class="sd">    included_plots</span>
<span class="sd">        Which plots to include. Must be some subset of ``&#39;display_metamer&#39;,</span>
<span class="sd">        &#39;plot_loss&#39;, &#39;plot_representation_error&#39;, &#39;plot_pixel_values&#39;``.</span>
<span class="sd">    width_ratios</span>
<span class="sd">        If ``width_ratios`` is an empty dictionary, all plots will have the</span>
<span class="sd">        same width. To change that, specify their relative widths; keys should</span>
<span class="sd">        be strings (possible values same as ``included_plots``) and values should</span>
<span class="sd">        be floats specifying their relative width.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    fig</span>
<span class="sd">        The figure containing this plot.</span>
<span class="sd">    axes_idx</span>
<span class="sd">        Dictionary giving index of each plot.</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        If ``metamer.metamer`` object is not 3d or 4d.</span>
<span class="sd">    ValueError</span>
<span class="sd">        If the ``iteration is not None`` and the given ``metamer`` object was run</span>
<span class="sd">        with ``store_progress=False``.</span>

<span class="sd">    Warns</span>
<span class="sd">    -----</span>
<span class="sd">    UserWarning</span>
<span class="sd">        If the iteration used for ``saved_metamer`` is not the same as the argument</span>
<span class="sd">        ``iteration`` (because e.g., you set ``iteration=3`` but</span>
<span class="sd">        ``metamer.store_progress=2``).</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    display_metamer</span>
<span class="sd">        One of this function&#39;s axis-level component functions: display metamer at</span>
<span class="sd">        a given synthesis iteration.</span>
<span class="sd">    plot_loss</span>
<span class="sd">        One of this function&#39;s axis-level component functions: plot synthesis loss</span>
<span class="sd">        over iterations.</span>
<span class="sd">    plot_representation_error</span>
<span class="sd">        One of this function&#39;s axis-level component functions: plot error in model</span>
<span class="sd">        representation at a given synthesis iteration.</span>
<span class="sd">    plot_pixel_values</span>
<span class="sd">        One of this function&#39;s axis-level component functions: plot histogram of</span>
<span class="sd">        pixel values in target image and metamer at a given synthesis iteration.</span>
<span class="sd">    animate</span>
<span class="sd">        Create a video that animates this figure over synthesis iteration.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    .. plot::</span>
<span class="sd">      :context: reset</span>

<span class="sd">      &gt;&gt;&gt; import plenoptic as po</span>
<span class="sd">      &gt;&gt;&gt; import torch</span>
<span class="sd">      &gt;&gt;&gt; img = po.data.einstein()</span>
<span class="sd">      &gt;&gt;&gt; model = po.simul.Gaussian(30).eval()</span>
<span class="sd">      &gt;&gt;&gt; po.tools.remove_grad(model)</span>
<span class="sd">      &gt;&gt;&gt; met = po.synth.Metamer(img, model)</span>
<span class="sd">      &gt;&gt;&gt; met.to(torch.float64)</span>
<span class="sd">      &gt;&gt;&gt; met.load(po.data.fetch_data(&quot;example_metamer_gaussian.pt&quot;))</span>
<span class="sd">      &gt;&gt;&gt; po.synth.metamer.plot_synthesis_status(met)</span>
<span class="sd">      (&lt;Figure size ...&gt;, {&#39;display_metamer&#39;: 0, ...})</span>

<span class="sd">    If model has its own ``plot_representation`` method, this function will use it</span>
<span class="sd">    for plotting the representation error (see</span>
<span class="sd">    :func:`~plenoptic.simulate.models.portilla_simoncelli.PortillaSimoncelli.plot_representation`</span>
<span class="sd">    ):</span>

<span class="sd">    .. plot::</span>
<span class="sd">      :context: close-figs</span>

<span class="sd">      &gt;&gt;&gt; img = po.data.reptile_skin()</span>
<span class="sd">      &gt;&gt;&gt; model = po.simul.PortillaSimoncelli(img.shape[-2:])</span>
<span class="sd">      &gt;&gt;&gt; met = po.synth.MetamerCTF(img, model, po.tools.optim.l2_norm)</span>
<span class="sd">      &gt;&gt;&gt; met.to(torch.float64)</span>
<span class="sd">      &gt;&gt;&gt; met.load(po.data.fetch_data(&quot;example_metamerCTF_ps.pt&quot;))</span>
<span class="sd">      &gt;&gt;&gt; po.synth.metamer.plot_synthesis_status(met)</span>
<span class="sd">      (&lt;Figure size ...&gt;, {&#39;display_metamer&#39;: 0, ...})</span>

<span class="sd">    Change the included plots:</span>

<span class="sd">    .. plot::</span>
<span class="sd">      :context: close-figs</span>

<span class="sd">      &gt;&gt;&gt; included_plots = [&quot;plot_loss&quot;, &quot;plot_pixel_values&quot;]</span>
<span class="sd">      &gt;&gt;&gt; po.synth.metamer.plot_synthesis_status(met, included_plots=included_plots)</span>
<span class="sd">      (&lt;Figure size ...&gt;, {&#39;plot_loss&#39;: 0, ...})</span>

<span class="sd">    Adjust width of included plots:</span>

<span class="sd">    .. plot::</span>
<span class="sd">      :context: close-figs</span>

<span class="sd">      &gt;&gt;&gt; width_ratios = {&quot;plot_representation_error&quot;: 3}</span>
<span class="sd">      &gt;&gt;&gt; po.synth.metamer.plot_synthesis_status(met, width_ratios=width_ratios)</span>
<span class="sd">      (&lt;Figure size ...&gt;, {&#39;display_metamer&#39;: 0, ...})</span>

<span class="sd">    Plot on existing figure, ignoring some axes and rearranging others:</span>

<span class="sd">    .. plot::</span>
<span class="sd">      :context: close-figs</span>

<span class="sd">      &gt;&gt;&gt; fig, axes = plt.subplots(1, 5, figsize=(16, 4))</span>
<span class="sd">      &gt;&gt;&gt; axes_idx = {&quot;misc&quot;: [0, 3], &quot;plot_loss&quot;: 4}</span>
<span class="sd">      &gt;&gt;&gt; po.synth.metamer.plot_synthesis_status(met, fig=fig, axes_idx=axes_idx)</span>
<span class="sd">      (&lt;Figure size ...&gt;, {&#39;misc&#39;: [0, 3], ...})</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">iteration</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">metamer</span><span class="o">.</span><span class="n">store_progress</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;synthesis() was run with store_progress=False, &quot;</span>
            <span class="s2">&quot;cannot specify which iteration to plot (only&quot;</span>
            <span class="s2">&quot; last one, with iteration=None)&quot;</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="n">metamer</span><span class="o">.</span><span class="n">metamer</span><span class="o">.</span><span class="n">ndim</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;plot_synthesis_status() expects 3 or 4d data;&quot;</span>
            <span class="s2">&quot;unexpected behavior will result otherwise!&quot;</span>
        <span class="p">)</span>
    <span class="n">_check_included_plots</span><span class="p">(</span><span class="n">included_plots</span><span class="p">,</span> <span class="s2">&quot;included_plots&quot;</span><span class="p">)</span>
    <span class="n">_check_included_plots</span><span class="p">(</span><span class="n">width_ratios</span><span class="p">,</span> <span class="s2">&quot;width_ratios&quot;</span><span class="p">)</span>
    <span class="n">_check_included_plots</span><span class="p">(</span><span class="n">axes_idx</span><span class="p">,</span> <span class="s2">&quot;axes_idx&quot;</span><span class="p">)</span>
    <span class="n">width_ratios</span> <span class="o">=</span> <span class="p">{</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2">_width&quot;</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">width_ratios</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span><span class="p">,</span> <span class="n">axes_idx</span> <span class="o">=</span> <span class="n">_setup_synthesis_fig</span><span class="p">(</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">axes_idx</span><span class="p">,</span> <span class="n">figsize</span><span class="p">,</span> <span class="n">included_plots</span><span class="p">,</span> <span class="o">**</span><span class="n">width_ratios</span>
    <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">check_iterables</span><span class="p">(</span><span class="n">i</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">vals</span><span class="p">:</span> <span class="nb">list</span> <span class="o">|</span> <span class="nb">tuple</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Determine whether i is in vals.</span>

<span class="sd">        Works with an iterable of iterables and iterable of non-iterables.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        i</span>
<span class="sd">            The value we&#39;re looking for.</span>
<span class="sd">        vals</span>
<span class="sd">            The iterable it might be in.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        contained</span>
<span class="sd">            Whether i is in vals.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># numpydoc ignore=EX01</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">vals</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="c1"># then it&#39;s an iterable</span>
                <span class="k">if</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">j</span><span class="p">:</span>
                    <span class="k">return</span> <span class="kc">True</span>
            <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>
                <span class="c1"># then it&#39;s not an iterable</span>
                <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="n">j</span><span class="p">:</span>
                    <span class="k">return</span> <span class="kc">True</span>

    <span class="k">if</span> <span class="s2">&quot;display_metamer&quot;</span> <span class="ow">in</span> <span class="n">included_plots</span><span class="p">:</span>
        <span class="n">display_metamer</span><span class="p">(</span>
            <span class="n">metamer</span><span class="p">,</span>
            <span class="n">batch_idx</span><span class="o">=</span><span class="n">batch_idx</span><span class="p">,</span>
            <span class="n">channel_idx</span><span class="o">=</span><span class="n">channel_idx</span><span class="p">,</span>
            <span class="n">iteration</span><span class="o">=</span><span class="n">iteration</span><span class="p">,</span>
            <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="n">axes_idx</span><span class="p">[</span><span class="s2">&quot;display_metamer&quot;</span><span class="p">]],</span>
            <span class="n">zoom</span><span class="o">=</span><span class="n">zoom</span><span class="p">,</span>
            <span class="n">vrange</span><span class="o">=</span><span class="n">vrange</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="s2">&quot;plot_loss&quot;</span> <span class="ow">in</span> <span class="n">included_plots</span><span class="p">:</span>
        <span class="n">plot_loss</span><span class="p">(</span><span class="n">metamer</span><span class="p">,</span> <span class="n">iteration</span><span class="o">=</span><span class="n">iteration</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="n">axes_idx</span><span class="p">[</span><span class="s2">&quot;plot_loss&quot;</span><span class="p">]])</span>
    <span class="k">if</span> <span class="s2">&quot;plot_representation_error&quot;</span> <span class="ow">in</span> <span class="n">included_plots</span><span class="p">:</span>
        <span class="n">plot_representation_error</span><span class="p">(</span>
            <span class="n">metamer</span><span class="p">,</span>
            <span class="n">batch_idx</span><span class="o">=</span><span class="n">batch_idx</span><span class="p">,</span>
            <span class="n">iteration</span><span class="o">=</span><span class="n">iteration</span><span class="p">,</span>
            <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="n">axes_idx</span><span class="p">[</span><span class="s2">&quot;plot_representation_error&quot;</span><span class="p">]],</span>
            <span class="n">ylim</span><span class="o">=</span><span class="n">ylim</span><span class="p">,</span>
            <span class="n">as_rgb</span><span class="o">=</span><span class="n">plot_representation_error_as_rgb</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1"># this can add a bunch of axes, so this will try and figure</span>
        <span class="c1"># them out</span>
        <span class="n">new_axes</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">i</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">fig</span><span class="o">.</span><span class="n">axes</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">check_iterables</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">axes_idx</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
        <span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">axes_idx</span><span class="p">[</span><span class="s2">&quot;plot_representation_error&quot;</span><span class="p">]]</span>
        <span class="n">axes_idx</span><span class="p">[</span><span class="s2">&quot;plot_representation_error&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_axes</span>
    <span class="k">if</span> <span class="s2">&quot;plot_pixel_values&quot;</span> <span class="ow">in</span> <span class="n">included_plots</span><span class="p">:</span>
        <span class="n">plot_pixel_values</span><span class="p">(</span>
            <span class="n">metamer</span><span class="p">,</span>
            <span class="n">batch_idx</span><span class="o">=</span><span class="n">batch_idx</span><span class="p">,</span>
            <span class="n">channel_idx</span><span class="o">=</span><span class="n">channel_idx</span><span class="p">,</span>
            <span class="n">iteration</span><span class="o">=</span><span class="n">iteration</span><span class="p">,</span>
            <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="n">axes_idx</span><span class="p">[</span><span class="s2">&quot;plot_pixel_values&quot;</span><span class="p">]],</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="n">fig</span><span class="p">,</span> <span class="n">axes_idx</span></div>



<div class="viewcode-block" id="animate">
<a class="viewcode-back" href="../../../generated/plenoptic.synthesize.metamer.html#plenoptic.synthesize.metamer.animate">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">animate</span><span class="p">(</span>
    <span class="n">metamer</span><span class="p">:</span> <span class="n">Metamer</span><span class="p">,</span>
    <span class="n">framerate</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
    <span class="n">batch_idx</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">channel_idx</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">ylim</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">|</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">|</span> <span class="n">Literal</span><span class="p">[</span><span class="kc">False</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">vrange</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
    <span class="n">zoom</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">plot_representation_error_as_rgb</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">fig</span><span class="p">:</span> <span class="n">mpl</span><span class="o">.</span><span class="n">figure</span><span class="o">.</span><span class="n">Figure</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">axes_idx</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">{},</span>
    <span class="n">figsize</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">included_plots</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s2">&quot;display_metamer&quot;</span><span class="p">,</span>
        <span class="s2">&quot;plot_loss&quot;</span><span class="p">,</span>
        <span class="s2">&quot;plot_representation_error&quot;</span><span class="p">,</span>
    <span class="p">],</span>
    <span class="n">width_ratios</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="p">{},</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">mpl</span><span class="o">.</span><span class="n">animation</span><span class="o">.</span><span class="n">FuncAnimation</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Animate synthesis progress.</span>

<span class="sd">    This is essentially the figure produced by</span>
<span class="sd">    ``metamer.plot_synthesis_status`` animated over time, for each stored</span>
<span class="sd">    iteration.</span>

<span class="sd">    This functions returns a matplotlib FuncAnimation object. See our</span>
<span class="sd">    documentation (e.g., :ref:`quickstart-nb`) for examples on how to view it in</span>
<span class="sd">    a Jupyter notebook. In order to save, use ``anim.save(filename)``. In either</span>
<span class="sd">    case, this can take a while and you&#39;ll need the appropriate writer installed</span>
<span class="sd">    and on your path, e.g., ffmpeg, imagemagick, etc). See</span>
<span class="sd">    :doc:`matplotlib documentation &lt;matplotlib:api/animation_api&gt;` for more details.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    metamer</span>
<span class="sd">        Metamer object whose synthesis we want to animate.</span>
<span class="sd">    framerate</span>
<span class="sd">        How many frames a second to display.</span>
<span class="sd">    batch_idx</span>
<span class="sd">        Which index to take from the batch dimension.</span>
<span class="sd">    channel_idx</span>
<span class="sd">        Which index to take from the channel dimension. If ``None``, we use all</span>
<span class="sd">        channels (assumed use-case is RGB(A) image).</span>
<span class="sd">    ylim</span>
<span class="sd">        The y-limits of the representation_error plot:</span>

<span class="sd">        * If a tuple, then this is the ylim of all plots</span>

<span class="sd">        * If ``None``, then all plots have the same limits, all</span>
<span class="sd">          symmetric about 0 with a limit of</span>
<span class="sd">          ``np.abs(representation_error).max()`` (for the initial</span>
<span class="sd">          representation_error).</span>

<span class="sd">        * If ``False``, don&#39;t modify limits.</span>

<span class="sd">        * If a string, must be ``&quot;rescale&quot;`` or of the form ``&quot;rescaleN&quot;``,</span>
<span class="sd">          where N can be any integer. If ``&quot;rescaleN&quot;``, we rescale the</span>
<span class="sd">          limits every N frames (we rescale as if ``ylim=None``). If</span>
<span class="sd">          ``&quot;rescale&quot;``, then we do this 10 times over the course of the</span>
<span class="sd">          animation.</span>

<span class="sd">    vrange</span>
<span class="sd">        The vrange option to pass to :func:`display_metamer()`. See</span>
<span class="sd">        docstring of :func:`~plenoptic.tools.display.imshow` for possible values.</span>
<span class="sd">    zoom</span>
<span class="sd">        How much to zoom in / enlarge the metamer, the ratio</span>
<span class="sd">        of display pixels to image pixels. If ``None``, we</span>
<span class="sd">        attempt to find the best value ourselves.</span>
<span class="sd">    plot_representation_error_as_rgb</span>
<span class="sd">        The representation can be image-like with multiple channels, and we</span>
<span class="sd">        have no way to determine whether it should be represented as an RGB</span>
<span class="sd">        image or not, so the user must set this flag to tell us. It will be</span>
<span class="sd">        ignored if the representation doesn&#39;t look image-like or if the</span>
<span class="sd">        model has its own ``plot_representation_error()`` method. Else, it will</span>
<span class="sd">        be passed to :func:`~plenoptic.tools.display.imshow`, see that method&#39;s</span>
<span class="sd">        docstring for details.</span>
<span class="sd">    fig</span>
<span class="sd">        If ``None``, create the figure from scratch. Else, should be an empty</span>
<span class="sd">        figure with enough axes (the expected use here is have same-size</span>
<span class="sd">        movies with different plots).</span>
<span class="sd">    axes_idx</span>
<span class="sd">        Dictionary specifying which axes contains which type of plot, allows</span>
<span class="sd">        for more fine-grained control of the resulting figure. Probably only</span>
<span class="sd">        helpful if fig is also defined. Possible keys: ``&#39;display_metamer&#39;,</span>
<span class="sd">        &#39;plot_loss&#39;, &#39;plot_representation_error&#39;, &#39;plot_pixel_values&#39;,</span>
<span class="sd">        &#39;misc&#39;``. Values should all be ints. If you tell this function to</span>
<span class="sd">        create a plot that doesn&#39;t have a corresponding key, we find the lowest</span>
<span class="sd">        int that is not already in the dict, so if you have axes that you want</span>
<span class="sd">        unchanged, place their idx in ``&#39;misc&#39;``.</span>
<span class="sd">    figsize</span>
<span class="sd">        The size of the figure to create. It may take a little bit of</span>
<span class="sd">        playing around to find a reasonable value. If ``None``, we attempt to</span>
<span class="sd">        make our best guess, aiming to have each axis be of size ``(5, 5)``.</span>
<span class="sd">    included_plots :</span>
<span class="sd">        Which plots to include. Must be some subset of ``&#39;display_metamer&#39;,</span>
<span class="sd">        &#39;plot_loss&#39;, &#39;plot_representation_error&#39;, &#39;plot_pixel_values&#39;``.</span>
<span class="sd">    width_ratios</span>
<span class="sd">        If ``width_ratios`` is an empty dictionary, all plots will have the</span>
<span class="sd">        same width. To change that, specify their relative widths; keys should</span>
<span class="sd">        be strings (possible values same as ``included_plots``) and values should</span>
<span class="sd">        be floats specifying their relative width.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    anim</span>
<span class="sd">        The animation object. In order to view, must convert to HTML</span>
<span class="sd">        or save.</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        If the given ``metamer`` object was run with ``store_progress=False``.</span>
<span class="sd">    ValueError</span>
<span class="sd">        If ``metamer.metamer`` object is not 3d or 4d.</span>
<span class="sd">    ValueError</span>
<span class="sd">        If we do not know how to interpret the value of ``ylim``.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    display_metamer</span>
<span class="sd">        One of this function&#39;s axis-level component functions: display metamer at</span>
<span class="sd">        a given synthesis iteration.</span>
<span class="sd">    plot_loss</span>
<span class="sd">        One of this function&#39;s axis-level component functions: plot synthesis loss</span>
<span class="sd">        over iterations.</span>
<span class="sd">    plot_representation_error</span>
<span class="sd">        One of this function&#39;s axis-level component functions: plot error in model</span>
<span class="sd">        representation at a given synthesis iteration.</span>
<span class="sd">    plot_pixel_values</span>
<span class="sd">        One of this function&#39;s axis-level component functions: plot histogram of</span>
<span class="sd">        pixel values in target image and metamer at a given synthesis iteration.</span>
<span class="sd">    plot_synthesis_status</span>
<span class="sd">        Create a figure that shows a frame from this movie: the synthesis status at</span>
<span class="sd">        a given iteration.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    Unless specified, we use the ffmpeg backend, which requires that you have</span>
<span class="sd">    ffmpeg installed and on your path (https://ffmpeg.org/download.html). To use</span>
<span class="sd">    a different, use the matplotlib rcParams:</span>
<span class="sd">    ``matplotlib.rcParams[&#39;animation.writer&#39;] = writer``, see `matplotlib</span>
<span class="sd">    documentation</span>
<span class="sd">    &lt;https://matplotlib.org/stable/api/animation_api.html#writer-classes&gt;`_ for</span>
<span class="sd">    more details.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    .. plot::</span>
<span class="sd">      :context: reset</span>

<span class="sd">      &gt;&gt;&gt; import plenoptic as po</span>
<span class="sd">      &gt;&gt;&gt; import torch</span>
<span class="sd">      &gt;&gt;&gt; img = po.data.einstein()</span>
<span class="sd">      &gt;&gt;&gt; model = po.simul.Gaussian(30).eval()</span>
<span class="sd">      &gt;&gt;&gt; po.tools.remove_grad(model)</span>
<span class="sd">      &gt;&gt;&gt; met = po.synth.Metamer(img, model)</span>
<span class="sd">      &gt;&gt;&gt; met.to(torch.float64)</span>
<span class="sd">      &gt;&gt;&gt; met.load(po.data.fetch_data(&quot;example_metamer_gaussian.pt&quot;))</span>
<span class="sd">      &gt;&gt;&gt; ani = po.synth.metamer.animate(met)</span>
<span class="sd">      &gt;&gt;&gt; # Save the video (here we&#39;re saving it as a .gif)</span>
<span class="sd">      &gt;&gt;&gt; ani.save(&quot;animate-example-1.gif&quot;)</span>

<span class="sd">    .. image:: animate-example-1.gif</span>

<span class="sd">    This function can only be used if</span>
<span class="sd">    :meth:`~plenoptic.synthesize.metamer.Metamer.synthesize` was called with</span>
<span class="sd">    ``store_progress``.</span>

<span class="sd">    &gt;&gt;&gt; import plenoptic as po</span>
<span class="sd">    &gt;&gt;&gt; img = po.data.einstein()</span>
<span class="sd">    &gt;&gt;&gt; model = po.simul.Gaussian(30).eval()</span>
<span class="sd">    &gt;&gt;&gt; po.tools.remove_grad(model)</span>
<span class="sd">    &gt;&gt;&gt; met = po.synth.Metamer(img, model)</span>
<span class="sd">    &gt;&gt;&gt; met.to(torch.float64)</span>
<span class="sd">    &gt;&gt;&gt; met.synthesize(5)</span>
<span class="sd">    &gt;&gt;&gt; ani = po.synth.metamer.animate(met)</span>
<span class="sd">    Traceback (most recent call last):</span>
<span class="sd">    ValueError: synthesize() was run with store_progress=False...</span>

<span class="sd">    If model has its own ``plot_representation`` method, this function will use it</span>
<span class="sd">    for plotting the representation error (see</span>
<span class="sd">    :func:`~plenoptic.simulate.models.portilla_simoncelli.PortillaSimoncelli.plot_representation`</span>
<span class="sd">    ):</span>

<span class="sd">    .. plot::</span>
<span class="sd">      :context: close-figs</span>

<span class="sd">      &gt;&gt;&gt; img = po.data.reptile_skin()</span>
<span class="sd">      &gt;&gt;&gt; model = po.simul.PortillaSimoncelli(img.shape[-2:])</span>
<span class="sd">      &gt;&gt;&gt; met = po.synth.MetamerCTF(img, model, po.tools.optim.l2_norm)</span>
<span class="sd">      &gt;&gt;&gt; met.to(torch.float64)</span>
<span class="sd">      &gt;&gt;&gt; met.load(po.data.fetch_data(&quot;example_metamerCTF_ps.pt&quot;))</span>
<span class="sd">      &gt;&gt;&gt; ani = po.synth.metamer.animate(met)</span>
<span class="sd">      &gt;&gt;&gt; # Save the video (here we&#39;re saving it as a .gif)</span>
<span class="sd">      &gt;&gt;&gt; ani.save(&quot;animate-example-2.gif&quot;)</span>

<span class="sd">    .. image:: animate-example-2.gif</span>

<span class="sd">    Change the included plots:</span>

<span class="sd">    .. plot::</span>
<span class="sd">      :context: close-figs</span>

<span class="sd">      &gt;&gt;&gt; included_plots = [&quot;plot_loss&quot;, &quot;plot_pixel_values&quot;]</span>
<span class="sd">      &gt;&gt;&gt; ani = po.synth.metamer.animate(met, included_plots=included_plots)</span>
<span class="sd">      &gt;&gt;&gt; # Save the video (here we&#39;re saving it as a .gif)</span>
<span class="sd">      &gt;&gt;&gt; ani.save(&quot;animate-example-3.gif&quot;)</span>

<span class="sd">    .. image:: animate-example-3.gif</span>

<span class="sd">    Adjust width of included plots:</span>

<span class="sd">    .. plot::</span>
<span class="sd">      :context: close-figs</span>

<span class="sd">      &gt;&gt;&gt; width_ratios = {&quot;plot_representation_error&quot;: 3}</span>
<span class="sd">      &gt;&gt;&gt; ani = po.synth.metamer.animate(met, width_ratios=width_ratios)</span>
<span class="sd">      &gt;&gt;&gt; # Save the video (here we&#39;re saving it as a .gif)</span>
<span class="sd">      &gt;&gt;&gt; ani.save(&quot;animate-example-4.gif&quot;)</span>

<span class="sd">    .. image:: animate-example-4.gif</span>

<span class="sd">    Use an existing figure, ignoring some axes and rearranging others:</span>

<span class="sd">    .. plot::</span>
<span class="sd">      :context: close-figs</span>

<span class="sd">      &gt;&gt;&gt; fig, axes = plt.subplots(1, 5, figsize=(16, 4))</span>
<span class="sd">      &gt;&gt;&gt; axes_idx = {&quot;misc&quot;: [0, 3], &quot;plot_loss&quot;: 4}</span>
<span class="sd">      &gt;&gt;&gt; ani = po.synth.metamer.animate(met, fig=fig, axes_idx=axes_idx)</span>
<span class="sd">      &gt;&gt;&gt; # Save the video (here we&#39;re saving it as a .gif)</span>
<span class="sd">      &gt;&gt;&gt; ani.save(&quot;animate-example-5.gif&quot;)</span>

<span class="sd">    .. image:: animate-example-5.gif</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">metamer</span><span class="o">.</span><span class="n">store_progress</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;synthesize() was run with store_progress=False, cannot animate!&quot;</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="n">metamer</span><span class="o">.</span><span class="n">metamer</span><span class="o">.</span><span class="n">ndim</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;animate() expects 3 or 4d data; unexpected behavior will result otherwise!&quot;</span>
        <span class="p">)</span>
    <span class="n">_check_included_plots</span><span class="p">(</span><span class="n">included_plots</span><span class="p">,</span> <span class="s2">&quot;included_plots&quot;</span><span class="p">)</span>
    <span class="n">_check_included_plots</span><span class="p">(</span><span class="n">width_ratios</span><span class="p">,</span> <span class="s2">&quot;width_ratios&quot;</span><span class="p">)</span>
    <span class="n">_check_included_plots</span><span class="p">(</span><span class="n">axes_idx</span><span class="p">,</span> <span class="s2">&quot;axes_idx&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">metamer</span><span class="o">.</span><span class="n">target_representation</span><span class="o">.</span><span class="n">ndimension</span><span class="p">()</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
        <span class="c1"># we have to do this here so that we set the</span>
        <span class="c1"># ylim_rescale_interval such that we never rescale ylim</span>
        <span class="c1"># (rescaling ylim messes up an image axis)</span>
        <span class="n">ylim</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">ylim</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;rescale&quot;</span><span class="p">):</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">ylim_rescale_interval</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">ylim</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;rescale&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">))</span>
            <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
                <span class="c1"># then there&#39;s nothing we can convert to an int there</span>
                <span class="n">ylim_rescale_interval</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="n">metamer</span><span class="o">.</span><span class="n">saved_metamer</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="mi">10</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">ylim_rescale_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">ylim_rescale_interval</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">metamer</span><span class="o">.</span><span class="n">saved_metamer</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">ylim</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Don&#39;t know how to handle ylim </span><span class="si">{</span><span class="n">ylim</span><span class="si">}</span><span class="s2">!&quot;</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
        <span class="c1"># this way we&#39;ll never rescale</span>
        <span class="n">ylim_rescale_interval</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">metamer</span><span class="o">.</span><span class="n">saved_metamer</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="c1"># we run plot_synthesis_status to initialize the figure if either fig is</span>
    <span class="c1"># None or if there are no titles on any axes, which we assume means that</span>
    <span class="c1"># it&#39;s an empty figure</span>
    <span class="k">if</span> <span class="n">fig</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="ow">not</span> <span class="nb">any</span><span class="p">([</span><span class="n">ax</span><span class="o">.</span><span class="n">get_title</span><span class="p">()</span> <span class="k">for</span> <span class="n">ax</span> <span class="ow">in</span> <span class="n">fig</span><span class="o">.</span><span class="n">axes</span><span class="p">]):</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">axes_idx</span> <span class="o">=</span> <span class="n">plot_synthesis_status</span><span class="p">(</span>
            <span class="n">metamer</span><span class="o">=</span><span class="n">metamer</span><span class="p">,</span>
            <span class="n">batch_idx</span><span class="o">=</span><span class="n">batch_idx</span><span class="p">,</span>
            <span class="n">channel_idx</span><span class="o">=</span><span class="n">channel_idx</span><span class="p">,</span>
            <span class="n">iteration</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">,</span>
            <span class="n">ylim</span><span class="o">=</span><span class="n">ylim</span><span class="p">,</span>
            <span class="n">vrange</span><span class="o">=</span><span class="n">vrange</span><span class="p">,</span>
            <span class="n">zoom</span><span class="o">=</span><span class="n">zoom</span><span class="p">,</span>
            <span class="n">fig</span><span class="o">=</span><span class="n">fig</span><span class="p">,</span>
            <span class="n">axes_idx</span><span class="o">=</span><span class="n">axes_idx</span><span class="p">,</span>
            <span class="n">included_plots</span><span class="o">=</span><span class="n">included_plots</span><span class="p">,</span>
            <span class="n">plot_representation_error_as_rgb</span><span class="o">=</span><span class="n">plot_representation_error_as_rgb</span><span class="p">,</span>
            <span class="n">width_ratios</span><span class="o">=</span><span class="n">width_ratios</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="c1"># grab the artist for the second plot (we don&#39;t need to do this for the</span>
    <span class="c1"># metamer or representation plot, because we use the update_plot</span>
    <span class="c1"># function for that)</span>
    <span class="k">if</span> <span class="s2">&quot;plot_loss&quot;</span> <span class="ow">in</span> <span class="n">included_plots</span><span class="p">:</span>
        <span class="n">scat</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">axes</span><span class="p">[</span><span class="n">axes_idx</span><span class="p">[</span><span class="s2">&quot;plot_loss&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">collections</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="c1"># can have multiple plots</span>
    <span class="k">if</span> <span class="s2">&quot;plot_representation_error&quot;</span> <span class="ow">in</span> <span class="n">included_plots</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">rep_error_axes</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">fig</span><span class="o">.</span><span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">axes_idx</span><span class="p">[</span><span class="s2">&quot;plot_representation_error&quot;</span><span class="p">]</span>
            <span class="p">]</span>
        <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>
            <span class="c1"># in this case, axes_idx[&#39;plot_representation_error&#39;] is not iterable and</span>
            <span class="c1"># so is a single value</span>
            <span class="n">rep_error_axes</span> <span class="o">=</span> <span class="p">[</span><span class="n">fig</span><span class="o">.</span><span class="n">axes</span><span class="p">[</span><span class="n">axes_idx</span><span class="p">[</span><span class="s2">&quot;plot_representation_error&quot;</span><span class="p">]]]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">rep_error_axes</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">if</span> <span class="s2">&quot;display_metamer&quot;</span> <span class="ow">in</span> <span class="n">included_plots</span><span class="p">:</span>
        <span class="n">fig</span><span class="o">.</span><span class="n">axes</span><span class="p">[</span><span class="n">axes_idx</span><span class="p">[</span><span class="s2">&quot;display_metamer&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Metamer&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">metamer</span><span class="o">.</span><span class="n">target_representation</span><span class="o">.</span><span class="n">ndimension</span><span class="p">()</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
        <span class="k">if</span> <span class="s2">&quot;plot_representation_error&quot;</span> <span class="ow">in</span> <span class="n">included_plots</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;Looks like representation is image-like, haven&#39;t fully&quot;</span>
                <span class="s2">&quot; thought out how to best handle rescaling color ranges yet!&quot;</span>
            <span class="p">)</span>
        <span class="c1"># replace the bit of the title that specifies the range,</span>
        <span class="c1"># since we don&#39;t make any promises about that. we have to do</span>
        <span class="c1"># this here because we need the figure to have been created</span>
        <span class="k">for</span> <span class="n">ax</span> <span class="ow">in</span> <span class="n">rep_error_axes</span><span class="p">:</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;\n range: .* \n&quot;</span><span class="p">,</span> <span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">ax</span><span class="o">.</span><span class="n">get_title</span><span class="p">()))</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">movie_plot</span><span class="p">(</span><span class="n">i</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">mpl</span><span class="o">.</span><span class="n">artist</span><span class="o">.</span><span class="n">Artist</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Matplotlib function for animation.</span>

<span class="sd">        Update plots for frame ``i``.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        i</span>
<span class="sd">            The frame to plot.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        artists</span>
<span class="sd">            The updated matplotlib artists.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># numpydoc ignore=EX01</span>
        <span class="c1"># this warning is not relevant for animate</span>
        <span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">():</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span>
                <span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="s2">&quot;loss iteration and iteration for&quot;</span>
            <span class="p">)</span>
            <span class="n">artists</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">if</span> <span class="s2">&quot;display_metamer&quot;</span> <span class="ow">in</span> <span class="n">included_plots</span><span class="p">:</span>
                <span class="n">artists</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span>
                    <span class="n">display</span><span class="o">.</span><span class="n">update_plot</span><span class="p">(</span>
                        <span class="n">fig</span><span class="o">.</span><span class="n">axes</span><span class="p">[</span><span class="n">axes_idx</span><span class="p">[</span><span class="s2">&quot;display_metamer&quot;</span><span class="p">]],</span>
                        <span class="n">data</span><span class="o">=</span><span class="n">metamer</span><span class="o">.</span><span class="n">saved_metamer</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                        <span class="n">batch_idx</span><span class="o">=</span><span class="n">batch_idx</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="s2">&quot;plot_representation_error&quot;</span> <span class="ow">in</span> <span class="n">included_plots</span><span class="p">:</span>
                <span class="n">rep_error</span> <span class="o">=</span> <span class="n">_representation_error</span><span class="p">(</span>
                    <span class="n">metamer</span><span class="p">,</span>
                    <span class="n">iteration</span><span class="o">=</span><span class="nb">min</span><span class="p">(</span><span class="n">i</span> <span class="o">*</span> <span class="n">metamer</span><span class="o">.</span><span class="n">store_progress</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">metamer</span><span class="o">.</span><span class="n">losses</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span>
                <span class="p">)</span>

                <span class="c1"># we pass rep_error_axes to update, and we&#39;ve grabbed</span>
                <span class="c1"># the right things above</span>
                <span class="n">artists</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span>
                    <span class="n">display</span><span class="o">.</span><span class="n">update_plot</span><span class="p">(</span>
                        <span class="n">rep_error_axes</span><span class="p">,</span>
                        <span class="n">batch_idx</span><span class="o">=</span><span class="n">batch_idx</span><span class="p">,</span>
                        <span class="n">model</span><span class="o">=</span><span class="n">metamer</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                        <span class="n">data</span><span class="o">=</span><span class="n">rep_error</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="p">)</span>
                <span class="c1"># again, we know that rep_error_axes contains all the axes</span>
                <span class="c1"># with the representation ratio info</span>
                <span class="k">if</span> <span class="p">(</span>
                    <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">ylim_rescale_interval</span> <span class="o">==</span> <span class="mi">0</span>
                    <span class="ow">and</span> <span class="n">metamer</span><span class="o">.</span><span class="n">target_representation</span><span class="o">.</span><span class="n">ndimension</span><span class="p">()</span> <span class="o">==</span> <span class="mi">3</span>
                <span class="p">):</span>
                    <span class="n">display</span><span class="o">.</span><span class="n">rescale_ylim</span><span class="p">(</span><span class="n">rep_error_axes</span><span class="p">,</span> <span class="n">rep_error</span><span class="p">)</span>

            <span class="k">if</span> <span class="s2">&quot;plot_pixel_values&quot;</span> <span class="ow">in</span> <span class="n">included_plots</span><span class="p">:</span>
                <span class="c1"># this is the dumbest way to do this, but it&#39;s simple --</span>
                <span class="c1"># clearing the axes can cause problems if the user has, for</span>
                <span class="c1"># example, changed the tick locator or formatter. not sure how</span>
                <span class="c1"># to handle this best right now</span>
                <span class="n">fig</span><span class="o">.</span><span class="n">axes</span><span class="p">[</span><span class="n">axes_idx</span><span class="p">[</span><span class="s2">&quot;plot_pixel_values&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
                <span class="n">plot_pixel_values</span><span class="p">(</span>
                    <span class="n">metamer</span><span class="p">,</span>
                    <span class="n">batch_idx</span><span class="o">=</span><span class="n">batch_idx</span><span class="p">,</span>
                    <span class="n">channel_idx</span><span class="o">=</span><span class="n">channel_idx</span><span class="p">,</span>
                    <span class="n">iteration</span><span class="o">=</span><span class="nb">min</span><span class="p">(</span><span class="n">i</span> <span class="o">*</span> <span class="n">metamer</span><span class="o">.</span><span class="n">store_progress</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">metamer</span><span class="o">.</span><span class="n">losses</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span>
                    <span class="n">ax</span><span class="o">=</span><span class="n">fig</span><span class="o">.</span><span class="n">axes</span><span class="p">[</span><span class="n">axes_idx</span><span class="p">[</span><span class="s2">&quot;plot_pixel_values&quot;</span><span class="p">]],</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="s2">&quot;plot_loss&quot;</span> <span class="ow">in</span> <span class="n">included_plots</span><span class="p">:</span>
                <span class="c1"># loss always contains values from every iteration, but everything</span>
                <span class="c1"># else will be subsampled.</span>
                <span class="n">x_val</span> <span class="o">=</span> <span class="n">metamer</span><span class="o">.</span><span class="n">_convert_iteration</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
                <span class="n">scat</span><span class="o">.</span><span class="n">set_offsets</span><span class="p">((</span><span class="n">x_val</span><span class="p">,</span> <span class="n">metamer</span><span class="o">.</span><span class="n">losses</span><span class="p">[</span><span class="n">x_val</span><span class="p">]))</span>
                <span class="n">artists</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">scat</span><span class="p">)</span>
            <span class="c1"># as long as blitting is True, need to return a sequence of artists</span>
            <span class="k">return</span> <span class="n">artists</span>

    <span class="c1"># don&#39;t need an init_func, since we handle initialization ourselves</span>
    <span class="n">anim</span> <span class="o">=</span> <span class="n">mpl</span><span class="o">.</span><span class="n">animation</span><span class="o">.</span><span class="n">FuncAnimation</span><span class="p">(</span>
        <span class="n">fig</span><span class="p">,</span>
        <span class="n">movie_plot</span><span class="p">,</span>
        <span class="n">frames</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">metamer</span><span class="o">.</span><span class="n">saved_metamer</span><span class="p">),</span>
        <span class="n">blit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">interval</span><span class="o">=</span><span class="mf">1000.0</span> <span class="o">/</span> <span class="n">framerate</span><span class="p">,</span>
        <span class="n">repeat</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">anim</span></div>

</pre></div>

                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
       Copyright 2019-2025, Plenoptic authors.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 9.0.4.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.1.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>