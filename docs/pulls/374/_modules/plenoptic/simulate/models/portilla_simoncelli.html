
<!DOCTYPE html>


<html lang="en" data-content_root="../../../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>plenoptic.simulate.models.portilla_simoncelli &#8212; plenoptic 1.3.2.dev302 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../../../../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/togglebutton.css?v=9c3e77be" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/custom.css?v=d54d67fd" />
  
  <!-- So that users can add custom icons -->
  <script src="../../../../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../../../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../../../../_static/documentation_options.js?v=06b62906"></script>
    <script src="../../../../_static/doctools.js?v=fd6eb6e6"></script>
    <script src="../../../../_static/sphinx_highlight.js?v=6ffebe34"></script>
    <script src="../../../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../../../_static/copybutton.js?v=6dbb43f8"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../../_static/togglebutton.js?v=1ae7504c"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../../../_static/design-tabs.js?v=f930bc37"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_modules/plenoptic/simulate/models/portilla_simoncelli';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_version = '0.16.1';
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = 'https://docs.plenoptic.org/docs/branch/main/_static/version_switcher.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = '1.3.2';
        DOCUMENTATION_OPTIONS.show_version_warning_banner =
            true;
        </script>
    <script src="../../../../_static/custom-icon.js?v=0bae05a2"></script>
    <link rel="icon" href="../../../../_static/plenoptic.ico"/>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="1.3.2" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../../../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../../../_static/Plenoptic_Logo_CMYK_Full_Wide.svg" class="logo__image only-light" alt="plenoptic 1.3.2.dev302 documentation - Home"/>
    <img src="../../../../_static/Plenoptic_Logo_CMYK_Full_DarkMode_Wide.svg" class="logo__image only-dark pst-js-only" alt="plenoptic 1.3.2.dev302 documentation - Home"/>
  
  
</a></div>
    
      <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-2"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-2"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-2"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-2">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../getting_started/index.html">
    Getting started
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../user_guide/index.html">
    User Guide
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../api.html">
    API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../reference/index.html">
    Reference
  </a>
</li>

            <li class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button"
                data-bs-toggle="dropdown" aria-expanded="false"
                aria-controls="pst-nav-more-links">
                    More
                </button>
                <ul id="pst-nav-more-links" class="dropdown-menu">
                    
<li class=" ">
  <a class="nav-link dropdown-item nav-external" href="https://github.com/plenoptic-org/plenoptic/releases">
    Changelog
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../../../developers/index.html">
    For developers
  </a>
</li>

                </ul>
            </li>
            
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://plenoptic.org" title="Home" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-solid fa-house fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Home</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/plenoptic-org/plenoptic" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fab fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/plenoptic" title="PyPI" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-custom fa-pypi fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPI</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar hide-on-wide">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../getting_started/index.html">
    Getting started
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../user_guide/index.html">
    User Guide
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../api.html">
    API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../reference/index.html">
    Reference
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://github.com/plenoptic-org/plenoptic/releases">
    Changelog
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../developers/index.html">
    For developers
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://plenoptic.org" title="Home" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-solid fa-house fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Home</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/plenoptic-org/plenoptic" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fab fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/plenoptic" title="PyPI" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-custom fa-pypi fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPI</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../../../index.html" class="nav-link">Module code</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">plenoptic.simulate.models.portilla_simoncelli</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <h1>Source code for plenoptic.simulate.models.portilla_simoncelli</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Portilla-Simoncelli texture statistics.</span>

<span class="sd">The Portilla-Simoncelli (PS) texture statistics are a set of image statistics, first</span>
<span class="sd">described in Portilla and Simoncelli, 2000 [1]_, that are proposed as a sufficient set</span>
<span class="sd">of measurements for describing visual textures. That is, if two texture images have the</span>
<span class="sd">same values for all PS texture stats, humans should consider them as members of the same</span>
<span class="sd">family of textures.</span>

<span class="sd">References</span>
<span class="sd">----------</span>
<span class="sd">.. [1] J Portilla and E P Simoncelli. A Parametric Texture Model based on</span>
<span class="sd">   Joint Statistics of Complex Wavelet Coefficients. Int&#39;l Journal of</span>
<span class="sd">   Computer Vision. 40(1):49-71, October, 2000.</span>
<span class="sd">   https://www.cns.nyu.edu/~eero/ABSTRACTS/portilla99-abstract.html</span>
<span class="sd">   https://www.cns.nyu.edu/~lcv/texture/</span>
<span class="sd">&quot;&quot;&quot;</span>  <span class="c1"># numpydoc ignore=EX01</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">collections</span><span class="w"> </span><span class="kn">import</span> <span class="n">OrderedDict</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Literal</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">einops</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">mpl</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.fft</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">Tensor</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">...tools</span><span class="w"> </span><span class="kn">import</span> <span class="n">signal</span><span class="p">,</span> <span class="n">stats</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">...tools.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">to_numpy</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">...tools.display</span><span class="w"> </span><span class="kn">import</span> <span class="n">clean_stem_plot</span><span class="p">,</span> <span class="n">clean_up_axes</span><span class="p">,</span> <span class="n">update_stem</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">...tools.validate</span><span class="w"> </span><span class="kn">import</span> <span class="n">validate_input</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">..canonical_computations.steerable_pyramid_freq</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">SCALES_TYPE</span> <span class="k">as</span> <span class="n">PYR_SCALES_TYPE</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">..canonical_computations.steerable_pyramid_freq</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">SteerablePyramidFreq</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">SCALES_TYPE</span> <span class="o">=</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;pixel_statistics&quot;</span><span class="p">]</span> <span class="o">|</span> <span class="n">PYR_SCALES_TYPE</span>


<div class="viewcode-block" id="PortillaSimoncelli">
<a class="viewcode-back" href="../../../../generated/plenoptic.simulate.models.portilla_simoncelli.html#plenoptic.simulate.models.portilla_simoncelli.PortillaSimoncelli">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">PortillaSimoncelli</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Portila-Simoncelli texture statistics.</span>

<span class="sd">    The Portilla-Simoncelli (PS) texture statistics are a set of image statistics, first</span>
<span class="sd">    described in Portilla and Simoncelli, 2000 [2]_, that are proposed as a sufficient</span>
<span class="sd">    set of measurements for describing visual textures. That is, if two texture images</span>
<span class="sd">    have the same values for all PS texture stats, humans should consider them as</span>
<span class="sd">    members of the same family of textures.</span>

<span class="sd">    The PS stats are computed based on the</span>
<span class="sd">    :class:`~plenoptic.simulate.canonical_computations.steerable_pyramid_freq.SteerablePyramidFreq`</span>
<span class="sd">    (Simoncelli and Freeman, 1995, [3]_). They consist of the local auto-correlations,</span>
<span class="sd">    cross-scale (within-orientation) correlations, and cross-orientation (within-scale)</span>
<span class="sd">    correlations of both the pyramid coefficients and the local energy (as computed by</span>
<span class="sd">    those coefficients). Additionally, they include the first four global moments (mean,</span>
<span class="sd">    variance, skew, and kurtosis) of the image and down-sampled versions of that image.</span>
<span class="sd">    See the paper and notebook for more description.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    image_shape</span>
<span class="sd">        Shape of input image.</span>
<span class="sd">    n_scales</span>
<span class="sd">        The number of pyramid scales used to measure the statistics.</span>
<span class="sd">    n_orientations</span>
<span class="sd">        The number of orientations used to measure the statistics.</span>
<span class="sd">    spatial_corr_width</span>
<span class="sd">        The width of the spatial cross- and auto-correlation statistics.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    scales: list</span>
<span class="sd">        The names of the unique scales of coefficients in the pyramid, used for</span>
<span class="sd">        coarse-to-fine metamer synthesis.</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        If the height or width of ``image`` cannot be divided by 2 ``n_scales``</span>
<span class="sd">        times. This is necessary because of how the model handles multiscale</span>
<span class="sd">        representations.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [2] J Portilla and E P Simoncelli. A Parametric Texture Model based on</span>
<span class="sd">       Joint Statistics of Complex Wavelet Coefficients. Int&#39;l Journal of</span>
<span class="sd">       Computer Vision. 40(1):49-71, October, 2000.</span>
<span class="sd">       https://www.cns.nyu.edu/~eero/ABSTRACTS/portilla99-abstract.html</span>
<span class="sd">       https://www.cns.nyu.edu/~lcv/texture/</span>
<span class="sd">    .. [3] E P Simoncelli and W T Freeman, &quot;The Steerable Pyramid: A Flexible</span>
<span class="sd">       Architecture for Multi-Scale Derivative Computation,&quot; Second Int&#39;l Conf</span>
<span class="sd">       on Image Processing, Washington, DC, Oct 1995.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    Compute texture statistics of an image:</span>

<span class="sd">    .. plot::</span>
<span class="sd">      :context: reset</span>

<span class="sd">       &gt;&gt;&gt; import plenoptic as po</span>
<span class="sd">       &gt;&gt;&gt; img = po.data.reptile_skin()</span>
<span class="sd">       &gt;&gt;&gt; ps_model = po.simul.PortillaSimoncelli(img.shape[2:])</span>
<span class="sd">       &gt;&gt;&gt; ps_model(img)</span>
<span class="sd">       tensor([[[0.4172, 0.0547, ..., 0.0048]]])</span>

<span class="sd">    Visualize texture statistics:</span>

<span class="sd">    .. plot::</span>
<span class="sd">      :context: close-figs</span>

<span class="sd">      &gt;&gt;&gt; fig, axes = ps_model.plot_representation(ps_model(img))</span>

<span class="sd">    Convert texture statistics into an easier-to-read format:</span>

<span class="sd">    &gt;&gt;&gt; representation_dict = ps_model.convert_to_dict(ps_model(img))</span>
<span class="sd">    &gt;&gt;&gt; representation_dict.keys()</span>
<span class="sd">    odict_keys([&#39;pixel_statistics&#39;, ..., &#39;var_highpass_residual&#39;])</span>

<span class="sd">    Synthesize a texture metamer:</span>

<span class="sd">    .. plot::</span>
<span class="sd">      :context: close-figs</span>

<span class="sd">      &gt;&gt;&gt; import plenoptic as po</span>
<span class="sd">      &gt;&gt;&gt; import matplotlib.pyplot as plt</span>
<span class="sd">      &gt;&gt;&gt; import torch</span>
<span class="sd">      &gt;&gt;&gt; img = po.data.reptile_skin()</span>
<span class="sd">      &gt;&gt;&gt; ps_model = po.simul.PortillaSimoncelli(img.shape[2:])</span>
<span class="sd">      &gt;&gt;&gt; loss = po.tools.optim.portilla_simoncelli_loss_factory(ps_model, img)</span>
<span class="sd">      &gt;&gt;&gt; met = po.synth.Metamer(img, ps_model, loss_function=loss)</span>
<span class="sd">      &gt;&gt;&gt; opt_kwargs = {</span>
<span class="sd">      ...     &quot;max_iter&quot;: 10,</span>
<span class="sd">      ...     &quot;max_eval&quot;: 10,</span>
<span class="sd">      ...     &quot;history_size&quot;: 100,</span>
<span class="sd">      ...     &quot;line_search_fn&quot;: &quot;strong_wolfe&quot;,</span>
<span class="sd">      ...     &quot;lr&quot;: 1,</span>
<span class="sd">      ... }</span>
<span class="sd">      &gt;&gt;&gt; met.setup(optimizer=torch.optim.LBFGS, optimizer_kwargs=opt_kwargs)</span>
<span class="sd">      &gt;&gt;&gt; # Note that this isn&#39;t enough to run synthesis to completion,</span>
<span class="sd">      &gt;&gt;&gt; # just an example to demonstrate what synthesis looks like</span>
<span class="sd">      &gt;&gt;&gt; met.synthesize(max_iter=20)</span>
<span class="sd">      &gt;&gt;&gt; fig, axes = plt.subplots(1, 4, figsize=(25, 4), width_ratios=[1, 1, 1, 3])</span>
<span class="sd">      &gt;&gt;&gt; po.imshow(img, ax=axes[0], title=&quot;Target image&quot;)</span>
<span class="sd">      &lt;Figure size ... with 4 Axes&gt;</span>
<span class="sd">      &gt;&gt;&gt; axes[0].xaxis.set_visible(False)</span>
<span class="sd">      &gt;&gt;&gt; axes[0].yaxis.set_visible(False)</span>
<span class="sd">      &gt;&gt;&gt; po.synth.metamer.plot_synthesis_status(met, fig=fig, axes_idx={&quot;misc&quot;: 0})[0]</span>
<span class="sd">      &lt;Figure size ...&gt;</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">image_shape</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span>
        <span class="n">n_scales</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
        <span class="n">n_orientations</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
        <span class="n">spatial_corr_width</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">9</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">image_shape</span> <span class="o">=</span> <span class="n">image_shape</span>
        <span class="k">if</span> <span class="nb">any</span><span class="p">([(</span><span class="n">image_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="mi">2</span><span class="o">**</span><span class="n">i</span><span class="p">)</span> <span class="o">%</span> <span class="mi">2</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_scales</span><span class="p">)])</span> <span class="ow">or</span> <span class="nb">any</span><span class="p">(</span>
            <span class="p">[(</span><span class="n">image_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">/</span> <span class="mi">2</span><span class="o">**</span><span class="n">i</span><span class="p">)</span> <span class="o">%</span> <span class="mi">2</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_scales</span><span class="p">)]</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Because of how the Portilla-Simoncelli model handles &quot;</span>
                <span class="s2">&quot;multiscale representations, it only works with images&quot;</span>
                <span class="s2">&quot; whose shape can be divided by 2 `n_scales` times.&quot;</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">spatial_corr_width</span> <span class="o">=</span> <span class="n">spatial_corr_width</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span> <span class="o">=</span> <span class="n">n_scales</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_orientations</span> <span class="o">=</span> <span class="n">n_orientations</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_pyr</span> <span class="o">=</span> <span class="n">SteerablePyramidFreq</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">image_shape</span><span class="p">,</span>
            <span class="n">height</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span><span class="p">,</span>
            <span class="n">order</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_orientations</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span>
            <span class="n">is_complex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">tight_frame</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">scales</span> <span class="o">=</span> <span class="p">(</span>
            <span class="p">[</span><span class="s2">&quot;pixel_statistics&quot;</span><span class="p">,</span> <span class="s2">&quot;residual_lowpass&quot;</span><span class="p">]</span>
            <span class="o">+</span> <span class="p">[</span><span class="n">ii</span> <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_scales</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)]</span>
            <span class="o">+</span> <span class="p">[</span><span class="s2">&quot;residual_highpass&quot;</span><span class="p">]</span>
        <span class="p">)</span>

        <span class="c1"># Dictionary defining shape of the statistics and which scale they&#39;re</span>
        <span class="c1"># associated with</span>
        <span class="n">scales_shape_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_scales_shape_dict</span><span class="p">()</span>

        <span class="c1"># Dictionary defining necessary statistics, that is, those that are not</span>
        <span class="c1"># redundant</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_necessary_stats_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_necessary_stats_dict</span><span class="p">(</span>
            <span class="n">scales_shape_dict</span>
        <span class="p">)</span>
        <span class="c1"># turn this into tensor we can use in forward pass. first into a</span>
        <span class="c1"># boolean mask...</span>
        <span class="n">_necessary_stats_mask</span> <span class="o">=</span> <span class="n">einops</span><span class="o">.</span><span class="n">pack</span><span class="p">(</span>
            <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_necessary_stats_dict</span><span class="o">.</span><span class="n">values</span><span class="p">()),</span> <span class="s2">&quot;*&quot;</span>
        <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="c1"># then into a tensor of indices</span>
        <span class="n">_necessary_stats_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">_necessary_stats_mask</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;_necessary_stats_mask&quot;</span><span class="p">,</span> <span class="n">_necessary_stats_mask</span><span class="p">)</span>

        <span class="c1"># This array is composed of the following values: &#39;pixel_statistics&#39;,</span>
        <span class="c1"># &#39;residual_lowpass&#39;, &#39;residual_highpass&#39; and integer values from 0 to</span>
        <span class="c1"># self.n_scales-1. It is the same size as the representation tensor</span>
        <span class="c1"># returned by this object&#39;s forward method. It must be a numpy array so</span>
        <span class="c1"># we can have a mixture of ints and strs (and so we can use np.isin</span>
        <span class="c1"># later)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_representation_scales</span> <span class="o">=</span> <span class="n">einops</span><span class="o">.</span><span class="n">pack</span><span class="p">(</span>
            <span class="nb">list</span><span class="p">(</span><span class="n">scales_shape_dict</span><span class="o">.</span><span class="n">values</span><span class="p">()),</span> <span class="s2">&quot;*&quot;</span>
        <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="c1"># just select the scales of the necessary stats.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_representation_scales</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_representation_scales</span><span class="p">[</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_necessary_stats_mask</span>
        <span class="p">]</span>
        <span class="c1"># This model has no trainable parameters, so it&#39;s always in eval mode</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_create_scales_shape_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">OrderedDict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create dictionary defining scales and shape of each stat.</span>

<span class="sd">        This dictionary functions as metadata which is used for two main</span>
<span class="sd">        purposes:</span>

<span class="sd">        - Scale assignment. In order for optimization to work well, we proceed</span>
<span class="sd">          in a &quot;coarse-to-fine&quot; manner. That is, we start optimization by only</span>
<span class="sd">          considering the statistics related to the lowest frequencies, and</span>
<span class="sd">          gradually add in those related to higher and higher frequencies. This</span>
<span class="sd">          is similar to blurring the objective function and then gradually</span>
<span class="sd">          adding in finer and finer details. The numbers in this dictionary map</span>
<span class="sd">          the computed statistics to their corresponding scales, which we use</span>
<span class="sd">          in remove_scales to throw away some stats as needed.</span>

<span class="sd">        - Redundant stat identification. As described at the bottom of the</span>
<span class="sd">          notebook, the model incidentally computes a whole bunch of redundant</span>
<span class="sd">          stats, because auto- and cross-correlation matrices have certain</span>
<span class="sd">          symmetries. the _create_necessary_stats_dict method accepts the</span>
<span class="sd">          dictionary created here as input and uses the values to get the</span>
<span class="sd">          shapes of these and insert True/False as necessary.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        scales_shape_dict</span>
<span class="sd">           Dictionary defining shape and associated scales of each computed</span>
<span class="sd">           statistic. The keys name each statistic, with dummy arrays as</span>
<span class="sd">           values. These arrays have the same shape as the stat (excluding</span>
<span class="sd">           batch and channel), with values defining which scale they correspond</span>
<span class="sd">           to.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># numpydoc ignore=EX01</span>
        <span class="n">shape_dict</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
        <span class="c1"># There are 6 pixel statistics</span>
        <span class="n">shape_dict</span><span class="p">[</span><span class="s2">&quot;pixel_statistics&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="mi">6</span> <span class="o">*</span> <span class="p">[</span><span class="s2">&quot;pixel_statistics&quot;</span><span class="p">])</span>

        <span class="c1"># These are the basic building blocks of the scale assignments for many</span>
        <span class="c1"># of the statistics calculated by the PortillaSimoncelli model.</span>
        <span class="n">scales</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span><span class="p">)</span>
        <span class="c1"># the cross-scale correlations exclude the coarsest scale</span>
        <span class="n">scales_without_coarsest</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="c1"># the statistics computed on the reconstructed bandpass images have an</span>
        <span class="c1"># extra scale corresponding to the lowpass residual</span>
        <span class="n">scales_with_lowpass</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
            <span class="n">scales</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="o">+</span> <span class="p">[</span><span class="s2">&quot;residual_lowpass&quot;</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">object</span>
        <span class="p">)</span>

        <span class="c1"># now we go through each statistic in order and create a dummy array</span>
        <span class="c1"># full of 1s with the same shape as the actual statistic (excluding the</span>
        <span class="c1"># batch and channel dimensions, as each stat is computed independently</span>
        <span class="c1"># across those dimensions). We then multiply it by one of the scales</span>
        <span class="c1"># arrays above to turn those 1s into values describing the</span>
        <span class="c1"># corresponding scale.</span>

        <span class="n">auto_corr_mag</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span>
            <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">spatial_corr_width</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">spatial_corr_width</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">n_orientations</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span><span class="p">,</span>
            <span class="p">),</span>
            <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1"># this rearrange call is turning scales from 1d with shape (n_scales, )</span>
        <span class="c1"># to 4d with shape (1, 1, n_scales, 1), so that it matches</span>
        <span class="c1"># auto_corr_mag. the following rearrange calls do similar.</span>
        <span class="n">auto_corr_mag</span> <span class="o">*=</span> <span class="n">einops</span><span class="o">.</span><span class="n">rearrange</span><span class="p">(</span><span class="n">scales</span><span class="p">,</span> <span class="s2">&quot;s -&gt; 1 1 1 s&quot;</span><span class="p">)</span>
        <span class="n">shape_dict</span><span class="p">[</span><span class="s2">&quot;auto_correlation_magnitude&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">auto_corr_mag</span>

        <span class="n">shape_dict</span><span class="p">[</span><span class="s2">&quot;skew_reconstructed&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">scales_with_lowpass</span>

        <span class="n">shape_dict</span><span class="p">[</span><span class="s2">&quot;kurtosis_reconstructed&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">scales_with_lowpass</span>

        <span class="n">auto_corr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span>
            <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">spatial_corr_width</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">spatial_corr_width</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
            <span class="p">),</span>
            <span class="n">dtype</span><span class="o">=</span><span class="nb">object</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">auto_corr</span> <span class="o">*=</span> <span class="n">einops</span><span class="o">.</span><span class="n">rearrange</span><span class="p">(</span><span class="n">scales_with_lowpass</span><span class="p">,</span> <span class="s2">&quot;s -&gt; 1 1 s&quot;</span><span class="p">)</span>
        <span class="n">shape_dict</span><span class="p">[</span><span class="s2">&quot;auto_correlation_reconstructed&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">auto_corr</span>

        <span class="n">shape_dict</span><span class="p">[</span><span class="s2">&quot;std_reconstructed&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">scales_with_lowpass</span>

        <span class="n">cross_orientation_corr_mag</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span>
            <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_orientations</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_orientations</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span><span class="p">),</span>
            <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">cross_orientation_corr_mag</span> <span class="o">*=</span> <span class="n">einops</span><span class="o">.</span><span class="n">rearrange</span><span class="p">(</span><span class="n">scales</span><span class="p">,</span> <span class="s2">&quot;s -&gt; 1 1 s&quot;</span><span class="p">)</span>
        <span class="n">shape_dict</span><span class="p">[</span><span class="s2">&quot;cross_orientation_correlation_magnitude&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">cross_orientation_corr_mag</span>
        <span class="p">)</span>

        <span class="n">mags_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">n_orientations</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
        <span class="n">mags_std</span> <span class="o">*=</span> <span class="n">einops</span><span class="o">.</span><span class="n">rearrange</span><span class="p">(</span><span class="n">scales</span><span class="p">,</span> <span class="s2">&quot;s -&gt; 1 s&quot;</span><span class="p">)</span>
        <span class="n">shape_dict</span><span class="p">[</span><span class="s2">&quot;magnitude_std&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">mags_std</span>

        <span class="n">cross_scale_corr_mag</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span>
            <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_orientations</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_orientations</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">cross_scale_corr_mag</span> <span class="o">*=</span> <span class="n">einops</span><span class="o">.</span><span class="n">rearrange</span><span class="p">(</span><span class="n">scales_without_coarsest</span><span class="p">,</span> <span class="s2">&quot;s -&gt; 1 1 s&quot;</span><span class="p">)</span>
        <span class="n">shape_dict</span><span class="p">[</span><span class="s2">&quot;cross_scale_correlation_magnitude&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">cross_scale_corr_mag</span>

        <span class="n">cross_scale_corr_real</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span>
            <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_orientations</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_orientations</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">cross_scale_corr_real</span> <span class="o">*=</span> <span class="n">einops</span><span class="o">.</span><span class="n">rearrange</span><span class="p">(</span><span class="n">scales_without_coarsest</span><span class="p">,</span> <span class="s2">&quot;s -&gt; 1 1 s&quot;</span><span class="p">)</span>
        <span class="n">shape_dict</span><span class="p">[</span><span class="s2">&quot;cross_scale_correlation_real&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">cross_scale_corr_real</span>

        <span class="n">shape_dict</span><span class="p">[</span><span class="s2">&quot;var_highpass_residual&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="s2">&quot;residual_highpass&quot;</span><span class="p">])</span>

        <span class="k">return</span> <span class="n">shape_dict</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_create_necessary_stats_dict</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">scales_shape_dict</span><span class="p">:</span> <span class="n">OrderedDict</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">OrderedDict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create mask specifying the necessary statistics.</span>

<span class="sd">        Some of the statistics computed by the model are redundant, due to</span>
<span class="sd">        symmetries. For example, about half of the values in the</span>
<span class="sd">        autocorrelation matrices are duplicates. See the Portilla-Simoncelli</span>
<span class="sd">        notebook for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        scales_shape_dict</span>
<span class="sd">            Dictionary defining shape and associated scales of each computed</span>
<span class="sd">            statistic.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        necessary_stats_dict</span>
<span class="sd">            Dictionary defining which statistics are necessary (i.e., not</span>
<span class="sd">            redundant). Will have the same keys as scales_shape_dict, with the</span>
<span class="sd">            values being boolean tensors of the same shape as</span>
<span class="sd">            scales_shape_dict&#39;s corresponding values. True denotes the</span>
<span class="sd">            statistics that will be included in the model&#39;s output, while False</span>
<span class="sd">            denotes the redundant ones we will toss.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># numpydoc ignore=EX01</span>
        <span class="n">mask_dict</span> <span class="o">=</span> <span class="n">scales_shape_dict</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="c1"># Pre-compute some necessary indices.</span>
        <span class="c1"># Lower triangular indices (including diagonal), for auto correlations</span>
        <span class="n">tril_inds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tril_indices</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">spatial_corr_width</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">spatial_corr_width</span><span class="p">)</span>
        <span class="c1"># Get the second half of the diagonal, i.e., everything from the center</span>
        <span class="c1"># element on. These are all repeated for the auto correlations. (As</span>
        <span class="c1"># these are autocorrelations (rather than auto-covariance) matrices,</span>
        <span class="c1"># they&#39;ve been normalized by the variance and so the center element is</span>
        <span class="c1"># always 1, and thus uninformative)</span>
        <span class="n">diag_repeated</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span>
            <span class="n">start</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">spatial_corr_width</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">spatial_corr_width</span>
        <span class="p">)</span>
        <span class="c1"># Upper triangle indices, including diagonal. These are redundant stats</span>
        <span class="c1"># for cross_orientation_correlation_magnitude (because we&#39;ve normalized</span>
        <span class="c1"># this matrix to be true cross-correlations, the diagonals are all 1,</span>
        <span class="c1"># like for the auto-correlations)</span>
        <span class="n">triu_inds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">triu_indices</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_orientations</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_orientations</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">mask_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="p">[</span>
                <span class="s2">&quot;auto_correlation_magnitude&quot;</span><span class="p">,</span>
                <span class="s2">&quot;auto_correlation_reconstructed&quot;</span><span class="p">,</span>
            <span class="p">]:</span>
                <span class="c1"># Symmetry M_{i,j} = M_{n-i+1, n-j+1}</span>
                <span class="c1"># Start with all False, then place True in necessary stats.</span>
                <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
                <span class="n">mask</span><span class="p">[</span><span class="n">tril_inds</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">tril_inds</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="c1"># if spatial_corr_width is even, then the first row is not</span>
                <span class="c1"># redundant with anything either</span>
                <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">mod</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">spatial_corr_width</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">mask</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="n">mask</span><span class="p">[</span><span class="n">diag_repeated</span><span class="p">,</span> <span class="n">diag_repeated</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">elif</span> <span class="n">k</span> <span class="o">==</span> <span class="s2">&quot;cross_orientation_correlation_magnitude&quot;</span><span class="p">:</span>
                <span class="c1"># Symmetry M_{i,j} = M_{j,i}.</span>
                <span class="c1"># Start with all True, then place False in redundant stats.</span>
                <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
                <span class="n">mask</span><span class="p">[</span><span class="n">triu_inds</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">triu_inds</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># all of the other stats have no redundancies</span>
                <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
            <span class="n">mask_dict</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">mask</span>
        <span class="k">return</span> <span class="n">mask_dict</span>

<div class="viewcode-block" id="PortillaSimoncelli.forward">
<a class="viewcode-back" href="../../../../generated/plenoptic.simulate.models.portilla_simoncelli.html#plenoptic.simulate.models.portilla_simoncelli.PortillaSimoncelli.forward">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">scales</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">SCALES_TYPE</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generate Texture Statistics representation of an image.</span>

<span class="sd">        Note that separate batches and channels are analyzed in parallel.</span>

<span class="sd">        For any representation that contains info across scales, the scales always run</span>
<span class="sd">        from fine to coarse, representing all orientations at a given scale before</span>
<span class="sd">        moving on.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        image</span>
<span class="sd">            A 4d tensor (batch, channel, height, width) containing the image(s) to</span>
<span class="sd">            analyze.</span>
<span class="sd">        scales</span>
<span class="sd">            Which scales to include in the returned representation. If None, we</span>
<span class="sd">            include all scales. Otherwise, can contain subset of values present</span>
<span class="sd">            in this model&#39;s ``scales`` attribute, and the returned tensor will</span>
<span class="sd">            then contain the subset corresponding to those scales.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        representation_tensor</span>
<span class="sd">            3d tensor of shape (batch, channel, stats) containing the measured</span>
<span class="sd">            texture statistics.</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If ``image`` is not 4d or has a dtype other than float or complex.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; import plenoptic as po</span>
<span class="sd">        &gt;&gt;&gt; img = po.data.reptile_skin()</span>
<span class="sd">        &gt;&gt;&gt; portilla_simoncelli_model = po.simul.PortillaSimoncelli(img.shape[2:])</span>
<span class="sd">        &gt;&gt;&gt; representation_tensor = portilla_simoncelli_model(img)</span>
<span class="sd">        &gt;&gt;&gt; representation_tensor.shape</span>
<span class="sd">        torch.Size([1, 1, 1046])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">validate_input</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

        <span class="c1"># pyr_dict is the dictionary of complex-valued tensors returned by the</span>
        <span class="c1"># steerable pyramid. pyr_coeffs is a list (length n_scales) of 5d</span>
        <span class="c1"># tensors, each of shape (batch, channel, scales, n_orientations,</span>
        <span class="c1"># height, width) containing the complex-valued oriented bands, while</span>
        <span class="c1"># highpass is a real-valued 4d tensor of shape (batch, channel, height,</span>
        <span class="c1"># width). Note that the residual lowpass in pyr_dict has been demeaned.</span>
        <span class="c1"># We keep both the dict and list of pyramid coefficients because we</span>
        <span class="c1"># need the dictionary for reconstructing the image done later on.</span>
        <span class="n">pyr_dict</span><span class="p">,</span> <span class="n">pyr_coeffs</span><span class="p">,</span> <span class="n">highpass</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_pyr_coeffs</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

        <span class="c1"># Now, we create several intermediate representations that we&#39;ll use to</span>
        <span class="c1"># compute the texture statistics later.</span>

        <span class="c1"># First, two intermediate dictionaries: magnitude_pyr_coeffs and</span>
        <span class="c1"># real_pyr_coeffs, which contain the demeaned magnitude of the pyramid</span>
        <span class="c1"># coefficients and the real part of the pyramid coefficients</span>
        <span class="c1"># respectively.</span>
        <span class="p">(</span>
            <span class="n">mag_pyr_coeffs</span><span class="p">,</span>
            <span class="n">real_pyr_coeffs</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_intermediate_representations</span><span class="p">(</span><span class="n">pyr_coeffs</span><span class="p">)</span>

        <span class="c1"># Then, the reconstructed lowpass image at each scale. (this is a list</span>
        <span class="c1"># of length n_scales+1 containing tensors of shape (batch, channel,</span>
        <span class="c1"># height, width))</span>
        <span class="n">reconstructed_images</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_reconstruct_lowpass_at_each_scale</span><span class="p">(</span><span class="n">pyr_dict</span><span class="p">)</span>
        <span class="c1"># the reconstructed_images list goes from coarse-to-fine, but we want</span>
        <span class="c1"># each of the stats computed from it to go from fine-to-coarse, so we</span>
        <span class="c1"># reverse its direction.</span>
        <span class="n">reconstructed_images</span> <span class="o">=</span> <span class="n">reconstructed_images</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="c1"># Now, start calculating the PS texture stats.</span>

        <span class="c1"># Calculate pixel statistics (mean, variance, skew, kurtosis, min,</span>
        <span class="c1"># max).</span>
        <span class="n">pixel_stats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_pixel_stats</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

        <span class="c1"># Compute the central autocorrelation of the coefficient magnitudes. This is a</span>
        <span class="c1"># tensor of shape: (batch, channel, spatial_corr_width, spatial_corr_width,</span>
        <span class="c1"># n_orientations, n_scales). var_mags is a tensor of shape (batch, channel,</span>
        <span class="c1"># n_orientations, n_scales)</span>
        <span class="n">autocorr_mags</span><span class="p">,</span> <span class="n">mags_var</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_autocorr</span><span class="p">(</span><span class="n">mag_pyr_coeffs</span><span class="p">)</span>
        <span class="c1"># mags_var is the variance of the magnitude coefficients at each scale (it&#39;s an</span>
        <span class="c1"># intermediary of the computation of the auto-correlations). We take the square</span>
        <span class="c1"># root to get the standard deviation.</span>
        <span class="n">mags_std</span> <span class="o">=</span> <span class="n">mags_var</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>

        <span class="c1"># Compute the central autocorrelation of the reconstructed lowpass</span>
        <span class="c1"># images at each scale (and their variances). autocorr_recon is a</span>
        <span class="c1"># tensor of shape (batch, channel, spatial_corr_width,</span>
        <span class="c1"># spatial_corr_width, n_scales+1), and var_recon is a tensor of shape</span>
        <span class="c1"># (batch, channel, n_scales+1)</span>
        <span class="n">autocorr_recon</span><span class="p">,</span> <span class="n">var_recon</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_autocorr</span><span class="p">(</span><span class="n">reconstructed_images</span><span class="p">)</span>
        <span class="c1"># Compute the standard deviation, skew, and kurtosis of each</span>
        <span class="c1"># reconstructed lowpass image. std_recon, skew_recon, and</span>
        <span class="c1"># kurtosis_recon will all end up as tensors of shape (batch, channel,</span>
        <span class="c1"># n_scales+1)</span>
        <span class="n">std_recon</span> <span class="o">=</span> <span class="n">var_recon</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>
        <span class="n">skew_recon</span><span class="p">,</span> <span class="n">kurtosis_recon</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_skew_kurtosis_recon</span><span class="p">(</span>
            <span class="n">reconstructed_images</span><span class="p">,</span> <span class="n">var_recon</span><span class="p">,</span> <span class="n">pixel_stats</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
        <span class="p">)</span>

        <span class="c1"># Compute the cross-orientation correlations between the magnitude</span>
        <span class="c1"># coefficients at each scale. this will be a tensor of shape (batch,</span>
        <span class="c1"># channel, n_orientations, n_orientations, n_scales)</span>
        <span class="n">cross_ori_corr_mags</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_cross_correlation</span><span class="p">(</span>
            <span class="n">mag_pyr_coeffs</span><span class="p">,</span> <span class="n">mag_pyr_coeffs</span><span class="p">,</span> <span class="n">mags_var</span><span class="p">,</span> <span class="n">mags_var</span>
        <span class="p">)</span>

        <span class="c1"># If we have more than one scale, compute the cross-scale correlations</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># First, double the phase the coefficients, so we can correctly</span>
            <span class="c1"># compute correlations across scales.</span>
            <span class="p">(</span>
                <span class="n">phase_doubled_mags</span><span class="p">,</span>
                <span class="n">phase_doubled_sep</span><span class="p">,</span>
            <span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_double_phase_pyr_coeffs</span><span class="p">(</span><span class="n">pyr_coeffs</span><span class="p">)</span>
            <span class="c1"># Compute the cross-scale correlations between the magnitude</span>
            <span class="c1"># coefficients. For each coefficient, we&#39;re correlating it with the</span>
            <span class="c1"># coefficients at the next-coarsest scale. this will be a tensor of</span>
            <span class="c1"># shape (batch, channel, n_orientations, n_orientations,</span>
            <span class="c1"># n_scales-1)</span>
            <span class="n">cross_scale_corr_mags</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_cross_correlation</span><span class="p">(</span>
                <span class="n">mag_pyr_coeffs</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">phase_doubled_mags</span><span class="p">,</span> <span class="n">mags_var</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="p">)</span>
            <span class="c1"># Compute the cross-scale correlations between the real</span>
            <span class="c1"># coefficients and the real and imaginary coefficients at the next</span>
            <span class="c1"># coarsest scale. this will be a tensor of shape (batch, channel,</span>
            <span class="c1"># n_orientations, 2*n_orientations, n_scales-1)</span>
            <span class="n">cross_scale_corr_real</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_cross_correlation</span><span class="p">(</span>
                <span class="n">real_pyr_coeffs</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">phase_doubled_sep</span>
            <span class="p">)</span>

        <span class="c1"># Compute the variance of the highpass residual</span>
        <span class="n">var_highpass_residual</span> <span class="o">=</span> <span class="n">highpass</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>

        <span class="c1"># Now, combine all these stats together, first into a list</span>
        <span class="n">all_stats</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">pixel_stats</span><span class="p">,</span>
            <span class="n">autocorr_mags</span><span class="p">,</span>
            <span class="n">skew_recon</span><span class="p">,</span>
            <span class="n">kurtosis_recon</span><span class="p">,</span>
            <span class="n">autocorr_recon</span><span class="p">,</span>
            <span class="n">std_recon</span><span class="p">,</span>
            <span class="n">cross_ori_corr_mags</span><span class="p">,</span>
            <span class="n">mags_std</span><span class="p">,</span>
        <span class="p">]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">all_stats</span> <span class="o">+=</span> <span class="p">[</span><span class="n">cross_scale_corr_mags</span><span class="p">,</span> <span class="n">cross_scale_corr_real</span><span class="p">]</span>
        <span class="n">all_stats</span> <span class="o">+=</span> <span class="p">[</span><span class="n">var_highpass_residual</span><span class="p">]</span>
        <span class="c1"># And then pack them into a 3d tensor</span>
        <span class="n">representation_tensor</span><span class="p">,</span> <span class="n">pack_info</span> <span class="o">=</span> <span class="n">einops</span><span class="o">.</span><span class="n">pack</span><span class="p">(</span><span class="n">all_stats</span><span class="p">,</span> <span class="s2">&quot;b c *&quot;</span><span class="p">)</span>

        <span class="c1"># the only time when this is None is during testing, when we make sure</span>
        <span class="c1"># that our assumptions are all valid.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_necessary_stats_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># store this so we can unpack this info (only possible when we&#39;ve</span>
            <span class="c1"># discarded no stats)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_pack_info</span> <span class="o">=</span> <span class="n">pack_info</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Throw away all redundant statistics</span>
            <span class="n">representation_tensor</span> <span class="o">=</span> <span class="n">representation_tensor</span><span class="o">.</span><span class="n">index_select</span><span class="p">(</span>
                <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_necessary_stats_mask</span>
            <span class="p">)</span>

        <span class="c1"># Return the subset of stats corresponding to the specified scale.</span>
        <span class="k">if</span> <span class="n">scales</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">representation_tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">remove_scales</span><span class="p">(</span><span class="n">representation_tensor</span><span class="p">,</span> <span class="n">scales</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">representation_tensor</span></div>


<div class="viewcode-block" id="PortillaSimoncelli.remove_scales">
<a class="viewcode-back" href="../../../../generated/plenoptic.simulate.models.portilla_simoncelli.html#plenoptic.simulate.models.portilla_simoncelli.PortillaSimoncelli.remove_scales">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">remove_scales</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">representation_tensor</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">scales_to_keep</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">SCALES_TYPE</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Remove statistics not associated with scales.</span>

<span class="sd">        For a given representation_tensor and a list of scales_to_keep, this</span>
<span class="sd">        attribute removes all statistics *not* associated with those scales.</span>

<span class="sd">        Note that calling this method will always remove statistics.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        representation_tensor</span>
<span class="sd">            3d tensor containing the measured representation statistics.</span>
<span class="sd">        scales_to_keep</span>
<span class="sd">            Which scales to include in the returned representation. Can contain</span>
<span class="sd">            subset of values present in this model&#39;s ``scales`` attribute, and</span>
<span class="sd">            the returned tensor will then contain the subset of the full</span>
<span class="sd">            representation corresponding to those scales.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        limited_representation_tensor</span>
<span class="sd">            Representation tensor with some statistics removed.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; import plenoptic as po</span>
<span class="sd">        &gt;&gt;&gt; img = po.data.reptile_skin()</span>
<span class="sd">        &gt;&gt;&gt; portilla_simoncelli_model = po.simul.PortillaSimoncelli(img.shape[2:])</span>
<span class="sd">        &gt;&gt;&gt; representation_tensor = portilla_simoncelli_model(img)</span>
<span class="sd">        &gt;&gt;&gt; representation_tensor.shape</span>
<span class="sd">        torch.Size([1, 1, 1046])</span>
<span class="sd">        &gt;&gt;&gt; limited_representation_tensor = portilla_simoncelli_model.remove_scales(</span>
<span class="sd">        ...     representation_tensor, scales_to_keep=[0]</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; limited_representation_tensor.shape</span>
<span class="sd">        torch.Size([1, 1, 261])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># this is necessary because object is the dtype of</span>
        <span class="c1"># self._representation_scales</span>
        <span class="n">scales_to_keep</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">scales_to_keep</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">object</span><span class="p">)</span>
        <span class="c1"># np.isin returns a 1d boolean array of the same shape as</span>
        <span class="c1"># self._representation_scales with True at each location where that</span>
        <span class="c1"># value appears in scales_to_keep. where then converts this boolean</span>
        <span class="c1"># array into indices</span>
        <span class="n">ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_representation_scales</span><span class="p">,</span> <span class="n">scales_to_keep</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">ind</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">ind</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">representation_tensor</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">representation_tensor</span><span class="o">.</span><span class="n">index_select</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">ind</span><span class="p">)</span></div>


<div class="viewcode-block" id="PortillaSimoncelli.convert_to_tensor">
<a class="viewcode-back" href="../../../../generated/plenoptic.simulate.models.portilla_simoncelli.html#plenoptic.simulate.models.portilla_simoncelli.PortillaSimoncelli.convert_to_tensor">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">convert_to_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">representation_dict</span><span class="p">:</span> <span class="n">OrderedDict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Convert dictionary of statistics to a tensor.</span>

<span class="sd">        The output has shape (batch, channel, n_statistics), flattening and</span>
<span class="sd">        concatenating across all statistic classes. The dictionary representation</span>
<span class="sd">        may be easier to make sense of.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        representation_dict</span>
<span class="sd">             Dictionary of representation.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        rep</span>
<span class="sd">            3d tensor of statistics.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        convert_to_dict</span>
<span class="sd">            Convert tensor representation to dictionary.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; import plenoptic as po</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>
<span class="sd">        &gt;&gt;&gt; img = po.data.reptile_skin()</span>
<span class="sd">        &gt;&gt;&gt; portilla_simoncelli_model = po.simul.PortillaSimoncelli(img.shape[2:])</span>
<span class="sd">        &gt;&gt;&gt; representation_tensor = portilla_simoncelli_model(img)</span>
<span class="sd">        &gt;&gt;&gt; representation_dict = portilla_simoncelli_model.convert_to_dict(</span>
<span class="sd">        ...     representation_tensor</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; representation_tensor_new = portilla_simoncelli_model.convert_to_tensor(</span>
<span class="sd">        ...     representation_dict</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; torch.equal(representation_tensor, representation_tensor_new)</span>
<span class="sd">        True</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">rep</span> <span class="o">=</span> <span class="n">einops</span><span class="o">.</span><span class="n">pack</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">representation_dict</span><span class="o">.</span><span class="n">values</span><span class="p">()),</span> <span class="s2">&quot;b c *&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="c1"># then get rid of all the nans / unnecessary stats</span>
        <span class="k">return</span> <span class="n">rep</span><span class="o">.</span><span class="n">index_select</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_necessary_stats_mask</span><span class="p">)</span></div>


<div class="viewcode-block" id="PortillaSimoncelli.convert_to_dict">
<a class="viewcode-back" href="../../../../generated/plenoptic.simulate.models.portilla_simoncelli.html#plenoptic.simulate.models.portilla_simoncelli.PortillaSimoncelli.convert_to_dict">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">convert_to_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">representation_tensor</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">OrderedDict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Convert tensor of statistics to a dictionary.</span>

<span class="sd">        While the tensor representation is required by plenoptic&#39;s synthesis</span>
<span class="sd">        objects, the dictionary representation is easier to manually inspect.</span>

<span class="sd">        This dictionary will contain NaNs in its values: these are placeholders</span>
<span class="sd">        for the redundant statistics.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        representation_tensor</span>
<span class="sd">            3d tensor of statistics.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        rep</span>
<span class="sd">            Dictionary of representation, with informative keys.</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If ``representation_tensor`` has an unexpected number of elements. This can</span>
<span class="sd">            happen if some elements were manually removed from</span>
<span class="sd">            ``representation_tensor``, if a non-``None`` value was passed to ``forward``</span>
<span class="sd">            when computing it, or if it was computed using a different instantiation of</span>
<span class="sd">            the model.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        convert_to_tensor:</span>
<span class="sd">            Convert dictionary representation to tensor.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; import plenoptic as po</span>
<span class="sd">        &gt;&gt;&gt; img = po.data.reptile_skin()</span>
<span class="sd">        &gt;&gt;&gt; portilla_simoncelli_model = po.simul.PortillaSimoncelli(</span>
<span class="sd">        ...     img.shape[2:], n_scales=3</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; representation_tensor = portilla_simoncelli_model(img)</span>
<span class="sd">        &gt;&gt;&gt; representation_dict = portilla_simoncelli_model.convert_to_dict(</span>
<span class="sd">        ...     representation_tensor</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; # We will go through and examine each of these keys individually</span>
<span class="sd">        &gt;&gt;&gt; # Shape is (batch, channel, 6): first four moments plus min and max</span>
<span class="sd">        &gt;&gt;&gt; # of input image</span>
<span class="sd">        &gt;&gt;&gt; representation_dict[&quot;pixel_statistics&quot;].shape</span>
<span class="sd">        torch.Size([1, 1, 6])</span>
<span class="sd">        &gt;&gt;&gt; # Shape is (batch, channel, spatial_corr_width, spatial_corr_width,</span>
<span class="sd">        &gt;&gt;&gt; # n_orientations, n_scales)</span>
<span class="sd">        &gt;&gt;&gt; representation_dict[&quot;auto_correlation_magnitude&quot;].shape</span>
<span class="sd">        torch.Size([1, 1, 9, 9, 4, 3])</span>
<span class="sd">        &gt;&gt;&gt; # Shape is (batch, channel, n_scales+1)</span>
<span class="sd">        &gt;&gt;&gt; representation_dict[&quot;skew_reconstructed&quot;].shape</span>
<span class="sd">        torch.Size([1, 1, 4])</span>
<span class="sd">        &gt;&gt;&gt; # Shape is (batch, channel, n_scales+1)</span>
<span class="sd">        &gt;&gt;&gt; representation_dict[&quot;kurtosis_reconstructed&quot;].shape</span>
<span class="sd">        torch.Size([1, 1, 4])</span>
<span class="sd">        &gt;&gt;&gt; # Shape is (batch, channel, spatial_corr_width, spatial_corr_width,</span>
<span class="sd">        &gt;&gt;&gt; # n_scales+1)</span>
<span class="sd">        &gt;&gt;&gt; representation_dict[&quot;auto_correlation_reconstructed&quot;].shape</span>
<span class="sd">        torch.Size([1, 1, 9, 9, 4])</span>
<span class="sd">        &gt;&gt;&gt; # Shape is (batch, channel, n_scales+1)</span>
<span class="sd">        &gt;&gt;&gt; representation_dict[&quot;std_reconstructed&quot;].shape</span>
<span class="sd">        torch.Size([1, 1, 4])</span>
<span class="sd">        &gt;&gt;&gt; # Shape is (batch, channel, n_orientations, n_orientations, n_scales)</span>
<span class="sd">        &gt;&gt;&gt; representation_dict[&quot;cross_orientation_correlation_magnitude&quot;].shape</span>
<span class="sd">        torch.Size([1, 1, 4, 4, 3])</span>
<span class="sd">        &gt;&gt;&gt; # Shape is (batch, channel, n_orientations, n_scales)</span>
<span class="sd">        &gt;&gt;&gt; representation_dict[&quot;magnitude_std&quot;].shape</span>
<span class="sd">        torch.Size([1, 1, 4, 3])</span>
<span class="sd">        &gt;&gt;&gt; # Shape is (batch, channel, n_orientations, n_orientations, n_scales-1)</span>
<span class="sd">        &gt;&gt;&gt; representation_dict[&quot;cross_scale_correlation_magnitude&quot;].shape</span>
<span class="sd">        torch.Size([1, 1, 4, 4, 2])</span>
<span class="sd">        &gt;&gt;&gt; # Shape is (batch, channel, n_orientations, 2*n_orientations, n_scales-1)</span>
<span class="sd">        &gt;&gt;&gt; representation_dict[&quot;cross_scale_correlation_real&quot;].shape</span>
<span class="sd">        torch.Size([1, 1, 4, 8, 2])</span>
<span class="sd">        &gt;&gt;&gt; # Shape is (batch, channel, 1)</span>
<span class="sd">        &gt;&gt;&gt; representation_dict[&quot;var_highpass_residual&quot;].shape</span>
<span class="sd">        torch.Size([1, 1, 1])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">representation_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_representation_scales</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;representation tensor is the wrong length (expected&quot;</span>
                <span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_representation_scales</span><span class="p">)</span><span class="si">}</span><span class="s2"> but got&quot;</span>
                <span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="n">representation_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">)! Did you remove some of&quot;</span>
                <span class="s2">&quot; the scales? (i.e., by setting scales in the forward pass)?&quot;</span>
                <span class="s2">&quot; convert_to_dict does not support such tensors.&quot;</span>
            <span class="p">)</span>

        <span class="n">rep</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_necessary_stats_dict</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">n_filled</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">rep</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="c1"># each statistic is a tensor with batch and channel dimensions as</span>
            <span class="c1"># found in representation_tensor and all the other dimensions</span>
            <span class="c1"># determined by the values in necessary_stats_dict.</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="o">*</span><span class="n">representation_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">],</span> <span class="o">*</span><span class="n">v</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
            <span class="n">new_v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nan</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span>
                <span class="n">shape</span><span class="p">,</span>
                <span class="n">dtype</span><span class="o">=</span><span class="n">representation_tensor</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                <span class="n">device</span><span class="o">=</span><span class="n">representation_tensor</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="c1"># v.sum() gives the number of necessary elements from this stat</span>
            <span class="n">this_stat_vec</span> <span class="o">=</span> <span class="n">representation_tensor</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">n_filled</span> <span class="p">:</span> <span class="n">n_filled</span> <span class="o">+</span> <span class="n">v</span><span class="o">.</span><span class="n">sum</span><span class="p">()]</span>
            <span class="c1"># use boolean indexing to put the values from new_stat_vec in the</span>
            <span class="c1"># appropriate place</span>
            <span class="n">new_v</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">v</span><span class="p">]</span> <span class="o">=</span> <span class="n">this_stat_vec</span>
            <span class="n">rep</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_v</span>
            <span class="n">n_filled</span> <span class="o">+=</span> <span class="n">v</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">rep</span></div>


    <span class="k">def</span><span class="w"> </span><span class="nf">_compute_pyr_coeffs</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">image</span><span class="p">:</span> <span class="n">Tensor</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">OrderedDict</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute pyramid coefficients of image.</span>

<span class="sd">        Note that the residual lowpass has been demeaned independently for each</span>
<span class="sd">        batch and channel (and this is true of the lowpass returned separately</span>
<span class="sd">        as well as the one included in pyr_coeffs_dict).</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        image</span>
<span class="sd">            4d tensor of shape (batch, channel, height, width) containing the</span>
<span class="sd">            image.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        pyr_coeffs_dict</span>
<span class="sd">            OrderedDict of containing all pyramid coefficients.</span>
<span class="sd">        pyr_coeffs</span>
<span class="sd">            List of length n_scales, containing 5d tensors of shape (batch,</span>
<span class="sd">            channel, n_orientations, height, width) containing the complex-valued</span>
<span class="sd">            oriented bands (note that height and width shrink by half on each</span>
<span class="sd">            scale). This excludes the residual highpass and lowpass bands.</span>
<span class="sd">        highpass</span>
<span class="sd">            The residual highpass as a real-valued 4d tensor (batch, channel,</span>
<span class="sd">            height, width).</span>
<span class="sd">        lowpass</span>
<span class="sd">            The residual lowpass as a real-valued 4d tensor (batch, channel,</span>
<span class="sd">            height, width). This tensor has been demeaned (independently for</span>
<span class="sd">            each batch and channel).</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># numpydoc ignore=EX01</span>
        <span class="n">pyr_coeffs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pyr</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
        <span class="c1"># separate out the residuals and demean the residual lowpass</span>
        <span class="n">lowpass</span> <span class="o">=</span> <span class="n">pyr_coeffs</span><span class="p">[</span><span class="s2">&quot;residual_lowpass&quot;</span><span class="p">]</span>
        <span class="n">lowpass</span> <span class="o">=</span> <span class="n">lowpass</span> <span class="o">-</span> <span class="n">lowpass</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">pyr_coeffs</span><span class="p">[</span><span class="s2">&quot;residual_lowpass&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">lowpass</span>
        <span class="n">highpass</span> <span class="o">=</span> <span class="n">pyr_coeffs</span><span class="p">[</span><span class="s2">&quot;residual_highpass&quot;</span><span class="p">]</span>

        <span class="c1"># This is a list of tensors, one for each scale, where each tensor is</span>
        <span class="c1"># of shape (batch, channel, n_orientations, height, width) (note that</span>
        <span class="c1"># height and width halves on each scale)</span>
        <span class="n">coeffs_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">pyr_coeffs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span><span class="p">)]</span>
        <span class="k">return</span> <span class="n">pyr_coeffs</span><span class="p">,</span> <span class="n">coeffs_list</span><span class="p">,</span> <span class="n">highpass</span><span class="p">,</span> <span class="n">lowpass</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_compute_pixel_stats</span><span class="p">(</span><span class="n">image</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the PS pixel stats: first four moments, min, and max.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        image</span>
<span class="sd">            4d tensor of shape (batch, channel, height, width) containing input</span>
<span class="sd">            image. Stats are computed independently for each batch and channel.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        pixel_stats</span>
<span class="sd">            3d tensor of shape (batch, channel, 6) containing the mean,</span>
<span class="sd">            variance, skew, kurtosis, minimum pixel value, and maximum pixel</span>
<span class="sd">            value (in that order).</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># numpydoc ignore=ES01,EX01</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="c1"># we use torch.var instead of plenoptic.tools.variance, because our</span>
        <span class="c1"># variance is the uncorrected (or sample) variance and we want the</span>
        <span class="c1"># corrected one here.</span>
        <span class="n">var</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">skew</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">skew</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">var</span><span class="o">=</span><span class="n">var</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">kurtosis</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">kurtosis</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">var</span><span class="o">=</span><span class="n">var</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="c1"># can&#39;t compute min/max over two dims simultaneously with</span>
        <span class="c1"># torch.min/max, so use einops</span>
        <span class="n">img_min</span> <span class="o">=</span> <span class="n">einops</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="s2">&quot;b c h w -&gt; b c&quot;</span><span class="p">,</span> <span class="s2">&quot;min&quot;</span><span class="p">)</span>
        <span class="n">img_max</span> <span class="o">=</span> <span class="n">einops</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="s2">&quot;b c h w -&gt; b c&quot;</span><span class="p">,</span> <span class="s2">&quot;max&quot;</span><span class="p">)</span>
        <span class="c1"># mean needed to be unflattened to be used by skew and kurtosis</span>
        <span class="c1"># correctly, but we&#39;ll want it to be flattened like this in the final</span>
        <span class="c1"># representation tensor</span>
        <span class="k">return</span> <span class="n">einops</span><span class="o">.</span><span class="n">pack</span><span class="p">([</span><span class="n">mean</span><span class="p">,</span> <span class="n">var</span><span class="p">,</span> <span class="n">skew</span><span class="p">,</span> <span class="n">kurtosis</span><span class="p">,</span> <span class="n">img_min</span><span class="p">,</span> <span class="n">img_max</span><span class="p">],</span> <span class="s2">&quot;b c *&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_compute_intermediate_representations</span><span class="p">(</span>
        <span class="n">pyr_coeffs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Tensor</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="n">Tensor</span><span class="p">],</span> <span class="nb">list</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute useful intermediate representations.</span>

<span class="sd">        These representations are:</span>
<span class="sd">          1) demeaned magnitude of the pyramid coefficients,</span>
<span class="sd">          2) real part of the pyramid coefficients</span>

<span class="sd">        These two are used in computing some of the texture representation.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        pyr_coeffs</span>
<span class="sd">            Complex steerable pyramid coefficients (without residuals), as list</span>
<span class="sd">            of length n_scales, containing 5d tensors of shape (batch, channel,</span>
<span class="sd">            n_orientations, height, width).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        magnitude_pyr_coeffs</span>
<span class="sd">           List of length n_scales, containing 5d tensors of shape (batch,</span>
<span class="sd">           channel, n_orientations, height, width) (same as ``pyr_coeffs``),</span>
<span class="sd">           containing the demeaned magnitude of the steerable pyramid</span>
<span class="sd">           coefficients (i.e., ``coeffs.abs() - coeffs.abs().mean((-2, -1))``).</span>
<span class="sd">        real_pyr_coeffs :</span>
<span class="sd">           List of length n_scales, containing 5d tensors of shape (batch,</span>
<span class="sd">           channel, n_orientations, height, width) (same as ``pyr_coeffs``),</span>
<span class="sd">           containing the real components of the coefficients (i.e.</span>
<span class="sd">           ``coeffs.real``).</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># numpydoc ignore=EX01</span>
        <span class="n">magnitude_pyr_coeffs</span> <span class="o">=</span> <span class="p">[</span><span class="n">coeff</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span> <span class="k">for</span> <span class="n">coeff</span> <span class="ow">in</span> <span class="n">pyr_coeffs</span><span class="p">]</span>
        <span class="n">magnitude_means</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">mag</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">for</span> <span class="n">mag</span> <span class="ow">in</span> <span class="n">magnitude_pyr_coeffs</span>
        <span class="p">]</span>
        <span class="n">magnitude_pyr_coeffs</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">mag</span> <span class="o">-</span> <span class="n">mn</span> <span class="k">for</span> <span class="n">mag</span><span class="p">,</span> <span class="n">mn</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">magnitude_pyr_coeffs</span><span class="p">,</span> <span class="n">magnitude_means</span><span class="p">)</span>
        <span class="p">]</span>
        <span class="n">real_pyr_coeffs</span> <span class="o">=</span> <span class="p">[</span><span class="n">coeff</span><span class="o">.</span><span class="n">real</span> <span class="k">for</span> <span class="n">coeff</span> <span class="ow">in</span> <span class="n">pyr_coeffs</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">magnitude_pyr_coeffs</span><span class="p">,</span> <span class="n">real_pyr_coeffs</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reconstruct_lowpass_at_each_scale</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">pyr_coeffs_dict</span><span class="p">:</span> <span class="n">OrderedDict</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Reconstruct the lowpass unoriented image at each scale.</span>

<span class="sd">        The autocorrelation, standard deviation, skew, and kurtosis of each of</span>
<span class="sd">        these images is part of the texture representation.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        pyr_coeffs_dict</span>
<span class="sd">            Dictionary containing the steerable pyramid coefficients, with the</span>
<span class="sd">            lowpass residual demeaned.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        reconstructed_images</span>
<span class="sd">            List of length n_scales+1 containing the reconstructed unoriented</span>
<span class="sd">            image at each scale, from fine to coarse. The final image is</span>
<span class="sd">            reconstructed just from the residual lowpass image. Each is a 4d</span>
<span class="sd">            tensor, this is a list because they are all different heights and</span>
<span class="sd">            widths.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># numpydoc ignore=EX01</span>
        <span class="n">reconstructed_images</span> <span class="o">=</span> <span class="p">[</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_pyr</span><span class="o">.</span><span class="n">recon_pyr</span><span class="p">(</span><span class="n">pyr_coeffs_dict</span><span class="p">,</span> <span class="n">levels</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;residual_lowpass&quot;</span><span class="p">])</span>
        <span class="p">]</span>
        <span class="c1"># go through scales backwards</span>
        <span class="k">for</span> <span class="n">lev</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">recon</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pyr</span><span class="o">.</span><span class="n">recon_pyr</span><span class="p">(</span><span class="n">pyr_coeffs_dict</span><span class="p">,</span> <span class="n">levels</span><span class="o">=</span><span class="p">[</span><span class="n">lev</span><span class="p">])</span>
            <span class="n">reconstructed_images</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">recon</span> <span class="o">+</span> <span class="n">reconstructed_images</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="c1"># now downsample as necessary, so that these end up the same size as</span>
        <span class="c1"># their corresponding coefficients. We multiply by the factor of 4 here</span>
        <span class="c1"># in order to approximately equalize the steerable pyramid coefficient</span>
        <span class="c1"># values across scales. This could also be handled by making the</span>
        <span class="c1"># pyramid tight frame</span>
        <span class="n">reconstructed_images</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">signal</span><span class="o">.</span><span class="n">shrink</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="mi">2</span> <span class="o">**</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span> <span class="o">-</span> <span class="n">i</span><span class="p">))</span> <span class="o">*</span> <span class="mi">4</span> <span class="o">**</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span> <span class="o">-</span> <span class="n">i</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">reconstructed_images</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="p">]</span>
        <span class="k">return</span> <span class="n">reconstructed_images</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_compute_autocorr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">coeffs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Tensor</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the autocorrelation of some statistics.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        coeffs_list</span>
<span class="sd">            List (of length s) of tensors of shape (batch, channel, *, height,</span>
<span class="sd">            width), where * is zero or one additional dimensions. Intended use</span>
<span class="sd">            case: ``magnitude_pyr_coeffs`` (which is list of length ``n_scales`` of 5d</span>
<span class="sd">            tensors, with * containing ``n_orientations``) or ``reconstructed_images``</span>
<span class="sd">            (which is a list of length ``n_scales+1`` of 4d tensors).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        autocorrs</span>
<span class="sd">            Tensor of shape (batch, channel, spatial_corr_width,</span>
<span class="sd">            spatial_corr_width, *, s) containing the autocorrelation (up to</span>
<span class="sd">            distance ``spatial_corr_width//2``) of each element in</span>
<span class="sd">            ``coeffs_list``, computed independently over all but the final two</span>
<span class="sd">            dimensions.</span>
<span class="sd">        vars</span>
<span class="sd">            3d Tensor of shape (batch, channel, *, s) containing the variance</span>
<span class="sd">            of each element in ``coeffs_list``, computed independently over all</span>
<span class="sd">            but the final two dimensions.</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If ``coeffs_list`` contains tensors that have other than 4 or 5 dimensions.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># numpydoc ignore=ES01,EX01</span>
        <span class="k">if</span> <span class="n">coeffs_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">5</span><span class="p">:</span>
            <span class="n">dims</span> <span class="o">=</span> <span class="s2">&quot;o&quot;</span>
        <span class="k">elif</span> <span class="n">coeffs_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
            <span class="n">dims</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;coeffs_list must contain tensors of either 4 or 5 dimensions!&quot;</span>
            <span class="p">)</span>
        <span class="n">acs</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">signal</span><span class="o">.</span><span class="n">center_crop</span><span class="p">(</span><span class="n">signal</span><span class="o">.</span><span class="n">autocorrelation</span><span class="p">(</span><span class="n">coeff</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">spatial_corr_width</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">coeff</span> <span class="ow">in</span> <span class="n">coeffs_list</span>
        <span class="p">]</span>
        <span class="n">acs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">acs</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">var</span> <span class="o">=</span> <span class="n">signal</span><span class="o">.</span><span class="n">center_crop</span><span class="p">(</span><span class="n">acs</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">acs</span> <span class="o">=</span> <span class="n">acs</span> <span class="o">/</span> <span class="n">var</span>
        <span class="n">var</span> <span class="o">=</span> <span class="n">einops</span><span class="o">.</span><span class="n">rearrange</span><span class="p">(</span><span class="n">var</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;b c s </span><span class="si">{</span><span class="n">dims</span><span class="si">}</span><span class="s2"> 1 1 -&gt; b c </span><span class="si">{</span><span class="n">dims</span><span class="si">}</span><span class="s2"> s&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">einops</span><span class="o">.</span><span class="n">rearrange</span><span class="p">(</span><span class="n">acs</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;b c s </span><span class="si">{</span><span class="n">dims</span><span class="si">}</span><span class="s2"> a1 a2 -&gt; b c a1 a2 </span><span class="si">{</span><span class="n">dims</span><span class="si">}</span><span class="s2"> s&quot;</span><span class="p">),</span> <span class="n">var</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_compute_skew_kurtosis_recon</span><span class="p">(</span>
        <span class="n">reconstructed_images</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">var_recon</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">img_var</span><span class="p">:</span> <span class="n">Tensor</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the skew and kurtosis of each lowpass reconstructed image.</span>

<span class="sd">        For each scale, if the ratio of its variance to the original image&#39;s</span>
<span class="sd">        pixel variance is below a threshold of</span>
<span class="sd">        ``torch.finfo(img_var.dtype).resolution`` (``1e-6`` for ``float32``,</span>
<span class="sd">        ``1e-15`` for ``float64``), skew and kurtosis are assigned default</span>
<span class="sd">        values of ``0`` or ``3``, respectively.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        reconstructed_images</span>
<span class="sd">            List of length ``n_scales+1`` containing the reconstructed unoriented</span>
<span class="sd">            image at each scale, from fine to coarse. The final image is</span>
<span class="sd">            reconstructed just from the residual lowpass image.</span>
<span class="sd">        var_recon</span>
<span class="sd">            Tensor of shape (batch, channel, n_scales+1) containing the</span>
<span class="sd">            variance of each tensor in reconstruced_images.</span>
<span class="sd">        img_var</span>
<span class="sd">            Tensor of shape (batch, channel) containing the pixel variance</span>
<span class="sd">            (from ``pixel_stats`` tensor).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        skew_recon, kurtosis_recon</span>
<span class="sd">            Tensors of shape (batch, channel, n_scales+1) containing the skew</span>
<span class="sd">            and kurtosis, respectively, of each tensor in</span>
<span class="sd">            ``reconstructed_images``.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># numpydoc ignore=EX01</span>
        <span class="n">skew_recon</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">stats</span><span class="o">.</span><span class="n">skew</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">var</span><span class="o">=</span><span class="n">var_recon</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">i</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">im</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">reconstructed_images</span><span class="p">)</span>
        <span class="p">]</span>
        <span class="n">skew_recon</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">skew_recon</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">kurtosis_recon</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">stats</span><span class="o">.</span><span class="n">kurtosis</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">var</span><span class="o">=</span><span class="n">var_recon</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">i</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">im</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">reconstructed_images</span><span class="p">)</span>
        <span class="p">]</span>
        <span class="n">kurtosis_recon</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">kurtosis_recon</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">skew_default</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">skew_recon</span><span class="p">)</span>
        <span class="n">kurtosis_default</span> <span class="o">=</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">kurtosis_recon</span><span class="p">)</span>
        <span class="c1"># if this variance ratio is too small, then use the default values</span>
        <span class="c1"># instead. unsqueeze is used here because var_recon is shape (batch,</span>
        <span class="c1"># channel, scales+1), whereas img_var is just (batch, channel)</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">img_var</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">resolution</span>
        <span class="n">unstable_locs</span> <span class="o">=</span> <span class="n">var_recon</span> <span class="o">/</span> <span class="n">img_var</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">res</span>
        <span class="n">skew_recon</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">unstable_locs</span><span class="p">,</span> <span class="n">skew_default</span><span class="p">,</span> <span class="n">skew_recon</span><span class="p">)</span>
        <span class="n">kurtosis_recon</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">unstable_locs</span><span class="p">,</span> <span class="n">kurtosis_default</span><span class="p">,</span> <span class="n">kurtosis_recon</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">skew_recon</span><span class="p">,</span> <span class="n">kurtosis_recon</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_compute_cross_correlation</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">coeffs_tensor</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Tensor</span><span class="p">],</span>
        <span class="n">coeffs_tensor_other</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Tensor</span><span class="p">],</span>
        <span class="n">coeffs_var</span><span class="p">:</span> <span class="kc">None</span> <span class="o">|</span> <span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">coeffs_other_var</span><span class="p">:</span> <span class="kc">None</span> <span class="o">|</span> <span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute cross-correlations.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        coeffs_tensor, coeffs_tensor_other</span>
<span class="sd">            The two lists of length scales, each containing 5d tensors of shape</span>
<span class="sd">            (batch, channel, n_orientations, height, width) to be correlated.</span>
<span class="sd">        coeffs_var, coeffs_other_var</span>
<span class="sd">            Two optional tensors containing the variances of coeffs_tensor and</span>
<span class="sd">            coeffs_tensor_other, respectively, in case they&#39;ve already been computed.</span>
<span class="sd">            Should be of shape (batch, channel, n_orientations, n_scales). Used to</span>
<span class="sd">            normalize the covariances into cross-correlations.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        cross_corrs</span>
<span class="sd">            Tensor of shape (batch, channel, n_orientations, n_orientations,</span>
<span class="sd">            scales) containing the cross-correlations at each</span>
<span class="sd">            scale.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># numpydoc ignore=ES01,EX01</span>
        <span class="n">covars</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">coeff</span><span class="p">,</span> <span class="n">coeff_other</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span>
            <span class="nb">zip</span><span class="p">(</span><span class="n">coeffs_tensor</span><span class="p">,</span> <span class="n">coeffs_tensor_other</span><span class="p">)</span>
        <span class="p">):</span>
            <span class="c1"># precompute this, which we&#39;ll use for normalization</span>
            <span class="n">numel</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="o">*</span><span class="n">coeff</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:])</span>
            <span class="c1"># compute the covariance</span>
            <span class="n">covar</span> <span class="o">=</span> <span class="n">einops</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span>
                <span class="n">coeff</span><span class="p">,</span> <span class="n">coeff_other</span><span class="p">,</span> <span class="s2">&quot;b c o1 h w, b c o2 h w -&gt; b c o1 o2&quot;</span>
            <span class="p">)</span>
            <span class="n">covar</span> <span class="o">=</span> <span class="n">covar</span> <span class="o">/</span> <span class="n">numel</span>
            <span class="c1"># Then normalize it to get the Pearson product-moment correlation</span>
            <span class="c1"># coefficient, see</span>
            <span class="c1"># https://numpy.org/doc/stable/reference/generated/numpy.corrcoef.html.</span>
            <span class="k">if</span> <span class="n">coeffs_var</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># First, compute the variances of each coeff</span>
                <span class="n">coeff_var</span> <span class="o">=</span> <span class="n">einops</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span>
                    <span class="n">coeff</span><span class="p">,</span> <span class="n">coeff</span><span class="p">,</span> <span class="s2">&quot;b c o1 h w, b c o1 h w -&gt; b c o1&quot;</span>
                <span class="p">)</span>
                <span class="n">coeff_var</span> <span class="o">=</span> <span class="n">coeff_var</span> <span class="o">/</span> <span class="n">numel</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">coeff_var</span> <span class="o">=</span> <span class="n">coeffs_var</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">coeffs_other_var</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># First, compute the variances of each coeff</span>
                <span class="n">coeff_other_var</span> <span class="o">=</span> <span class="n">einops</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span>
                    <span class="n">coeff_other</span><span class="p">,</span> <span class="n">coeff_other</span><span class="p">,</span> <span class="s2">&quot;b c o1 h w, b c o1 h w -&gt; b c o1&quot;</span>
                <span class="p">)</span>
                <span class="n">coeff_other_var</span> <span class="o">=</span> <span class="n">coeff_other_var</span> <span class="o">/</span> <span class="n">numel</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">coeff_other_var</span> <span class="o">=</span> <span class="n">coeffs_other_var</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span>
            <span class="c1"># Then compute the outer product of those variances.</span>
            <span class="n">var_outer_prod</span> <span class="o">=</span> <span class="n">einops</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span>
                <span class="n">coeff_var</span><span class="p">,</span> <span class="n">coeff_other_var</span><span class="p">,</span> <span class="s2">&quot;b c o1, b c o2 -&gt; b c o1 o2&quot;</span>
            <span class="p">)</span>
            <span class="c1"># And the sqrt of this is what we use to normalize the covariance</span>
            <span class="c1"># into the cross-correlation</span>
            <span class="n">covars</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">covar</span> <span class="o">/</span> <span class="n">var_outer_prod</span><span class="o">.</span><span class="n">sqrt</span><span class="p">())</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">covars</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_double_phase_pyr_coeffs</span><span class="p">(</span>
        <span class="n">pyr_coeffs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Tensor</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="n">Tensor</span><span class="p">],</span> <span class="nb">list</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Upsample and double the phase of pyramid coefficients.</span>

<span class="sd">        This is trick is key to correctly computing the correlation between</span>
<span class="sd">        coefficients at different spatial scales.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        pyr_coeffs</span>
<span class="sd">            Complex steerable pyramid coefficients (without residuals), as list</span>
<span class="sd">            of length n_scales, containing 5d tensors of shape (batch, channel,</span>
<span class="sd">            n_orientations, height, width).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        doubled_phase_mags</span>
<span class="sd">            The demeaned magnitude (i.e., pyr_coeffs.abs()) of each upsampled</span>
<span class="sd">            double-phased coefficient. List of length n_scales-1 containing</span>
<span class="sd">            tensors of same shape the input (the finest scale has been</span>
<span class="sd">            removed).</span>
<span class="sd">        doubled_phase_separate</span>
<span class="sd">            The real and imaginary parts of each double-phased coefficient.</span>
<span class="sd">            List of length n_scales-1, containing tensors of shape (batch,</span>
<span class="sd">            channel, 2*n_orientations, height, width), with the real component</span>
<span class="sd">            found at the same orientation index as the input, and the imaginary</span>
<span class="sd">            at orientation+self.n_orientations. (The finest scale has been</span>
<span class="sd">            removed).</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># numpydoc ignore=EX01</span>
        <span class="n">doubled_phase_mags</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">doubled_phase_sep</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="c1"># don&#39;t do this for the finest scale</span>
        <span class="k">for</span> <span class="n">coeff</span> <span class="ow">in</span> <span class="n">pyr_coeffs</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span>
            <span class="c1"># We divide by the factor of 4 here in order to approximately</span>
            <span class="c1"># equalize the steerable pyramid coefficient values across scales.</span>
            <span class="c1"># This could also be handled by making the pyramid tight frame</span>
            <span class="n">doubled_phase</span> <span class="o">=</span> <span class="n">signal</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">coeff</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="mf">4.0</span>
            <span class="n">doubled_phase</span> <span class="o">=</span> <span class="n">signal</span><span class="o">.</span><span class="n">modulate_phase</span><span class="p">(</span><span class="n">doubled_phase</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
            <span class="n">doubled_phase_mag</span> <span class="o">=</span> <span class="n">doubled_phase</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span>
            <span class="n">doubled_phase_mag</span> <span class="o">=</span> <span class="n">doubled_phase_mag</span> <span class="o">-</span> <span class="n">doubled_phase_mag</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span>
                <span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)</span>
            <span class="n">doubled_phase_mags</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">doubled_phase_mag</span><span class="p">)</span>
            <span class="n">doubled_phase_sep</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">einops</span><span class="o">.</span><span class="n">pack</span><span class="p">([</span><span class="n">doubled_phase</span><span class="o">.</span><span class="n">real</span><span class="p">,</span> <span class="n">doubled_phase</span><span class="o">.</span><span class="n">imag</span><span class="p">],</span> <span class="s2">&quot;b c * h w&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">doubled_phase_mags</span><span class="p">,</span> <span class="n">doubled_phase_sep</span>

<div class="viewcode-block" id="PortillaSimoncelli.plot_representation">
<a class="viewcode-back" href="../../../../generated/plenoptic.simulate.models.portilla_simoncelli.html#plenoptic.simulate.models.portilla_simoncelli.PortillaSimoncelli.plot_representation">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">plot_representation</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">data</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">ax</span><span class="p">:</span> <span class="n">plt</span><span class="o">.</span><span class="n">Axes</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">figsize</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">ylim</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">|</span> <span class="n">Literal</span><span class="p">[</span><span class="kc">False</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">batch_idx</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">title</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">plt</span><span class="o">.</span><span class="n">Figure</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="n">plt</span><span class="o">.</span><span class="n">Axes</span><span class="p">]]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Plot the representation in a human viewable format.</span>

<span class="sd">        We plot the representation as stem plots with data separated out by</span>
<span class="sd">        statistic type.</span>

<span class="sd">        This plots the representation of a single batch and averages over all</span>
<span class="sd">        channels in the representation.</span>

<span class="sd">        We create the following axes:</span>

<span class="sd">        - pixels+var_highpass: marginal pixel statistics (first four moments,</span>
<span class="sd">          min, max) and variance of the residual highpass.</span>

<span class="sd">        - std+skew+kurtosis recon: the standard deviation, skew, and kurtosis</span>
<span class="sd">          of the reconstructed lowpass image at each scale</span>

<span class="sd">        - magnitude_std: the standard deviation of the steerable pyramid</span>
<span class="sd">          coefficient magnitudes at each orientation and scale.</span>

<span class="sd">        - auto_correlation_reconstructed: the auto-correlation of the</span>
<span class="sd">          reconstructed lowpass image at each scale (summarized using Euclidean</span>
<span class="sd">          norm).</span>

<span class="sd">        - auto_correlation_magnitude: the auto-correlation of the pyramid</span>
<span class="sd">          coefficient magnitudes at each scale and orientation (summarized</span>
<span class="sd">          using Euclidean norm).</span>

<span class="sd">        - cross_orientation_correlation_magnitude: the cross-correlations</span>
<span class="sd">          between each orientation at each scale (summarized using Euclidean</span>
<span class="sd">          norm)</span>

<span class="sd">        If ``self.n_scales &gt; 1``, we also have combination of the following, where</span>
<span class="sd">        all cross-correlations are summarized using Euclidean norm over the</span>
<span class="sd">        channel dimension:</span>

<span class="sd">        - cross_scale_correlation_magnitude: the cross-correlations between the</span>
<span class="sd">          pyramid coefficient magnitude at one scale and the same orientation</span>
<span class="sd">          at the next-coarsest scale.</span>

<span class="sd">        - cross_scale_correlation_real: the cross-correlations between the real</span>
<span class="sd">          component of the pyramid coefficients and the real and imaginary</span>
<span class="sd">          components (at the same orientation) at the next-coarsest scale.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data</span>
<span class="sd">            The data to show on the plot. Else, should look like the output of</span>
<span class="sd">            ``self.forward(img)``, with the exact same structure (e.g., as</span>
<span class="sd">            returned by ``metamer.representation_error()`` or another instance</span>
<span class="sd">            of this class).</span>
<span class="sd">        ax</span>
<span class="sd">            Axes where we will plot the data. If a ``plt.Axes`` instance, will</span>
<span class="sd">            subdivide into 6 or 8 new axes (depending on self.n_scales). If</span>
<span class="sd">            None, we create a new figure.</span>
<span class="sd">        figsize</span>
<span class="sd">            The size of the figure to create. Must be ``None`` if ax is not ``None``. If</span>
<span class="sd">            both figsize and ax are ``None``, then we set ``figsize=(12, 15)``.</span>
<span class="sd">        ylim</span>
<span class="sd">            If not None, the y-limits to use for this plot. If None, we use the</span>
<span class="sd">            default, slightly adjusted so that the minimum is 0. If False, do not</span>
<span class="sd">            change y-limits.</span>
<span class="sd">        batch_idx</span>
<span class="sd">            Which index to take from the batch dimension (the first one).</span>
<span class="sd">        title</span>
<span class="sd">            Title for the plot.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        fig</span>
<span class="sd">            Figure containing the plot.</span>
<span class="sd">        axes</span>
<span class="sd">            List of 6 or 8 axes containing the plot (depending on ``self.n_scales``).</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If both ``figsize`` and ``ax`` are not ``None``.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        .. plot::</span>
<span class="sd">          :context: reset</span>

<span class="sd">          &gt;&gt;&gt; import plenoptic as po</span>
<span class="sd">          &gt;&gt;&gt; img = po.data.reptile_skin()</span>
<span class="sd">          &gt;&gt;&gt; portilla_simoncelli_model = po.simul.PortillaSimoncelli(img.shape[2:])</span>
<span class="sd">          &gt;&gt;&gt; representation_tensor = portilla_simoncelli_model(img)</span>
<span class="sd">          &gt;&gt;&gt; fig, axes = portilla_simoncelli_model.plot_representation(</span>
<span class="sd">          ...     representation_tensor</span>
<span class="sd">          ... )</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">ax</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">figsize</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">ax</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">figsize</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;figsize can&#39;t be set if ax is not None&quot;</span><span class="p">)</span>
        <span class="c1"># pick the batch_idx we want (but keep the data 3d), and average over</span>
        <span class="c1"># channels (but keep the data 3d). We keep data 3d because</span>
        <span class="c1"># convert_to_dict relies on it.</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">batch_idx</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="c1"># each of these values should now be a 3d tensor with 1 element in each</span>
        <span class="c1"># of the first two dims</span>
        <span class="n">rep</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">convert_to_dict</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
        <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_representation_for_plotting</span><span class="p">(</span><span class="n">rep</span><span class="p">)</span>

        <span class="c1"># Determine plot grid layout</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">n_rows</span> <span class="o">=</span> <span class="mi">3</span>
            <span class="n">n_cols</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_rows</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># then we don&#39;t have any cross-scale correlations, so fewer axes.</span>
            <span class="n">n_rows</span> <span class="o">=</span> <span class="mi">2</span>
            <span class="n">n_cols</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_rows</span><span class="p">))</span>

        <span class="c1"># Set up grid spec</span>
        <span class="k">if</span> <span class="n">ax</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># we add 2 to order because we&#39;re adding one to get the</span>
            <span class="c1"># number of orientations and then another one to add an</span>
            <span class="c1"># extra column for the mean luminance plot</span>
            <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">)</span>
            <span class="n">gs</span> <span class="o">=</span> <span class="n">mpl</span><span class="o">.</span><span class="n">gridspec</span><span class="o">.</span><span class="n">GridSpec</span><span class="p">(</span><span class="n">n_rows</span><span class="p">,</span> <span class="n">n_cols</span><span class="p">,</span> <span class="n">fig</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># want to make sure the axis we&#39;re taking over is basically invisible.</span>
            <span class="n">ax</span> <span class="o">=</span> <span class="n">clean_up_axes</span><span class="p">(</span>
                <span class="n">ax</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;top&quot;</span><span class="p">,</span> <span class="s2">&quot;right&quot;</span><span class="p">,</span> <span class="s2">&quot;bottom&quot;</span><span class="p">,</span> <span class="s2">&quot;left&quot;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">]</span>
            <span class="p">)</span>
            <span class="n">gs</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">get_subplotspec</span><span class="p">()</span><span class="o">.</span><span class="n">subgridspec</span><span class="p">(</span><span class="n">n_rows</span><span class="p">,</span> <span class="n">n_cols</span><span class="p">)</span>
            <span class="n">fig</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">figure</span>

        <span class="c1"># plot data</span>
        <span class="n">axes</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
            <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="n">gs</span><span class="p">[</span><span class="n">i</span> <span class="o">//</span> <span class="n">n_cols</span><span class="p">,</span> <span class="n">i</span> <span class="o">%</span> <span class="n">n_cols</span><span class="p">])</span>
            <span class="n">ax</span> <span class="o">=</span> <span class="n">clean_stem_plot</span><span class="p">(</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">v</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">ax</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">ylim</span><span class="o">=</span><span class="n">ylim</span><span class="p">)</span>
            <span class="n">axes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ax</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">title</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span></div>


    <span class="k">def</span><span class="w"> </span><span class="nf">_representation_for_plotting</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rep</span><span class="p">:</span> <span class="n">OrderedDict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">OrderedDict</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Convert into a representation that is more convenient for plotting.</span>

<span class="sd">        Intended as a helper function for plot_representation.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        rep</span>
<span class="sd">            Dictionary of representation, with informative keys.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        plot_rep</span>
<span class="sd">            Dictionary of representation summarized for plotting.</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If the tensors in ``rep`` looks like they have more than one batch</span>
<span class="sd">            or channel. Should select or average over those dimensions.</span>
<span class="sd">        ValueError</span>
<span class="sd">            If ``rep`` contains unexpected keys.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># numpydoc ignore=EX01</span>
        <span class="k">if</span> <span class="n">rep</span><span class="p">[</span><span class="s2">&quot;skew_reconstructed&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Currently, only know how to plot single batch and channel at&quot;</span>
                <span class="s2">&quot; a time! Select and/or average over those dimensions&quot;</span>
            <span class="p">)</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
        <span class="n">data</span><span class="p">[</span><span class="s2">&quot;pixels+var_highpass&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
            <span class="p">[</span><span class="n">rep</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;pixel_statistics&quot;</span><span class="p">),</span> <span class="n">rep</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;var_highpass_residual&quot;</span><span class="p">)]</span>
        <span class="p">)</span>
        <span class="n">data</span><span class="p">[</span><span class="s2">&quot;std+skew+kurtosis recon&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
            <span class="p">(</span>
                <span class="n">rep</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;std_reconstructed&quot;</span><span class="p">),</span>
                <span class="n">rep</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;skew_reconstructed&quot;</span><span class="p">),</span>
                <span class="n">rep</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;kurtosis_reconstructed&quot;</span><span class="p">),</span>
            <span class="p">)</span>
        <span class="p">)</span>

        <span class="n">data</span><span class="p">[</span><span class="s2">&quot;magnitude_std&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">rep</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;magnitude_std&quot;</span><span class="p">)</span>

        <span class="c1"># want to plot these in a specific order</span>
        <span class="n">all_keys</span> <span class="o">=</span> <span class="p">[</span>
            <span class="s2">&quot;auto_correlation_reconstructed&quot;</span><span class="p">,</span>
            <span class="s2">&quot;auto_correlation_magnitude&quot;</span><span class="p">,</span>
            <span class="s2">&quot;cross_orientation_correlation_magnitude&quot;</span><span class="p">,</span>
            <span class="s2">&quot;cross_scale_correlation_magnitude&quot;</span><span class="p">,</span>
            <span class="s2">&quot;cross_scale_correlation_real&quot;</span><span class="p">,</span>
        <span class="p">]</span>
        <span class="k">if</span> <span class="nb">set</span><span class="p">(</span><span class="n">rep</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span> <span class="o">!=</span> <span class="nb">set</span><span class="p">(</span><span class="n">all_keys</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;representation has unexpected keys!&quot;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">all_keys</span><span class="p">:</span>
            <span class="c1"># if we only have one scale, no cross-scale stats</span>
            <span class="k">if</span> <span class="n">k</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;cross_scale&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="c1"># we compute L2 norm manually, since there are NaNs (marking</span>
            <span class="c1"># redundant stats)</span>
            <span class="n">data</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">rep</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">nansum</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">data</span>

<div class="viewcode-block" id="PortillaSimoncelli.update_plot">
<a class="viewcode-back" href="../../../../generated/plenoptic.simulate.models.portilla_simoncelli.html#plenoptic.simulate.models.portilla_simoncelli.PortillaSimoncelli.update_plot">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">update_plot</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">axes</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">plt</span><span class="o">.</span><span class="n">Axes</span><span class="p">],</span>
        <span class="n">data</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">batch_idx</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">plt</span><span class="o">.</span><span class="n">Artist</span><span class="p">]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Update the information in our representation plot.</span>

<span class="sd">        This is used for creating an animation of the representation</span>
<span class="sd">        over time. In order to create the animation, we need to know how</span>
<span class="sd">        to update the matplotlib Artists, and this provides a simple way</span>
<span class="sd">        of doing that. It relies on the fact that we&#39;ve used</span>
<span class="sd">        ``plot_representation`` to create the plots we want to update</span>
<span class="sd">        and so know that they&#39;re stem plots.</span>

<span class="sd">        We take the axes containing the representation information (note that</span>
<span class="sd">        this is probably a subset of the total number of axes in the figure, if</span>
<span class="sd">        we&#39;re showing other information, as done by ``Metamer.animate``), grab</span>
<span class="sd">        the representation from plotting and, since these are both lists,</span>
<span class="sd">        iterate through them, updating them to the values in ``data`` as we go.</span>

<span class="sd">        In order for this to be used by ``FuncAnimation``, we need to</span>
<span class="sd">        return Artists, so we return a list of the relevant artists, the</span>
<span class="sd">        ``markerline`` and ``stemlines`` from the ``StemContainer``.</span>

<span class="sd">        Currently, this averages over all channels in the representation.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        axes</span>
<span class="sd">            A list of axes to update. We assume that these are the axes</span>
<span class="sd">            created by ``plot_representation`` and so contain stem plots</span>
<span class="sd">            in the correct order.</span>
<span class="sd">        data</span>
<span class="sd">            The data to show on the plot. Else, should look like the output of</span>
<span class="sd">            ``self.forward(img)``, with the exact same structure (e.g., as</span>
<span class="sd">            returned by ``metamer.representation_error()`` or another instance</span>
<span class="sd">            of this class).</span>
<span class="sd">        batch_idx</span>
<span class="sd">            Which index to take from the batch dimension (the first one).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        stem_artists</span>
<span class="sd">            A list of the artists used to update the information on the</span>
<span class="sd">            stem plots.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        This method is meant to be used by animation functions, so users won&#39;t</span>
<span class="sd">        typically use this directly.</span>

<span class="sd">        &gt;&gt;&gt; import plenoptic as po</span>
<span class="sd">        &gt;&gt;&gt; img = po.data.reptile_skin()</span>
<span class="sd">        &gt;&gt;&gt; portilla_simoncelli_model = po.simul.PortillaSimoncelli(img.shape[2:])</span>
<span class="sd">        &gt;&gt;&gt; representation_tensor = portilla_simoncelli_model.forward(img)</span>
<span class="sd">        &gt;&gt;&gt; fig, axes = portilla_simoncelli_model.plot_representation(</span>
<span class="sd">        ...     representation_tensor</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; new_img = po.data.einstein()</span>
<span class="sd">        &gt;&gt;&gt; new_representation_tensor = portilla_simoncelli_model.forward(new_img)</span>
<span class="sd">        &gt;&gt;&gt; stem_artists = portilla_simoncelli_model.update_plot(</span>
<span class="sd">        ...     axes, new_representation_tensor</span>
<span class="sd">        ... )</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">stem_artists</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">axes</span> <span class="o">=</span> <span class="p">[</span><span class="n">ax</span> <span class="k">for</span> <span class="n">ax</span> <span class="ow">in</span> <span class="n">axes</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">ax</span><span class="o">.</span><span class="n">containers</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span>
        <span class="c1"># pick the batch_idx we want (but keep the data 3d), and average over</span>
        <span class="c1"># channels (but keep the data 3d). We keep data 3d because</span>
        <span class="c1"># convert_to_dict relies on it.</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">batch_idx</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="c1"># each of these values should now be a 3d tensor with 1 element in each</span>
        <span class="c1"># of the first two dims</span>
        <span class="n">rep</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">convert_to_dict</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
        <span class="n">rep</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_representation_for_plotting</span><span class="p">(</span><span class="n">rep</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axes</span><span class="p">,</span> <span class="n">rep</span><span class="o">.</span><span class="n">values</span><span class="p">()):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
                <span class="n">vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">dd</span><span class="p">)</span> <span class="k">for</span> <span class="n">dd</span> <span class="ow">in</span> <span class="n">d</span><span class="o">.</span><span class="n">values</span><span class="p">()])</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">vals</span> <span class="o">=</span> <span class="n">to_numpy</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>

            <span class="n">sc</span> <span class="o">=</span> <span class="n">update_stem</span><span class="p">(</span><span class="n">ax</span><span class="o">.</span><span class="n">containers</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">vals</span><span class="p">)</span>
            <span class="n">stem_artists</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="n">sc</span><span class="o">.</span><span class="n">markerline</span><span class="p">,</span> <span class="n">sc</span><span class="o">.</span><span class="n">stemlines</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">stem_artists</span></div>
</div>

</pre></div>

                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../../../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
       Copyright 2019-2025, Plenoptic authors.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 9.0.4.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.1.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>