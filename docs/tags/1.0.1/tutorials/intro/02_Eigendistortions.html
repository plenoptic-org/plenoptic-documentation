

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Eigendistortions &mdash; plenoptic 1.0.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=fa44fd50" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../_static/plot_directive.css" />
      <link rel="stylesheet" type="text/css" href="../../_static/nbsphinx-code-cells.css?v=2aa19091" />

  
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=292eb321"></script>
      <script src="../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
      <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
      <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Representational Geodesic" href="05_Geodesics.html" />
    <link rel="prev" title="Quickstart" href="../00_quickstart.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            plenoptic
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Basic concepts</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../install.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../conceptual_intro.html">Conceptual Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../models.html">Model requirements</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_quickstart.html">Quickstart</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Synthesis method introductions</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Eigendistortions</a></li>
<li class="toctree-l1"><a class="reference internal" href="05_Geodesics.html">Representational Geodesic</a></li>
<li class="toctree-l1"><a class="reference internal" href="06_Metamer.html">Metamers</a></li>
<li class="toctree-l1"><a class="reference internal" href="07_Simple_MAD.html">MAD Competition Conceptual Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="08_MAD_Competition.html">MAD Competition Usage</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Models and metrics</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../models/03_Steerable_Pyramid.html">Steerable Pyramid</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models/04_Perceptual_distance.html">Perceptual distance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models/Metamer-Portilla-Simoncelli.html">Portilla-Simoncelli Texture Metamer</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Synthesis method examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../applications/09_Original_MAD.html">Reproducing Wang and Simoncelli, 2008 (MAD Competition)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../applications/Demo_Eigendistortion.html">Reproducing Berardino et al., 2017 (Eigendistortions)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced usage</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../synthesis.html">Synthesis object design</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tips.html">Tips and Tricks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reproducibility.html">Reproducibility</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/modules.html">Modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/Display.html">Display and animate functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/Synthesis_extensions.html">Extending existing synthesis objects</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">plenoptic</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Eigendistortions</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/tutorials/intro/02_Eigendistortions.nblink.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="Eigendistortions">
<h1>Eigendistortions<a class="headerlink" href="#Eigendistortions" title="Link to this heading"></a></h1>
<p><strong>Run notebook online with Binder:</strong><a class="reference external" href="https://mybinder.org/v2/gh/LabForComputationalVision/plenoptic/1.0.1?filepath=examples/02_Eigendistortions.ipynb"><img alt="Binder" src="http://mybinder.org/badge_logo.svg" /></a></p>
<p><strong>In this tutorial we will cover:</strong></p>
<ul class="simple">
<li><p>theory behind eigendistortions</p></li>
<li><p>how to use the <code class="docutils literal notranslate"><span class="pre">plenoptic.synthesize.eigendistortion.Eigendistortion</span></code> object</p></li>
<li><p>computing eigendistortions using a simple input and linear model</p></li>
<li><p>computing extremal eigendistortions for different layers of ResNet18</p></li>
</ul>
<section id="Introduction">
<h2>Introduction<a class="headerlink" href="#Introduction" title="Link to this heading"></a></h2>
<p>How can we assess whether a model sees like we do? One way is to test whether they “notice” image distortions the same way as us. For a model, a noticeable distortion would be an image perturbation that elicits a change in its response. If our goal is to create models with human-like vision, then an image distortion that is (not) noticeable to a human should also (not) be noticeable to our models. Eigendistortions provide a framework with which to compare models to human visual perception of
distortions.</p>
<p><em>Berardino, A., Laparra, V., Ballé, J. and Simoncelli, E., 2017. Eigen-distortions of hierarchical representations. In Advances in neural information processing systems (pp. 3530-3539).</em></p>
<p><a class="reference external" href="http://www.cns.nyu.edu/pub/lcv/berardino17c-final.pdf">http://www.cns.nyu.edu/pub/lcv/berardino17c-final.pdf</a></p>
<p><a class="reference external" href="http://www.cns.nyu.edu/~lcv/eigendistortions/">http://www.cns.nyu.edu/~lcv/eigendistortions/</a></p>
<p><strong>See the last section of this notebook for more mathematical detail</strong></p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="c1"># so that relative sizes of axes created by po.imshow and others look right</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.dpi&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">72</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">plenoptic.synthesize.eigendistortion</span> <span class="kn">import</span> <span class="n">Eigendistortion</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">models</span>
<span class="kn">import</span> <span class="nn">os.path</span> <span class="k">as</span> <span class="nn">op</span>
<span class="kn">import</span> <span class="nn">plenoptic</span> <span class="k">as</span> <span class="nn">po</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/home/billbrod/miniconda3/envs/plenoptic/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html
  from .autonotebook import tqdm as notebook_tqdm
</pre></div></div>
</div>
</section>
<section id="Example-1:-Linear-model,-small-1D-input-%22image%22">
<h2>Example 1: Linear model, small 1D input “image”<a class="headerlink" href="#Example-1:-Linear-model,-small-1D-input-%22image%22" title="Link to this heading"></a></h2>
<section id="1.1)-Creating-the-model">
<h3>1.1) Creating the model<a class="headerlink" href="#1.1)-Creating-the-model" title="Link to this heading"></a></h3>
<p>The fundamental goal of computing eigendistortions is to understand how small changes (distortions) in inputs affect model outputs. Any model can be thought of as a black box mapping an input to an output, <span class="math notranslate nohighlight">\(f(x): x \in \mathbb{R}^n \mapsto y \in \mathbb{R}^m\)</span>, i.e. a function takes as input an n-dimensional vector <span class="math notranslate nohighlight">\(x\)</span> and outputs an m-dimensional vector <span class="math notranslate nohighlight">\(y\)</span>.</p>
<p>The simplest model that achieves this is linear,</p>
<div class="math notranslate nohighlight">
\begin{align}
    y &amp;= f(x) = Mx, &amp;&amp; \text{$M\in \mathbb{R^{m\times n}}$}.
\end{align}</div><p>In this linear case, the Jacobian is fixed <span class="math notranslate nohighlight">\(J= \frac{\partial f}{\partial x}=M\)</span> for all possible inputs <span class="math notranslate nohighlight">\(x\)</span>. Can we <em>synthesize</em> a distortion <span class="math notranslate nohighlight">\(\epsilon\)</span> such that <span class="math notranslate nohighlight">\(f(x+\epsilon)\)</span> is maximally/minimally perturbed from the original <span class="math notranslate nohighlight">\(f(x)\)</span>? Yes! This would amount to finding the first and last eigenvectors of the Fisher information matrix, i.e. <span class="math notranslate nohighlight">\(J^TJ v = \lambda v\)</span>.</p>
<p><strong>A few things to note:</strong></p>
<ul class="simple">
<li><p>Input image should always be a 4D tensor whose dimensions <code class="docutils literal notranslate"><span class="pre">torch.Size([batch=1,</span> <span class="pre">channel,</span> <span class="pre">height,</span> <span class="pre">width])</span></code>.</p></li>
<li><p>We don’t allow for batch synthesis of eigendistortions so the batch dim should always = 1</p></li>
</ul>
<p>We’ll be working with the <code class="docutils literal notranslate"><span class="pre">Eigendistortion</span></code> object and its instance method, <code class="docutils literal notranslate"><span class="pre">synthesize()</span></code>.</p>
<p>Let’s make a linear PyTorch model and compute eigendistortions for a given input.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">LinearModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;The simplest model we can make.</span>
<span class="sd">    Its Jacobian should be the weight matrix of M, and the eigenvectors of the Fisher matrix are therefore the</span>
<span class="sd">    eigenvectors of M.T @ M&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LinearModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">M</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">M</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># this computes y = x @ M.T</span>
        <span class="k">return</span> <span class="n">y</span>

<span class="n">n</span> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># input vector dim (can you predict what the eigenvec/vals would be when n&lt;m or n=m? Feel free to try!)</span>
<span class="n">m</span> <span class="o">=</span> <span class="mi">10</span>  <span class="c1"># output vector dim</span>

<span class="n">mdl_linear</span> <span class="o">=</span> <span class="n">LinearModel</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>
<span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">remove_grad</span><span class="p">(</span><span class="n">mdl_linear</span><span class="p">)</span>

<span class="n">x0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>  <span class="c1"># input must betorch.Size([batch=1, n_chan, img_height, img_width])</span>
<span class="n">y0</span> <span class="o">=</span> <span class="n">mdl_linear</span><span class="p">(</span><span class="n">x0</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">sharex</span><span class="o">=</span><span class="s1">&#39;all&#39;</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="s1">&#39;all&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="n">x0</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">use_line_collection</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">n</span><span class="si">:</span><span class="s1">d</span><span class="si">}</span><span class="s1">D Input&#39;</span><span class="p">)</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="n">y0</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span> <span class="n">use_line_collection</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">markerfmt</span><span class="o">=</span><span class="s1">&#39;C1o&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">m</span><span class="si">:</span><span class="s1">d</span><span class="si">}</span><span class="s1">D Output&#39;</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/tmp/ipykernel_3193448/949728541.py:24: MatplotlibDeprecationWarning: The &#39;use_line_collection&#39; parameter of stem() was deprecated in Matplotlib 3.6 and will be removed two minor releases later. If any parameter follows &#39;use_line_collection&#39;, they should be passed as keyword, not positionally.
  ax[0].stem(x0.squeeze(), use_line_collection=True)
/tmp/ipykernel_3193448/949728541.py:27: MatplotlibDeprecationWarning: The &#39;use_line_collection&#39; parameter of stem() was deprecated in Matplotlib 3.6 and will be removed two minor releases later. If any parameter follows &#39;use_line_collection&#39;, they should be passed as keyword, not positionally.
  ax[1].stem(y0.squeeze().detach(), use_line_collection=True, markerfmt=&#39;C1o&#39;)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_intro_02_Eigendistortions_3_1.png" src="../../_images/tutorials_intro_02_Eigendistortions_3_1.png" />
</div>
</div>
</section>
<section id="1.2---Synthesizing-eigendistortions-of-linear-model">
<h3>1.2 - Synthesizing eigendistortions of linear model<a class="headerlink" href="#1.2---Synthesizing-eigendistortions-of-linear-model" title="Link to this heading"></a></h3>
<p>To compute the eigendistortions of this model, we can instantiate an <code class="docutils literal notranslate"><span class="pre">Eigendistortion</span></code> object with a 4D input image with dims <code class="docutils literal notranslate"><span class="pre">torch.Size([batch=1,</span> <span class="pre">n_channels,</span> <span class="pre">img_height,</span> <span class="pre">img_width])</span></code>, and any PyTorch model with valid <code class="docutils literal notranslate"><span class="pre">forward</span></code> and <code class="docutils literal notranslate"><span class="pre">backward</span></code> methods. After that, we simply call the instance method <code class="docutils literal notranslate"><span class="pre">synthesize()</span></code> and choose the appropriate synthesis method. Normally our input has thousands of entries, but our input in this case is small (only n=25 entries), so we can compute the full
<span class="math notranslate nohighlight">\(m \times n\)</span> Jacobian, and all the eigenvectors of the <span class="math notranslate nohighlight">\(n \times n\)</span> Fisher matrix, <span class="math notranslate nohighlight">\(F=J^TJ\)</span>. The <code class="docutils literal notranslate"><span class="pre">synthesize</span></code> method does this for us and stores the outputs (eigendistortions, eigenvalues, eigenindex) of the synthesis. These return values point to <code class="docutils literal notranslate"><span class="pre">synthesized_signal</span></code>, <code class="docutils literal notranslate"><span class="pre">synthesized_eigenvalues</span></code>, <code class="docutils literal notranslate"><span class="pre">synthesized_eigenindex</span></code> attributes of the object, respectively.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">help</span><span class="p">(</span><span class="n">Eigendistortion</span><span class="o">.</span><span class="n">synthesize</span><span class="p">)</span>  <span class="c1"># fully documented</span>

<span class="n">eig_jac</span> <span class="o">=</span> <span class="n">Eigendistortion</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">mdl_linear</span><span class="p">)</span>  <span class="c1"># instantiate Eigendistortion object using an input and model</span>
<span class="n">eig_jac</span><span class="o">.</span><span class="n">synthesize</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;exact&#39;</span><span class="p">)</span>  <span class="c1"># compute the entire Jacobian exactly</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Help on function synthesize in module plenoptic.synthesize.eigendistortion:

synthesize(self, method: Literal[&#39;exact&#39;, &#39;power&#39;, &#39;randomized_svd&#39;] = &#39;power&#39;, k: int = 1, max_iter: int = 1000, p: int = 5, q: int = 2, tol: float = 1e-07)
    Compute eigendistortions of Fisher Information Matrix with given input image.

    Parameters
    ----------
    method
        Eigensolver method. &#39;exact&#39; tries to do eigendecomposition directly (
        not recommended for very large inputs). &#39;power&#39; (default) uses the power method to compute first and
        last eigendistortions, with maximum number of iterations dictated by n_steps. &#39;randomized_svd&#39; uses
        randomized SVD to approximate the top k eigendistortions and their corresponding eigenvalues.
    k
        How many vectors to return using block power method or svd.
    max_iter
        Maximum number of steps to run for ``method=&#39;power&#39;`` in eigenvalue computation. Ignored
        for other methods.
    p
        Oversampling parameter for randomized SVD. k+p vectors will be sampled, and k will be returned. See
        docstring of ``_synthesize_randomized_svd`` for more details including algorithm reference.
    q
        Matrix power parameter for randomized SVD. This is an effective trick for the algorithm to converge to
        the correct eigenvectors when the eigenspectrum does not decay quickly. See
        ``_synthesize_randomized_svd`` for more details including algorithm reference.
    tol
        Tolerance for error criterion in power iteration.


Initializing Eigendistortion -- Input dim: 25 | Output dim: 10
Computing all eigendistortions
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/home/billbrod/Documents/plenoptic/plenoptic/tools/validate.py:178: UserWarning: model is in training mode, you probably want to call eval() to switch to evaluation mode
  warnings.warn(
</pre></div></div>
</div>
</section>
<section id="1.3---Comparing-our-synthesis-to-ground-truth">
<h3>1.3 - Comparing our synthesis to ground-truth<a class="headerlink" href="#1.3---Comparing-our-synthesis-to-ground-truth" title="Link to this heading"></a></h3>
<p>The Jacobian is in general a rectangular (not necessarily square) matrix <span class="math notranslate nohighlight">\(J\in \mathbb{R}^{m\times n}\)</span>. Since this is a linear model, let’s check if the computed Jacobian (stored as an attribute in the <code class="docutils literal notranslate"><span class="pre">Eigendistortion</span></code> object) matches the weight matrix <span class="math notranslate nohighlight">\(M\)</span>.</p>
<p>Since the eigendistortions are each 1D (vectors) in this example, we can display them all as an image where each column is an eigendistortion, each pixel is an entry of the eigendistortion, and the intensity is proportional to its value.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">sharex</span><span class="o">=</span><span class="s1">&#39;all&#39;</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="s1">&#39;all&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">eig_jac</span><span class="o">.</span><span class="n">jacobian</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">mdl_linear</span><span class="o">.</span><span class="n">M</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">eig_jac</span><span class="o">.</span><span class="n">jacobian</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">vmax</span><span class="o">=</span><span class="n">eig_jac</span><span class="o">.</span><span class="n">jacobian</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xticks</span><span class="o">=</span><span class="p">[],</span> <span class="n">yticks</span><span class="o">=</span><span class="p">[],</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Solved Jacobian&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">&#39;Linear model weight matrix&#39;</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Jacobian == weight matrix M?:&quot;</span><span class="p">,</span> <span class="n">eig_jac</span><span class="o">.</span><span class="n">jacobian</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">mdl_linear</span><span class="o">.</span><span class="n">M</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">))</span>

<span class="c1"># Eigenvectors (aka eigendistortions) and associated eigenvectors are found in the distortions dict attribute</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">sharex</span><span class="o">=</span><span class="s1">&#39;all&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">eig_jac</span><span class="o">.</span><span class="n">eigendistortions</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">vmin</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;coolwarm&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">&#39;Eigendistortions&#39;</span><span class="p">,</span> <span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Eigenvector index&#39;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;Entry&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">eig_jac</span><span class="o">.</span><span class="n">eigenvalues</span><span class="p">,</span> <span class="s1">&#39;.&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">&#39;Eigenvalues&#39;</span><span class="p">,</span> <span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Eigenvector index&#39;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;Eigenvalue&#39;</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Jacobian == weight matrix M?: True
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_intro_02_Eigendistortions_7_1.png" src="../../_images/tutorials_intro_02_Eigendistortions_7_1.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_intro_02_Eigendistortions_7_2.png" src="../../_images/tutorials_intro_02_Eigendistortions_7_2.png" />
</div>
</div>
</section>
<section id="1.4---What-do-these-eigendistortions-mean?">
<h3>1.4 - What do these eigendistortions <em>mean</em>?<a class="headerlink" href="#1.4---What-do-these-eigendistortions-mean?" title="Link to this heading"></a></h3>
<p>The first eigenvector (with the largest eigenvalue) is the direction in which we can distort our input <span class="math notranslate nohighlight">\(x\)</span> and change the response of the model the <em>most</em>, i.e. its most noticeable distortion. For the last eigenvector, since its associated eigenvalue is 0, then <em>no change in response occurs</em> when we distort the input in that direction, i.e. <span class="math notranslate nohighlight">\(f(x+\epsilon)=f(x)\)</span>. So this distortion would be <em>imperceptible</em> to the model.</p>
<p>In most cases, our input would be much larger. An <span class="math notranslate nohighlight">\(n\times n\)</span> image has <span class="math notranslate nohighlight">\(n^2\)</span> entries, meaning the Fisher matrix is <span class="math notranslate nohighlight">\(n^2 \times n^2\)</span>, and therefore <span class="math notranslate nohighlight">\(n^2\)</span> possible eigendistortions – certainly too large to store in memory. We need to instead resort to numerical methods to compute the eigendistortions. To do this, we can just set our synthesis <code class="docutils literal notranslate"><span class="pre">method='power'</span></code> to estimate the first eigenvector (most noticeable distortion) and last eigenvector (least noticeable
distortion) for the image.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">eig_pow</span> <span class="o">=</span> <span class="n">Eigendistortion</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">mdl_linear</span><span class="p">)</span>
<span class="n">eig_pow</span><span class="o">.</span><span class="n">synthesize</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;power&#39;</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">eigdist_pow</span> <span class="o">=</span> <span class="n">eig_pow</span><span class="o">.</span><span class="n">eigendistortions</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>  <span class="c1"># squeeze out singleton channel dimension (these are grayscale)</span>
<span class="n">eigdist_jac</span> <span class="o">=</span> <span class="n">eig_jac</span><span class="o">.</span><span class="n">eigendistortions</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Indices of computed eigenvectors: </span><span class="si">{</span><span class="n">eig_pow</span><span class="o">.</span><span class="n">eigenindex</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">eig_pow</span><span class="o">.</span><span class="n">eigenindex</span><span class="p">,</span> <span class="n">eig_pow</span><span class="o">.</span><span class="n">eigenvalues</span><span class="p">,</span> <span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Power&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">eig_jac</span><span class="o">.</span><span class="n">eigenvalues</span><span class="p">,</span> <span class="s1">&#39;.-&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Jacobian&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">&#39;Power method vs Jacobian&#39;</span><span class="p">,</span> <span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Eigenvector index&#39;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;Eigenvalue&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">&#39;Synth. method&#39;</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">sharex</span><span class="o">=</span><span class="s1">&#39;all&#39;</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="s1">&#39;all&#39;</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">eigdist_pow</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">eigdist_jac</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">&#39;Difference in first eigendists&#39;</span><span class="p">)</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="n">eigdist_pow</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">eigdist_jac</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">use_line_collection</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">&#39;Difference in last eigendists&#39;</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="n">eigdist_jac</span> <span class="o">@</span> <span class="n">eigdist_pow</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="p">,</span> <span class="n">use_line_collection</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">&quot;Power method&#39;s last eigenvec projected on all Jacobian method&#39;s eigenvec&quot;</span><span class="p">,</span>
       <span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Eigenvector index&#39;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;Projection&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Are the first eigendistortions the same?&#39;</span><span class="p">,</span> <span class="n">eigdist_pow</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">eigdist_jac</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">atol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Are the last eigendistortions the same?&#39;</span><span class="p">,</span> <span class="n">eigdist_pow</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">eigdist_jac</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">atol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">))</span>

<span class="c1"># find eigendistortions of Jacobian-method whose eigenvalues are zero</span>
<span class="n">ind_zero</span> <span class="o">=</span> <span class="n">eig_jac</span><span class="o">.</span><span class="n">eigenvalues</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">atol</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Initializing Eigendistortion -- Input dim: 25 | Output dim: 10
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Top k=1 eigendists:   2%|███▏                                                                                                                                                    | 21/1000 [00:00&lt;00:03, 288.26it/s, delta_eigenval=5.96E-08]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Top k=1 eigendists computed | Tolerance 1.00E-07 reached.
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Bottom k=1 eigendists:  14%|████████████████████▎                                                                                                                               | 137/1000 [00:00&lt;00:02, 315.37it/s, delta_eigenval=9.92E-08]
/tmp/ipykernel_3193448/841978278.py:18: MatplotlibDeprecationWarning: The &#39;use_line_collection&#39; parameter of stem() was deprecated in Matplotlib 3.6 and will be removed two minor releases later. If any parameter follows &#39;use_line_collection&#39;, they should be passed as keyword, not positionally.
  ax[1].stem(eigdist_pow[-1] - eigdist_jac[-1], use_line_collection=True)
/tmp/ipykernel_3193448/841978278.py:22: MatplotlibDeprecationWarning: The &#39;use_line_collection&#39; parameter of stem() was deprecated in Matplotlib 3.6 and will be removed two minor releases later. If any parameter follows &#39;use_line_collection&#39;, they should be passed as keyword, not positionally.
  ax.stem(eigdist_jac @ eigdist_pow[-1] , use_line_collection=True)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Bottom k=1 eigendists computed | Tolerance 1.00E-07 reached.
Indices of computed eigenvectors: tensor([ 0, 24])

Are the first eigendistortions the same? True
Are the last eigendistortions the same? False
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_intro_02_Eigendistortions_9_5.png" src="../../_images/tutorials_intro_02_Eigendistortions_9_5.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_intro_02_Eigendistortions_9_6.png" src="../../_images/tutorials_intro_02_Eigendistortions_9_6.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_intro_02_Eigendistortions_9_7.png" src="../../_images/tutorials_intro_02_Eigendistortions_9_7.png" />
</div>
</div>
<p>The power method’s first eigendistortion matches the ground-truth first eigendistortion obtained via the Jacobian solve. And while the last eigendistortions don’t match, the last power method eigendistortion lies in the span of all the eigendistortions whose eigenvalues are zero. Each of these eigendistortions whose eigenvalues are zero are equivalent. Any distortion of <span class="math notranslate nohighlight">\(x\)</span> in the span of these eigendistortions would result in <em>no change</em> in the model output, and would therefore be
imperceptible to the model.</p>
</section>
<section id="1.5---The-Fisher-information-matrix-is-a-locally-adaptive">
<h3>1.5 - The Fisher information matrix is a locally adaptive<a class="headerlink" href="#1.5---The-Fisher-information-matrix-is-a-locally-adaptive" title="Link to this heading"></a></h3>
<p>Different inputs should in general have different sets of eigendistortions – a noticible distortion in one image would not necessarily be noticeable in a different image. The only case where they should be the same regardless of input is when the model is fully linear, as in this simple example. So let’s check if the Jacobian at a different input still equals the weight matrix <span class="math notranslate nohighlight">\(M\)</span>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">x0</span><span class="p">)</span>  <span class="c1"># generate some random input</span>
<span class="n">eig_jac2</span> <span class="o">=</span> <span class="n">Eigendistortion</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">mdl_linear</span><span class="p">)</span>
<span class="n">eig_jac2</span><span class="o">.</span><span class="n">synthesize</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;exact&#39;</span><span class="p">)</span>  <span class="c1"># since the model is linear, the Jacobian should be the exact same as before</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Does the jacobian at x1 still equal the model weight matrix?&#39;</span>
      <span class="sa">f</span><span class="s1">&#39; </span><span class="si">{</span><span class="n">eig_jac2</span><span class="o">.</span><span class="n">jacobian</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">mdl_linear</span><span class="o">.</span><span class="n">M</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Initializing Eigendistortion -- Input dim: 25 | Output dim: 10
Computing all eigendistortions
Does the jacobian at x1 still equal the model weight matrix? True
</pre></div></div>
</div>
</section>
</section>
<section id="Example-2:-Which-layer-of-ResNet-is-a-better-model-of-human-visual-distortion-perception?">
<h2>Example 2: Which layer of ResNet is a better model of human visual distortion perception?<a class="headerlink" href="#Example-2:-Which-layer-of-ResNet-is-a-better-model-of-human-visual-distortion-perception?" title="Link to this heading"></a></h2>
<p>Now that we understand what eigendistortions are and how the <code class="docutils literal notranslate"><span class="pre">Eigendistortion</span></code> class works, let’s compute them real images using a more complex model like Vgg16. The response vector <span class="math notranslate nohighlight">\(y\)</span> doesn’t necessarily have to be the output of the last layer of the model; we can also compute Eigendistortions for intermediate model layers too. Let’s synthesize distortions for an image using different layers of Vgg16 to see which layer produces extremal eigendistortions that align more with human
perception.</p>
<section id="2.1---Load-an-example-an-image">
<h3>2.1 - Load an example an image<a class="headerlink" href="#2.1---Load-an-example-an-image" title="Link to this heading"></a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># a couple helper functions</span>

<span class="k">def</span> <span class="nf">center_crop</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Crop an nxn image from the center of im&quot;&quot;&quot;</span>
    <span class="n">im_height</span><span class="p">,</span> <span class="n">im_width</span> <span class="o">=</span> <span class="n">im</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>
    <span class="k">assert</span> <span class="n">n</span><span class="o">&lt;</span><span class="n">im_height</span> <span class="ow">and</span> <span class="n">n</span><span class="o">&lt;</span><span class="n">im_width</span>

    <span class="n">im_crop</span> <span class="o">=</span> <span class="n">im</span><span class="p">[</span><span class="n">im_height</span><span class="o">//</span><span class="mi">2</span><span class="o">-</span><span class="n">n</span><span class="o">//</span><span class="mi">2</span><span class="p">:</span><span class="n">im_height</span><span class="o">//</span><span class="mi">2</span><span class="o">+</span><span class="n">n</span><span class="o">//</span><span class="mi">2</span><span class="p">,</span>
              <span class="n">im_width</span><span class="o">//</span><span class="mi">2</span><span class="o">-</span><span class="n">n</span><span class="o">//</span><span class="mi">2</span><span class="p">:</span><span class="n">im_width</span><span class="o">//</span><span class="mi">2</span><span class="o">+</span><span class="n">n</span><span class="o">//</span><span class="mi">2</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">im_crop</span>

<span class="n">n</span> <span class="o">=</span> <span class="mi">128</span>  <span class="c1"># this will be the img_height and width of the input, you can change this to accommodate your machine</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">op</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s1">&#39;../data&#39;</span><span class="p">,</span> <span class="s1">&#39;color_wheel.jpg&#39;</span><span class="p">))</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

<span class="c1"># center crop the image to nxn</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">center_crop</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>

<span class="n">img</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">rescale</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>  <span class="c1"># rescale to [0, 1]</span>

<span class="n">img3</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span> <span class="c1"># permute to (b, c, h, w)</span>
<span class="n">po</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img3</span><span class="p">,</span> <span class="n">as_rgb</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">zoom</span><span class="o">=</span><span class="mi">3</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_intro_02_Eigendistortions_14_0.png" src="../../_images/tutorials_intro_02_Eigendistortions_14_0.png" />
</div>
</div>
</section>
<section id="2.2---Instantiate-models-and-Eigendistortion-objects">
<h3>2.2 - Instantiate models and Eigendistortion objects<a class="headerlink" href="#2.2---Instantiate-models-and-Eigendistortion-objects" title="Link to this heading"></a></h3>
<p>Let’s make a wrapper class that can return the nth layer output of vgg. We’re going to use this to compare eigendistortions synthesized using different layers of Vgg as models for distortion perception.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create a class that takes the nth layer output of a given model</span>
<span class="k">class</span> <span class="nc">NthLayer</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Wrap any model to get the response of an intermediate layer</span>

<span class="sd">    Works for Resnet18 or VGG16.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">layer</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        model: PyTorch model</span>
<span class="sd">        layer: int</span>
<span class="sd">            Which model response layer to output</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># then this is VGG16</span>
            <span class="n">features</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">features</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
            <span class="c1"># then it&#39;s resnet18</span>
            <span class="n">features</span> <span class="o">=</span> <span class="p">([</span><span class="n">model</span><span class="o">.</span><span class="n">conv1</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">bn1</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">maxpool</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">l</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">layer1</span><span class="p">]</span> <span class="o">+</span>
                        <span class="p">[</span><span class="n">l</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">layer2</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">l</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">layer3</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">l</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">layer4</span><span class="p">]</span> <span class="o">+</span>
                        <span class="p">[</span><span class="n">model</span><span class="o">.</span><span class="n">avgpool</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">fc</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">features</span><span class="p">)</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">layer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">layer</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer</span> <span class="o">=</span> <span class="n">layer</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">ii</span><span class="p">,</span> <span class="n">mdl</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">mdl</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">ii</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">x</span>

<span class="c1"># different potential models of human visual perception of distortions</span>
<span class="n">resnet18_a</span> <span class="o">=</span> <span class="n">NthLayer</span><span class="p">(</span><span class="n">models</span><span class="o">.</span><span class="n">resnet18</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span> <span class="n">layer</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">remove_grad</span><span class="p">(</span><span class="n">resnet18_a</span><span class="p">)</span>
<span class="n">resnet18_b</span> <span class="o">=</span> <span class="n">NthLayer</span><span class="p">(</span><span class="n">models</span><span class="o">.</span><span class="n">resnet18</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span> <span class="n">layer</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>
<span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">remove_grad</span><span class="p">(</span><span class="n">resnet18_b</span><span class="p">)</span>

<span class="n">ed_resneta</span> <span class="o">=</span> <span class="n">Eigendistortion</span><span class="p">(</span><span class="n">img3</span><span class="p">,</span> <span class="n">resnet18_a</span><span class="p">)</span>
<span class="n">ed_resnetb</span> <span class="o">=</span> <span class="n">Eigendistortion</span><span class="p">(</span><span class="n">img3</span><span class="p">,</span> <span class="n">resnet18_b</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/home/billbrod/miniconda3/envs/plenoptic/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter &#39;pretrained&#39; is deprecated since 0.13 and may be removed in the future, please use &#39;weights&#39; instead.
  warnings.warn(
/home/billbrod/miniconda3/envs/plenoptic/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for &#39;weights&#39; are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Initializing Eigendistortion -- Input dim: 49152 | Output dim: 65536

Initializing Eigendistortion -- Input dim: 49152 | Output dim: 32768
</pre></div></div>
</div>
</section>
<section id="2.3---Synthesizing-distortions">
<h3>2.3 - Synthesizing distortions<a class="headerlink" href="#2.3---Synthesizing-distortions" title="Link to this heading"></a></h3>
<p>The input dimensionality in this example is huge compared to our linear model example – it is <span class="math notranslate nohighlight">\((\text{n_chan} \times \text{img_height} \times \text{img_width})^2\)</span>, meaning the Fisher matrix is too massive to compute exactly. We must turn to iterative methods. Let’s synthesize the extremal eigendistortions for this picture of Einstein using the different layers of ResNet as defined above.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Bump up n_steps if you wish</span>
<span class="n">ed_resneta</span><span class="o">.</span><span class="n">synthesize</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;power&#39;</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">400</span><span class="p">)</span>
<span class="n">ed_resnetb</span><span class="o">.</span><span class="n">synthesize</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;power&#39;</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">400</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Top k=1 eigendists:  43%|█████████████████████████████████████████████████████████████████▊                                                                                       | 172/400 [00:05&lt;00:07, 29.49it/s, delta_eigenval=0.00E+00]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Top k=1 eigendists computed | Tolerance 1.00E-07 reached.
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Bottom k=1 eigendists: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [00:13&lt;00:00, 30.26it/s, delta_eigenval=3.42E-05]
Top k=1 eigendists:  15%|███████████████████████▍                                                                                                                                  | 61/400 [00:04&lt;00:26, 13.01it/s, delta_eigenval=0.00E+00]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Top k=1 eigendists computed | Tolerance 1.00E-07 reached.
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Bottom k=1 eigendists: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [00:31&lt;00:00, 12.54it/s, delta_eigenval=4.72E-03]
</pre></div></div>
</div>
</section>
<section id="2.4---Visualizing-eigendistortions">
<h3>2.4 - Visualizing eigendistortions<a class="headerlink" href="#2.4---Visualizing-eigendistortions" title="Link to this heading"></a></h3>
<p>Let’s display the eigendistortions. <code class="docutils literal notranslate"><span class="pre">Eigendistortion</span></code> has an instance method <code class="docutils literal notranslate"><span class="pre">display</span></code> that will display a 2x3 subplot figure of images. The top row shows the original image on the left, the synthesized maximal eigendistortion on the right, and some constsant <span class="math notranslate nohighlight">\(\alpha\)</span> times the eigendistortion added to the image in the middle panel. The bottow row has a similar layout, but displays the minimal eigendistortion. Let’s display the eigendistortions for both models.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">po</span><span class="o">.</span><span class="n">synth</span><span class="o">.</span><span class="n">eigendistortion</span><span class="o">.</span><span class="n">display_eigendistortion</span><span class="p">(</span><span class="n">ed_resneta</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">as_rgb</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">zoom</span><span class="o">=</span><span class="mi">3</span><span class="p">);</span>
<span class="n">po</span><span class="o">.</span><span class="n">synth</span><span class="o">.</span><span class="n">eigendistortion</span><span class="o">.</span><span class="n">display_eigendistortion</span><span class="p">(</span><span class="n">ed_resneta</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">as_rgb</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">zoom</span><span class="o">=</span><span class="mi">3</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_intro_02_Eigendistortions_20_0.png" src="../../_images/tutorials_intro_02_Eigendistortions_20_0.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_intro_02_Eigendistortions_20_1.png" src="../../_images/tutorials_intro_02_Eigendistortions_20_1.png" />
</div>
</div>
</section>
<section id="2.5---Which-synthesized-extremal-eigendistortions-better-characterize-human-perception?">
<h3>2.5 - Which synthesized extremal eigendistortions better characterize human perception?<a class="headerlink" href="#2.5---Which-synthesized-extremal-eigendistortions-better-characterize-human-perception?" title="Link to this heading"></a></h3>
<p>Let’s compare eigendistortions within a model first. One thing we immediately notice is that the first eigendistortion (labeled <code class="docutils literal notranslate"><span class="pre">maxdist</span></code>) is indeed more noticeable than <code class="docutils literal notranslate"><span class="pre">mindist</span></code>. <code class="docutils literal notranslate"><span class="pre">maxdist</span></code> is localized to a single portion of the image, and has lower, more prominent spatial frequency content than <code class="docutils literal notranslate"><span class="pre">mindist</span></code>. <code class="docutils literal notranslate"><span class="pre">mindist</span></code> looks more like high frequency noise distributed across the image.</p>
<p>But how do the distortions compare between models – which model better characterizes human visual perception of distortions? The only way to truly this is to run an experiment and ask human observers which distortions are most/least noticeable to them. The best model should produce a maximally noticeable distortion that is more noticeable than other models’ maximally noticeable distortions, and its minimally noticeable distortion should be less noticeable than other models’ minimally noticeable
distortions.</p>
<p>See Berardino et al. 2017 for more details.</p>
</section>
<section id="2.6---Synthesizing-distortions-for-other-images">
<h3>2.6 - Synthesizing distortions for other images<a class="headerlink" href="#2.6---Synthesizing-distortions-for-other-images" title="Link to this heading"></a></h3>
<p>Remember the Fisher matrix is locally adaptive, meaning that a different image should have a different set of eigendistortions. Let’s finish off this notebook with another set of extremal eigendistortions for these two Vgg16 layers on a different image.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">img</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">op</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s1">&#39;../data&#39;</span><span class="p">,</span> <span class="s1">&#39;256/curie.pgm&#39;</span><span class="p">))</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

<span class="c1"># center crop the image to nxn</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">center_crop</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>

<span class="n">img</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">rescale</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>  <span class="c1"># rescale to [0, 1]</span>

<span class="n">img</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">img3</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">ed_resneta</span> <span class="o">=</span> <span class="n">Eigendistortion</span><span class="p">(</span><span class="n">img3</span><span class="p">,</span> <span class="n">resnet18_a</span><span class="p">)</span>
<span class="n">ed_resnetb</span> <span class="o">=</span> <span class="n">Eigendistortion</span><span class="p">(</span><span class="n">img3</span><span class="p">,</span> <span class="n">resnet18_b</span><span class="p">)</span>

<span class="n">ed_resneta</span><span class="o">.</span><span class="n">synthesize</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;power&#39;</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">400</span><span class="p">)</span>
<span class="n">ed_resnetb</span><span class="o">.</span><span class="n">synthesize</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;power&#39;</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">400</span><span class="p">)</span>

<span class="n">po</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">zoom</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Original&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Initializing Eigendistortion -- Input dim: 49152 | Output dim: 65536

Initializing Eigendistortion -- Input dim: 49152 | Output dim: 32768
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Top k=1 eigendists:  11%|█████████████████▎                                                                                                                                        | 45/400 [00:01&lt;00:11, 30.25it/s, delta_eigenval=0.00E+00]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Top k=1 eigendists computed | Tolerance 1.00E-07 reached.
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Bottom k=1 eigendists: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [00:10&lt;00:00, 36.59it/s, delta_eigenval=3.96E-05]
Top k=1 eigendists:  50%|█████████████████████████████████████████████████████████████████████████████▎                                                                           | 202/400 [00:28&lt;00:27,  7.11it/s, delta_eigenval=0.00E+00]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Top k=1 eigendists computed | Tolerance 1.00E-07 reached.
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Bottom k=1 eigendists: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [00:31&lt;00:00, 12.86it/s, delta_eigenval=3.48E-03]
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_intro_02_Eigendistortions_22_6.png" src="../../_images/tutorials_intro_02_Eigendistortions_22_6.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">po</span><span class="o">.</span><span class="n">synth</span><span class="o">.</span><span class="n">eigendistortion</span><span class="o">.</span><span class="n">display_eigendistortion</span><span class="p">(</span><span class="n">ed_resneta</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">as_rgb</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">zoom</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;top eigendist&quot;</span><span class="p">);</span>
<span class="n">po</span><span class="o">.</span><span class="n">synth</span><span class="o">.</span><span class="n">eigendistortion</span><span class="o">.</span><span class="n">display_eigendistortion</span><span class="p">(</span><span class="n">ed_resneta</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">as_rgb</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">zoom</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;bottom eigendist&quot;</span><span class="p">);</span>

<span class="n">po</span><span class="o">.</span><span class="n">synth</span><span class="o">.</span><span class="n">eigendistortion</span><span class="o">.</span><span class="n">display_eigendistortion</span><span class="p">(</span><span class="n">ed_resnetb</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">as_rgb</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">zoom</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;top eigendist&quot;</span><span class="p">);</span>
<span class="n">po</span><span class="o">.</span><span class="n">synth</span><span class="o">.</span><span class="n">eigendistortion</span><span class="o">.</span><span class="n">display_eigendistortion</span><span class="p">(</span><span class="n">ed_resnetb</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">as_rgb</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">zoom</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;bottom eigendist&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_intro_02_Eigendistortions_23_0.png" src="../../_images/tutorials_intro_02_Eigendistortions_23_0.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_intro_02_Eigendistortions_23_1.png" src="../../_images/tutorials_intro_02_Eigendistortions_23_1.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_intro_02_Eigendistortions_23_2.png" src="../../_images/tutorials_intro_02_Eigendistortions_23_2.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_intro_02_Eigendistortions_23_3.png" src="../../_images/tutorials_intro_02_Eigendistortions_23_3.png" />
</div>
</div>
</section>
</section>
<section id="Appendix:-More-mathematical-detail">
<h2>Appendix: More mathematical detail<a class="headerlink" href="#Appendix:-More-mathematical-detail" title="Link to this heading"></a></h2>
<p>If we have a model that takes an N-dimensional input and outputs an M-dimensional response, then its Jacobian, <span class="math notranslate nohighlight">\(J=\frac{\partial f}{\partial x}\)</span>, is an <span class="math notranslate nohighlight">\(M\times N\)</span> matrix of partial derivatives that tells us how much a change in each entry of the input would change each entry of the output. With the assumption of additive Gaussian noise in the output space Fisher Information Matrix, <span class="math notranslate nohighlight">\(F\)</span>, is a symmetric positive semi-definite, <span class="math notranslate nohighlight">\(N\times N\)</span> matrix computed using the
Jacobian, <span class="math notranslate nohighlight">\(F=J^TJ\)</span>. If you are familiar with linear algebra, you might notice that the eigenvectors of <span class="math notranslate nohighlight">\(F\)</span> are the right singular vectors of the Jacobian. Thus, an eigendecomposition <span class="math notranslate nohighlight">\(F=V\Lambda V\)</span> yields directions of the <em>input space</em> (vectors in <span class="math notranslate nohighlight">\(V\)</span>) along which changes in the <em>output space</em> are rank-ordered by entries in diagonal matrix <span class="math notranslate nohighlight">\(\Lambda\)</span>.</p>
<p>Given some input image <span class="math notranslate nohighlight">\(x_0\)</span>, an <strong>eigendistortion</strong> is an additive perturbation, <span class="math notranslate nohighlight">\(\epsilon\)</span>, in the <em>input domain</em> that changes the response in a model’s <em>output domain</em> of interest (e.g. an intermediate layer of a neural net, the output of a nonlinear model, etc.). These perturbations are named <em>eigendistortions</em> because they push <span class="math notranslate nohighlight">\(x_0\)</span> along eigenvectors of the Fisher Information Matrix. So we expect distortions <span class="math notranslate nohighlight">\(x_0\)</span> along the direction of the eigenvector with the
maximum eigenvalue will change the representation the <em>most</em>, and distortions along the eigenvector with the minimum eigenvalue will change the representation the <em>least</em>. (And pushing along intermediate eigenvectors will change the representation by an intermediate amount.)</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../00_quickstart.html" class="btn btn-neutral float-left" title="Quickstart" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="05_Geodesics.html" class="btn btn-neutral float-right" title="Representational Geodesic" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2019, Lab for Computational Vision.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>