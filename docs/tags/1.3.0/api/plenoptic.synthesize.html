

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>plenoptic.synthesize package &mdash; plenoptic 1.3.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=9edc463e" />
      <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css" />
      <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />

  
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=1f29e9d3"></script>
      <script src="../_static/doctools.js?v=9bcbadda"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="../_static/copybutton.js?v=35a8b989"></script>
      <script src="../_static/design-tabs.js?v=f930bc37"></script>
      <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
      <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
      <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="plenoptic.tools package" href="plenoptic.tools.html" />
    <link rel="prev" title="plenoptic.simulate.models package" href="plenoptic.simulate.models.html" /> 
</head>

<body class="wy-body-for-nav">

<div style="background-color: rgb(248, 215, 218); color: rgb(114, 28, 36); text-align: center;">
  <div>
    <div>This is documentation for <strong>an old version</strong>.
      <a href="https://docs.plenoptic.org/" style="background-color: rgb(220, 53, 69); color: rgb(255, 255, 255); margin: 1rem; padding: 0.375rem 0.75rem; border-radius: 4px; display: inline-block; text-align: center;">Switch to stable version</a>
    </div>
  </div>
</div>
 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            plenoptic
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Basic concepts</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../install.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../jupyter.html">Using Jupyter to Run Example Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../conceptual_intro.html">Conceptual Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models.html">Model requirements</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/00_quickstart.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../citation.html">Citation Guide and Bibliography</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Synthesis method introductions</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/intro/02_Eigendistortions.html">Eigendistortions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/intro/06_Metamer.html">Metamers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/intro/07_Simple_MAD.html">MAD Competition Conceptual Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/intro/08_MAD_Competition.html">MAD Competition Usage</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Models and metrics</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/models/03_Steerable_Pyramid.html">Steerable Pyramid</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/models/04_Perceptual_distance.html">Perceptual distance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/models/Metamer-Portilla-Simoncelli.html">Portilla-Simoncelli Texture Metamer</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Synthesis method examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/applications/09_Original_MAD.html">Reproducing Wang and Simoncelli, 2008 (MAD Competition)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/applications/Demo_Eigendistortion.html">Reproducing Berardino et al., 2017 (Eigendistortions)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced usage</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../synthesis.html">Synthesis object design</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tips.html">Tips and Tricks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reproducibility.html">Reproducibility</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="modules.html">API Documentation</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="plenoptic.html">plenoptic package</a><ul class="current">
<li class="toctree-l3 current"><a class="reference internal" href="plenoptic.html#subpackages">Subpackages</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="plenoptic.data.html">plenoptic.data package</a></li>
<li class="toctree-l4"><a class="reference internal" href="plenoptic.metric.html">plenoptic.metric package</a></li>
<li class="toctree-l4"><a class="reference internal" href="plenoptic.simulate.html">plenoptic.simulate package</a></li>
<li class="toctree-l4 current"><a class="current reference internal" href="#">plenoptic.synthesize package</a></li>
<li class="toctree-l4"><a class="reference internal" href="plenoptic.tools.html">plenoptic.tools package</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="plenoptic.html#module-plenoptic">Module contents</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/advanced/Display.html">Display and animate functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/advanced/Synthesis_extensions.html">Extending existing synthesis objects</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">plenoptic</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="modules.html">plenoptic</a></li>
          <li class="breadcrumb-item"><a href="plenoptic.html">plenoptic package</a></li>
      <li class="breadcrumb-item active">plenoptic.synthesize package</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/api/plenoptic.synthesize.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="plenoptic-synthesize-package">
<h1>plenoptic.synthesize package<a class="headerlink" href="#plenoptic-synthesize-package" title="Link to this heading"></a></h1>
<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Link to this heading"></a></h2>
</section>
<section id="module-plenoptic.synthesize.autodiff">
<span id="plenoptic-synthesize-autodiff-module"></span><h2>plenoptic.synthesize.autodiff module<a class="headerlink" href="#module-plenoptic.synthesize.autodiff" title="Link to this heading"></a></h2>
<p>Helper functions for comptuing Jacobian and related outputs.</p>
<p>Not intended for users to interact with directly; users should use
<a class="reference internal" href="#plenoptic.synthesize.eigendistortion.Eigendistortion" title="plenoptic.synthesize.eigendistortion.Eigendistortion"><code class="xref py py-class docutils literal notranslate"><span class="pre">Eigendistortion</span></code></a>.</p>
<dl class="py function">
<dt class="sig sig-object py" id="plenoptic.synthesize.autodiff.jacobian">
<span class="sig-name descname"><span class="pre">jacobian</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/autodiff.html#jacobian"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.autodiff.jacobian" title="Link to this definition"></a></dt>
<dd><p>Explicitly compute the full Jacobian matrix.</p>
<p>N.B. This is only recommended for small input sizes (e.g. fewer than 10,000
elements).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Model output with gradient attached. Must be a vector, of shape
<code class="docutils literal notranslate"><span class="pre">torch.Size([m,</span> <span class="pre">1])</span></code>.</p></li>
<li><p><strong>x</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Tensor with gradient function model input with gradient attached. Must
be a vector, of shape <code class="docutils literal notranslate"><span class="pre">torch.Size([n,</span> <span class="pre">1])</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>J</em> – Jacobian matrix with <code class="docutils literal notranslate"><span class="pre">torch.Size([m,</span> <span class="pre">n])</span></code>.</p>
</dd>
<dt class="field-even">Warns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>UserWarning</strong> – If <code class="docutils literal notranslate"><span class="pre">x</span></code> has more than 1e4 elements, in which case we believe that this
calculation will take too long.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="plenoptic.synthesize.autodiff.jacobian_vector_product">
<span class="sig-name descname"><span class="pre">jacobian_vector_product</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">V</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dummy_vec</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/autodiff.html#jacobian_vector_product"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.autodiff.jacobian_vector_product" title="Link to this definition"></a></dt>
<dd><p>Compute Jacobian Vector Product: <span class="math notranslate nohighlight">\(\text{jvp} = (\partial y/\partial x) v\)</span>.</p>
<p>Forward Mode Auto-Differentiation (<code class="docutils literal notranslate"><span class="pre">Rop</span></code> in Theano). PyTorch does not natively
support this operation; this function essentially calls backward mode autodiff
twice, as described in <a class="reference internal" href="#r5c039d101f42-1" id="id1">[1]</a>.</p>
<p>See <a class="reference internal" href="#plenoptic.synthesize.autodiff.vector_jacobian_product" title="plenoptic.synthesize.autodiff.vector_jacobian_product"><code class="xref py py-meth docutils literal notranslate"><span class="pre">vector_jacobian_product()</span></code></a> docstring on why we and pass arguments for
<code class="docutils literal notranslate"><span class="pre">retain_graph</span></code> and <code class="docutils literal notranslate"><span class="pre">create_graph</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Model output with gradient attached, shape is <code class="docutils literal notranslate"><span class="pre">torch.Size([m,</span> <span class="pre">1])</span></code>.</p></li>
<li><p><strong>x</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Model input with gradient attached, shape is <code class="docutils literal notranslate"><span class="pre">torch.Size([n,</span> <span class="pre">1])</span></code>, i.e. same
dim as input tensor.</p></li>
<li><p><strong>V</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Directions in which to compute product, shape is <code class="docutils literal notranslate"><span class="pre">torch.Size([n,</span> <span class="pre">k])</span></code> where
<code class="docutils literal notranslate"><span class="pre">k</span></code> is the number of vectors to compute.</p></li>
<li><p><strong>dummy_vec</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Vector with which to do jvp trick <a class="reference internal" href="#r5c039d101f42-1" id="id2">[1]</a>, shape matches <code class="docutils literal notranslate"><span class="pre">y</span></code>. If argument exists,
then use some pre-allocated, cached vector, otherwise create a new one and move
to <code class="docutils literal notranslate"><span class="pre">y.device</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Jv</em> – Jacobian-vector product, <code class="docutils literal notranslate"><span class="pre">torch.Size([n,</span> <span class="pre">k])</span></code>.</p>
</dd>
</dl>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r5c039d101f42-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id1">1</a>,<a role="doc-backlink" href="#id2">2</a>)</span>
<p><a class="reference external" href="https://j-towns.github.io/2017/06/12/A-new-trick.html">https://j-towns.github.io/2017/06/12/A-new-trick.html</a></p>
</div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="plenoptic.synthesize.autodiff.vector_jacobian_product">
<span class="sig-name descname"><span class="pre">vector_jacobian_product</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">U</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retain_graph</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">create_graph</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">detach</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/autodiff.html#vector_jacobian_product"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.autodiff.vector_jacobian_product" title="Link to this definition"></a></dt>
<dd><p>Compute vector Jacobian product <span class="math notranslate nohighlight">\(\text{vjp} = u^T(\partial y/\partial x)\)</span>.</p>
<p>Backward Mode Auto-Differentiation (<code class="docutils literal notranslate"><span class="pre">Lop</span></code> in Theano).</p>
<p>Note on efficiency: When this function is used in the context of power iteration for
computing eigenvectors, the vector output will be repeatedly fed back into this
method and <a class="reference internal" href="#plenoptic.synthesize.autodiff.jacobian_vector_product" title="plenoptic.synthesize.autodiff.jacobian_vector_product"><code class="xref py py-meth docutils literal notranslate"><span class="pre">jacobian_vector_product()</span></code></a>. To prevent the accumulation of gradient
history in this vector (especially on GPU), we need to ensure the computation graph
is not kept in memory after each iteration. We can do this by detaching the output,
as well as carefully specifying where/when to retain the created graph.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Output with gradient attached, <code class="docutils literal notranslate"><span class="pre">torch.Size([m,</span> <span class="pre">1])</span></code>.</p></li>
<li><p><strong>x</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Input with gradient attached, <code class="docutils literal notranslate"><span class="pre">torch.Size([n,</span> <span class="pre">1])</span></code>.</p></li>
<li><p><strong>U</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Direction, shape is <code class="docutils literal notranslate"><span class="pre">torch.Size([m,</span> <span class="pre">k])</span></code>, i.e. same dim as output tensor.
<code class="docutils literal notranslate"><span class="pre">k</span></code> is the number of directions.</p></li>
<li><p><strong>retain_graph</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></span>) – Whether or not to keep graph after doing one <a class="reference internal" href="#plenoptic.synthesize.autodiff.vector_jacobian_product" title="plenoptic.synthesize.autodiff.vector_jacobian_product"><code class="xref py py-meth docutils literal notranslate"><span class="pre">vector_jacobian_product()</span></code></a>.
Must be set to True if <code class="docutils literal notranslate"><span class="pre">k&gt;1</span></code>.</p></li>
<li><p><strong>create_graph</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></span>) – Whether or not to create computational graph. Usually should be set to True
unless you’re reusing the graph like in the second step
of <a class="reference internal" href="#plenoptic.synthesize.autodiff.jacobian_vector_product" title="plenoptic.synthesize.autodiff.jacobian_vector_product"><code class="xref py py-meth docutils literal notranslate"><span class="pre">jacobian_vector_product()</span></code></a>.</p></li>
<li><p><strong>detach</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></span>) – As with <code class="docutils literal notranslate"><span class="pre">create_graph</span></code>, only necessary to be True when reusing the output
like we do in the 2nd step of <a class="reference internal" href="#plenoptic.synthesize.autodiff.jacobian_vector_product" title="plenoptic.synthesize.autodiff.jacobian_vector_product"><code class="xref py py-meth docutils literal notranslate"><span class="pre">jacobian_vector_product()</span></code></a>.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>vJ</em> – Vector-Jacobian product, <code class="docutils literal notranslate"><span class="pre">torch.Size([m,</span> <span class="pre">k])</span></code>.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-plenoptic.synthesize.eigendistortion">
<span id="plenoptic-synthesize-eigendistortion-module"></span><h2>plenoptic.synthesize.eigendistortion module<a class="headerlink" href="#module-plenoptic.synthesize.eigendistortion" title="Link to this heading"></a></h2>
<p>Eigendistortions.</p>
<p>Classes to perform the synthesis of eigendistortions.</p>
<dl class="py class">
<dt class="sig sig-object py" id="plenoptic.synthesize.eigendistortion.Eigendistortion">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">Eigendistortion</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/eigendistortion.html#Eigendistortion"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.eigendistortion.Eigendistortion" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#plenoptic.synthesize.synthesis.Synthesis" title="plenoptic.synthesize.synthesis.Synthesis"><code class="xref py py-class docutils literal notranslate"><span class="pre">Synthesis</span></code></a></p>
<p>Synthesize eigendistortions induced by a model on a given input image.</p>
<p>Following the basic idea in <a class="reference internal" href="#r1708efe03b12-1" id="id3">[1]</a>, this class synthesizes image perturbations that
are considered the most and least noticeable for a model on a given image. Because
these are perturbations on the input image, they are local in pixel space, i.e.,
they do not change the pixels much.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>image</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Image to perturb. We currently do not support batches of images, as each image
requires its own optimization, so either <code class="docutils literal notranslate"><span class="pre">image.ndimension()==1</span></code> or
<code class="docutils literal notranslate"><span class="pre">image.shape[0]==1</span></code>.</p></li>
<li><p><strong>model</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a></span>) – Torch model with defined forward and backward operations.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>This is a method for comparing image representations in terms of their ability to
explain perceptual sensitivity in humans. It estimates eigenvectors of the Fisher
Information Matrix. A model, <span class="math notranslate nohighlight">\(y = f(x)\)</span>, is a deterministic (and
differentiable) mapping from the input pixels <span class="math notranslate nohighlight">\(x \in \mathbb{R}^n\)</span> to a mean
output response vector <span class="math notranslate nohighlight">\(y\in \mathbb{R}^m\)</span>, where we assume additive white
Gaussian noise in the response space.
The Jacobian matrix at <span class="math notranslate nohighlight">\(x\)</span> is:</p>
<blockquote>
<div><p><span class="math notranslate nohighlight">\(J(x) = J = dydx\)</span>,
<span class="math notranslate nohighlight">\(J\in\mathbb{R}^{m \times n}\)</span> (ie. output_dim x input_dim)</p>
</div></blockquote>
<p>The matrix consists of all partial derivatives of the vector-valued function
<span class="math notranslate nohighlight">\(f\)</span>. The Fisher Information Matrix (FIM) at <span class="math notranslate nohighlight">\(x\)</span>, under white Gaussian
noise in the response space, is:</p>
<blockquote>
<div><p><span class="math notranslate nohighlight">\(F = J^T J\)</span></p>
</div></blockquote>
<p>It is a quadratic approximation of the discriminability of distortions
relative to <span class="math notranslate nohighlight">\(x\)</span>.</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r1708efe03b12-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id3">1</a><span class="fn-bracket">]</span></span>
<p>Berardino, A., Laparra, V., Ballé, J. and Simoncelli, E., 2017.
Eigen-distortions of hierarchical representations. In Advances in
neural information processing systems (pp. 3530-3539).
<a class="reference external" href="https://www.cns.nyu.edu/pub/lcv/berardino17c-final.pdf">https://www.cns.nyu.edu/pub/lcv/berardino17c-final.pdf</a>
<a class="reference external" href="https://www.cns.nyu.edu/~lcv/eigendistortions/">https://www.cns.nyu.edu/~lcv/eigendistortions/</a></p>
</div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Attributes<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><a class="reference internal" href="#plenoptic.synthesize.eigendistortion.Eigendistortion.eigendistortions" title="plenoptic.synthesize.eigendistortion.Eigendistortion.eigendistortions"><code class="xref py py-obj docutils literal notranslate"><span class="pre">eigendistortions</span></code></a></dt><dd><p>Eigendistortions, ordered by eigenvalue.</p>
</dd>
<dt><a class="reference internal" href="#plenoptic.synthesize.eigendistortion.Eigendistortion.eigenindex" title="plenoptic.synthesize.eigendistortion.Eigendistortion.eigenindex"><code class="xref py py-obj docutils literal notranslate"><span class="pre">eigenindex</span></code></a></dt><dd><p>Index of each eigenvector/eigenvalue.</p>
</dd>
<dt><a class="reference internal" href="#plenoptic.synthesize.eigendistortion.Eigendistortion.eigenvalues" title="plenoptic.synthesize.eigendistortion.Eigendistortion.eigenvalues"><code class="xref py py-obj docutils literal notranslate"><span class="pre">eigenvalues</span></code></a></dt><dd><p>Eigenvalues corresponding to each eigendistortion, in decreasing order.</p>
</dd>
<dt><a class="reference internal" href="#plenoptic.synthesize.eigendistortion.Eigendistortion.image" title="plenoptic.synthesize.eigendistortion.Eigendistortion.image"><code class="xref py py-obj docutils literal notranslate"><span class="pre">image</span></code></a></dt><dd><p>Target image of eigendistortion synthesis.</p>
</dd>
<dt><a class="reference internal" href="#plenoptic.synthesize.eigendistortion.Eigendistortion.jacobian" title="plenoptic.synthesize.eigendistortion.Eigendistortion.jacobian"><code class="xref py py-obj docutils literal notranslate"><span class="pre">jacobian</span></code></a></dt><dd><p>Jacobian matrix of <a class="reference internal" href="#plenoptic.synthesize.eigendistortion.Eigendistortion.model" title="plenoptic.synthesize.eigendistortion.Eigendistortion.model"><code class="xref py py-attr docutils literal notranslate"><span class="pre">model</span></code></a> with respect to <a class="reference internal" href="#plenoptic.synthesize.eigendistortion.Eigendistortion.image" title="plenoptic.synthesize.eigendistortion.Eigendistortion.image"><code class="xref py py-attr docutils literal notranslate"><span class="pre">image</span></code></a>.</p>
</dd>
<dt><a class="reference internal" href="#plenoptic.synthesize.eigendistortion.Eigendistortion.model" title="plenoptic.synthesize.eigendistortion.Eigendistortion.model"><code class="xref py py-obj docutils literal notranslate"><span class="pre">model</span></code></a></dt><dd><p>The model for which the eigendistortions are synthesized.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Methods</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#plenoptic.synthesize.eigendistortion.Eigendistortion.compute_jacobian" title="plenoptic.synthesize.eigendistortion.Eigendistortion.compute_jacobian"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute_jacobian</span></code></a>()</p></td>
<td><p>Compute (via <code class="xref py py-func docutils literal notranslate"><span class="pre">autodiff.jacobian()</span></code>), cache, and return jacobian.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#plenoptic.synthesize.eigendistortion.Eigendistortion.load" title="plenoptic.synthesize.eigendistortion.Eigendistortion.load"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load</span></code></a>(file_path[, map_location, ...])</p></td>
<td><p>Load all relevant stuff from a .pt file.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#plenoptic.synthesize.eigendistortion.Eigendistortion.save" title="plenoptic.synthesize.eigendistortion.Eigendistortion.save"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save</span></code></a>(file_path)</p></td>
<td><p>Save all relevant variables in .pt file.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#plenoptic.synthesize.eigendistortion.Eigendistortion.synthesize" title="plenoptic.synthesize.eigendistortion.Eigendistortion.synthesize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">synthesize</span></code></a>([method, k, max_iter, p, q, ...])</p></td>
<td><p>Compute eigendistortions of Fisher Information Matrix with given input image.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#id5" title="plenoptic.synthesize.eigendistortion.Eigendistortion.to"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to</span></code></a>(*args, **kwargs)</p></td>
<td><p>Move and/or cast the parameters and buffers.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="plenoptic.synthesize.eigendistortion.Eigendistortion.compute_jacobian">
<span class="sig-name descname"><span class="pre">compute_jacobian</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/eigendistortion.html#Eigendistortion.compute_jacobian"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.eigendistortion.Eigendistortion.compute_jacobian" title="Link to this definition"></a></dt>
<dd><p>Compute (via <code class="xref py py-func docutils literal notranslate"><span class="pre">autodiff.jacobian()</span></code>), cache, and return jacobian.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><em>J</em> – Jacobian of representation with respect to input.</p>
</dd>
<dt class="field-odd">Warns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>UserWarning</strong> – If input dimensionality is greater than 1e4, in which case we believe that
this calculation will take too long.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="plenoptic.synthesize.eigendistortion.Eigendistortion.eigendistortions">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">eigendistortions</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><span class="pre">Tensor</span></a></em><a class="headerlink" href="#plenoptic.synthesize.eigendistortion.Eigendistortion.eigendistortions" title="Link to this definition"></a></dt>
<dd><p>Eigendistortions, ordered by eigenvalue.</p>
<p>Eigendistortions are the eigenvectors of Fisher matrix, will have size
<code class="docutils literal notranslate"><span class="pre">Size((n_distortions,</span> <span class="pre">*image.shape[1:]))</span></code>.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="plenoptic.synthesize.eigendistortion.Eigendistortion.eigenindex">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">eigenindex</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><span class="pre">Tensor</span></a></em><a class="headerlink" href="#plenoptic.synthesize.eigendistortion.Eigendistortion.eigenindex" title="Link to this definition"></a></dt>
<dd><p>Index of each eigenvector/eigenvalue.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="plenoptic.synthesize.eigendistortion.Eigendistortion.eigenvalues">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">eigenvalues</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><span class="pre">Tensor</span></a></em><a class="headerlink" href="#plenoptic.synthesize.eigendistortion.Eigendistortion.eigenvalues" title="Link to this definition"></a></dt>
<dd><p>Eigenvalues corresponding to each eigendistortion, in decreasing order.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="plenoptic.synthesize.eigendistortion.Eigendistortion.image">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">image</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><span class="pre">Tensor</span></a></em><a class="headerlink" href="#plenoptic.synthesize.eigendistortion.Eigendistortion.image" title="Link to this definition"></a></dt>
<dd><p>Target image of eigendistortion synthesis.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="plenoptic.synthesize.eigendistortion.Eigendistortion.jacobian">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">jacobian</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><span class="pre">Tensor</span></a></em><a class="headerlink" href="#plenoptic.synthesize.eigendistortion.Eigendistortion.jacobian" title="Link to this definition"></a></dt>
<dd><p>Jacobian matrix of <a class="reference internal" href="#plenoptic.synthesize.eigendistortion.Eigendistortion.model" title="plenoptic.synthesize.eigendistortion.Eigendistortion.model"><code class="xref py py-attr docutils literal notranslate"><span class="pre">model</span></code></a> with respect to <a class="reference internal" href="#plenoptic.synthesize.eigendistortion.Eigendistortion.image" title="plenoptic.synthesize.eigendistortion.Eigendistortion.image"><code class="xref py py-attr docutils literal notranslate"><span class="pre">image</span></code></a>.</p>
<p>Only set when <a class="reference internal" href="#plenoptic.synthesize.eigendistortion.Eigendistortion.synthesize" title="plenoptic.synthesize.eigendistortion.Eigendistortion.synthesize"><code class="xref py py-func docutils literal notranslate"><span class="pre">synthesize()</span></code></a> is run with <code class="docutils literal notranslate"><span class="pre">method='exact'</span></code>.
Else, <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="plenoptic.synthesize.eigendistortion.Eigendistortion.load">
<span class="sig-name descname"><span class="pre">load</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">map_location</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensor_equality_atol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-08</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensor_equality_rtol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">pickle_load_args</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/eigendistortion.html#Eigendistortion.load"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.eigendistortion.Eigendistortion.load" title="Link to this definition"></a></dt>
<dd><p>Load all relevant stuff from a .pt file.</p>
<p>This must be called by a <code class="docutils literal notranslate"><span class="pre">Eigendistortion</span></code> object initialized just like the
saved object.</p>
<p>Note this operates in place and so doesn’t return anything.</p>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 1.2: </span>load behavior changed in a backwards-incompatible manner in order to
compatible with breaking changes in torch 2.6.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>file_path</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></span>) – The path to load the synthesis object from.</p></li>
<li><p><strong>map_location</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Argument to pass to <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.load.html#torch.load" title="(in PyTorch v2.10)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.load()</span></code></a> as <code class="docutils literal notranslate"><span class="pre">map_location</span></code>. If you
save stuff that was being run on a GPU and are loading onto a
CPU, you’ll need this to make sure everything lines up
properly. This should be structured like the str you would
pass to <a class="reference external" href="https://docs.pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.device</span></code></a>.</p></li>
<li><p><strong>tensor_equality_atol</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></span>) – Absolute tolerance to use when checking for tensor equality during load,
passed to <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.allclose.html#torch.allclose" title="(in PyTorch v2.10)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.allclose()</span></code></a>. It may be necessary to increase if you are
saving and loading on two machines with torch built by different cuda
versions. Be careful when changing this! See
<a class="reference external" href="https://docs.pytorch.org/docs/stable/type_info.html#torch.torch.finfo" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.finfo</span></code></a> for more details about floating
point precision of different data types (especially, <code class="docutils literal notranslate"><span class="pre">eps</span></code>); if you have
to increase this by more than 1 or 2 decades, then you are probably not
dealing with a numerical issue.</p></li>
<li><p><strong>tensor_equality_rtol</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></span>) – Relative tolerance to use when checking for tensor equality during load,
passed to <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.allclose.html#torch.allclose" title="(in PyTorch v2.10)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.allclose()</span></code></a>. It may be necessary to increase if you are
saving and loading on two machines with torch built by different cuda
versions. Be careful when changing this! See
<a class="reference external" href="https://docs.pytorch.org/docs/stable/type_info.html#torch.torch.finfo" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.finfo</span></code></a> for more details about floating
point precision of different data types (especially, <code class="docutils literal notranslate"><span class="pre">eps</span></code>); if you have
to increase this by more than 1 or 2 decades, then you are probably not
dealing with a numerical issue.</p></li>
<li><p><strong>**pickle_load_args</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></span>) – Any additional kwargs will be added to <code class="docutils literal notranslate"><span class="pre">pickle_module.load</span></code> via
<a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.load.html#torch.load" title="(in PyTorch v2.10)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.load()</span></code></a>, see that function’s docstring for details.</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>ValueError</strong> – If <a class="reference internal" href="#plenoptic.synthesize.eigendistortion.Eigendistortion.synthesize" title="plenoptic.synthesize.eigendistortion.Eigendistortion.synthesize"><code class="xref py py-func docutils literal notranslate"><span class="pre">synthesize()</span></code></a> has been called before this call to <code class="docutils literal notranslate"><span class="pre">load</span></code>.</p></li>
<li><p><strong>ValueError</strong> – If the object saved at <code class="docutils literal notranslate"><span class="pre">file_path</span></code> is not a <code class="docutils literal notranslate"><span class="pre">Eigendistortion</span></code> object.</p></li>
<li><p><strong>ValueError</strong> – If the saved and loading <code class="docutils literal notranslate"><span class="pre">Eigendistortion</span></code> objects have a different value
for <a class="reference internal" href="#plenoptic.synthesize.eigendistortion.Eigendistortion.image" title="plenoptic.synthesize.eigendistortion.Eigendistortion.image"><code class="xref py py-attr docutils literal notranslate"><span class="pre">image</span></code></a>.</p></li>
<li><p><strong>ValueError</strong> – If the behavior of <a class="reference internal" href="#plenoptic.synthesize.eigendistortion.Eigendistortion.model" title="plenoptic.synthesize.eigendistortion.Eigendistortion.model"><code class="xref py py-attr docutils literal notranslate"><span class="pre">model</span></code></a> is different between the saved and loading
objects.</p></li>
</ul>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="plenoptic.tools.html#plenoptic.tools.io.examine_saved_synthesis" title="plenoptic.tools.io.examine_saved_synthesis"><code class="xref py py-func docutils literal notranslate"><span class="pre">examine_saved_synthesis()</span></code></a></dt><dd><p>Examine metadata from saved object: pytorch and plenoptic versions, name of the synthesis object, shapes of tensors, etc.</p>
</dd>
</dl>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">plenoptic</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">po</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">einstein</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">simul</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">remove_grad</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">eig</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">synth</span><span class="o">.</span><span class="n">Eigendistortion</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">eig</span><span class="o">.</span><span class="n">synthesize</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">eig</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;eig.pt&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">eig_copy</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">synth</span><span class="o">.</span><span class="n">Eigendistortion</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">eig_copy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;eig.pt&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="plenoptic.synthesize.eigendistortion.Eigendistortion.model">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.10)"><span class="pre">Module</span></a></em><a class="headerlink" href="#plenoptic.synthesize.eigendistortion.Eigendistortion.model" title="Link to this definition"></a></dt>
<dd><p>The model for which the eigendistortions are synthesized.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="plenoptic.synthesize.eigendistortion.Eigendistortion.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/eigendistortion.html#Eigendistortion.save"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.eigendistortion.Eigendistortion.save" title="Link to this definition"></a></dt>
<dd><p>Save all relevant variables in .pt file.</p>
<p>See <a class="reference internal" href="#plenoptic.synthesize.eigendistortion.Eigendistortion.load" title="plenoptic.synthesize.eigendistortion.Eigendistortion.load"><code class="xref py py-meth docutils literal notranslate"><span class="pre">load()</span></code></a> docstring for an example of use.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>file_path</strong> (<em>str</em>) – The path to save the Eigendistortion object to.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="plenoptic.synthesize.eigendistortion.Eigendistortion.synthesize">
<span class="sig-name descname"><span class="pre">synthesize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'power'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop_criterion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-07</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/eigendistortion.html#Eigendistortion.synthesize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.eigendistortion.Eigendistortion.synthesize" title="Link to this definition"></a></dt>
<dd><p>Compute eigendistortions of Fisher Information Matrix with given input image.</p>
<p>There are three potential ways of computing the eigendistortion for a model;
all have the same interpretation. See <code class="docutils literal notranslate"><span class="pre">method</span></code> argument for details.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>method</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Literal</span></code>[<code class="docutils literal notranslate"><span class="pre">'exact'</span></code>, <code class="docutils literal notranslate"><span class="pre">'power'</span></code>, <code class="docutils literal notranslate"><span class="pre">'randomized_svd'</span></code>]</span>) – Eigensolver method. <code class="docutils literal notranslate"><span class="pre">'exact'</span></code> tries to do eigendecomposition directly
(not recommended for very large inputs). <code class="docutils literal notranslate"><span class="pre">'power'</span></code> uses the power
method to compute first and last eigendistortions, with maximum number of
iterations dictated by n_steps. <code class="docutils literal notranslate"><span class="pre">'randomized_svd'</span></code> uses randomized SVD to
approximate the top k eigendistortions and their corresponding eigenvalues.</p></li>
<li><p><strong>k</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – How many vectors to return using block power method or svd.</p></li>
<li><p><strong>max_iter</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – Maximum number of steps to run for <code class="docutils literal notranslate"><span class="pre">method='power'</span></code> in eigenvalue
computation. Ignored for other methods.</p></li>
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – Oversampling parameter for randomized SVD. k+p vectors will be sampled,
and k will be returned. See docstring of <code class="xref py py-meth docutils literal notranslate"><span class="pre">_synthesize_randomized_svd()</span></code>
for more details including algorithm reference.</p></li>
<li><p><strong>q</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – Matrix power parameter for randomized SVD. This is an effective trick for
the algorithm to converge to the correct eigenvectors when the
eigenspectrum does not decay quickly. See <code class="xref py py-meth docutils literal notranslate"><span class="pre">_synthesize_randomized_svd()</span></code>
for more details including algorithm reference.</p></li>
<li><p><strong>stop_criterion</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></span>) – Used if <code class="docutils literal notranslate"><span class="pre">method='power'</span></code> to check for convergence. If the L2-norm
of the eigenvalues has changed by less than this value from one
iteration to the next, we terminate synthesis.</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ValueError</strong> – If <code class="docutils literal notranslate"><span class="pre">method</span></code> takes an illegal value.</p>
</dd>
<dt class="field-odd">Warns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>UserWarning</strong> – If <code class="docutils literal notranslate"><span class="pre">method</span> <span class="pre">==</span> <span class="pre">&quot;power&quot;</span></code> but the Jacobian size is greater than 1e6 (which
depends on the number of elements in the model’s representation and input
image), in which case we’re worried abour running out of memory.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="plenoptic.synthesize.eigendistortion.Eigendistortion.to">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/eigendistortion.html#Eigendistortion.to"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.eigendistortion.Eigendistortion.to" title="Link to this definition"></a></dt>
<dd><p>Move and/or cast the parameters and buffers.</p>
<p>This can be called as</p>
<dl class="py function">
<dt class="sig sig-object py" id="id0">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">non_blocking</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/eigendistortion.html#Eigendistortion.to"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id0" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="id4">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dtype</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">non_blocking</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/eigendistortion.html#Eigendistortion.to"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id4" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="id5">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">non_blocking</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/eigendistortion.html#Eigendistortion.to"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id5" title="Link to this definition"></a></dt>
<dd></dd></dl>

<p>Its signature is similar to <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.Tensor.to.html#torch.Tensor.to" title="(in PyTorch v2.10)"><code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.Tensor.to()</span></code></a>, but only accepts
floating point desired <code class="xref py py-attr docutils literal notranslate"><span class="pre">dtype</span></code> s. In addition, this method will
only cast the floating point parameters and buffers to <code class="xref py py-attr docutils literal notranslate"><span class="pre">dtype</span></code>
(if given). The integral parameters and buffers will be moved
<code class="xref py py-attr docutils literal notranslate"><span class="pre">device</span></code>, if that is given, but with dtypes unchanged. When
<code class="xref py py-attr docutils literal notranslate"><span class="pre">non_blocking</span></code> is set, it tries to convert/move asynchronously
with respect to the host if possible, e.g., moving CPU Tensors with
pinned memory to CUDA devices.</p>
<p>See <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.to" title="(in PyTorch v2.10)"><code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.to()</span></code></a> for examples.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>device</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="(in PyTorch v2.10)"><em>torch.device</em></a>) – The desired device of the parameters and buffers in this module.</p></li>
<li><p><strong>dtype</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensor_attributes.html#torch.dtype" title="(in PyTorch v2.10)"><em>torch.dtype</em></a>) – The desired floating point type of the floating point parameters and
buffers in this module.</p></li>
<li><p><strong>tensor</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><em>torch.Tensor</em></a>) – Tensor whose dtype and device are the desired dtype and device for
all parameters and buffers in this module.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="plenoptic.synthesize.eigendistortion.display_eigendistortion">
<span class="sig-name descname"><span class="pre">display_eigendistortion</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">eigendistortion</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eigenindex=0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha=5.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">process_image=&lt;function</span> <span class="pre">&lt;lambda&gt;&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ax=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">plot_complex='rectangular'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">**kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/eigendistortion.html#display_eigendistortion"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.eigendistortion.display_eigendistortion" title="Link to this definition"></a></dt>
<dd><p>Display specified eigendistortion added to the image.</p>
<p>If image or eigendistortions have 3 channels, then it is assumed to be a color
image and it is converted to grayscale. This is merely for display convenience
and may change in the future.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>eigendistortion</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="#plenoptic.synthesize.eigendistortion.Eigendistortion" title="plenoptic.synthesize.eigendistortion.Eigendistortion"><code class="xref py py-class docutils literal notranslate"><span class="pre">Eigendistortion</span></code></a></span>) – Eigendistortion object whose synthesized eigendistortion we want to display.</p></li>
<li><p><strong>eigenindex</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – Index of eigendistortion to plot. E.g. If there are 10 eigenvectors, 0 will
index the first one, and -1 or 9 will index the last one.</p></li>
<li><p><strong>alpha</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></span>) – Amount by which to scale eigendistortion for
<code class="docutils literal notranslate"><span class="pre">image</span> <span class="pre">+</span> <span class="pre">(alpha</span> <span class="pre">*</span> <span class="pre">eigendistortion)</span></code> for display.</p></li>
<li><p><strong>process_image</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">Callable</span></code>[[<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>], <a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span>) – A function to process the image+alpha*distortion before clamping between 0,1.
E.g. multiplying by the stdev ImageNet then adding the mean of ImageNet to undo
image preprocessing.</p></li>
<li><p><strong>ax</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.html#matplotlib.axes.Axes" title="(in Matplotlib v3.10.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Axes</span></code></a> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Axis handle on which to plot.</p></li>
<li><p><strong>plot_complex</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></span>) – Parameter for <code class="xref py py-meth docutils literal notranslate"><span class="pre">plenoptic.imshow()</span></code> determining how to handle complex values.
Defaults to <code class="docutils literal notranslate"><span class="pre">'rectangular'</span></code>, which plots real and complex components as
separate images. See that method’s docstring for details.</p></li>
<li><p><strong>**kwargs</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></span>) – Additional arguments for <code class="xref py py-meth docutils literal notranslate"><span class="pre">po.imshow()</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.figure.Figure.html#matplotlib.figure.Figure" title="(in Matplotlib v3.10.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Figure</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>fig</em> – Figure handle returned by <code class="xref py py-meth docutils literal notranslate"><span class="pre">plenoptic.imshow()</span></code>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="plenoptic.synthesize.eigendistortion.fisher_info_matrix_eigenvalue">
<span class="sig-name descname"><span class="pre">fisher_info_matrix_eigenvalue</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">v</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dummy_vec</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/eigendistortion.html#fisher_info_matrix_eigenvalue"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.eigendistortion.fisher_info_matrix_eigenvalue" title="Link to this definition"></a></dt>
<dd><p>Compute eigenvalues of Fisher vector products.</p>
<p>We compute the Fisher Information Matrix corresponding to eigenvectors in <code class="docutils literal notranslate"><span class="pre">v</span></code>:
<span class="math notranslate nohighlight">\(\lambda= v^T F v\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Output tensor with gradient attached.</p></li>
<li><p><strong>x</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Input tensor with gradient attached.</p></li>
<li><p><strong>v</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – The vectors with which to compute Fisher vector products.</p></li>
<li><p><strong>dummy_vec</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Dummy vector for Jacobian vector product trick.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>lmbda</em> – The computed eigenvalues.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="plenoptic.synthesize.eigendistortion.fisher_info_matrix_vector_product">
<span class="sig-name descname"><span class="pre">fisher_info_matrix_vector_product</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">v</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dummy_vec</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/eigendistortion.html#fisher_info_matrix_vector_product"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.eigendistortion.fisher_info_matrix_vector_product" title="Link to this definition"></a></dt>
<dd><p>Compute Fisher Information Matrix Vector Product: <span class="math notranslate nohighlight">\(Fv\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Output tensor with gradient attached.</p></li>
<li><p><strong>x</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Input tensor with gradient attached.</p></li>
<li><p><strong>v</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – The vectors with which to compute Fisher vector products.</p></li>
<li><p><strong>dummy_vec</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Dummy vector for Jacobian vector product trick.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Fv</em> – Vector, Fisher vector product.</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>Under white Gaussian noise assumption, <span class="math notranslate nohighlight">\(F\)</span> is matrix multiplication
of Jacobian transpose and Jacobian:
<span class="math notranslate nohighlight">\(F = J^T J\)</span>. Hence:
<span class="math notranslate nohighlight">\(Fv = J^T (Jv)\)</span></p>
</dd></dl>

</section>
<section id="module-plenoptic.synthesize.mad_competition">
<span id="plenoptic-synthesize-mad-competition-module"></span><h2>plenoptic.synthesize.mad_competition module<a class="headerlink" href="#module-plenoptic.synthesize.mad_competition" title="Link to this heading"></a></h2>
<p>Run MAD Competition.</p>
<p>Classes to perform the synthesis of Maximum Differentiation Competition.</p>
<dl class="py class">
<dt class="sig sig-object py" id="plenoptic.synthesize.mad_competition.MADCompetition">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">MADCompetition</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimized_metric</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reference_metric</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">minmax</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_tradeoff_lambda</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">range_penalty_lambda</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">allowed_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0,</span> <span class="pre">1)</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/mad_competition.html#MADCompetition"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.mad_competition.MADCompetition" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#plenoptic.synthesize.synthesis.OptimizedSynthesis" title="plenoptic.synthesize.synthesis.OptimizedSynthesis"><code class="xref py py-class docutils literal notranslate"><span class="pre">OptimizedSynthesis</span></code></a></p>
<p>Synthesize a single maximally-differentiating image for two metrics.</p>
<p>Following the basic idea in <a class="reference internal" href="#r457fcb70e19f-1" id="id6">[1]</a>, this class synthesizes a
maximally-differentiating image for two given metrics, based on a given
image. We start by adding noise to this image and then iteratively
adjusting its pixels so as to either minimize or maximize
<code class="docutils literal notranslate"><span class="pre">optimized_metric</span></code> while holding the value of <code class="docutils literal notranslate"><span class="pre">reference_metric</span></code> constant.</p>
<p>MADCompetiton accepts two metrics as its input. These should be callables
that take two images and return a single number, and that number should be
0 if and only if the two images are identical (thus, the larger the number,
the more different the two images).</p>
<p>Note that a full set of MAD Competition images consists of two pairs: a maximal and
a minimal image for each metric. A single instantiation of <code class="docutils literal notranslate"><span class="pre">MADCompetition</span></code> will
generate one of these four images.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>image</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – A tensor, this is the image we use as the reference point.</p></li>
<li><p><strong>optimized_metric</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a> | <code class="xref py py-class docutils literal notranslate"><span class="pre">Callable</span></code>[[<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>], <a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span>) – The metric whose value you wish to minimize or maximize, which takes
two tensors and returns a scalar.</p></li>
<li><p><strong>reference_metric</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a> | <code class="xref py py-class docutils literal notranslate"><span class="pre">Callable</span></code>[[<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>], <a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span>) – The metric whose value you wish to keep fixed, which takes two tensors
and returns a scalar.</p></li>
<li><p><strong>minmax</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Literal</span></code>[<code class="docutils literal notranslate"><span class="pre">'min'</span></code>, <code class="docutils literal notranslate"><span class="pre">'max'</span></code>]</span>) – Whether you wish to minimize or maximize <code class="docutils literal notranslate"><span class="pre">optimized_metric</span></code>.</p></li>
<li><p><strong>metric_tradeoff_lambda</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Lambda to multiply by <code class="docutils literal notranslate"><span class="pre">reference_metric</span></code> loss and add to
<code class="docutils literal notranslate"><span class="pre">optimized_metric</span></code> loss. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, we pick a value so the two
initial losses are approximately equal in magnitude.</p></li>
<li><p><strong>range_penalty_lambda</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></span>) – Lambda to multiply by range penalty and add to loss.</p></li>
<li><p><strong>allowed_range</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>]</span>) – Range (inclusive) of allowed pixel values. Any values outside this
range will be penalized.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r457fcb70e19f-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id6">1</a><span class="fn-bracket">]</span></span>
<p>Wang, Z., &amp; Simoncelli, E. P. (2008). Maximum differentiation (MAD)
competition: A methodology for comparing computational models of
perceptual discriminability. Journal of Vision, 8(12), 1–13.
<a class="reference external" href="https://dx.doi.org/10.1167/8.12.8">https://dx.doi.org/10.1167/8.12.8</a></p>
</div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Attributes<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">allowed_range</span></code></dt><dd><p>Allowable range of pixel values.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient_norm</span></code></dt><dd><p>Optimization gradient’s L2 norm over iterations.</p>
</dd>
<dt><a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition.image" title="plenoptic.synthesize.mad_competition.MADCompetition.image"><code class="xref py py-obj docutils literal notranslate"><span class="pre">image</span></code></a></dt><dd><p>The reference image for this MAD Competition.</p>
</dd>
<dt><a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition.initial_image" title="plenoptic.synthesize.mad_competition.MADCompetition.initial_image"><code class="xref py py-obj docutils literal notranslate"><span class="pre">initial_image</span></code></a></dt><dd><p>Initial image for MAD Competition.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">losses</span></code></dt><dd><p>Optimization loss over iterations.</p>
</dd>
<dt><a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition.mad_image" title="plenoptic.synthesize.mad_competition.MADCompetition.mad_image"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mad_image</span></code></a></dt><dd><p>Maximally-differentiating image, the parameter we are optimizing.</p>
</dd>
<dt><a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition.metric_tradeoff_lambda" title="plenoptic.synthesize.mad_competition.MADCompetition.metric_tradeoff_lambda"><code class="xref py py-obj docutils literal notranslate"><span class="pre">metric_tradeoff_lambda</span></code></a></dt><dd><p>Tradeoff between the two metrics in synthesis loss.</p>
</dd>
<dt><a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition.minmax" title="plenoptic.synthesize.mad_competition.MADCompetition.minmax"><code class="xref py py-obj docutils literal notranslate"><span class="pre">minmax</span></code></a></dt><dd><p>Whether we are minimizing or maximizing <a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition.optimized_metric" title="plenoptic.synthesize.mad_competition.MADCompetition.optimized_metric"><code class="xref py py-attr docutils literal notranslate"><span class="pre">optimized_metric</span></code></a>.</p>
</dd>
<dt><a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition.optimized_metric" title="plenoptic.synthesize.mad_competition.MADCompetition.optimized_metric"><code class="xref py py-obj docutils literal notranslate"><span class="pre">optimized_metric</span></code></a></dt><dd><p>The metric whose value we are minimizing or maximizing.</p>
</dd>
<dt><a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition.optimized_metric_loss" title="plenoptic.synthesize.mad_competition.MADCompetition.optimized_metric_loss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">optimized_metric_loss</span></code></a></dt><dd><p><a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition.optimized_metric" title="plenoptic.synthesize.mad_competition.MADCompetition.optimized_metric"><code class="xref py py-attr docutils literal notranslate"><span class="pre">optimized_metric</span></code></a> loss over iterations.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">optimizer</span></code></dt><dd><p>Torch optimizer object which updates the synthesis target.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">pixel_change_norm</span></code></dt><dd><p>L2 norm change in pixel values over iterations.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">range_penalty_lambda</span></code></dt><dd><p>Magnitude of the penalty on pixel values outside <code class="xref py py-attr docutils literal notranslate"><span class="pre">allowed_range</span></code>.</p>
</dd>
<dt><a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition.reference_metric" title="plenoptic.synthesize.mad_competition.MADCompetition.reference_metric"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reference_metric</span></code></a></dt><dd><p>The metric whose value we are keeping constant.</p>
</dd>
<dt><a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition.reference_metric_loss" title="plenoptic.synthesize.mad_competition.MADCompetition.reference_metric_loss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reference_metric_loss</span></code></a></dt><dd><p><a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition.reference_metric" title="plenoptic.synthesize.mad_competition.MADCompetition.reference_metric"><code class="xref py py-attr docutils literal notranslate"><span class="pre">reference_metric</span></code></a> loss over iterations.</p>
</dd>
<dt><a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition.saved_mad_image" title="plenoptic.synthesize.mad_competition.MADCompetition.saved_mad_image"><code class="xref py py-obj docutils literal notranslate"><span class="pre">saved_mad_image</span></code></a></dt><dd><p><a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition.mad_image" title="plenoptic.synthesize.mad_competition.MADCompetition.mad_image"><code class="xref py py-attr docutils literal notranslate"><span class="pre">mad_image</span></code></a>, cached over time for later examination.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">scheduler</span></code></dt><dd><p>Learning rate scheduler which adjusts optimizer learning rate.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">store_progress</span></code></dt><dd><p>How often we are caching progress.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Methods</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition.load" title="plenoptic.synthesize.mad_competition.MADCompetition.load"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load</span></code></a>(file_path[, map_location, ...])</p></td>
<td><p>Load all relevant stuff from a .pt file.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition.objective_function" title="plenoptic.synthesize.mad_competition.MADCompetition.objective_function"><code class="xref py py-obj docutils literal notranslate"><span class="pre">objective_function</span></code></a>([mad_image, image])</p></td>
<td><p>Compute the MADCompetition synthesis loss.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition.save" title="plenoptic.synthesize.mad_competition.MADCompetition.save"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save</span></code></a>(file_path)</p></td>
<td><p>Save all relevant variables in .pt file.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition.setup" title="plenoptic.synthesize.mad_competition.MADCompetition.setup"><code class="xref py py-obj docutils literal notranslate"><span class="pre">setup</span></code></a>([initial_noise, optimizer, ...])</p></td>
<td><p>Initialize the MAD image, optimizer, and scheduler.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition.synthesize" title="plenoptic.synthesize.mad_competition.MADCompetition.synthesize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">synthesize</span></code></a>([max_iter, store_progress, ...])</p></td>
<td><p>Synthesize a MAD image.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#id9" title="plenoptic.synthesize.mad_competition.MADCompetition.to"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to</span></code></a>(*args, **kwargs)</p></td>
<td><p>Move and/or casts the parameters and buffers.</p></td>
</tr>
</tbody>
</table>
<dl class="py property">
<dt class="sig sig-object py" id="plenoptic.synthesize.mad_competition.MADCompetition.image">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">image</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><span class="pre">Tensor</span></a></em><a class="headerlink" href="#plenoptic.synthesize.mad_competition.MADCompetition.image" title="Link to this definition"></a></dt>
<dd><p>The reference image for this MAD Competition.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="plenoptic.synthesize.mad_competition.MADCompetition.initial_image">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">initial_image</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><span class="pre">Tensor</span></a></em><a class="headerlink" href="#plenoptic.synthesize.mad_competition.MADCompetition.initial_image" title="Link to this definition"></a></dt>
<dd><p>Initial image for MAD Competition.</p>
<p>This is the image whose distance to <code class="docutils literal notranslate"><span class="pre">image</span></code>, the reference, we are
maximizing/minimizing for <code class="docutils literal notranslate"><span class="pre">optimized_metric</span></code>, while keeping constant for
<code class="docutils literal notranslate"><span class="pre">reference_metric</span></code>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="plenoptic.synthesize.mad_competition.MADCompetition.load">
<span class="sig-name descname"><span class="pre">load</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">map_location</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensor_equality_atol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-08</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensor_equality_rtol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">pickle_load_args</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/mad_competition.html#MADCompetition.load"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.mad_competition.MADCompetition.load" title="Link to this definition"></a></dt>
<dd><p>Load all relevant stuff from a .pt file.</p>
<p>This must be called by a <code class="docutils literal notranslate"><span class="pre">MADCompetition</span></code> object initialized just like the
saved object.</p>
<p>Note this operates in place and so doesn’t return anything.</p>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 1.2: </span>load behavior changed in a backwards-incompatible manner in order to
compatible with breaking changes in torch 2.6.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>file_path</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></span>) – The path to load the synthesis object from.</p></li>
<li><p><strong>map_location</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Argument to pass to <code class="docutils literal notranslate"><span class="pre">torch.load</span></code> as <code class="docutils literal notranslate"><span class="pre">map_location</span></code>. If you save
stuff that was being run on a GPU and are loading onto a
CPU, you’ll need this to make sure everything lines up
properly. This should be structured like the str you would
pass to <a class="reference external" href="https://docs.pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.device</span></code></a>.</p></li>
<li><p><strong>tensor_equality_atol</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></span>) – Absolute tolerance to use when checking for tensor equality during load,
passed to <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.allclose.html#torch.allclose" title="(in PyTorch v2.10)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.allclose()</span></code></a>. It may be necessary to increase if you are
saving and loading on two machines with torch built by different cuda
versions. Be careful when changing this! See
<a class="reference external" href="https://docs.pytorch.org/docs/stable/type_info.html#torch.torch.finfo" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.finfo</span></code></a> for more details about floating
point precision of different data types (especially, <code class="docutils literal notranslate"><span class="pre">eps</span></code>); if you have
to increase this by more than 1 or 2 decades, then you are probably not
dealing with a numerical issue.</p></li>
<li><p><strong>tensor_equality_rtol</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></span>) – Relative tolerance to use when checking for tensor equality during load,
passed to <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.allclose.html#torch.allclose" title="(in PyTorch v2.10)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.allclose()</span></code></a>. It may be necessary to increase if you are
saving and loading on two machines with torch built by different cuda
versions. Be careful when changing this! See
<a class="reference external" href="https://docs.pytorch.org/docs/stable/type_info.html#torch.torch.finfo" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.finfo</span></code></a> for more details about floating
point precision of different data types (especially, <code class="docutils literal notranslate"><span class="pre">eps</span></code>); if you have
to increase this by more than 1 or 2 decades, then you are probably not
dealing with a numerical issue.</p></li>
<li><p><strong>**pickle_load_args</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></span>) – Any additional kwargs will be added to <code class="docutils literal notranslate"><span class="pre">pickle_module.load</span></code> via
<a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.load.html#torch.load" title="(in PyTorch v2.10)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.load()</span></code></a>, see that function’s docstring for details.</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>ValueError</strong> – If <a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition.setup" title="plenoptic.synthesize.mad_competition.MADCompetition.setup"><code class="xref py py-func docutils literal notranslate"><span class="pre">setup()</span></code></a> or <a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition.synthesize" title="plenoptic.synthesize.mad_competition.MADCompetition.synthesize"><code class="xref py py-func docutils literal notranslate"><span class="pre">synthesize()</span></code></a> has been called before this call
to <code class="docutils literal notranslate"><span class="pre">load</span></code>.</p></li>
<li><p><strong>ValueError</strong> – If the object saved at <code class="docutils literal notranslate"><span class="pre">file_path</span></code> is not a <code class="docutils literal notranslate"><span class="pre">MADCompetition</span></code> object.</p></li>
<li><p><strong>ValueError</strong> – If the saved and loading <code class="docutils literal notranslate"><span class="pre">MADCompetition</span></code> objects have a different value
for any of <a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition.image" title="plenoptic.synthesize.mad_competition.MADCompetition.image"><code class="xref py py-attr docutils literal notranslate"><span class="pre">image</span></code></a>, <code class="xref py py-attr docutils literal notranslate"><span class="pre">range_penalty_lambda</span></code>,
<code class="xref py py-attr docutils literal notranslate"><span class="pre">allowed_range</span></code>, <a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition.metric_tradeoff_lambda" title="plenoptic.synthesize.mad_competition.MADCompetition.metric_tradeoff_lambda"><code class="xref py py-attr docutils literal notranslate"><span class="pre">metric_tradeoff_lambda</span></code></a>, or <code class="xref py py-attr docutils literal notranslate"><span class="pre">minimax</span></code>.</p></li>
<li><p><strong>ValueError</strong> – If the behavior of <a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition.optimized_metric" title="plenoptic.synthesize.mad_competition.MADCompetition.optimized_metric"><code class="xref py py-attr docutils literal notranslate"><span class="pre">optimized_metric</span></code></a> or <a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition.reference_metric" title="plenoptic.synthesize.mad_competition.MADCompetition.reference_metric"><code class="xref py py-attr docutils literal notranslate"><span class="pre">reference_metric</span></code></a> is
different between the saved and loading objects.</p></li>
</ul>
</dd>
<dt class="field-odd">Warns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>UserWarning</strong> – If <a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition.setup" title="plenoptic.synthesize.mad_competition.MADCompetition.setup"><code class="xref py py-func docutils literal notranslate"><span class="pre">setup()</span></code></a> will need to be called after <code class="docutils literal notranslate"><span class="pre">load</span></code>, to finish
initializing <code class="xref py py-attr docutils literal notranslate"><span class="pre">optimizer</span></code> or <code class="xref py py-attr docutils literal notranslate"><span class="pre">scheduler</span></code>.</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="plenoptic.tools.html#plenoptic.tools.io.examine_saved_synthesis" title="plenoptic.tools.io.examine_saved_synthesis"><code class="xref py py-func docutils literal notranslate"><span class="pre">examine_saved_synthesis()</span></code></a></dt><dd><p>Examine metadata from saved object: pytorch and plenoptic versions, name of the synthesis object, shapes of tensors, etc.</p>
</dd>
</dl>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">plenoptic</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">po</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">einstein</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span><span class="w"> </span><span class="nf">ds_ssim</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">po</span><span class="o">.</span><span class="n">metric</span><span class="o">.</span><span class="n">ssim</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mad</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">synth</span><span class="o">.</span><span class="n">MADCompetition</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">img</span><span class="p">,</span> <span class="n">po</span><span class="o">.</span><span class="n">metric</span><span class="o">.</span><span class="n">mse</span><span class="p">,</span> <span class="n">ds_ssim</span><span class="p">,</span> <span class="s2">&quot;min&quot;</span><span class="p">,</span> <span class="n">metric_tradeoff_lambda</span><span class="o">=</span><span class="mi">10</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mad</span><span class="o">.</span><span class="n">synthesize</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">store_progress</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mad</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;mad.pt&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mad_copy</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">synth</span><span class="o">.</span><span class="n">MADCompetition</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">img</span><span class="p">,</span> <span class="n">po</span><span class="o">.</span><span class="n">metric</span><span class="o">.</span><span class="n">mse</span><span class="p">,</span> <span class="n">ds_ssim</span><span class="p">,</span> <span class="s2">&quot;min&quot;</span><span class="p">,</span> <span class="n">metric_tradeoff_lambda</span><span class="o">=</span><span class="mi">10</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mad_copy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;mad.pt&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="plenoptic.synthesize.mad_competition.MADCompetition.mad_image">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">mad_image</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><span class="pre">Tensor</span></a></em><a class="headerlink" href="#plenoptic.synthesize.mad_competition.MADCompetition.mad_image" title="Link to this definition"></a></dt>
<dd><p>Maximally-differentiating image, the parameter we are optimizing.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="plenoptic.synthesize.mad_competition.MADCompetition.metric_tradeoff_lambda">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">metric_tradeoff_lambda</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><a class="headerlink" href="#plenoptic.synthesize.mad_competition.MADCompetition.metric_tradeoff_lambda" title="Link to this definition"></a></dt>
<dd><p>Tradeoff between the two metrics in synthesis loss.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="plenoptic.synthesize.mad_competition.MADCompetition.minmax">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">minmax</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'min'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'max'</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#plenoptic.synthesize.mad_competition.MADCompetition.minmax" title="Link to this definition"></a></dt>
<dd><p>Whether we are minimizing or maximizing <a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition.optimized_metric" title="plenoptic.synthesize.mad_competition.MADCompetition.optimized_metric"><code class="xref py py-attr docutils literal notranslate"><span class="pre">optimized_metric</span></code></a>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="plenoptic.synthesize.mad_competition.MADCompetition.objective_function">
<span class="sig-name descname"><span class="pre">objective_function</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mad_image</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">image</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/mad_competition.html#MADCompetition.objective_function"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.mad_competition.MADCompetition.objective_function" title="Link to this definition"></a></dt>
<dd><p>Compute the MADCompetition synthesis loss.</p>
<p>This computes:</p>
<div class="math notranslate nohighlight">
\[\begin{split}t L_1(x, \hat{x}) &amp;+ \lambda_1 [L_2(x, x+\epsilon) - L_2(x, \hat{x})]^2 \\
                  &amp;+ \lambda_2 \mathcal{B}(\hat{x})\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(t\)</span> is 1 if <a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition.minmax" title="plenoptic.synthesize.mad_competition.MADCompetition.minmax"><code class="xref py py-attr docutils literal notranslate"><span class="pre">minmax</span></code></a> is <code class="docutils literal notranslate"><span class="pre">'min'</span></code> and -1 if it’s <code class="docutils literal notranslate"><span class="pre">'max'</span></code>,
<span class="math notranslate nohighlight">\(L_1\)</span> is <a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition.optimized_metric" title="plenoptic.synthesize.mad_competition.MADCompetition.optimized_metric"><code class="xref py py-attr docutils literal notranslate"><span class="pre">optimized_metric</span></code></a>, <span class="math notranslate nohighlight">\(L_2\)</span> is
<a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition.reference_metric" title="plenoptic.synthesize.mad_competition.MADCompetition.reference_metric"><code class="xref py py-attr docutils literal notranslate"><span class="pre">reference_metric</span></code></a>, <span class="math notranslate nohighlight">\(x\)</span> is <a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition.image" title="plenoptic.synthesize.mad_competition.MADCompetition.image"><code class="xref py py-attr docutils literal notranslate"><span class="pre">image</span></code></a>, <span class="math notranslate nohighlight">\(\hat{x}\)</span> is
<a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition.mad_image" title="plenoptic.synthesize.mad_competition.MADCompetition.mad_image"><code class="xref py py-attr docutils literal notranslate"><span class="pre">mad_image</span></code></a>, <span class="math notranslate nohighlight">\(\epsilon\)</span> is the initial noise, <span class="math notranslate nohighlight">\(\mathcal{B}\)</span> is
the quadratic bound penalty, <span class="math notranslate nohighlight">\(\lambda_1\)</span> is <a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition.metric_tradeoff_lambda" title="plenoptic.synthesize.mad_competition.MADCompetition.metric_tradeoff_lambda"><code class="xref py py-attr docutils literal notranslate"><span class="pre">metric_tradeoff_lambda</span></code></a>
and <span class="math notranslate nohighlight">\(\lambda_2\)</span> is <code class="xref py py-attr docutils literal notranslate"><span class="pre">range_penalty_lambda</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mad_image</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Proposed <code class="docutils literal notranslate"><span class="pre">mad_image</span></code>, <span class="math notranslate nohighlight">\(\hat{x}\)</span> in the above equation. If
None, use <code class="docutils literal notranslate"><span class="pre">self.mad_image</span></code>.</p></li>
<li><p><strong>image</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Proposed <code class="docutils literal notranslate"><span class="pre">image</span></code>, <span class="math notranslate nohighlight">\(x\)</span> in the above equation. If
None, use <code class="docutils literal notranslate"><span class="pre">self.image</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>loss</em> – 1-element tensor containing the loss on this step.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="plenoptic.synthesize.mad_competition.MADCompetition.optimized_metric">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">optimized_metric</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.10)"><span class="pre">Module</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><span class="pre">Tensor</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><span class="pre">Tensor</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><span class="pre">Tensor</span></a><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#plenoptic.synthesize.mad_competition.MADCompetition.optimized_metric" title="Link to this definition"></a></dt>
<dd><p>The metric whose value we are minimizing or maximizing.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="plenoptic.synthesize.mad_competition.MADCompetition.optimized_metric_loss">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">optimized_metric_loss</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><span class="pre">Tensor</span></a></em><a class="headerlink" href="#plenoptic.synthesize.mad_competition.MADCompetition.optimized_metric_loss" title="Link to this definition"></a></dt>
<dd><p><a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition.optimized_metric" title="plenoptic.synthesize.mad_competition.MADCompetition.optimized_metric"><code class="xref py py-attr docutils literal notranslate"><span class="pre">optimized_metric</span></code></a> loss over iterations.</p>
<p>That is, the value of <code class="docutils literal notranslate"><span class="pre">optimized_metric(image,</span> <span class="pre">mad_image)</span></code>. Ideally, this is
either very different from <code class="docutils literal notranslate"><span class="pre">optimized_metric(image,</span> <span class="pre">initial_image)</span></code>.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="plenoptic.synthesize.mad_competition.MADCompetition.reference_metric">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">reference_metric</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.10)"><span class="pre">Module</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><span class="pre">Tensor</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><span class="pre">Tensor</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><span class="pre">Tensor</span></a><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#plenoptic.synthesize.mad_competition.MADCompetition.reference_metric" title="Link to this definition"></a></dt>
<dd><p>The metric whose value we are keeping constant.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="plenoptic.synthesize.mad_competition.MADCompetition.reference_metric_loss">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">reference_metric_loss</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><span class="pre">Tensor</span></a></em><a class="headerlink" href="#plenoptic.synthesize.mad_competition.MADCompetition.reference_metric_loss" title="Link to this definition"></a></dt>
<dd><p><a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition.reference_metric" title="plenoptic.synthesize.mad_competition.MADCompetition.reference_metric"><code class="xref py py-attr docutils literal notranslate"><span class="pre">reference_metric</span></code></a> loss over iterations.</p>
<p>That is, the value of <code class="docutils literal notranslate"><span class="pre">reference_metric(image,</span> <span class="pre">mad_image)</span></code>. Ideally, this is
equal to <code class="docutils literal notranslate"><span class="pre">reference_metric(image,</span> <span class="pre">initial_image)</span></code>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="plenoptic.synthesize.mad_competition.MADCompetition.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/mad_competition.html#MADCompetition.save"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.mad_competition.MADCompetition.save" title="Link to this definition"></a></dt>
<dd><p>Save all relevant variables in .pt file.</p>
<p>Note that if <code class="docutils literal notranslate"><span class="pre">store_progress</span></code> is True, this will probably be very
large.</p>
<p>See <a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition.load" title="plenoptic.synthesize.mad_competition.MADCompetition.load"><code class="xref py py-func docutils literal notranslate"><span class="pre">load()</span></code></a> docstring for an example of use.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>file_path</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></span>) – The path to save the MADCompetition object to.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="plenoptic.synthesize.mad_competition.MADCompetition.saved_mad_image">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">saved_mad_image</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><span class="pre">Tensor</span></a></em><a class="headerlink" href="#plenoptic.synthesize.mad_competition.MADCompetition.saved_mad_image" title="Link to this definition"></a></dt>
<dd><p><a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition.mad_image" title="plenoptic.synthesize.mad_competition.MADCompetition.mad_image"><code class="xref py py-attr docutils literal notranslate"><span class="pre">mad_image</span></code></a>, cached over time for later examination.</p>
<p>How often the metamer is cached is determined by the <code class="docutils literal notranslate"><span class="pre">store_progress</span></code> argument
to the <a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition.synthesize" title="plenoptic.synthesize.mad_competition.MADCompetition.synthesize"><code class="xref py py-func docutils literal notranslate"><span class="pre">synthesize()</span></code></a> function.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="plenoptic.synthesize.mad_competition.MADCompetition.setup">
<span class="sig-name descname"><span class="pre">setup</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">initial_noise</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scheduler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scheduler_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/mad_competition.html#MADCompetition.setup"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.mad_competition.MADCompetition.setup" title="Link to this definition"></a></dt>
<dd><p>Initialize the MAD image, optimizer, and scheduler.</p>
<p>Can only be called once. If <code class="docutils literal notranslate"><span class="pre">load()</span></code> has been called, <code class="docutils literal notranslate"><span class="pre">initial_noise</span></code> must
be None.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>initial_noise</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – <a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition.mad_image" title="plenoptic.synthesize.mad_competition.MADCompetition.mad_image"><code class="xref py py-attr docutils literal notranslate"><span class="pre">mad_image</span></code></a> is initialized to <code class="docutils literal notranslate"><span class="pre">self.image</span> <span class="pre">+</span> <span class="pre">initial_noise</span> <span class="pre">*</span>
<span class="pre">torch.randn_like(self.image)</span></code>, so this gives the standard deviation of the
Gaussian noise. If None, we use a value of 0.1.</p></li>
<li><p><strong>optimizer</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code></a> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – The un-initialized optimizer object to use. If None, we use Adam.</p></li>
<li><p><strong>optimizer_kwargs</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – The keyword arguments to pass to the optimizer on initialization. If
<code class="docutils literal notranslate"><span class="pre">None</span></code>, we use <code class="docutils literal notranslate"><span class="pre">{&quot;lr&quot;:</span> <span class="pre">.01}</span></code> and, if optimizer is <code class="docutils literal notranslate"><span class="pre">None</span></code>,
<code class="docutils literal notranslate"><span class="pre">{&quot;amsgrad&quot;:</span> <span class="pre">True}</span></code>.</p></li>
<li><p><strong>scheduler</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.LRScheduler.html#torch.optim.lr_scheduler.LRScheduler" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">LRScheduler</span></code></a> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – The un-initialized learning rate scheduler object to use. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, we
don’t use one.</p></li>
<li><p><strong>scheduler_kwargs</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – The keyword arguments to pass to the scheduler on initialization.</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>ValueError</strong> – If you try to set <code class="docutils literal notranslate"><span class="pre">initial_noise</span></code> after calling <a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition.load" title="plenoptic.synthesize.mad_competition.MADCompetition.load"><code class="xref py py-func docutils literal notranslate"><span class="pre">load()</span></code></a>.</p></li>
<li><p><strong>ValueError</strong> – If <code class="docutils literal notranslate"><span class="pre">setup</span></code> is called more than once or after <a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition.synthesize" title="plenoptic.synthesize.mad_competition.MADCompetition.synthesize"><code class="xref py py-func docutils literal notranslate"><span class="pre">synthesize()</span></code></a>.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>Set initial noise:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">plenoptic</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">po</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">einstein</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mad</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">synth</span><span class="o">.</span><span class="n">MADCompetition</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">img</span><span class="p">,</span>
<span class="gp">... </span>    <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">po</span><span class="o">.</span><span class="n">metric</span><span class="o">.</span><span class="n">ssim</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span>
<span class="gp">... </span>    <span class="n">po</span><span class="o">.</span><span class="n">metric</span><span class="o">.</span><span class="n">mse</span><span class="p">,</span>
<span class="gp">... </span>    <span class="s2">&quot;min&quot;</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">metric_tradeoff_lambda</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mad</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mad</span><span class="o">.</span><span class="n">synthesize</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
<p>Set optimizer:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">plenoptic</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">po</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">einstein</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mad</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">synth</span><span class="o">.</span><span class="n">MADCompetition</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">img</span><span class="p">,</span>
<span class="gp">... </span>    <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">po</span><span class="o">.</span><span class="n">metric</span><span class="o">.</span><span class="n">ssim</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span>
<span class="gp">... </span>    <span class="n">po</span><span class="o">.</span><span class="n">metric</span><span class="o">.</span><span class="n">mse</span><span class="p">,</span>
<span class="gp">... </span>    <span class="s2">&quot;min&quot;</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">metric_tradeoff_lambda</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mad</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">,</span> <span class="n">optimizer_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">})</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mad</span><span class="o">.</span><span class="n">synthesize</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
<p>Use with save/load. Only the optimizer object is necessary, its kwargs and the
initial noise are handled by load.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">plenoptic</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">po</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">einstein</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mad</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">synth</span><span class="o">.</span><span class="n">MADCompetition</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">img</span><span class="p">,</span>
<span class="gp">... </span>    <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">po</span><span class="o">.</span><span class="n">metric</span><span class="o">.</span><span class="n">ssim</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span>
<span class="gp">... </span>    <span class="n">po</span><span class="o">.</span><span class="n">metric</span><span class="o">.</span><span class="n">mse</span><span class="p">,</span>
<span class="gp">... </span>    <span class="s2">&quot;min&quot;</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">metric_tradeoff_lambda</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mad</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">,</span> <span class="n">optimizer_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">})</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mad</span><span class="o">.</span><span class="n">synthesize</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mad</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;mad_setup.pt&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mad</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">synth</span><span class="o">.</span><span class="n">MADCompetition</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">img</span><span class="p">,</span>
<span class="gp">... </span>    <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">po</span><span class="o">.</span><span class="n">metric</span><span class="o">.</span><span class="n">ssim</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span>
<span class="gp">... </span>    <span class="n">po</span><span class="o">.</span><span class="n">metric</span><span class="o">.</span><span class="n">mse</span><span class="p">,</span>
<span class="gp">... </span>    <span class="s2">&quot;min&quot;</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">metric_tradeoff_lambda</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mad</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;mad_setup.pt&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mad</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mad</span><span class="o">.</span><span class="n">synthesize</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="plenoptic.synthesize.mad_competition.MADCompetition.synthesize">
<span class="sig-name descname"><span class="pre">synthesize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">store_progress</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop_criterion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop_iters_to_check</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">50</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/mad_competition.html#MADCompetition.synthesize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.mad_competition.MADCompetition.synthesize" title="Link to this definition"></a></dt>
<dd><p>Synthesize a MAD image.</p>
<p>Update the pixels of <a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition.initial_image" title="plenoptic.synthesize.mad_competition.MADCompetition.initial_image"><code class="xref py py-attr docutils literal notranslate"><span class="pre">initial_image</span></code></a> to maximize or minimize
(depending on the value of <code class="docutils literal notranslate"><span class="pre">minmax</span></code>) the value of
<code class="docutils literal notranslate"><span class="pre">optimized_metric(image,</span> <span class="pre">mad_image)</span></code> while keeping the value of
<code class="docutils literal notranslate"><span class="pre">reference_metric(image,</span> <span class="pre">mad_image)</span></code> constant.</p>
<p>We run this until either we reach <code class="docutils literal notranslate"><span class="pre">max_iter</span></code> or the change over the
past <code class="docutils literal notranslate"><span class="pre">stop_iters_to_check</span></code> iterations is less than
<code class="docutils literal notranslate"><span class="pre">stop_criterion</span></code>, whichever comes first.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>max_iter</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – The maximum number of iterations to run before we end synthesis
(unless we hit the stop criterion).</p></li>
<li><p><strong>store_progress</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code> | <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – Whether we should store the MAD image in progress during synthesis. If
False, we don’t save anything. If True, we save every iteration. If an int,
we save every <code class="docutils literal notranslate"><span class="pre">store_progress</span></code> iterations (note then that 0 is the same as
False and 1 the same as True).</p></li>
<li><p><strong>stop_criterion</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></span>) – If the loss over the past <code class="docutils literal notranslate"><span class="pre">stop_iters_to_check</span></code> has changed
less than <code class="docutils literal notranslate"><span class="pre">stop_criterion</span></code>, we terminate synthesis.</p></li>
<li><p><strong>stop_iters_to_check</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – How many iterations back to check in order to see if the
loss has stopped decreasing (for <code class="docutils literal notranslate"><span class="pre">stop_criterion</span></code>).</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ValueError</strong> – If we find a NaN during optimization.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="plenoptic.synthesize.mad_competition.MADCompetition.to">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/mad_competition.html#MADCompetition.to"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.mad_competition.MADCompetition.to" title="Link to this definition"></a></dt>
<dd><p>Move and/or casts the parameters and buffers.</p>
<p>This can be called as</p>
<dl class="py function">
<dt class="sig sig-object py" id="id7">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">non_blocking</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/mad_competition.html#MADCompetition.to"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id7" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="id8">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dtype</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">non_blocking</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/mad_competition.html#MADCompetition.to"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id8" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="id9">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">non_blocking</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/mad_competition.html#MADCompetition.to"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id9" title="Link to this definition"></a></dt>
<dd></dd></dl>

<p>Its signature is similar to <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.Tensor.to.html#torch.Tensor.to" title="(in PyTorch v2.10)"><code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.Tensor.to()</span></code></a>, but only accepts
floating point desired <code class="xref py py-attr docutils literal notranslate"><span class="pre">dtype</span></code> s. In addition, this method will
only cast the floating point parameters and buffers to <code class="xref py py-attr docutils literal notranslate"><span class="pre">dtype</span></code>
(if given). The integral parameters and buffers will be moved
<code class="xref py py-attr docutils literal notranslate"><span class="pre">device</span></code>, if that is given, but with dtypes unchanged. When
<code class="xref py py-attr docutils literal notranslate"><span class="pre">non_blocking</span></code> is set, it tries to convert/move asynchronously
with respect to the host if possible, e.g., moving CPU Tensors with
pinned memory to CUDA devices.</p>
<p>See <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.to" title="(in PyTorch v2.10)"><code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.to()</span></code></a> for examples.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>device</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="(in PyTorch v2.10)"><em>torch.device</em></a>) – The desired device of the parameters and buffers in this module.</p></li>
<li><p><strong>dtype</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensor_attributes.html#torch.dtype" title="(in PyTorch v2.10)"><em>torch.dtype</em></a>) – The desired floating point type of the floating point parameters and
buffers in this module.</p></li>
<li><p><strong>tensor</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><em>torch.Tensor</em></a>) – Tensor whose dtype and device are the desired dtype and device for
all parameters and buffers in this module.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="plenoptic.synthesize.mad_competition.animate">
<span class="sig-name descname"><span class="pre">animate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mad</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">framerate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">channel_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">zoom</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fig</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axes_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">figsize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">included_plots</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">['display_mad_image',</span> <span class="pre">'plot_loss',</span> <span class="pre">'plot_pixel_values']</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">width_ratios</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/mad_competition.html#animate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.mad_competition.animate" title="Link to this definition"></a></dt>
<dd><p>Animate synthesis progress.</p>
<p>This is essentially the figure produced by
<code class="docutils literal notranslate"><span class="pre">mad.plot_synthesis_status</span></code> animated over time, for each stored
iteration.</p>
<p>This functions returns a matplotlib FuncAnimation object. See our documentation
(e.g., <a class="reference external" href="https://docs.plenoptic.org/docs/branch/main/tutorials/00_quickstart.html">Quickstart</a>)
for examples on how to view it in a Jupyter notebook. In order to save, use
<code class="docutils literal notranslate"><span class="pre">anim.save(filename)</span></code>. In either case, this can take a while and you’ll need the
appropriate writer installed and on your path, e.g., ffmpeg, imagemagick, etc). See
<a class="reference external" href="https://matplotlib.org/stable/api/animation_api.html">matplotlib documentation</a>
for more details.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mad</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition" title="plenoptic.synthesize.mad_competition.MADCompetition"><code class="xref py py-class docutils literal notranslate"><span class="pre">MADCompetition</span></code></a></span>) – MADCompetition object whose synthesis we want to animate.</p></li>
<li><p><strong>framerate</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – How many frames a second to display.</p></li>
<li><p><strong>batch_idx</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – Which index to take from the batch dimension.</p></li>
<li><p><strong>channel_idx</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Which index to take from the channel dimension. If None, we use all
channels (assumed use-case is RGB(A) image).</p></li>
<li><p><strong>zoom</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – How much to zoom in / enlarge the synthesized image, the ratio
of display pixels to image pixels. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, we
attempt to find the best value ourselves.</p></li>
<li><p><strong>fig</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.figure.Figure.html#matplotlib.figure.Figure" title="(in Matplotlib v3.10.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Figure</span></code></a> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – If <code class="docutils literal notranslate"><span class="pre">None</span></code>, we create a new figure. otherwise we assume this is
an empty figure that has the appropriate size and number of
subplots.</p></li>
<li><p><strong>axes_idx</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]</span>) – Dictionary specifying which axes contains which type of plot, allows
for more fine-grained control of the resulting figure. Probably only
helpful if fig is also defined. Possible keys: <code class="docutils literal notranslate"><span class="pre">'mad_image',</span>
<span class="pre">'loss',</span> <span class="pre">'pixel_values',</span> <span class="pre">'misc'</span></code>. Values should all be ints. If you
tell this function to create a plot that doesn’t have a corresponding
key, we find the lowest int that is not already in the dict, so if you
have axes that you want unchanged, place their idx in <code class="docutils literal notranslate"><span class="pre">'misc'</span></code>.</p></li>
<li><p><strong>figsize</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>] | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – The size of the figure to create. It may take a little bit of
playing around to find a reasonable value. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, we attempt to
make our best guess, aiming to have each axis be of size <code class="docutils literal notranslate"><span class="pre">(5,</span> <span class="pre">5)</span></code>.</p></li>
<li><p><strong>included_plots</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]</span>) – Which plots to include. Must be some subset of <code class="docutils literal notranslate"><span class="pre">'display_mad_image',</span>
<span class="pre">'plot_loss',</span> <span class="pre">'plot_pixel_values'</span></code>.</p></li>
<li><p><strong>width_ratios</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>]</span>) – By default, <code class="docutils literal notranslate"><span class="pre">plot_loss</span></code> will have double the width of the other plots. To
change that, specify their relative widths using the keys: [‘display_mad_image’,
‘plot_loss’, ‘plot_pixel_values’] and floats specifying their relative width.
If keys are not included, revert to default behavior.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.animation.FuncAnimation.html#matplotlib.animation.FuncAnimation" title="(in Matplotlib v3.10.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">FuncAnimation</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>anim</em> – The animation object. In order to view, must convert to HTML
or save.</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>ValueError</strong> – If the given <code class="docutils literal notranslate"><span class="pre">mad</span></code> object was run with <code class="docutils literal notranslate"><span class="pre">store_progress=False</span></code>.</p></li>
<li><p><strong>ValueError</strong> – If <code class="docutils literal notranslate"><span class="pre">mad.mage_image</span></code> object is not 3d or 4d.</p></li>
<li><p><strong>ValueError</strong> – If we do not know how to interpret the value of <code class="docutils literal notranslate"><span class="pre">ylim</span></code>.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>By default, we use the ffmpeg backend, which requires that you have
ffmpeg installed and on your path (<a class="reference external" href="https://ffmpeg.org/download.html">https://ffmpeg.org/download.html</a>).
To use a different, use the matplotlib rcParams:
<code class="docutils literal notranslate"><span class="pre">matplotlib.rcParams['animation.writer']</span> <span class="pre">=</span> <span class="pre">writer</span></code>, see
<a class="reference external" href="https://matplotlib.org/stable/api/animation_api.html#writer-classes">matplotlib documentation</a> for more
details.</p>
<p>For displaying in a jupyter notebook, ffmpeg appears to be required.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="plenoptic.synthesize.mad_competition.display_mad_image">
<span class="sig-name descname"><span class="pre">display_mad_image</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mad</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">channel_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">zoom</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">title</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'MADCompetition'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/mad_competition.html#display_mad_image"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.mad_competition.display_mad_image" title="Link to this definition"></a></dt>
<dd><p>Display MAD image.</p>
<p>You can specify what iteration to view by using the <code class="docutils literal notranslate"><span class="pre">iteration</span></code> arg.
The default, <code class="docutils literal notranslate"><span class="pre">None</span></code>, shows the final one.</p>
<p>We use <code class="xref py py-func docutils literal notranslate"><span class="pre">plenoptic.imshow()</span></code> to display the synthesized image and attempt to
automatically find the most reasonable zoom value. You can override this
value using the zoom arg, but remember that <code class="xref py py-func docutils literal notranslate"><span class="pre">plenoptic.imshow()</span></code> is
opinionated about the size of the resulting image and will throw an
Exception if the axis created is not big enough for the selected zoom.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mad</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition" title="plenoptic.synthesize.mad_competition.MADCompetition"><code class="xref py py-class docutils literal notranslate"><span class="pre">MADCompetition</span></code></a></span>) – MADCompetition object whose MAD image we want to display.</p></li>
<li><p><strong>batch_idx</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – Which index to take from the batch dimension.</p></li>
<li><p><strong>channel_idx</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Which index to take from the channel dimension. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, we assume
image is RGB(A) and show all channels.</p></li>
<li><p><strong>zoom</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – How much to zoom in / enlarge the synthesized image, the ratio
of display pixels to image pixels. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, we
attempt to find the best value ourselves.</p></li>
<li><p><strong>iteration</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Which iteration to display. If None, the default, we show
the most recent one. Negative values are also allowed.</p></li>
<li><p><strong>ax</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.html#matplotlib.axes.Axes" title="(in Matplotlib v3.10.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Axes</span></code></a> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Pre-existing axes for plot. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, we call <a class="reference external" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.gca.html#matplotlib.pyplot.gca" title="(in Matplotlib v3.10.8)"><code class="xref py py-func docutils literal notranslate"><span class="pre">matplotlib.pyplot.gca()</span></code></a>.</p></li>
<li><p><strong>title</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></span>) – Title of the axis.</p></li>
<li><p><strong>**kwargs</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></span>) – Passed to <code class="xref py py-func docutils literal notranslate"><span class="pre">plenoptic.imshow()</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.html#matplotlib.axes.Axes" title="(in Matplotlib v3.10.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Axes</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>ax</em> – The matplotlib axes containing the plot.</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ValueError</strong> – If <code class="docutils literal notranslate"><span class="pre">batch_idx</span></code> is not an int.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="plenoptic.synthesize.mad_competition.display_mad_image_all">
<span class="sig-name descname"><span class="pre">display_mad_image_all</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mad_metric1_min</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mad_metric2_min</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mad_metric1_max</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mad_metric2_max</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric1_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric2_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">zoom</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/mad_competition.html#display_mad_image_all"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.mad_competition.display_mad_image_all" title="Link to this definition"></a></dt>
<dd><p>Display all MAD Competition images.</p>
<p>To generate a full set of MAD Competition images, you need four instances:
one for minimizing and maximizing each metric. This helper function creates
a figure to display the full set of images.</p>
<p>In addition to the four MAD Competition images, this also plots the initial
image from <code class="docutils literal notranslate"><span class="pre">mad_metric1_min</span></code>, for comparison.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mad_metric1_min</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition" title="plenoptic.synthesize.mad_competition.MADCompetition"><code class="xref py py-class docutils literal notranslate"><span class="pre">MADCompetition</span></code></a></span>) – <code class="docutils literal notranslate"><span class="pre">MADCompetition</span></code> object that minimized the first metric.</p></li>
<li><p><strong>mad_metric2_min</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition" title="plenoptic.synthesize.mad_competition.MADCompetition"><code class="xref py py-class docutils literal notranslate"><span class="pre">MADCompetition</span></code></a></span>) – <code class="docutils literal notranslate"><span class="pre">MADCompetition</span></code> object that minimized the second metric.</p></li>
<li><p><strong>mad_metric1_max</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition" title="plenoptic.synthesize.mad_competition.MADCompetition"><code class="xref py py-class docutils literal notranslate"><span class="pre">MADCompetition</span></code></a></span>) – <code class="docutils literal notranslate"><span class="pre">MADCompetition</span></code> object that maximized the first metric.</p></li>
<li><p><strong>mad_metric2_max</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition" title="plenoptic.synthesize.mad_competition.MADCompetition"><code class="xref py py-class docutils literal notranslate"><span class="pre">MADCompetition</span></code></a></span>) – <code class="docutils literal notranslate"><span class="pre">MADCompetition</span></code> object that maximized the second metric.</p></li>
<li><p><strong>metric1_name</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Name of the first metric. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, we use the name of the
<code class="docutils literal notranslate"><span class="pre">optimized_metric</span></code> function from <code class="docutils literal notranslate"><span class="pre">mad_metric1_min</span></code>.</p></li>
<li><p><strong>metric2_name</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Name of the second metric. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, we use the name of the
<code class="docutils literal notranslate"><span class="pre">optimized_metric</span></code> function from <code class="docutils literal notranslate"><span class="pre">mad_metric2_min</span></code>.</p></li>
<li><p><strong>zoom</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code> | <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></span>) – Ratio of display pixels to image pixels. See <code class="xref py py-func docutils literal notranslate"><span class="pre">plenoptic.imshow()</span></code> for
details.</p></li>
<li><p><strong>**kwargs</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></span>) – Passed to <code class="xref py py-func docutils literal notranslate"><span class="pre">plenoptic.imshow()</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.figure.Figure.html#matplotlib.figure.Figure" title="(in Matplotlib v3.10.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Figure</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>fig</em> – Figure containing the images.</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ValueError</strong> – If the four <code class="docutils literal notranslate"><span class="pre">MADCompetition</span></code> instances do not have the same <code class="docutils literal notranslate"><span class="pre">image</span></code>
attribute.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="plenoptic.synthesize.mad_competition.plot_loss">
<span class="sig-name descname"><span class="pre">plot_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mad</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/mad_competition.html#plot_loss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.mad_competition.plot_loss" title="Link to this definition"></a></dt>
<dd><p>Plot metric losses.</p>
<p>Plots <code class="docutils literal notranslate"><span class="pre">mad.optimized_metric_loss</span></code> and <code class="docutils literal notranslate"><span class="pre">mad.reference_metric_loss</span></code> on two
separate axes, over all iterations. Also plots a red dot at <code class="docutils literal notranslate"><span class="pre">iteration</span></code>,
to highlight the loss there. If <code class="docutils literal notranslate"><span class="pre">iteration=None</span></code>, then the dot will be at
the final iteration.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mad</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition" title="plenoptic.synthesize.mad_competition.MADCompetition"><code class="xref py py-class docutils literal notranslate"><span class="pre">MADCompetition</span></code></a></span>) – MADCompetition object whose loss we want to plot.</p></li>
<li><p><strong>iteration</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Which iteration to display. If None, the default, we show
the most recent one. Negative values are also allowed.</p></li>
<li><p><strong>axes</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>[<a class="reference external" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.html#matplotlib.axes.Axes" title="(in Matplotlib v3.10.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Axes</span></code></a>] | <a class="reference external" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.html#matplotlib.axes.Axes" title="(in Matplotlib v3.10.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Axes</span></code></a> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Pre-existing axes for plot. If a list of axes, must be the two axes to
use for this plot. If a single axis, we’ll split it in half
horizontally. If None, we call <a class="reference external" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.gca.html#matplotlib.pyplot.gca" title="(in Matplotlib v3.10.8)"><code class="xref py py-func docutils literal notranslate"><span class="pre">matplotlib.pyplot.gca()</span></code></a>.</p></li>
<li><p><strong>**kwargs</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></span>) – Passed to <a class="reference external" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.semilogy.html#matplotlib.pyplot.semilogy" title="(in Matplotlib v3.10.8)"><code class="xref py py-func docutils literal notranslate"><span class="pre">matplotlib.pyplot.semilogy()</span></code></a>.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.html#matplotlib.axes.Axes" title="(in Matplotlib v3.10.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Axes</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>axes</em> – The matplotlib axes containing the plot.</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>We plot <code class="docutils literal notranslate"><span class="pre">abs(mad.losses)</span></code> because if we’re maximizing the synthesis
metric, we minimized its negative. By plotting the absolute value, we get
them all on the same scale.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="plenoptic.synthesize.mad_competition.plot_loss_all">
<span class="sig-name descname"><span class="pre">plot_loss_all</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mad_metric1_min</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mad_metric2_min</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mad_metric1_max</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mad_metric2_max</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric1_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric2_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric1_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{'c':</span> <span class="pre">'C0'}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric2_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{'c':</span> <span class="pre">'C1'}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{'linestyle':</span> <span class="pre">'--'}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{'linestyle':</span> <span class="pre">'-'}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">figsize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(10,</span> <span class="pre">5)</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/mad_competition.html#plot_loss_all"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.mad_competition.plot_loss_all" title="Link to this definition"></a></dt>
<dd><p>Plot loss for full set of MAD Competiton instances.</p>
<p>To generate a full set of MAD Competition images, you need four instances:
one for minimizing and maximizing each metric. This helper function creates
a two-axis figure to display the loss for this full set.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mad_metric1_min</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition" title="plenoptic.synthesize.mad_competition.MADCompetition"><code class="xref py py-class docutils literal notranslate"><span class="pre">MADCompetition</span></code></a></span>) – <code class="docutils literal notranslate"><span class="pre">MADCompetition</span></code> object that minimized the first metric.</p></li>
<li><p><strong>mad_metric2_min</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition" title="plenoptic.synthesize.mad_competition.MADCompetition"><code class="xref py py-class docutils literal notranslate"><span class="pre">MADCompetition</span></code></a></span>) – <code class="docutils literal notranslate"><span class="pre">MADCompetition</span></code> object that minimized the second metric.</p></li>
<li><p><strong>mad_metric1_max</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition" title="plenoptic.synthesize.mad_competition.MADCompetition"><code class="xref py py-class docutils literal notranslate"><span class="pre">MADCompetition</span></code></a></span>) – <code class="docutils literal notranslate"><span class="pre">MADCompetition</span></code> object that maximized the first metric.</p></li>
<li><p><strong>mad_metric2_max</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition" title="plenoptic.synthesize.mad_competition.MADCompetition"><code class="xref py py-class docutils literal notranslate"><span class="pre">MADCompetition</span></code></a></span>) – <code class="docutils literal notranslate"><span class="pre">MADCompetition</span></code> object that maximized the second metric.</p></li>
<li><p><strong>metric1_name</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Name of the first metric. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, we use the name of the
<code class="docutils literal notranslate"><span class="pre">optimized_metric</span></code> function from <code class="docutils literal notranslate"><span class="pre">mad_metric1_min</span></code>.</p></li>
<li><p><strong>metric2_name</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Name of the second metric. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, we use the name of the
<code class="docutils literal notranslate"><span class="pre">optimized_metric</span></code> function from <code class="docutils literal notranslate"><span class="pre">mad_metric2_min</span></code>.</p></li>
<li><p><strong>metric1_kwargs</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></span>) – Dictionary of arguments to pass to <a class="reference external" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.plot.html#matplotlib.pyplot.plot" title="(in Matplotlib v3.10.8)"><code class="xref py py-func docutils literal notranslate"><span class="pre">matplotlib.pyplot.plot()</span></code></a> to identify
synthesis instance where the first metric was being optimized.</p></li>
<li><p><strong>metric2_kwargs</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></span>) – Dictionary of arguments to pass to <a class="reference external" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.plot.html#matplotlib.pyplot.plot" title="(in Matplotlib v3.10.8)"><code class="xref py py-func docutils literal notranslate"><span class="pre">matplotlib.pyplot.plot()</span></code></a> to identify
synthesis instance where the second metric was being optimized.</p></li>
<li><p><strong>min_kwargs</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></span>) – Dictionary of arguments to pass to <a class="reference external" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.plot.html#matplotlib.pyplot.plot" title="(in Matplotlib v3.10.8)"><code class="xref py py-func docutils literal notranslate"><span class="pre">matplotlib.pyplot.plot()</span></code></a> to identify
synthesis instance where <code class="docutils literal notranslate"><span class="pre">optimized_metric</span></code> was being minimized.</p></li>
<li><p><strong>max_kwargs</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></span>) – Dictionary of arguments to pass to <a class="reference external" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.plot.html#matplotlib.pyplot.plot" title="(in Matplotlib v3.10.8)"><code class="xref py py-func docutils literal notranslate"><span class="pre">matplotlib.pyplot.plot()</span></code></a> to identify
synthesis instance where <code class="docutils literal notranslate"><span class="pre">optimized_metric</span></code> was being maximized.</p></li>
<li><p><strong>figsize</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]</span>) – Size of the figure we create.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.figure.Figure.html#matplotlib.figure.Figure" title="(in Matplotlib v3.10.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Figure</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>fig</em> – Figure containing the plot.</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ValueError</strong> – If the four <code class="docutils literal notranslate"><span class="pre">MADCompetition</span></code> instances do not have the same <code class="docutils literal notranslate"><span class="pre">image</span></code>
attribute.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="plenoptic.synthesize.mad_competition.plot_pixel_values">
<span class="sig-name descname"><span class="pre">plot_pixel_values</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mad</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">channel_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ylim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/mad_competition.html#plot_pixel_values"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.mad_competition.plot_pixel_values" title="Link to this definition"></a></dt>
<dd><p>Plot histogram of pixel values of reference and MAD images.</p>
<p>As a way to check the distributions of pixel intensities and see
if there’s any values outside the allowed range.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mad</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition" title="plenoptic.synthesize.mad_competition.MADCompetition"><code class="xref py py-class docutils literal notranslate"><span class="pre">MADCompetition</span></code></a></span>) – MADCompetition object with the images whose pixel values we want to compare.</p></li>
<li><p><strong>batch_idx</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – Which index to take from the batch dimension.</p></li>
<li><p><strong>channel_idx</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Which index to take from the channel dimension. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, we use all
channels (assumed use-case is RGB(A) images).</p></li>
<li><p><strong>iteration</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Which iteration to display. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the default, we show
the most recent one. Negative values are also allowed.</p></li>
<li><p><strong>ylim</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>], <code class="xref py py-data docutils literal notranslate"><span class="pre">Literal</span></code>[<code class="docutils literal notranslate"><span class="pre">False</span></code>]]</span>) – If tuple, the ylimit to set for this axis. If False, we leave
it untouched.</p></li>
<li><p><strong>ax</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.html#matplotlib.axes.Axes" title="(in Matplotlib v3.10.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Axes</span></code></a> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Pre-existing axes for plot. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, we call
<a class="reference external" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.gca.html#matplotlib.pyplot.gca" title="(in Matplotlib v3.10.8)"><code class="xref py py-func docutils literal notranslate"><span class="pre">matplotlib.pyplot.gca()</span></code></a>.</p></li>
<li><p><strong>**kwargs</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></span>) – Passed to <a class="reference external" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.hist.html#matplotlib.pyplot.hist" title="(in Matplotlib v3.10.8)"><code class="xref py py-func docutils literal notranslate"><span class="pre">matplotlib.pyplot.hist()</span></code></a>.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.html#matplotlib.axes.Axes" title="(in Matplotlib v3.10.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Axes</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>ax</em> – Creates axes.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="plenoptic.synthesize.mad_competition.plot_synthesis_status">
<span class="sig-name descname"><span class="pre">plot_synthesis_status</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mad</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">channel_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vrange</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'indep1'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">zoom</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fig</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axes_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">figsize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">included_plots</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">['display_mad_image',</span> <span class="pre">'plot_loss',</span> <span class="pre">'plot_pixel_values']</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">width_ratios</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/mad_competition.html#plot_synthesis_status"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.mad_competition.plot_synthesis_status" title="Link to this definition"></a></dt>
<dd><p>Make a plot showing synthesis status.</p>
<p>We create several subplots to analyze this. By default, we create two
subplots on a new figure: the first one contains the MAD image and the
second contains the loss.</p>
<p>The plots to include are specified by including their name in the
<code class="docutils literal notranslate"><span class="pre">included_plots</span></code> list. All plots can be created separately using the
method with the same name.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mad</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="#plenoptic.synthesize.mad_competition.MADCompetition" title="plenoptic.synthesize.mad_competition.MADCompetition"><code class="xref py py-class docutils literal notranslate"><span class="pre">MADCompetition</span></code></a></span>) – MADCompetition object whose status we want to plot.</p></li>
<li><p><strong>batch_idx</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – Which index to take from the batch dimension.</p></li>
<li><p><strong>channel_idx</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Which index to take from the channel dimension. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, we use all
channels (assumed use-case is RGB(A) image).</p></li>
<li><p><strong>iteration</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Which iteration to display. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, we show
the most recent one. Negative values are also allowed.</p></li>
<li><p><strong>vrange</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>] | <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></span>) – The vrange option to pass to <code class="docutils literal notranslate"><span class="pre">display_mad_image()</span></code>. See
docstring of <code class="xref py py-func docutils literal notranslate"><span class="pre">plenoptic.imshow()</span></code> for possible values.</p></li>
<li><p><strong>zoom</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – How much to zoom in / enlarge the synthesized image, the ratio
of display pixels to image pixels. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, we
attempt to find the best value ourselves.</p></li>
<li><p><strong>fig</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.figure.Figure.html#matplotlib.figure.Figure" title="(in Matplotlib v3.10.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Figure</span></code></a> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – If <code class="docutils literal notranslate"><span class="pre">None</span></code>, we create a new figure. otherwise we assume this is
an empty figure that has the appropriate size and number of
subplots.</p></li>
<li><p><strong>axes_idx</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]</span>) – Dictionary specifying which axes contains which type of plot, allows
for more fine-grained control of the resulting figure. Probably only
helpful if fig is also defined. Possible keys: <code class="docutils literal notranslate"><span class="pre">'mad_image',</span>
<span class="pre">'loss',</span> <span class="pre">'pixel_values',</span> <span class="pre">'misc'</span></code>. Values should all be ints. If you
tell this function to create a plot that doesn’t have a corresponding
key, we find the lowest int that is not already in the dict, so if you
have axes that you want unchanged, place their idx in <code class="docutils literal notranslate"><span class="pre">'misc'</span></code>.</p></li>
<li><p><strong>figsize</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>] | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – The size of the figure to create. It may take a little bit of
playing around to find a reasonable value. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, we attempt to
make our best guess, aiming to have each axis be of size <code class="docutils literal notranslate"><span class="pre">(5,</span> <span class="pre">5)</span></code>.</p></li>
<li><p><strong>included_plots</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]</span>) – Which plots to include. Must be some subset of <code class="docutils literal notranslate"><span class="pre">'display_mad_image',</span>
<span class="pre">'plot_loss',</span> <span class="pre">'plot_pixel_values'</span></code>.</p></li>
<li><p><strong>width_ratios</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>]</span>) – By default, <code class="docutils literal notranslate"><span class="pre">plot_loss</span></code> will have double the width of the other plots. To
change that, specify their relative widths using the keys: [‘display_mad_image’,
‘plot_loss’, ‘plot_pixel_values’] and floats specifying their relative width.
If keys are not included, revert to default behavior.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code>[<a class="reference external" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.figure.Figure.html#matplotlib.figure.Figure" title="(in Matplotlib v3.10.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Figure</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]]</span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><ul class="simple">
<li><p><em>fig</em> – The figure containing this plot.</p></li>
<li><p><em>axes_idx</em> – Dictionary giving index of each plot.</p></li>
</ul>
</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>ValueError</strong> – If <code class="docutils literal notranslate"><span class="pre">mad.mad_image</span></code> object is not 3d or 4d.</p></li>
<li><p><strong>ValueError</strong> – If the <code class="docutils literal notranslate"><span class="pre">iteration</span> <span class="pre">is</span> <span class="pre">not</span> <span class="pre">None</span></code> and the given <code class="docutils literal notranslate"><span class="pre">mad</span></code> object was run
with <code class="docutils literal notranslate"><span class="pre">store_progress=False</span></code>.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-plenoptic.synthesize.metamer">
<span id="plenoptic-synthesize-metamer-module"></span><h2>plenoptic.synthesize.metamer module<a class="headerlink" href="#module-plenoptic.synthesize.metamer" title="Link to this heading"></a></h2>
<p>Model metamers.</p>
<p>Classes to perform the synthesis of model metamers.</p>
<dl class="py class">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.Metamer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">Metamer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_function=&lt;function</span> <span class="pre">mse&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">range_penalty_lambda=0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">allowed_range=(0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">1)</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/metamer.html#Metamer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.metamer.Metamer" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#plenoptic.synthesize.synthesis.OptimizedSynthesis" title="plenoptic.synthesize.synthesis.OptimizedSynthesis"><code class="xref py py-class docutils literal notranslate"><span class="pre">OptimizedSynthesis</span></code></a></p>
<p>Synthesize metamers for image-computable differentiable models.</p>
<p>Following the basic idea in <a class="reference internal" href="#r868b9832577a-1" id="id11">[1]</a>, this class creates a metamer for a given model on
a given image. We iteratively adjust the pixel values so as to match the
representation of the <a class="reference internal" href="#plenoptic.synthesize.metamer.Metamer.metamer" title="plenoptic.synthesize.metamer.Metamer.metamer"><code class="xref py py-attr docutils literal notranslate"><span class="pre">metamer</span></code></a> and <a class="reference internal" href="#plenoptic.synthesize.metamer.Metamer.image" title="plenoptic.synthesize.metamer.Metamer.image"><code class="xref py py-attr docutils literal notranslate"><span class="pre">image</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>image</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – A tensor, this is the image whose representation we wish to
match.</p></li>
<li><p><strong>model</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a></span>) – A visual model.</p></li>
<li><p><strong>loss_function</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">Callable</span></code>[[<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>], <a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span>) – The loss function to use to compare the representations of the models
in order to determine their loss.</p></li>
<li><p><strong>range_penalty_lambda</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></span>) – Strength of the regularizer that enforces the allowed_range. Must be
non-negative.</p></li>
<li><p><strong>allowed_range</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>]</span>) – Range (inclusive) of allowed pixel values. Any values outside this
range will be penalized.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r868b9832577a-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id11">1</a><span class="fn-bracket">]</span></span>
<p>J Portilla and E P Simoncelli. A Parametric Texture Model
based on Joint Statistics of Complex Wavelet Coefficients. Int’l
Journal of Computer Vision. 40(1):49-71, October, 2000.
<a class="reference external" href="https://www.cns.nyu.edu/~eero/ABSTRACTS/portilla99-abstract.html">https://www.cns.nyu.edu/~eero/ABSTRACTS/portilla99-abstract.html</a>
<a class="reference external" href="https://www.cns.nyu.edu/~lcv/texture/">https://www.cns.nyu.edu/~lcv/texture/</a></p>
</div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Attributes<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">allowed_range</span></code></dt><dd><p>Allowable range of pixel values.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient_norm</span></code></dt><dd><p>Optimization gradient’s L2 norm over iterations.</p>
</dd>
<dt><a class="reference internal" href="#plenoptic.synthesize.metamer.Metamer.image" title="plenoptic.synthesize.metamer.Metamer.image"><code class="xref py py-obj docutils literal notranslate"><span class="pre">image</span></code></a></dt><dd><p>Target image of metamer optimization.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">losses</span></code></dt><dd><p>Optimization loss over iterations.</p>
</dd>
<dt><a class="reference internal" href="#plenoptic.synthesize.metamer.Metamer.metamer" title="plenoptic.synthesize.metamer.Metamer.metamer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">metamer</span></code></a></dt><dd><p>Model metamer, the parameter we are optimizing.</p>
</dd>
<dt><a class="reference internal" href="#plenoptic.synthesize.metamer.Metamer.model" title="plenoptic.synthesize.metamer.Metamer.model"><code class="xref py py-obj docutils literal notranslate"><span class="pre">model</span></code></a></dt><dd><p>The model for which the metamer is synthesized.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">optimizer</span></code></dt><dd><p>Torch optimizer object which updates the synthesis target.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">pixel_change_norm</span></code></dt><dd><p>L2 norm change in pixel values over iterations.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">range_penalty_lambda</span></code></dt><dd><p>Magnitude of the penalty on pixel values outside <code class="xref py py-attr docutils literal notranslate"><span class="pre">allowed_range</span></code>.</p>
</dd>
<dt><a class="reference internal" href="#plenoptic.synthesize.metamer.Metamer.saved_metamer" title="plenoptic.synthesize.metamer.Metamer.saved_metamer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">saved_metamer</span></code></a></dt><dd><p><a class="reference internal" href="#plenoptic.synthesize.metamer.Metamer.metamer" title="plenoptic.synthesize.metamer.Metamer.metamer"><code class="xref py py-attr docutils literal notranslate"><span class="pre">metamer</span></code></a>, cached over time for later examination.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">scheduler</span></code></dt><dd><p>Learning rate scheduler which adjusts optimizer learning rate.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">store_progress</span></code></dt><dd><p>How often we are caching progress.</p>
</dd>
<dt><a class="reference internal" href="#plenoptic.synthesize.metamer.Metamer.target_representation" title="plenoptic.synthesize.metamer.Metamer.target_representation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">target_representation</span></code></a></dt><dd><p><a class="reference internal" href="#plenoptic.synthesize.metamer.Metamer.model" title="plenoptic.synthesize.metamer.Metamer.model"><code class="xref py py-attr docutils literal notranslate"><span class="pre">model</span></code></a> representation of <a class="reference internal" href="#plenoptic.synthesize.metamer.Metamer.image" title="plenoptic.synthesize.metamer.Metamer.image"><code class="xref py py-attr docutils literal notranslate"><span class="pre">image</span></code></a>, i.e. <code class="docutils literal notranslate"><span class="pre">model(image)</span></code>.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Methods</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#plenoptic.synthesize.metamer.Metamer.load" title="plenoptic.synthesize.metamer.Metamer.load"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load</span></code></a>(file_path[, map_location, ...])</p></td>
<td><p>Load all relevant stuff from a .pt file.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#plenoptic.synthesize.metamer.Metamer.objective_function" title="plenoptic.synthesize.metamer.Metamer.objective_function"><code class="xref py py-obj docutils literal notranslate"><span class="pre">objective_function</span></code></a>([metamer_representation, ...])</p></td>
<td><p>Compute the metamer synthesis loss.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#plenoptic.synthesize.metamer.Metamer.save" title="plenoptic.synthesize.metamer.Metamer.save"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save</span></code></a>(file_path)</p></td>
<td><p>Save all relevant variables in .pt file.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#plenoptic.synthesize.metamer.Metamer.setup" title="plenoptic.synthesize.metamer.Metamer.setup"><code class="xref py py-obj docutils literal notranslate"><span class="pre">setup</span></code></a>([initial_image, optimizer, ...])</p></td>
<td><p>Initialize the metamer, optimizer, and scheduler.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#plenoptic.synthesize.metamer.Metamer.synthesize" title="plenoptic.synthesize.metamer.Metamer.synthesize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">synthesize</span></code></a>([max_iter, store_progress, ...])</p></td>
<td><p>Synthesize a metamer.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#id14" title="plenoptic.synthesize.metamer.Metamer.to"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to</span></code></a>(*args, **kwargs)</p></td>
<td><p>Move and/or cast the parameters and buffers.</p></td>
</tr>
</tbody>
</table>
<dl class="py property">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.Metamer.image">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">image</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><span class="pre">Tensor</span></a></em><a class="headerlink" href="#plenoptic.synthesize.metamer.Metamer.image" title="Link to this definition"></a></dt>
<dd><p>Target image of metamer optimization.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.Metamer.load">
<span class="sig-name descname"><span class="pre">load</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">map_location</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensor_equality_atol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-08</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensor_equality_rtol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">pickle_load_args</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/metamer.html#Metamer.load"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.metamer.Metamer.load" title="Link to this definition"></a></dt>
<dd><p>Load all relevant stuff from a .pt file.</p>
<p>This must be called by a <code class="docutils literal notranslate"><span class="pre">Metamer</span></code> object initialized just like the saved
object.</p>
<p>Note this operates in place and so doesn’t return anything.</p>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 1.2: </span>load behavior changed in a backwards-incompatible manner in order to
compatible with breaking changes in torch 2.6.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>file_path</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></span>) – The path to load the synthesis object from.</p></li>
<li><p><strong>map_location</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Argument to pass to <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.load.html#torch.load" title="(in PyTorch v2.10)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.load()</span></code></a> as <code class="docutils literal notranslate"><span class="pre">map_location</span></code>. If you
save stuff that was being run on a GPU and are loading onto a
CPU, you’ll need this to make sure everything lines up
properly. This should be structured like the str you would
pass to <a class="reference external" href="https://docs.pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.device</span></code></a>.</p></li>
<li><p><strong>tensor_equality_atol</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></span>) – Absolute tolerance to use when checking for tensor equality during load,
passed to <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.allclose.html#torch.allclose" title="(in PyTorch v2.10)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.allclose()</span></code></a>. It may be necessary to increase if you are
saving and loading on two machines with torch built by different cuda
versions. Be careful when changing this! See
<a class="reference external" href="https://docs.pytorch.org/docs/stable/type_info.html#torch.torch.finfo" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.finfo</span></code></a> for more details about floating
point precision of different data types (especially, <code class="docutils literal notranslate"><span class="pre">eps</span></code>); if you have
to increase this by more than 1 or 2 decades, then you are probably not
dealing with a numerical issue.</p></li>
<li><p><strong>tensor_equality_rtol</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></span>) – Relative tolerance to use when checking for tensor equality during load,
passed to <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.allclose.html#torch.allclose" title="(in PyTorch v2.10)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.allclose()</span></code></a>. It may be necessary to increase if you are
saving and loading on two machines with torch built by different cuda
versions. Be careful when changing this! See
<a class="reference external" href="https://docs.pytorch.org/docs/stable/type_info.html#torch.torch.finfo" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.finfo</span></code></a> for more details about floating
point precision of different data types (especially, <code class="docutils literal notranslate"><span class="pre">eps</span></code>); if you have
to increase this by more than 1 or 2 decades, then you are probably not
dealing with a numerical issue.</p></li>
<li><p><strong>**pickle_load_args</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></span>) – Any additional kwargs will be added to <code class="docutils literal notranslate"><span class="pre">pickle_module.load</span></code> via
<a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.load.html#torch.load" title="(in PyTorch v2.10)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.load()</span></code></a>, see that function’s docstring for details.</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>ValueError</strong> – If <a class="reference internal" href="#plenoptic.synthesize.metamer.Metamer.setup" title="plenoptic.synthesize.metamer.Metamer.setup"><code class="xref py py-func docutils literal notranslate"><span class="pre">setup()</span></code></a> or <a class="reference internal" href="#plenoptic.synthesize.metamer.Metamer.synthesize" title="plenoptic.synthesize.metamer.Metamer.synthesize"><code class="xref py py-func docutils literal notranslate"><span class="pre">synthesize()</span></code></a> has been called before this call
to <code class="docutils literal notranslate"><span class="pre">load</span></code>.</p></li>
<li><p><strong>ValueError</strong> – If the object saved at <code class="docutils literal notranslate"><span class="pre">file_path</span></code> is not a <code class="docutils literal notranslate"><span class="pre">Metamer</span></code> object.</p></li>
<li><p><strong>ValueError</strong> – If the saved and loading <code class="docutils literal notranslate"><span class="pre">Metamer</span></code> objects have a different value
for any of <a class="reference internal" href="#plenoptic.synthesize.metamer.Metamer.image" title="plenoptic.synthesize.metamer.Metamer.image"><code class="xref py py-attr docutils literal notranslate"><span class="pre">image</span></code></a>, <code class="xref py py-attr docutils literal notranslate"><span class="pre">range_penalty_lambda</span></code>,
or <code class="xref py py-attr docutils literal notranslate"><span class="pre">allowed_range</span></code>.</p></li>
<li><p><strong>ValueError</strong> – If the behavior of <code class="xref py py-attr docutils literal notranslate"><span class="pre">loss_function</span></code> or <a class="reference internal" href="#plenoptic.synthesize.metamer.Metamer.model" title="plenoptic.synthesize.metamer.Metamer.model"><code class="xref py py-attr docutils literal notranslate"><span class="pre">model</span></code></a> is different
between the saved and loading objects.</p></li>
</ul>
</dd>
<dt class="field-odd">Warns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>UserWarning</strong> – If <a class="reference internal" href="#plenoptic.synthesize.metamer.Metamer.setup" title="plenoptic.synthesize.metamer.Metamer.setup"><code class="xref py py-func docutils literal notranslate"><span class="pre">setup()</span></code></a> will need to be called after load, to finish initializing
<code class="xref py py-attr docutils literal notranslate"><span class="pre">optimizer</span></code> or <code class="xref py py-attr docutils literal notranslate"><span class="pre">scheduler</span></code>.</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="plenoptic.tools.html#plenoptic.tools.io.examine_saved_synthesis" title="plenoptic.tools.io.examine_saved_synthesis"><code class="xref py py-func docutils literal notranslate"><span class="pre">examine_saved_synthesis()</span></code></a></dt><dd><p>Examine metadata from saved object: pytorch and plenoptic versions, name of the synthesis object, shapes of tensors, etc.</p>
</dd>
</dl>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">plenoptic</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">po</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">einstein</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">simul</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">remove_grad</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metamer</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">synth</span><span class="o">.</span><span class="n">Metamer</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metamer</span><span class="o">.</span><span class="n">synthesize</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">store_progress</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metamer</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;metamers.pt&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metamer_copy</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">synth</span><span class="o">.</span><span class="n">Metamer</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metamer_copy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;metamers.pt&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.Metamer.metamer">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">metamer</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><span class="pre">Tensor</span></a></em><a class="headerlink" href="#plenoptic.synthesize.metamer.Metamer.metamer" title="Link to this definition"></a></dt>
<dd><p>Model metamer, the parameter we are optimizing.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.Metamer.model">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.10)"><span class="pre">Module</span></a></em><a class="headerlink" href="#plenoptic.synthesize.metamer.Metamer.model" title="Link to this definition"></a></dt>
<dd><p>The model for which the metamer is synthesized.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.Metamer.objective_function">
<span class="sig-name descname"><span class="pre">objective_function</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">metamer_representation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_representation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/metamer.html#Metamer.objective_function"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.metamer.Metamer.objective_function" title="Link to this definition"></a></dt>
<dd><p>Compute the metamer synthesis loss.</p>
<p>This calls self.loss_function on <code class="docutils literal notranslate"><span class="pre">metamer_representation</span></code> and
<code class="docutils literal notranslate"><span class="pre">target_representation</span></code> and then adds the weighted range penalty.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>metamer_representation</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Model response to <code class="docutils literal notranslate"><span class="pre">metamer</span></code>. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, we use
<code class="docutils literal notranslate"><span class="pre">self.model(self.metamer)</span></code>.</p></li>
<li><p><strong>target_representation</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Model response to <code class="docutils literal notranslate"><span class="pre">image</span></code>. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, we use
<code class="docutils literal notranslate"><span class="pre">self.target_representation</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>loss</em> – 1-element tensor containing the loss on this step.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.Metamer.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/metamer.html#Metamer.save"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.metamer.Metamer.save" title="Link to this definition"></a></dt>
<dd><p>Save all relevant variables in .pt file.</p>
<p>Note that if <code class="docutils literal notranslate"><span class="pre">store_progress</span></code> is True, this will probably be very
large.</p>
<p>See <a class="reference internal" href="#plenoptic.synthesize.metamer.Metamer.load" title="plenoptic.synthesize.metamer.Metamer.load"><code class="xref py py-func docutils literal notranslate"><span class="pre">load()</span></code></a> docstring for an example of use.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>file_path</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></span>) – The path to save the metamer object to.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.Metamer.saved_metamer">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">saved_metamer</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><span class="pre">Tensor</span></a></em><a class="headerlink" href="#plenoptic.synthesize.metamer.Metamer.saved_metamer" title="Link to this definition"></a></dt>
<dd><p><a class="reference internal" href="#plenoptic.synthesize.metamer.Metamer.metamer" title="plenoptic.synthesize.metamer.Metamer.metamer"><code class="xref py py-attr docutils literal notranslate"><span class="pre">metamer</span></code></a>, cached over time for later examination.</p>
<p>How often the metamer is cached is determined by the <code class="docutils literal notranslate"><span class="pre">store_progress</span></code> argument
to the <a class="reference internal" href="#plenoptic.synthesize.metamer.Metamer.synthesize" title="plenoptic.synthesize.metamer.Metamer.synthesize"><code class="xref py py-func docutils literal notranslate"><span class="pre">synthesize()</span></code></a> function.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.Metamer.setup">
<span class="sig-name descname"><span class="pre">setup</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">initial_image</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scheduler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scheduler_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/metamer.html#Metamer.setup"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.metamer.Metamer.setup" title="Link to this definition"></a></dt>
<dd><p>Initialize the metamer, optimizer, and scheduler.</p>
<p>Can only be called once. If <code class="docutils literal notranslate"><span class="pre">load()</span></code> has been called, <code class="docutils literal notranslate"><span class="pre">initial_image</span></code> must
be <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>initial_image</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – The tensor we use to initialize the metamer. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, we initialize with
uniformly-distributed random noise lying within <code class="docutils literal notranslate"><span class="pre">self.allowed_range</span></code>.</p></li>
<li><p><strong>optimizer</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code></a> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – The un-initialized optimizer object to use. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, we use
<a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.optim.Adam</span></code></a>.</p></li>
<li><p><strong>optimizer_kwargs</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – The keyword arguments to pass to the optimizer on initialization. If
<code class="docutils literal notranslate"><span class="pre">None</span></code>, we use <code class="docutils literal notranslate"><span class="pre">{&quot;lr&quot;:</span> <span class="pre">.01}</span></code> and, if optimizer is <code class="docutils literal notranslate"><span class="pre">None</span></code>,
<code class="docutils literal notranslate"><span class="pre">{&quot;amsgrad&quot;:</span> <span class="pre">True}</span></code>.</p></li>
<li><p><strong>scheduler</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.LRScheduler.html#torch.optim.lr_scheduler.LRScheduler" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">LRScheduler</span></code></a> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – The un-initialized learning rate scheduler object to use. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, we
don’t use one.</p></li>
<li><p><strong>scheduler_kwargs</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – The keyword arguments to pass to the scheduler on initialization.</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>ValueError</strong> – If you try to set <code class="docutils literal notranslate"><span class="pre">initial_image</span></code> after calling <a class="reference internal" href="#plenoptic.synthesize.metamer.Metamer.load" title="plenoptic.synthesize.metamer.Metamer.load"><code class="xref py py-func docutils literal notranslate"><span class="pre">load()</span></code></a>.</p></li>
<li><p><strong>ValueError</strong> – If <code class="docutils literal notranslate"><span class="pre">setup</span></code> is called more than once or after <a class="reference internal" href="#plenoptic.synthesize.metamer.Metamer.synthesize" title="plenoptic.synthesize.metamer.Metamer.synthesize"><code class="xref py py-func docutils literal notranslate"><span class="pre">synthesize()</span></code></a>.</p></li>
<li><p><strong>ValueError</strong> – If you try to set <code class="docutils literal notranslate"><span class="pre">optimizer_kwargs</span></code> after calling <a class="reference internal" href="#plenoptic.synthesize.metamer.Metamer.load" title="plenoptic.synthesize.metamer.Metamer.load"><code class="xref py py-func docutils literal notranslate"><span class="pre">load()</span></code></a>.</p></li>
<li><p><strong>TypeError</strong> – If the loaded object had a non-Adam optimizer, but the <code class="docutils literal notranslate"><span class="pre">optimizer</span></code> arg
is not specified.</p></li>
<li><p><strong>ValueError</strong> – If the loaded object had an optimizer, and the <code class="docutils literal notranslate"><span class="pre">optimizer</span></code> arg is
a different type.</p></li>
<li><p><strong>ValueError</strong> – If you try to set <code class="docutils literal notranslate"><span class="pre">scheduler_kwargs</span></code> after calling <a class="reference internal" href="#plenoptic.synthesize.metamer.Metamer.load" title="plenoptic.synthesize.metamer.Metamer.load"><code class="xref py py-func docutils literal notranslate"><span class="pre">load()</span></code></a>.</p></li>
<li><p><strong>TypeError</strong> – If the loaded object had a scheduler, but the <code class="docutils literal notranslate"><span class="pre">scheduler</span></code> arg is not
specified.</p></li>
<li><p><strong>ValueError</strong> – If the loaded object had a scheduler, but the <code class="docutils literal notranslate"><span class="pre">scheduler</span></code> arg is
a different type.</p></li>
</ul>
</dd>
<dt class="field-odd">Warns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>UserWarning</strong> – If <code class="docutils literal notranslate"><span class="pre">initial_image</span></code> is a different shape than <code class="docutils literal notranslate"><span class="pre">self.image</span></code>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>Set initial image:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">plenoptic</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">po</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">einstein</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">simul</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">remove_grad</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">met</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">synth</span><span class="o">.</span><span class="n">Metamer</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">met</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="n">po</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">curie</span><span class="p">())</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">met</span><span class="o">.</span><span class="n">synthesize</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
<p>Set optimizer:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">plenoptic</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">po</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">einstein</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">simul</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">remove_grad</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">met</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">synth</span><span class="o">.</span><span class="n">Metamer</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">met</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">,</span> <span class="n">optimizer_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">})</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">met</span><span class="o">.</span><span class="n">synthesize</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
<p>Use with save/load. Only the optimizer object is necessary, its kwargs and the
initial image are handled by load.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">plenoptic</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">po</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">einstein</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">simul</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">remove_grad</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">met</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">synth</span><span class="o">.</span><span class="n">Metamer</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">met</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">po</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">curie</span><span class="p">(),</span>
<span class="gp">... </span>    <span class="n">optimizer</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">optimizer_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">},</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">met</span><span class="o">.</span><span class="n">synthesize</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">met</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;metamer_setup.pt&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">met</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">synth</span><span class="o">.</span><span class="n">Metamer</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">met</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;metamer_setup.pt&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">met</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">met</span><span class="o">.</span><span class="n">synthesize</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.Metamer.synthesize">
<span class="sig-name descname"><span class="pre">synthesize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">store_progress</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop_criterion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop_iters_to_check</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">50</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/metamer.html#Metamer.synthesize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.metamer.Metamer.synthesize" title="Link to this definition"></a></dt>
<dd><p>Synthesize a metamer.</p>
<p>Update the pixels of <a class="reference internal" href="#plenoptic.synthesize.metamer.Metamer.metamer" title="plenoptic.synthesize.metamer.Metamer.metamer"><code class="xref py py-attr docutils literal notranslate"><span class="pre">metamer</span></code></a> until its representation matches that of
<a class="reference internal" href="#plenoptic.synthesize.metamer.Metamer.image" title="plenoptic.synthesize.metamer.Metamer.image"><code class="xref py py-attr docutils literal notranslate"><span class="pre">image</span></code></a>.</p>
<p>We run this until either we reach <code class="docutils literal notranslate"><span class="pre">max_iter</span></code> or the change over the
past <code class="docutils literal notranslate"><span class="pre">stop_iters_to_check</span></code> iterations is less than
<code class="docutils literal notranslate"><span class="pre">stop_criterion</span></code>, whichever comes first.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>max_iter</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – The maximum number of iterations to run before we end synthesis
(unless we hit the stop criterion).</p></li>
<li><p><strong>store_progress</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code> | <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – Whether we should store the metamer image in progress during
synthesis. If False, we don’t save anything. If True, we save every
iteration. If an int, we save every <code class="docutils literal notranslate"><span class="pre">store_progress</span></code> iterations
(note then that 0 is the same as False and 1 the same as True).</p></li>
<li><p><strong>stop_criterion</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></span>) – If the loss over the past <code class="docutils literal notranslate"><span class="pre">stop_iters_to_check</span></code> has changed
less than <code class="docutils literal notranslate"><span class="pre">stop_criterion</span></code>, we terminate synthesis.</p></li>
<li><p><strong>stop_iters_to_check</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – How many iterations back to check in order to see if the
loss has stopped decreasing (for <code class="docutils literal notranslate"><span class="pre">stop_criterion</span></code>).</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ValueError</strong> – If we find a NaN during optimization.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.Metamer.target_representation">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">target_representation</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><span class="pre">Tensor</span></a></em><a class="headerlink" href="#plenoptic.synthesize.metamer.Metamer.target_representation" title="Link to this definition"></a></dt>
<dd><p><a class="reference internal" href="#plenoptic.synthesize.metamer.Metamer.model" title="plenoptic.synthesize.metamer.Metamer.model"><code class="xref py py-attr docutils literal notranslate"><span class="pre">model</span></code></a> representation of <a class="reference internal" href="#plenoptic.synthesize.metamer.Metamer.image" title="plenoptic.synthesize.metamer.Metamer.image"><code class="xref py py-attr docutils literal notranslate"><span class="pre">image</span></code></a>, i.e. <code class="docutils literal notranslate"><span class="pre">model(image)</span></code>.</p>
<p>The goal of synthesis is for <code class="docutils literal notranslate"><span class="pre">model(metamer)</span></code> to match this value.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.Metamer.to">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/metamer.html#Metamer.to"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.metamer.Metamer.to" title="Link to this definition"></a></dt>
<dd><p>Move and/or cast the parameters and buffers.</p>
<p>This can be called as</p>
<dl class="py function">
<dt class="sig sig-object py" id="id12">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">non_blocking</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/metamer.html#Metamer.to"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id12" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="id13">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dtype</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">non_blocking</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/metamer.html#Metamer.to"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id13" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="id14">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">non_blocking</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/metamer.html#Metamer.to"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id14" title="Link to this definition"></a></dt>
<dd></dd></dl>

<p>Its signature is similar to <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.Tensor.to.html#torch.Tensor.to" title="(in PyTorch v2.10)"><code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.Tensor.to()</span></code></a>, but only accepts
floating point desired <code class="xref py py-attr docutils literal notranslate"><span class="pre">dtype</span></code> s. In addition, this method will
only cast the floating point parameters and buffers to <code class="xref py py-attr docutils literal notranslate"><span class="pre">dtype</span></code>
(if given). The integral parameters and buffers will be moved
<code class="xref py py-attr docutils literal notranslate"><span class="pre">device</span></code>, if that is given, but with dtypes unchanged. When
<code class="xref py py-attr docutils literal notranslate"><span class="pre">non_blocking</span></code> is set, it tries to convert/move asynchronously
with respect to the host if possible, e.g., moving CPU Tensors with
pinned memory to CUDA devices.</p>
<p>See <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.to" title="(in PyTorch v2.10)"><code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.to()</span></code></a> for examples.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>device</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="(in PyTorch v2.10)"><em>torch.device</em></a>) – The desired device of the parameters and buffers in this module.</p></li>
<li><p><strong>dtype</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensor_attributes.html#torch.dtype" title="(in PyTorch v2.10)"><em>torch.dtype</em></a>) – The desired floating point type of the floating point parameters and
buffers in this module.</p></li>
<li><p><strong>tensor</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><em>torch.Tensor</em></a>) – Tensor whose dtype and device are the desired dtype and device for
all parameters and buffers in this module.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.MetamerCTF">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">MetamerCTF</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_function=&lt;function</span> <span class="pre">mse&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">range_penalty_lambda=0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">allowed_range=(0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">1)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">coarse_to_fine='together'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/metamer.html#MetamerCTF"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.metamer.MetamerCTF" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#plenoptic.synthesize.metamer.Metamer" title="plenoptic.synthesize.metamer.Metamer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Metamer</span></code></a></p>
<p>Synthesize model metamers with coarse-to-fine synthesis.</p>
<p>This is a special case of <code class="docutils literal notranslate"><span class="pre">Metamer</span></code>, which uses the coarse-to-fine
synthesis procedure described in <a class="reference internal" href="#r9b34c7472ede-1" id="id15">[1]</a>: we start by updating metamer with
respect to only a subset of the model’s representation (generally, that
which corresponds to the lowest spatial frequencies), and changing which
subset we consider over the course of synthesis. This is similar to
optimizing with a blurred version of the objective function and gradually
adding in finer details. It improves synthesis performance for some models.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>image</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – A tensor, this is the image whose representation we wish to
match.</p></li>
<li><p><strong>model</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a></span>) – A visual model.</p></li>
<li><p><strong>loss_function</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">Callable</span></code>[[<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>], <a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span>) – The loss function to use to compare the representations of the models
in order to determine their loss.</p></li>
<li><p><strong>range_penalty_lambda</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></span>) – Strength of the regularizer that enforces the allowed_range. Must be
non-negative.</p></li>
<li><p><strong>allowed_range</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>]</span>) – Range (inclusive) of allowed pixel values. Any values outside this
range will be penalized.</p></li>
<li><p><strong>coarse_to_fine</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Literal</span></code>[<code class="docutils literal notranslate"><span class="pre">'together'</span></code>, <code class="docutils literal notranslate"><span class="pre">'separate'</span></code>]</span>) – <ul>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;together&quot;</span></code>: start with the coarsest scale, then gradually
add each finer scale.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;separate&quot;</span></code>: compute the gradient with respect to each
scale separately (ignoring the others), then with respect
to all of them at the end.</p></li>
</ul>
<p>(see <a class="reference external" href="https://docs.plenoptic.org/docs/branch/main/tutorials/intro/06_Metamer.html">Metamer tutorial</a>
for more details).</p>
</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r9b34c7472ede-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id15">1</a><span class="fn-bracket">]</span></span>
<p>J Portilla and E P Simoncelli. A Parametric Texture Model
based on Joint Statistics of Complex Wavelet Coefficients. Int’l
Journal of Computer Vision. 40(1):49-71, October, 2000.
<a class="reference external" href="https://www.cns.nyu.edu/~eero/ABSTRACTS/portilla99-abstract.html">https://www.cns.nyu.edu/~eero/ABSTRACTS/portilla99-abstract.html</a>
<a class="reference external" href="https://www.cns.nyu.edu/~lcv/texture/">https://www.cns.nyu.edu/~lcv/texture/</a></p>
</div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Attributes<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">allowed_range</span></code></dt><dd><p>Allowable range of pixel values.</p>
</dd>
<dt><a class="reference internal" href="#plenoptic.synthesize.metamer.MetamerCTF.coarse_to_fine" title="plenoptic.synthesize.metamer.MetamerCTF.coarse_to_fine"><code class="xref py py-obj docutils literal notranslate"><span class="pre">coarse_to_fine</span></code></a></dt><dd><p>How we scales are handled, see <a class="reference internal" href="#plenoptic.synthesize.metamer.MetamerCTF" title="plenoptic.synthesize.metamer.MetamerCTF"><code class="xref py py-class docutils literal notranslate"><span class="pre">MetamerCTF</span></code></a> for details.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient_norm</span></code></dt><dd><p>Optimization gradient’s L2 norm over iterations.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">image</span></code></dt><dd><p>Target image of metamer optimization.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">losses</span></code></dt><dd><p>Optimization loss over iterations.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">metamer</span></code></dt><dd><p>Model metamer, the parameter we are optimizing.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">model</span></code></dt><dd><p>The model for which the metamer is synthesized.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">optimizer</span></code></dt><dd><p>Torch optimizer object which updates the synthesis target.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">pixel_change_norm</span></code></dt><dd><p>L2 norm change in pixel values over iterations.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">range_penalty_lambda</span></code></dt><dd><p>Magnitude of the penalty on pixel values outside <code class="xref py py-attr docutils literal notranslate"><span class="pre">allowed_range</span></code>.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">saved_metamer</span></code></dt><dd><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">metamer</span></code>, cached over time for later examination.</p>
</dd>
<dt><a class="reference internal" href="#plenoptic.synthesize.metamer.MetamerCTF.scales" title="plenoptic.synthesize.metamer.MetamerCTF.scales"><code class="xref py py-obj docutils literal notranslate"><span class="pre">scales</span></code></a></dt><dd><p>Model scales that we’ve yet to optimize, modified during optimization.</p>
</dd>
<dt><a class="reference internal" href="#plenoptic.synthesize.metamer.MetamerCTF.scales_finished" title="plenoptic.synthesize.metamer.MetamerCTF.scales_finished"><code class="xref py py-obj docutils literal notranslate"><span class="pre">scales_finished</span></code></a></dt><dd><p>Model scales that we’ve finished optimizing, modified during optimization.</p>
</dd>
<dt><a class="reference internal" href="#plenoptic.synthesize.metamer.MetamerCTF.scales_loss" title="plenoptic.synthesize.metamer.MetamerCTF.scales_loss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">scales_loss</span></code></a></dt><dd><p>Scale-specific loss at each iteration.</p>
</dd>
<dt><a class="reference internal" href="#plenoptic.synthesize.metamer.MetamerCTF.scales_timing" title="plenoptic.synthesize.metamer.MetamerCTF.scales_timing"><code class="xref py py-obj docutils literal notranslate"><span class="pre">scales_timing</span></code></a></dt><dd><p>Information about when each scale was started and stopped.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">scheduler</span></code></dt><dd><p>Learning rate scheduler which adjusts optimizer learning rate.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">store_progress</span></code></dt><dd><p>How often we are caching progress.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">target_representation</span></code></dt><dd><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">model</span></code> representation of <code class="xref py py-attr docutils literal notranslate"><span class="pre">image</span></code>, i.e. <code class="docutils literal notranslate"><span class="pre">model(image)</span></code>.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Methods</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#plenoptic.synthesize.metamer.MetamerCTF.load" title="plenoptic.synthesize.metamer.MetamerCTF.load"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load</span></code></a>(file_path[, map_location, ...])</p></td>
<td><p>Load all relevant stuff from a .pt file.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">objective_function</span></code>([metamer_representation, ...])</p></td>
<td><p>Compute the metamer synthesis loss.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">save</span></code>(file_path)</p></td>
<td><p>Save all relevant variables in .pt file.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">setup</span></code>([initial_image, optimizer, ...])</p></td>
<td><p>Initialize the metamer, optimizer, and scheduler.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#plenoptic.synthesize.metamer.MetamerCTF.synthesize" title="plenoptic.synthesize.metamer.MetamerCTF.synthesize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">synthesize</span></code></a>([max_iter, store_progress, ...])</p></td>
<td><p>Synthesize a metamer.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">to</span></code>(*args, **kwargs)</p></td>
<td><p>Move and/or cast the parameters and buffers.</p></td>
</tr>
</tbody>
</table>
<dl class="py property">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.MetamerCTF.coarse_to_fine">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">coarse_to_fine</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><a class="headerlink" href="#plenoptic.synthesize.metamer.MetamerCTF.coarse_to_fine" title="Link to this definition"></a></dt>
<dd><p>How we scales are handled, see <a class="reference internal" href="#plenoptic.synthesize.metamer.MetamerCTF" title="plenoptic.synthesize.metamer.MetamerCTF"><code class="xref py py-class docutils literal notranslate"><span class="pre">MetamerCTF</span></code></a> for details.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.MetamerCTF.load">
<span class="sig-name descname"><span class="pre">load</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">map_location</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensor_equality_atol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-08</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensor_equality_rtol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">pickle_load_args</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/metamer.html#MetamerCTF.load"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.metamer.MetamerCTF.load" title="Link to this definition"></a></dt>
<dd><p>Load all relevant stuff from a .pt file.</p>
<p>This should be called by an initialized <code class="docutils literal notranslate"><span class="pre">Metamer</span></code> object – we will
ensure that <code class="docutils literal notranslate"><span class="pre">image</span></code>, <code class="docutils literal notranslate"><span class="pre">target_representation</span></code> (and thus
<code class="docutils literal notranslate"><span class="pre">model</span></code>), and <code class="docutils literal notranslate"><span class="pre">loss_function</span></code> are all identical.</p>
<p>Note this operates in place and so doesn’t return anything.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>file_path</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></span>) – The path to load the synthesis object from.</p></li>
<li><p><strong>map_location</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Argument to pass to <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.load.html#torch.load" title="(in PyTorch v2.10)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.load()</span></code></a> as <code class="docutils literal notranslate"><span class="pre">map_location</span></code>. If you
save stuff that was being run on a GPU and are loading onto a
CPU, you’ll need this to make sure everything lines up
properly. This should be structured like the str you would
pass to <a class="reference external" href="https://docs.pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.device</span></code></a>.</p></li>
<li><p><strong>tensor_equality_atol</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></span>) – Absolute tolerance to use when checking for tensor equality during load,
passed to <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.allclose.html#torch.allclose" title="(in PyTorch v2.10)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.allclose()</span></code></a>. It may be necessary to increase if you are
saving and loading on two machines with torch built by different cuda
versions. Be careful when changing this! See
<a class="reference external" href="https://docs.pytorch.org/docs/stable/type_info.html#torch.torch.finfo" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.finfo</span></code></a> for more details about floating
point precision of different data types (especially, <code class="docutils literal notranslate"><span class="pre">eps</span></code>); if you have
to increase this by more than 1 or 2 decades, then you are probably not
dealing with a numerical issue.</p></li>
<li><p><strong>tensor_equality_rtol</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></span>) – Relative tolerance to use when checking for tensor equality during load,
passed to <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.allclose.html#torch.allclose" title="(in PyTorch v2.10)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.allclose()</span></code></a>. It may be necessary to increase if you are
saving and loading on two machines with torch built by different cuda
versions. Be careful when changing this! See
<a class="reference external" href="https://docs.pytorch.org/docs/stable/type_info.html#torch.torch.finfo" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.finfo</span></code></a> for more details about floating
point precision of different data types (especially, <code class="docutils literal notranslate"><span class="pre">eps</span></code>); if you have
to increase this by more than 1 or 2 decades, then you are probably not
dealing with a numerical issue.</p></li>
<li><p><strong>**pickle_load_args</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></span>) – Any additional kwargs will be added to <code class="docutils literal notranslate"><span class="pre">pickle_module.load</span></code> via
<a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.load.html#torch.load" title="(in PyTorch v2.10)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.load()</span></code></a>, see that function’s docstring for details.</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>ValueError</strong> – If <code class="xref py py-func docutils literal notranslate"><span class="pre">setup()</span></code> or <a class="reference internal" href="#plenoptic.synthesize.metamer.MetamerCTF.synthesize" title="plenoptic.synthesize.metamer.MetamerCTF.synthesize"><code class="xref py py-func docutils literal notranslate"><span class="pre">synthesize()</span></code></a> has been called before this call
to <code class="docutils literal notranslate"><span class="pre">load</span></code>.</p></li>
<li><p><strong>ValueError</strong> – If the object saved at <code class="docutils literal notranslate"><span class="pre">file_path</span></code> is not a <code class="docutils literal notranslate"><span class="pre">MetamerCTF</span></code> object.</p></li>
<li><p><strong>ValueError</strong> – If the saved and loading <code class="docutils literal notranslate"><span class="pre">MetamerCTF</span></code> objects have a different value
for any of <code class="xref py py-attr docutils literal notranslate"><span class="pre">image</span></code>, <code class="xref py py-attr docutils literal notranslate"><span class="pre">range_penalty_lambda</span></code>,
<code class="xref py py-attr docutils literal notranslate"><span class="pre">allowed_range</span></code>, or <a class="reference internal" href="#plenoptic.synthesize.metamer.MetamerCTF.coarse_to_fine" title="plenoptic.synthesize.metamer.MetamerCTF.coarse_to_fine"><code class="xref py py-attr docutils literal notranslate"><span class="pre">coarse_to_fine</span></code></a>.</p></li>
<li><p><strong>ValueError</strong> – If the behavior of <code class="xref py py-attr docutils literal notranslate"><span class="pre">loss_function</span></code> or <code class="xref py py-attr docutils literal notranslate"><span class="pre">model</span></code> is different
between the saved and loading objects.</p></li>
</ul>
</dd>
<dt class="field-odd">Warns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>UserWarning</strong> – If <code class="xref py py-func docutils literal notranslate"><span class="pre">setup()</span></code> will need to be called after load, to finish initializing
<code class="xref py py-attr docutils literal notranslate"><span class="pre">optimizer</span></code> or <code class="xref py py-attr docutils literal notranslate"><span class="pre">scheduler</span></code>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">plenoptic</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">po</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">einstein</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">simul</span><span class="o">.</span><span class="n">PortillaSimoncelli</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metamer</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">synth</span><span class="o">.</span><span class="n">MetamerCTF</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metamer</span><span class="o">.</span><span class="n">synthesize</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">store_progress</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metamer</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;metamers.pt&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metamer_copy</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">synth</span><span class="o">.</span><span class="n">MetamerCTF</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metamer_copy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;metamers.pt&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.MetamerCTF.scales">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">scales</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">tuple</span></em><a class="headerlink" href="#plenoptic.synthesize.metamer.MetamerCTF.scales" title="Link to this definition"></a></dt>
<dd><p>Model scales that we’ve yet to optimize, modified during optimization.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.MetamerCTF.scales_finished">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">scales_finished</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">tuple</span></em><a class="headerlink" href="#plenoptic.synthesize.metamer.MetamerCTF.scales_finished" title="Link to this definition"></a></dt>
<dd><p>Model scales that we’ve finished optimizing, modified during optimization.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.MetamerCTF.scales_loss">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">scales_loss</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">tuple</span></em><a class="headerlink" href="#plenoptic.synthesize.metamer.MetamerCTF.scales_loss" title="Link to this definition"></a></dt>
<dd><p>Scale-specific loss at each iteration.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.MetamerCTF.scales_timing">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">scales_timing</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">dict</span></em><a class="headerlink" href="#plenoptic.synthesize.metamer.MetamerCTF.scales_timing" title="Link to this definition"></a></dt>
<dd><p>Information about when each scale was started and stopped.</p>
<p>Keys are the values found in <a class="reference internal" href="#plenoptic.synthesize.metamer.MetamerCTF.scales" title="plenoptic.synthesize.metamer.MetamerCTF.scales"><code class="xref py py-attr docutils literal notranslate"><span class="pre">scales</span></code></a>, and values are lists specifying
the iteration where we started and stopped optimizing this scale, which are
modified during optimization.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.MetamerCTF.synthesize">
<span class="sig-name descname"><span class="pre">synthesize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">store_progress</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop_criterion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop_iters_to_check</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">50</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">change_scale_criterion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctf_iters_to_check</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">50</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/metamer.html#MetamerCTF.synthesize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.metamer.MetamerCTF.synthesize" title="Link to this definition"></a></dt>
<dd><p>Synthesize a metamer.</p>
<p>Update the pixels of <code class="docutils literal notranslate"><span class="pre">metamer</span></code> until its representation matches
that of <code class="docutils literal notranslate"><span class="pre">image</span></code>.</p>
<p>We run this until either we reach <code class="docutils literal notranslate"><span class="pre">max_iter</span></code> or the change over the
past <code class="docutils literal notranslate"><span class="pre">stop_iters_to_check</span></code> iterations is less than
<code class="docutils literal notranslate"><span class="pre">stop_criterion</span></code>, whichever comes first.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>max_iter</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – The maximum number of iterations to run before we end synthesis
(unless we hit the stop criterion).</p></li>
<li><p><strong>store_progress</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code> | <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – Whether we should store the metamer image in progress on every
iteration. If False, we don’t save anything. If True, we save every
iteration. If an int, we save every <code class="docutils literal notranslate"><span class="pre">store_progress</span></code> iterations
(note then that 0 is the same as False and 1 the same as True).</p></li>
<li><p><strong>stop_criterion</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></span>) – If the loss over the past <code class="docutils literal notranslate"><span class="pre">stop_iters_to_check</span></code> has changed
less than <code class="docutils literal notranslate"><span class="pre">stop_criterion</span></code>, we terminate synthesis.</p></li>
<li><p><strong>stop_iters_to_check</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – How many iterations back to check in order to see if the
loss has stopped decreasing (for <code class="docutils literal notranslate"><span class="pre">stop_criterion</span></code>).</p></li>
<li><p><strong>change_scale_criterion</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Scale-specific analogue of <code class="docutils literal notranslate"><span class="pre">change_scale_criterion</span></code>: we consider
a given scale finished (and move onto the next) if the loss has
changed less than this in the past <code class="docutils literal notranslate"><span class="pre">ctf_iters_to_check</span></code>
iterations. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, we’ll change scales as soon as we’ve spent
<code class="docutils literal notranslate"><span class="pre">ctf_iters_to_check</span></code> on a given scale.</p></li>
<li><p><strong>ctf_iters_to_check</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – Scale-specific analogue of <code class="docutils literal notranslate"><span class="pre">stop_iters_to_check</span></code>: how many
iterations back in order to check in order to see if we should
switch scales.</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>ValueError</strong> – If <code class="docutils literal notranslate"><span class="pre">stop_criterion</span> <span class="pre">&gt;=</span> <span class="pre">change_scale_criterion</span></code> – behavior is strange
otherwise.</p></li>
<li><p><strong>ValueError</strong> – If we find a NaN during optimization.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.animate">
<span class="sig-name descname"><span class="pre">animate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">metamer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">framerate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">channel_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ylim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vrange</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0,</span> <span class="pre">1)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">zoom</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">plot_representation_error_as_rgb</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fig</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axes_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">figsize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">included_plots</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">['display_metamer',</span> <span class="pre">'plot_loss',</span> <span class="pre">'plot_representation_error']</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">width_ratios</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/metamer.html#animate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.metamer.animate" title="Link to this definition"></a></dt>
<dd><p>Animate synthesis progress.</p>
<p>This is essentially the figure produced by
<code class="docutils literal notranslate"><span class="pre">metamer.plot_synthesis_status</span></code> animated over time, for each stored
iteration.</p>
<p>This functions returns a matplotlib FuncAnimation object. See our documentation
(e.g., <a class="reference external" href="https://docs.plenoptic.org/docs/branch/main/tutorials/00_quickstart.html">Quickstart</a>) for
examples on how to view it in a Jupyter notebook. In order to save, use
<code class="docutils literal notranslate"><span class="pre">anim.save(filename)</span></code>. In either case, this can take a while and you’ll need the
appropriate writer installed and on your path, e.g., ffmpeg, imagemagick, etc). See
<a class="reference external" href="https://matplotlib.org/stable/api/animation_api.html">matplotlib documentation</a>
for more details.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>metamer</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="#plenoptic.synthesize.metamer.Metamer" title="plenoptic.synthesize.metamer.Metamer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Metamer</span></code></a></span>) – Metamer object whose synthesis we want to animate.</p></li>
<li><p><strong>framerate</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – How many frames a second to display.</p></li>
<li><p><strong>batch_idx</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – Which index to take from the batch dimension.</p></li>
<li><p><strong>channel_idx</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Which index to take from the channel dimension. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, we use all
channels (assumed use-case is RGB(A) image).</p></li>
<li><p><strong>ylim</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>], <code class="xref py py-data docutils literal notranslate"><span class="pre">Literal</span></code>[<code class="docutils literal notranslate"><span class="pre">False</span></code>]]</span>) – <p>The y-limits of the representation_error plot:</p>
<ul>
<li><p>If a tuple, then this is the ylim of all plots</p></li>
<li><p>If <code class="docutils literal notranslate"><span class="pre">None</span></code>, then all plots have the same limits, all
symmetric about 0 with a limit of
<code class="docutils literal notranslate"><span class="pre">np.abs(representation_error).max()</span></code> (for the initial
representation_error).</p></li>
<li><p>If False, don’t modify limits.</p></li>
<li><p>If a string, must be <code class="docutils literal notranslate"><span class="pre">&quot;rescale&quot;</span></code> or of the form <code class="docutils literal notranslate"><span class="pre">&quot;rescaleN&quot;</span></code>,
where N can be any integer. If <code class="docutils literal notranslate"><span class="pre">&quot;rescaleN&quot;</span></code>, we rescale the
limits every N frames (we rescale as if <code class="docutils literal notranslate"><span class="pre">ylim=None</span></code>). If
<code class="docutils literal notranslate"><span class="pre">&quot;rescale&quot;</span></code>, then we do this 10 times over the course of the
animation.</p></li>
</ul>
</p></li>
<li><p><strong>vrange</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>] | <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></span>) – The vrange option to pass to <a class="reference internal" href="#plenoptic.synthesize.metamer.display_metamer" title="plenoptic.synthesize.metamer.display_metamer"><code class="xref py py-func docutils literal notranslate"><span class="pre">display_metamer()</span></code></a>. See
docstring of <code class="xref py py-func docutils literal notranslate"><span class="pre">plenoptic.imshow()</span></code> for possible values.</p></li>
<li><p><strong>zoom</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – How much to zoom in / enlarge the metamer, the ratio
of display pixels to image pixels. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, we
attempt to find the best value ourselves.</p></li>
<li><p><strong>plot_representation_error_as_rgb</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></span>) – The representation can be image-like with multiple channels, and we
have no way to determine whether it should be represented as an RGB
image or not, so the user must set this flag to tell us. It will be
ignored if the representation doesn’t look image-like or if the
model has its own plot_representation_error() method. Else, it will
be passed to <code class="xref py py-func docutils literal notranslate"><span class="pre">plenoptic.imshow()</span></code>, see that methods docstring for details.
since plot_synthesis_status normally sets it up for us.</p></li>
<li><p><strong>fig</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.figure.Figure.html#matplotlib.figure.Figure" title="(in Matplotlib v3.10.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Figure</span></code></a> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – If <code class="docutils literal notranslate"><span class="pre">None</span></code>, create the figure from scratch. Else, should be an empty
figure with enough axes (the expected use here is have same-size
movies with different plots).</p></li>
<li><p><strong>axes_idx</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]</span>) – Dictionary specifying which axes contains which type of plot, allows
for more fine-grained control of the resulting figure. Probably only
helpful if fig is also defined. Possible keys: <code class="docutils literal notranslate"><span class="pre">'display_metamer',</span>
<span class="pre">'plot_loss',</span> <span class="pre">'plot_representation_error',</span> <span class="pre">'plot_pixel_values',</span>
<span class="pre">'misc'</span></code>. Values should all be ints. If you tell this function to
create a plot that doesn’t have a corresponding key, we find the lowest
int that is not already in the dict, so if you have axes that you want
unchanged, place their idx in <code class="docutils literal notranslate"><span class="pre">'misc'</span></code>.</p></li>
<li><p><strong>figsize</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>] | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – The size of the figure to create. It may take a little bit of
playing around to find a reasonable value. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, we attempt to
make our best guess, aiming to have each axis be of size <code class="docutils literal notranslate"><span class="pre">(5,</span> <span class="pre">5)</span></code>.</p></li>
<li><p><strong>included_plots</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]</span>) – Which plots to include. Must be some subset of <code class="docutils literal notranslate"><span class="pre">'display_metamer',</span>
<span class="pre">'plot_loss',</span> <span class="pre">'plot_representation_error',</span> <span class="pre">'plot_pixel_values'</span></code>.</p></li>
<li><p><strong>width_ratios</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>]</span>) – By default, all plots axes will have the same width. To change
that, specify their relative widths using the keys: <code class="docutils literal notranslate"><span class="pre">'display_metamer',</span>
<span class="pre">'plot_loss',</span> <span class="pre">'plot_representation_error',</span> <span class="pre">'plot_pixel_values'</span></code> and floats
specifying their relative width. Any not included will be assumed to be
1.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.animation.FuncAnimation.html#matplotlib.animation.FuncAnimation" title="(in Matplotlib v3.10.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">FuncAnimation</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>anim</em> – The animation object. In order to view, must convert to HTML
or save.</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>ValueError</strong> – If the given <code class="docutils literal notranslate"><span class="pre">metamer</span></code> object was run with <code class="docutils literal notranslate"><span class="pre">store_progress=False</span></code>.</p></li>
<li><p><strong>ValueError</strong> – If <code class="docutils literal notranslate"><span class="pre">metamer.metamer</span></code> object is not 3d or 4d.</p></li>
<li><p><strong>ValueError</strong> – If we do not know how to interpret the value of <code class="docutils literal notranslate"><span class="pre">ylim</span></code>.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>By default, we use the ffmpeg backend, which requires that you have ffmpeg installed
and on your path (<a class="reference external" href="https://ffmpeg.org/download.html">https://ffmpeg.org/download.html</a>). To use a different, use the
matplotlib rcParams: <code class="docutils literal notranslate"><span class="pre">matplotlib.rcParams['animation.writer']</span> <span class="pre">=</span> <span class="pre">writer</span></code>, see
<a class="reference external" href="https://matplotlib.org/stable/api/animation_api.html#writer-classes">matplotlib documentation</a> for more
details.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.display_metamer">
<span class="sig-name descname"><span class="pre">display_metamer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">metamer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">channel_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">zoom</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/metamer.html#display_metamer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.metamer.display_metamer" title="Link to this definition"></a></dt>
<dd><p>Display metamer.</p>
<p>You can specify what iteration to view by using the <code class="docutils literal notranslate"><span class="pre">iteration</span></code> arg.
The default, <code class="docutils literal notranslate"><span class="pre">None</span></code>, shows the final one.</p>
<p>We use <code class="xref py py-func docutils literal notranslate"><span class="pre">plenoptic.imshow()</span></code> to display the metamer and attempt to
automatically find the most reasonable zoom value. You can override this
value using the zoom arg, but remember that <code class="xref py py-func docutils literal notranslate"><span class="pre">plenoptic.imshow()</span></code> is
opinionated about the size of the resulting image and will throw an
Exception if the axis created is not big enough for the selected zoom.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>metamer</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="#plenoptic.synthesize.metamer.Metamer" title="plenoptic.synthesize.metamer.Metamer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Metamer</span></code></a></span>) – Metamer object whose synthesized metamer we want to display.</p></li>
<li><p><strong>batch_idx</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – Which index to take from the batch dimension.</p></li>
<li><p><strong>channel_idx</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Which index to take from the channel dimension. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, we assume
image is RGB(A) and show all channels.</p></li>
<li><p><strong>zoom</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – How much to zoom in / enlarge the metamer, the ratio of display pixels
to image pixels. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, we attempt to find the best
value ourselves.</p></li>
<li><p><strong>iteration</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Which iteration to display. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, we show
the most recent one. Negative values are also allowed.</p></li>
<li><p><strong>ax</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.html#matplotlib.axes.Axes" title="(in Matplotlib v3.10.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Axes</span></code></a> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Pre-existing axes for plot. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, we call <a class="reference external" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.gca.html#matplotlib.pyplot.gca" title="(in Matplotlib v3.10.8)"><code class="xref py py-func docutils literal notranslate"><span class="pre">matplotlib.pyplot.gca()</span></code></a>.</p></li>
<li><p><strong>**kwargs</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></span>) – Passed to <code class="xref py py-func docutils literal notranslate"><span class="pre">plenoptic.imshow()</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.html#matplotlib.axes.Axes" title="(in Matplotlib v3.10.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Axes</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>ax</em> – The matplotlib axes containing the plot.</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ValueError</strong> – If <code class="docutils literal notranslate"><span class="pre">batch_idx</span></code> is not an int.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.plot_loss">
<span class="sig-name descname"><span class="pre">plot_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">metamer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/metamer.html#plot_loss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.metamer.plot_loss" title="Link to this definition"></a></dt>
<dd><p>Plot synthesis loss with log-scaled y axis.</p>
<p>Plots <code class="docutils literal notranslate"><span class="pre">metamer.losses</span></code> over all iterations. Also plots a red dot at
<code class="docutils literal notranslate"><span class="pre">iteration</span></code>, to highlight the loss there. If <code class="docutils literal notranslate"><span class="pre">iteration=None</span></code>, then the
dot will be at the final iteration.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>metamer</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="#plenoptic.synthesize.metamer.Metamer" title="plenoptic.synthesize.metamer.Metamer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Metamer</span></code></a></span>) – Metamer object whose loss we want to plot.</p></li>
<li><p><strong>iteration</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Which iteration to display. If <code class="docutils literal notranslate"><span class="pre">None</span></code>,  we show
the most recent one. Negative values are also allowed.</p></li>
<li><p><strong>ax</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.html#matplotlib.axes.Axes" title="(in Matplotlib v3.10.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Axes</span></code></a> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Pre-existing axes for plot. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, we call
<a class="reference external" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.gca.html#matplotlib.pyplot.gca" title="(in Matplotlib v3.10.8)"><code class="xref py py-func docutils literal notranslate"><span class="pre">matplotlib.pyplot.gca()</span></code></a>.</p></li>
<li><p><strong>**kwargs</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></span>) – Passed to <a class="reference external" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.semilogy.html#matplotlib.pyplot.semilogy" title="(in Matplotlib v3.10.8)"><code class="xref py py-func docutils literal notranslate"><span class="pre">matplotlib.pyplot.semilogy()</span></code></a>.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.html#matplotlib.axes.Axes" title="(in Matplotlib v3.10.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Axes</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>ax</em> – The matplotlib axes containing the plot.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.plot_pixel_values">
<span class="sig-name descname"><span class="pre">plot_pixel_values</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">metamer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">channel_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ylim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/metamer.html#plot_pixel_values"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.metamer.plot_pixel_values" title="Link to this definition"></a></dt>
<dd><p>Plot histogram of pixel values of target image and its metamer.</p>
<p>As a way to check the distributions of pixel intensities and see
if there’s any values outside the allowed range</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>metamer</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="#plenoptic.synthesize.metamer.Metamer" title="plenoptic.synthesize.metamer.Metamer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Metamer</span></code></a></span>) – Metamer object with the images whose pixel values we want to compare.</p></li>
<li><p><strong>batch_idx</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – Which index to take from the batch dimension.</p></li>
<li><p><strong>channel_idx</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Which index to take from the channel dimension. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, we use all
channels (assumed use-case is RGB(A) images).</p></li>
<li><p><strong>iteration</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Which iteration to display. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, we show
the most recent one. Negative values are also allowed.</p></li>
<li><p><strong>ylim</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>], <code class="xref py py-data docutils literal notranslate"><span class="pre">Literal</span></code>[<code class="docutils literal notranslate"><span class="pre">False</span></code>]]</span>) – If tuple, the ylimit to set for this axis. If False, we leave
it untouched.</p></li>
<li><p><strong>ax</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.html#matplotlib.axes.Axes" title="(in Matplotlib v3.10.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Axes</span></code></a> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Pre-existing axes for plot. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, we call
<a class="reference external" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.gca.html#matplotlib.pyplot.gca" title="(in Matplotlib v3.10.8)"><code class="xref py py-func docutils literal notranslate"><span class="pre">matplotlib.pyplot.gca()</span></code></a>.</p></li>
<li><p><strong>**kwargs</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></span>) – Passed to <a class="reference external" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.hist.html#matplotlib.pyplot.hist" title="(in Matplotlib v3.10.8)"><code class="xref py py-func docutils literal notranslate"><span class="pre">matplotlib.pyplot.hist()</span></code></a>.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.html#matplotlib.axes.Axes" title="(in Matplotlib v3.10.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Axes</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>ax</em> – Created axes.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.plot_representation_error">
<span class="sig-name descname"><span class="pre">plot_representation_error</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">metamer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ylim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">as_rgb</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/metamer.html#plot_representation_error"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.metamer.plot_representation_error" title="Link to this definition"></a></dt>
<dd><p>Plot distance ratio showing how close we are to convergence.</p>
<p>We plot <code class="docutils literal notranslate"><span class="pre">_representation_error(metamer,</span> <span class="pre">iteration)</span></code>. For more details, see
<code class="docutils literal notranslate"><span class="pre">plenoptic.tools.display.plot_representation</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>metamer</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="#plenoptic.synthesize.metamer.Metamer" title="plenoptic.synthesize.metamer.Metamer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Metamer</span></code></a></span>) – Metamer object whose synthesized metamer we want to display.</p></li>
<li><p><strong>batch_idx</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – Which index to take from the batch dimension.</p></li>
<li><p><strong>iteration</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Which iteration to display. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, we show
the most recent one. Negative values are also allowed.</p></li>
<li><p><strong>ylim</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Literal</span></code>[<code class="docutils literal notranslate"><span class="pre">False</span></code>]]</span>) – If <code class="docutils literal notranslate"><span class="pre">ylim</span></code> is <code class="docutils literal notranslate"><span class="pre">None</span></code>, we sets the axes’ y-limits to be <code class="docutils literal notranslate"><span class="pre">(-y_max,</span>
<span class="pre">y_max)</span></code>, where <code class="docutils literal notranslate"><span class="pre">y_max=np.abs(data).max()</span></code>. If it’s <code class="docutils literal notranslate"><span class="pre">False</span></code>, we do
nothing. If a tuple, we use that range.</p></li>
<li><p><strong>ax</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.html#matplotlib.axes.Axes" title="(in Matplotlib v3.10.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Axes</span></code></a> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Pre-existing axes for plot. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, we call <a class="reference external" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.gca.html#matplotlib.pyplot.gca" title="(in Matplotlib v3.10.8)"><code class="xref py py-func docutils literal notranslate"><span class="pre">matplotlib.pyplot.gca()</span></code></a>.</p></li>
<li><p><strong>as_rgb</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></span>) – The representation can be image-like with multiple channels, and we
have no way to determine whether it should be represented as an RGB
image or not, so the user must set this flag to tell us. It will be
ignored if the response doesn’t look image-like or if the model has its
own <code class="docutils literal notranslate"><span class="pre">plot_representation_error()</span></code> method. Else, it will be passed to
<code class="xref py py-func docutils literal notranslate"><span class="pre">plenoptic.imshow()</span></code>, see that methods docstring for details.</p></li>
<li><p><strong>**kwargs</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></span>) – Passed to <code class="docutils literal notranslate"><span class="pre">metamer.model.forward</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>[<a class="reference external" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.html#matplotlib.axes.Axes" title="(in Matplotlib v3.10.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Axes</span></code></a>]</span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>axes</em> – List of created axes.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="plenoptic.synthesize.metamer.plot_synthesis_status">
<span class="sig-name descname"><span class="pre">plot_synthesis_status</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">metamer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">channel_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ylim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vrange</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'indep1'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">zoom</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">plot_representation_error_as_rgb</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fig</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axes_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">figsize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">included_plots</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">['display_metamer',</span> <span class="pre">'plot_loss',</span> <span class="pre">'plot_representation_error']</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">width_ratios</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/metamer.html#plot_synthesis_status"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.metamer.plot_synthesis_status" title="Link to this definition"></a></dt>
<dd><p>Make a plot showing synthesis status.</p>
<p>We create several subplots to analyze this. By default, we create three
subplots on a new figure: the first one contains the synthesized metamer,
the second contains the loss, and the third contains the representation
error.</p>
<p>There is an optional additional plot: <code class="docutils literal notranslate"><span class="pre">plot_pixel_values</span></code>, a histogram of
pixel values of the metamer and target image.</p>
<p>The plots to include are specified by including their name in the
<code class="docutils literal notranslate"><span class="pre">included_plots</span></code> list. All plots can be created separately using the
method with the same name.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>metamer</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="#plenoptic.synthesize.metamer.Metamer" title="plenoptic.synthesize.metamer.Metamer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Metamer</span></code></a></span>) – Metamer object whose status we want to plot.</p></li>
<li><p><strong>batch_idx</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – Which index to take from the batch dimension.</p></li>
<li><p><strong>channel_idx</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Which index to take from the channel dimension. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, we use all
channels (assumed use-case is RGB(A) image).</p></li>
<li><p><strong>iteration</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Which iteration to display. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, we show
the most recent one. Negative values are also allowed.</p></li>
<li><p><strong>ylim</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Literal</span></code>[<code class="docutils literal notranslate"><span class="pre">False</span></code>]]</span>) – The ylimit to use for the representation_error plot. We pass
this value directly to <code class="docutils literal notranslate"><span class="pre">plot_representation_error</span></code>.</p></li>
<li><p><strong>vrange</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>] | <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></span>) – The vrange option to pass to <a class="reference internal" href="#plenoptic.synthesize.metamer.display_metamer" title="plenoptic.synthesize.metamer.display_metamer"><code class="xref py py-func docutils literal notranslate"><span class="pre">display_metamer()</span></code></a>. See
docstring of <code class="xref py py-func docutils literal notranslate"><span class="pre">plenoptic.imshow()</span></code> for possible values.</p></li>
<li><p><strong>zoom</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – How much to zoom in / enlarge the metamer, the ratio
of display pixels to image pixels. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, we
attempt to find the best value ourselves.</p></li>
<li><p><strong>plot_representation_error_as_rgb</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></span>) – The representation can be image-like with multiple channels, and we
have no way to determine whether it should be represented as an RGB
image or not, so the user must set this flag to tell us. It will be
ignored if the response doesn’t look image-like or if the
model has its own plot_representation_error() method. Else, it will
be passed to <code class="xref py py-func docutils literal notranslate"><span class="pre">plenoptic.imshow()</span></code>, see that methods docstring for details.</p></li>
<li><p><strong>fig</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.figure.Figure.html#matplotlib.figure.Figure" title="(in Matplotlib v3.10.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Figure</span></code></a> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – If <code class="docutils literal notranslate"><span class="pre">None</span></code>, we create a new figure. otherwise we assume this is
an empty figure that has the appropriate size and number of
subplots.</p></li>
<li><p><strong>axes_idx</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]</span>) – Dictionary specifying which axes contains which type of plot, allows
for more fine-grained control of the resulting figure. Probably only
helpful if fig is also defined. Possible keys: <code class="docutils literal notranslate"><span class="pre">'display_metamer',</span>
<span class="pre">'plot_loss',</span> <span class="pre">'plot_representation_error',</span> <span class="pre">'plot_pixel_values',</span>
<span class="pre">'misc'</span></code>. Values should all be ints. If you tell this function to
create a plot that doesn’t have a corresponding key, we find the lowest
int that is not already in the dict, so if you have axes that you want
unchanged, place their idx in <code class="docutils literal notranslate"><span class="pre">'misc'</span></code>.</p></li>
<li><p><strong>figsize</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>] | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – The size of the figure to create. It may take a little bit of
playing around to find a reasonable value. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, we attempt to
make our best guess, aiming to have each axis be of size <code class="docutils literal notranslate"><span class="pre">(5,</span> <span class="pre">5)</span></code>.</p></li>
<li><p><strong>included_plots</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]</span>) – Which plots to include. Must be some subset of <code class="docutils literal notranslate"><span class="pre">'display_metamer',</span>
<span class="pre">'plot_loss',</span> <span class="pre">'plot_representation_error',</span> <span class="pre">'plot_pixel_values'</span></code>.</p></li>
<li><p><strong>width_ratios</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>]</span>) – By default, all plots will have the same width. To change
that, specify their relative widths using the keys: <code class="docutils literal notranslate"><span class="pre">'display_metamer',</span>
<span class="pre">'plot_loss',</span> <span class="pre">'plot_representation_error',</span> <span class="pre">'plot_pixel_values'</span></code> and floats
specifying their relative width. Any not included will be assumed to be
1.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code>[<a class="reference external" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.figure.Figure.html#matplotlib.figure.Figure" title="(in Matplotlib v3.10.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Figure</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]]</span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><ul class="simple">
<li><p><em>fig</em> – The figure containing this plot.</p></li>
<li><p><em>axes_idx</em> – Dictionary giving index of each plot.</p></li>
</ul>
</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>ValueError</strong> – If <code class="docutils literal notranslate"><span class="pre">metamer.metamer</span></code> object is not 3d or 4d.</p></li>
<li><p><strong>ValueError</strong> – If the <code class="docutils literal notranslate"><span class="pre">iteration</span> <span class="pre">is</span> <span class="pre">not</span> <span class="pre">None</span></code> and the given <code class="docutils literal notranslate"><span class="pre">metamer</span></code> object was run
with <code class="docutils literal notranslate"><span class="pre">store_progress=False</span></code>.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-plenoptic.synthesize.synthesis">
<span id="plenoptic-synthesize-synthesis-module"></span><h2>plenoptic.synthesize.synthesis module<a class="headerlink" href="#module-plenoptic.synthesize.synthesis" title="Link to this heading"></a></h2>
<p>Abstract synthesis super-class.</p>
<p>Users should not interact with this file, but any concrete synthesis methods should
inherit one of these classes, to provide a unified interface.</p>
<dl class="py class">
<dt class="sig sig-object py" id="plenoptic.synthesize.synthesis.OptimizedSynthesis">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">OptimizedSynthesis</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">range_penalty_lambda</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">allowed_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0,</span> <span class="pre">1)</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/synthesis.html#OptimizedSynthesis"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.synthesis.OptimizedSynthesis" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#plenoptic.synthesize.synthesis.Synthesis" title="plenoptic.synthesize.synthesis.Synthesis"><code class="xref py py-class docutils literal notranslate"><span class="pre">Synthesis</span></code></a></p>
<p>Abstract super-class for synthesis objects that use optimization.</p>
<p>The primary difference between this and the generic Synthesis class is that
these will use an optimizer object to iteratively update their output.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>range_penalty_lambda</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></span>) – Strength of the regularizer that enforces the allowed_range. Must be
non-negative.</p></li>
<li><p><strong>allowed_range</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>]</span>) – Range (inclusive) of allowed pixel values. Any values outside this
range will be penalized.</p></li>
</ul>
</dd>
<dt class="field-even">Attributes<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><a class="reference internal" href="#plenoptic.synthesize.synthesis.OptimizedSynthesis.allowed_range" title="plenoptic.synthesize.synthesis.OptimizedSynthesis.allowed_range"><code class="xref py py-obj docutils literal notranslate"><span class="pre">allowed_range</span></code></a></dt><dd><p>Allowable range of pixel values.</p>
</dd>
<dt><a class="reference internal" href="#plenoptic.synthesize.synthesis.OptimizedSynthesis.gradient_norm" title="plenoptic.synthesize.synthesis.OptimizedSynthesis.gradient_norm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient_norm</span></code></a></dt><dd><p>Optimization gradient’s L2 norm over iterations.</p>
</dd>
<dt><a class="reference internal" href="#plenoptic.synthesize.synthesis.OptimizedSynthesis.losses" title="plenoptic.synthesize.synthesis.OptimizedSynthesis.losses"><code class="xref py py-obj docutils literal notranslate"><span class="pre">losses</span></code></a></dt><dd><p>Optimization loss over iterations.</p>
</dd>
<dt><a class="reference internal" href="#plenoptic.synthesize.synthesis.OptimizedSynthesis.optimizer" title="plenoptic.synthesize.synthesis.OptimizedSynthesis.optimizer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">optimizer</span></code></a></dt><dd><p>Torch optimizer object which updates the synthesis target.</p>
</dd>
<dt><a class="reference internal" href="#plenoptic.synthesize.synthesis.OptimizedSynthesis.pixel_change_norm" title="plenoptic.synthesize.synthesis.OptimizedSynthesis.pixel_change_norm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">pixel_change_norm</span></code></a></dt><dd><p>L2 norm change in pixel values over iterations.</p>
</dd>
<dt><a class="reference internal" href="#plenoptic.synthesize.synthesis.OptimizedSynthesis.range_penalty_lambda" title="plenoptic.synthesize.synthesis.OptimizedSynthesis.range_penalty_lambda"><code class="xref py py-obj docutils literal notranslate"><span class="pre">range_penalty_lambda</span></code></a></dt><dd><p>Magnitude of the penalty on pixel values outside <a class="reference internal" href="#plenoptic.synthesize.synthesis.OptimizedSynthesis.allowed_range" title="plenoptic.synthesize.synthesis.OptimizedSynthesis.allowed_range"><code class="xref py py-attr docutils literal notranslate"><span class="pre">allowed_range</span></code></a>.</p>
</dd>
<dt><a class="reference internal" href="#plenoptic.synthesize.synthesis.OptimizedSynthesis.scheduler" title="plenoptic.synthesize.synthesis.OptimizedSynthesis.scheduler"><code class="xref py py-obj docutils literal notranslate"><span class="pre">scheduler</span></code></a></dt><dd><p>Learning rate scheduler which adjusts optimizer learning rate.</p>
</dd>
<dt><a class="reference internal" href="#plenoptic.synthesize.synthesis.OptimizedSynthesis.store_progress" title="plenoptic.synthesize.synthesis.OptimizedSynthesis.store_progress"><code class="xref py py-obj docutils literal notranslate"><span class="pre">store_progress</span></code></a></dt><dd><p>How often we are caching progress.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Methods</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">load</span></code>(file_path, empty_on_init_attr[, ...])</p></td>
<td><p>Load all relevant attributes from a .pt file.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#plenoptic.synthesize.synthesis.OptimizedSynthesis.objective_function" title="plenoptic.synthesize.synthesis.OptimizedSynthesis.objective_function"><code class="xref py py-obj docutils literal notranslate"><span class="pre">objective_function</span></code></a>()</p></td>
<td><p>How good is the current synthesized object.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">save</span></code>(file_path[, save_io_attrs, ...])</p></td>
<td><p>Save all attributes in .pt file.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#plenoptic.synthesize.synthesis.OptimizedSynthesis.setup" title="plenoptic.synthesize.synthesis.OptimizedSynthesis.setup"><code class="xref py py-obj docutils literal notranslate"><span class="pre">setup</span></code></a>()</p></td>
<td><p>Initialize relevant attributes.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">synthesize</span></code>()</p></td>
<td><p>Synthesize something.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">to</span></code>(*args[, attrs])</p></td>
<td><p>Move and/or cast the parameters and buffers.</p></td>
</tr>
</tbody>
</table>
<dl class="py property">
<dt class="sig sig-object py" id="plenoptic.synthesize.synthesis.OptimizedSynthesis.allowed_range">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">allowed_range</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#plenoptic.synthesize.synthesis.OptimizedSynthesis.allowed_range" title="Link to this definition"></a></dt>
<dd><p>Allowable range of pixel values.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="plenoptic.synthesize.synthesis.OptimizedSynthesis.gradient_norm">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">gradient_norm</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><span class="pre">Tensor</span></a></em><a class="headerlink" href="#plenoptic.synthesize.synthesis.OptimizedSynthesis.gradient_norm" title="Link to this definition"></a></dt>
<dd><p>Optimization gradient’s L2 norm over iterations.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="plenoptic.synthesize.synthesis.OptimizedSynthesis.losses">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">losses</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><span class="pre">Tensor</span></a></em><a class="headerlink" href="#plenoptic.synthesize.synthesis.OptimizedSynthesis.losses" title="Link to this definition"></a></dt>
<dd><p>Optimization loss over iterations.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="plenoptic.synthesize.synthesis.OptimizedSynthesis.objective_function">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">objective_function</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/synthesis.html#OptimizedSynthesis.objective_function"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.synthesis.OptimizedSynthesis.objective_function" title="Link to this definition"></a></dt>
<dd><p>How good is the current synthesized object.</p>
<p>See <code class="docutils literal notranslate"><span class="pre">plenoptic.tools.optim</span></code> for some examples.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="plenoptic.synthesize.synthesis.OptimizedSynthesis.optimizer">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">optimizer</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(in PyTorch v2.10)"><span class="pre">Optimizer</span></a></em><a class="headerlink" href="#plenoptic.synthesize.synthesis.OptimizedSynthesis.optimizer" title="Link to this definition"></a></dt>
<dd><p>Torch optimizer object which updates the synthesis target.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="plenoptic.synthesize.synthesis.OptimizedSynthesis.pixel_change_norm">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">pixel_change_norm</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><span class="pre">Tensor</span></a></em><a class="headerlink" href="#plenoptic.synthesize.synthesis.OptimizedSynthesis.pixel_change_norm" title="Link to this definition"></a></dt>
<dd><p>L2 norm change in pixel values over iterations.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="plenoptic.synthesize.synthesis.OptimizedSynthesis.range_penalty_lambda">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">range_penalty_lambda</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><a class="headerlink" href="#plenoptic.synthesize.synthesis.OptimizedSynthesis.range_penalty_lambda" title="Link to this definition"></a></dt>
<dd><p>Magnitude of the penalty on pixel values outside <a class="reference internal" href="#plenoptic.synthesize.synthesis.OptimizedSynthesis.allowed_range" title="plenoptic.synthesize.synthesis.OptimizedSynthesis.allowed_range"><code class="xref py py-attr docutils literal notranslate"><span class="pre">allowed_range</span></code></a>.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="plenoptic.synthesize.synthesis.OptimizedSynthesis.scheduler">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">scheduler</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.LRScheduler.html#torch.optim.lr_scheduler.LRScheduler" title="(in PyTorch v2.10)"><span class="pre">LRScheduler</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#plenoptic.synthesize.synthesis.OptimizedSynthesis.scheduler" title="Link to this definition"></a></dt>
<dd><p>Learning rate scheduler which adjusts optimizer learning rate.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="plenoptic.synthesize.synthesis.OptimizedSynthesis.setup">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">setup</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/synthesis.html#OptimizedSynthesis.setup"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.synthesis.OptimizedSynthesis.setup" title="Link to this definition"></a></dt>
<dd><p>Initialize relevant attributes.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="plenoptic.synthesize.synthesis.OptimizedSynthesis.store_progress">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">store_progress</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#plenoptic.synthesize.synthesis.OptimizedSynthesis.store_progress" title="Link to this definition"></a></dt>
<dd><p>How often we are caching progress.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">False</span></code>, we don’t save anything. If <code class="docutils literal notranslate"><span class="pre">True</span></code>, we save every iteration. If
an int, we save every <code class="docutils literal notranslate"><span class="pre">store_progress</span></code> iterations (note then that 0 is the
same as <code class="docutils literal notranslate"><span class="pre">False</span></code> and 1 the same as <code class="docutils literal notranslate"><span class="pre">True</span></code>).</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="plenoptic.synthesize.synthesis.Synthesis">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">Synthesis</span></span><a class="reference internal" href="../_modules/plenoptic/synthesize/synthesis.html#Synthesis"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.synthesis.Synthesis" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">ABC</span></code></p>
<p>Abstract super-class for synthesis objects.</p>
<p>All synthesis objects share a variety of similarities and thus need
to have similar methods. Some of these can be implemented here and
simply inherited, some of them will need to be different for each
sub-class and thus are marked as abstract methods here.</p>
<p class="rubric">Methods</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#plenoptic.synthesize.synthesis.Synthesis.load" title="plenoptic.synthesize.synthesis.Synthesis.load"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load</span></code></a>(file_path, empty_on_init_attr[, ...])</p></td>
<td><p>Load all relevant attributes from a .pt file.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#plenoptic.synthesize.synthesis.Synthesis.save" title="plenoptic.synthesize.synthesis.Synthesis.save"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save</span></code></a>(file_path[, save_io_attrs, ...])</p></td>
<td><p>Save all attributes in .pt file.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#plenoptic.synthesize.synthesis.Synthesis.synthesize" title="plenoptic.synthesize.synthesis.Synthesis.synthesize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">synthesize</span></code></a>()</p></td>
<td><p>Synthesize something.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#id21" title="plenoptic.synthesize.synthesis.Synthesis.to"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to</span></code></a>(*args[, attrs])</p></td>
<td><p>Move and/or cast the parameters and buffers.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="plenoptic.synthesize.synthesis.Synthesis.load">
<span class="sig-name descname"><span class="pre">load</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">empty_on_init_attr</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">map_location</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">check_attributes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">check_io_attributes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">state_dict_attributes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensor_equality_atol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-08</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensor_equality_rtol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">pickle_load_args</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/synthesis.html#Synthesis.load"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.synthesis.Synthesis.load" title="Link to this definition"></a></dt>
<dd><p>Load all relevant attributes from a .pt file.</p>
<p>This should be called by <code class="docutils literal notranslate"><span class="pre">Synthesis</span></code> object that has just been initialized.</p>
<p>Note this operates in place and so doesn’t return anything.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>file_path</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></span>) – The path to load the synthesis object from.</p></li>
<li><p><strong>empty_on_init_attr</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></span>) – The name of an attribute that will either be None or have length 0 if the
Synthesis object has just been initialized.</p></li>
<li><p><strong>map_location</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code> | <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span>) – Argument to pass to <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.load.html#torch.load" title="(in PyTorch v2.10)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.load()</span></code></a> as <code class="docutils literal notranslate"><span class="pre">map_location</span></code>. If you save
stuff that was being run on a GPU and are loading onto a
CPU, you’ll need this to make sure everything lines up
properly. This should be structured like the str you would
pass to <a class="reference external" href="https://docs.pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.device</span></code></a>.</p></li>
<li><p><strong>check_attributes</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]</span>) – List of strings we ensure are identical in the current <code class="docutils literal notranslate"><span class="pre">Synthesis</span></code> object
and the loaded one.</p></li>
<li><p><strong>check_io_attributes</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]</span>) – Names of attributes whose input/output behavior we should check (i.e., if we
call them on identical inputs, do we get identical outputs). In the loaded
dictionary, these are a tuple of three values: the name of the callable, the
name of the attribute to use as input, and the output we expect.</p></li>
<li><p><strong>state_dict_attributes</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]</span>) – Names of attributes that were callables, saved as a tuple with the name of
the callable and their state_dict. We will ensure the name of the attributes
are identical and then load the state_dict. If the attribute is None on the
initialized Synthesis object, then we set the tuple, and count on the
Synthesis object to properly handle it when needed.</p></li>
<li><p><strong>tensor_equality_atol</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></span>) – Absolute tolerance to use when checking for tensor equality during load,
passed to <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.allclose.html#torch.allclose" title="(in PyTorch v2.10)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.allclose()</span></code></a>. It may be necessary to increase if you are
saving and loading on two machines with torch built by different cuda
versions. Be careful when changing this! See
<a class="reference external" href="https://docs.pytorch.org/docs/stable/type_info.html#torch.torch.finfo" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.finfo</span></code></a> for more details about floating
point precision of different data types (especially, <code class="docutils literal notranslate"><span class="pre">eps</span></code>); if you have
to increase this by more than 1 or 2 decades, then you are probably not
dealing with a numerical issue.</p></li>
<li><p><strong>tensor_equality_rtol</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></span>) – Relative tolerance to use when checking for tensor equality during load,
passed to <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.allclose.html#torch.allclose" title="(in PyTorch v2.10)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.allclose()</span></code></a>. It may be necessary to increase if you are
saving and loading on two machines with torch built by different cuda
versions. Be careful when changing this! See
<a class="reference external" href="https://docs.pytorch.org/docs/stable/type_info.html#torch.torch.finfo" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.finfo</span></code></a> for more details about floating
point precision of different data types (especially, <code class="docutils literal notranslate"><span class="pre">eps</span></code>); if you have
to increase this by more than 1 or 2 decades, then you are probably not
dealing with a numerical issue.</p></li>
<li><p><strong>**pickle_load_args</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></span>) – Any additional kwargs will be added to <code class="docutils literal notranslate"><span class="pre">pickle_module.load</span></code> via
<a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.load.html#torch.load" title="(in PyTorch v2.10)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.load()</span></code></a>, see that function’s docstring for details.</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>ValueError</strong> – If the loading object has not just been initialized.</p></li>
<li><p><strong>ValueError</strong> – If the object saved at <code class="docutils literal notranslate"><span class="pre">file_path</span></code> is not the same type as the loading
object.</p></li>
<li><p><strong>ValueError</strong> – If either the saved or loading object has attributes not found in the
other.</p></li>
<li><p><strong>ValueError</strong> – If the saved and loading objects have a different value for one of the
<code class="docutils literal notranslate"><span class="pre">check_attributes</span></code>.</p></li>
<li><p><strong>ValueError</strong> – If the behavior of one of the <code class="docutils literal notranslate"><span class="pre">check_io_attributes</span></code> is different between
the saved and loading objects.</p></li>
</ul>
</dd>
<dt class="field-odd">Warns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>UserWarning</strong> – If <code class="xref py py-func docutils literal notranslate"><span class="pre">setup()</span></code> will need to be called after load, to finish initializing
one of the <code class="docutils literal notranslate"><span class="pre">state_dict_attributes</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="plenoptic.synthesize.synthesis.Synthesis.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_io_attrs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_state_dict_attrs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/synthesis.html#Synthesis.save"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.synthesis.Synthesis.save" title="Link to this definition"></a></dt>
<dd><p>Save all attributes in .pt file.</p>
<p>Note that there are two special categories of attributes, as described below.
All other attributes will be pickled directly and so should be either tensors or
primitives (e.g., not a function or callable torch object). We do not check this
explicitly, but load will fail if that’s not the case.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>file_path</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></span>) – The path to save the synthesis object to.</p></li>
<li><p><strong>save_io_attrs</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]]</span>) – List with tuples of form (str, (str, …)). The first element is the name of
the attribute to we save, and the second element is a tuple of attributes of
the Synthesis object, which we can pass as inputs to the attribute. We save
them as tuples of (name, input_names, outputs). On load, we check that the
initialized object’s name hasn’t changed, and that when called on the same
inputs, we get the same outputs. Intended for models, metrics, loss
functions. Used to avoid saving callables, which is brittle and unsafe.</p></li>
<li><p><strong>save_state_dict_attrs</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]</span>) – Names of attributes that we save as tuples of (name, state_dict).
Corresponding attribute can be None, in which case we save an empty
dictionary as state_dict. On load, we check that the initialized object’s
name hasn’t changed, and load the state_dict. Intended for optimizers,
schedulers. Used to avoid saving callables, which is brittle and unsafe.</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ValueError</strong> – If any of the strings specified in <code class="docutils literal notranslate"><span class="pre">save_io_attrs</span></code> as inputs for the
callable attribute-to-save are not attributes of <code class="docutils literal notranslate"><span class="pre">self</span></code>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="plenoptic.synthesize.synthesis.Synthesis.synthesize">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">synthesize</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/synthesis.html#Synthesis.synthesize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.synthesis.Synthesis.synthesize" title="Link to this definition"></a></dt>
<dd><p>Synthesize something.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="plenoptic.synthesize.synthesis.Synthesis.to">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attrs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/synthesis.html#Synthesis.to"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.synthesize.synthesis.Synthesis.to" title="Link to this definition"></a></dt>
<dd><p>Move and/or cast the parameters and buffers.</p>
<p>Similar to <a class="reference internal" href="#plenoptic.synthesize.synthesis.Synthesis.save" title="plenoptic.synthesize.synthesis.Synthesis.save"><code class="xref py py-func docutils literal notranslate"><span class="pre">save()</span></code></a>, this is an abstract method only because you
need to define the attributes to call to on.</p>
<p>This can be called as</p>
<dl class="py function">
<dt class="sig sig-object py" id="id19">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">non_blocking</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/synthesis.html#Synthesis.to"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id19" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="id20">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dtype</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">non_blocking</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/synthesis.html#Synthesis.to"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id20" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="id21">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">non_blocking</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/synthesize/synthesis.html#Synthesis.to"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id21" title="Link to this definition"></a></dt>
<dd></dd></dl>

<p>Its signature is similar to <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.Tensor.to.html#torch.Tensor.to" title="(in PyTorch v2.10)"><code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.Tensor.to()</span></code></a>, but only accepts
floating point desired <code class="xref py py-attr docutils literal notranslate"><span class="pre">dtype</span></code> s. In addition, this method will
only cast the floating point parameters and buffers to <code class="xref py py-attr docutils literal notranslate"><span class="pre">dtype</span></code>
(if given). The integral parameters and buffers will be moved
<code class="xref py py-attr docutils literal notranslate"><span class="pre">device</span></code>, if that is given, but with dtypes unchanged. When
<code class="xref py py-attr docutils literal notranslate"><span class="pre">non_blocking</span></code> is set, it tries to convert/move asynchronously
with respect to the host if possible, e.g., moving CPU Tensors with
pinned memory to CUDA devices.</p>
<p>When calling this method to move tensors to a CUDA device, items in <code class="docutils literal notranslate"><span class="pre">attrs</span></code>
that start with <code class="docutils literal notranslate"><span class="pre">&quot;saved_&quot;</span></code> will not be moved.</p>
<p>See <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.to" title="(in PyTorch v2.10)"><code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.to()</span></code></a> for examples.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>device</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="(in PyTorch v2.10)"><em>torch.device</em></a>) – The desired device of the parameters and buffers in this module.</p></li>
<li><p><strong>dtype</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensor_attributes.html#torch.dtype" title="(in PyTorch v2.10)"><em>torch.dtype</em></a>) – The desired floating point type of the floating point parameters and
buffers in this module.</p></li>
<li><p><strong>tensor</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><em>torch.Tensor</em></a>) – Tensor whose dtype and device are the desired dtype and device for
all parameters and buffers in this module.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-plenoptic.synthesize">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-plenoptic.synthesize" title="Link to this heading"></a></h2>
<p>Synthesis methods.</p>
<p>Classes to perform stimulus synthesis.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="plenoptic.simulate.models.html" class="btn btn-neutral float-left" title="plenoptic.simulate.models package" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="plenoptic.tools.html" class="btn btn-neutral float-right" title="plenoptic.tools package" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2019, Plenoptic authors.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>