

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Portilla-Simoncelli Texture Metamer &mdash; plenoptic 1.1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=fa44fd50" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../_static/plot_directive.css" />
      <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../../_static/tabs.css?v=4c969af8" />
      <link rel="stylesheet" type="text/css" href="../../_static/nbsphinx-code-cells.css?v=2aa19091" />

  
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=fc837d61"></script>
      <script src="../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="../../_static/copybutton.js?v=f281be69"></script>
      <script src="../../_static/tabs.js?v=3ee01567"></script>
      <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
      <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
      <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Reproducing Wang and Simoncelli, 2008 (MAD Competition)" href="../applications/09_Original_MAD.html" />
    <link rel="prev" title="Perceptual distance" href="04_Perceptual_distance.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            plenoptic
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Basic concepts</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../install.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../conceptual_intro.html">Conceptual Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../models.html">Model requirements</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_quickstart.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../citation.html">Citation Guide</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Synthesis method introductions</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intro/02_Eigendistortions.html">Eigendistortions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/06_Metamer.html">Metamers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/07_Simple_MAD.html">MAD Competition Conceptual Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/08_MAD_Competition.html">MAD Competition Usage</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Models and metrics</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="03_Steerable_Pyramid.html">Steerable Pyramid</a></li>
<li class="toctree-l1"><a class="reference internal" href="04_Perceptual_distance.html">Perceptual distance</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Portilla-Simoncelli Texture Metamer</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Synthesis method examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../applications/09_Original_MAD.html">Reproducing Wang and Simoncelli, 2008 (MAD Competition)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../applications/Demo_Eigendistortion.html">Reproducing Berardino et al., 2017 (Eigendistortions)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced usage</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../synthesis.html">Synthesis object design</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tips.html">Tips and Tricks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reproducibility.html">Reproducibility</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/modules.html">API Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/Display.html">Display and animate functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/Synthesis_extensions.html">Extending existing synthesis objects</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">plenoptic</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Portilla-Simoncelli Texture Metamer</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/tutorials/models/Metamer-Portilla-Simoncelli.nblink.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">plenoptic</span> <span class="k">as</span> <span class="nn">po</span>
<span class="kn">import</span> <span class="nn">scipy.io</span> <span class="k">as</span> <span class="nn">sio</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">os.path</span> <span class="k">as</span> <span class="nn">op</span>
<span class="kn">import</span> <span class="nn">einops</span>
<span class="kn">import</span> <span class="nn">glob</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">pyrtools</span> <span class="k">as</span> <span class="nn">pt</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="o">%</span><span class="k">load_ext</span> autoreload
<span class="o">%</span><span class="k">autoreload</span>

<span class="c1"># We need to download some additional images for this notebook. In order to do so,</span>
<span class="c1"># we use an optional dependency, pooch. If the following raises an ImportError or ModuleNotFoundError</span>
<span class="c1"># then install pooch in your plenoptic environment and restart your kernel.</span>
<span class="n">DATA_PATH</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">fetch_data</span><span class="p">(</span><span class="s1">&#39;portilla_simoncelli_images.tar.gz&#39;</span><span class="p">)</span>
<span class="n">DEVICE</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>

<span class="c1"># so that relative sizes of axes created by po.imshow and others look right</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.dpi&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">72</span>

<span class="c1"># set seed for reproducibility</span>
<span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/mnt/home/wbroderick/miniconda3/envs/plenoptic/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html
  from .autonotebook import tqdm as notebook_tqdm
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># These variables control how long metamer synthesis runs for. The values present here will result in completed synthesis,</span>
<span class="c1"># but you may want to decrease these numbers if you&#39;re on a machine with limited resources.</span>
<span class="n">short_synth_max_iter</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">long_synth_max_iter</span> <span class="o">=</span> <span class="mi">3000</span>
<span class="n">longest_synth_max_iter</span> <span class="o">=</span> <span class="mi">4000</span>
</pre></div>
</div>
</div>
<section id="Portilla-Simoncelli-Texture-Metamer">
<h1>Portilla-Simoncelli Texture Metamer<a class="headerlink" href="#Portilla-Simoncelli-Texture-Metamer" title="Link to this heading"></a></h1>
<p>In this tutorial we will aim to replicate <a class="reference external" href="https://www.cns.nyu.edu/pub/eero/portilla99-reprint.pdf">Portilla &amp; Simoncelli (1999)</a>. The tutorial is broken into the following parts:</p>
<ol class="arabic simple">
<li><p>Introduce the concept of a Visual Texture.</p></li>
<li><p>How to synthesize metamers for the Portilla &amp; Simoncelli texture model.</p></li>
<li><p>Demonstrate the importance of different classes of statistics.</p></li>
<li><p>Example syntheses from different classes of textures (e.g., artificial, Julesz, pseudoperiodic, etc.)</p></li>
<li><p>Extrapolation and Mixtures: Applying texture synthesis to more complex texture problems.</p></li>
<li><p>Some model limitations.</p></li>
<li><p>List of notable differences between the MATLAB and python implementations of the Portilla Simoncelli texture model and texture synthesis.</p></li>
</ol>
<p>Note that this notebook takes a long time to run (roughly an hour with a GPU, several hours without), because of all the metamers that are synthesized.</p>
<section id="1.-What-is-a-visual-texture?">
<h2>1. What is a visual texture?<a class="headerlink" href="#1.-What-is-a-visual-texture?" title="Link to this heading"></a></h2>
<p>The simplest definition is a repeating visual pattern. Textures encompass a wide variety of images, including natural patterns such as bark or fur, artificial ones such as brick, and computer-generated ones such as the Julesz patterns (<a class="reference external" href="https://link.springer.com/article/10.1007/BF00336998">Julesz 1978</a>, <a class="reference external" href="https://opg.optica.org/josaa/abstract.cfm?uri=josaa-10-5-777">Yellot 1993</a>). Below we load some examples.</p>
<p>The Portilla-Simoncelli model was developed to measure the statistical properties of visual textures. Metamer synthesis was used (and can be used) in conjunction with the Portilla-Simoncelli texture model to demonstrate the necessity of different properties of the visual texture. We will use some of these example textures to demonstrate aspects of the Portilla Simoncelli model.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load and display a set of visual textures</span>

<span class="k">def</span> <span class="nf">display_images</span><span class="p">(</span><span class="n">im_files</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">images</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">load_images</span><span class="p">(</span><span class="n">im_files</span><span class="p">)</span>
    <span class="n">fig</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">col_wrap</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">title</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="n">title</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.05</span><span class="p">)</span>

<span class="n">natural</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;3a&#39;</span><span class="p">,</span><span class="s1">&#39;6a&#39;</span><span class="p">,</span><span class="s1">&#39;8a&#39;</span><span class="p">,</span><span class="s1">&#39;14b&#39;</span><span class="p">,</span><span class="s1">&#39;15c&#39;</span><span class="p">,</span><span class="s1">&#39;15d&#39;</span><span class="p">,</span><span class="s1">&#39;15e&#39;</span><span class="p">,</span><span class="s1">&#39;15f&#39;</span><span class="p">,</span><span class="s1">&#39;16c&#39;</span><span class="p">,</span><span class="s1">&#39;16b&#39;</span><span class="p">,</span><span class="s1">&#39;16a&#39;</span><span class="p">]</span>
<span class="n">artificial</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;4a&#39;</span><span class="p">,</span><span class="s1">&#39;4b&#39;</span><span class="p">,</span><span class="s1">&#39;14a&#39;</span><span class="p">,</span><span class="s1">&#39;16e&#39;</span><span class="p">,</span><span class="s1">&#39;14e&#39;</span><span class="p">,</span><span class="s1">&#39;14c&#39;</span><span class="p">,</span><span class="s1">&#39;5a&#39;</span><span class="p">]</span>
<span class="n">hand_drawn</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;5b&#39;</span><span class="p">,</span><span class="s1">&#39;13a&#39;</span><span class="p">,</span><span class="s1">&#39;13b&#39;</span><span class="p">,</span><span class="s1">&#39;13c&#39;</span><span class="p">,</span><span class="s1">&#39;13d&#39;</span><span class="p">]</span>

<span class="n">im_files</span> <span class="o">=</span> <span class="p">[</span><span class="n">DATA_PATH</span> <span class="o">/</span> <span class="sa">f</span><span class="s1">&#39;fig</span><span class="si">{</span><span class="n">num</span><span class="si">}</span><span class="s1">.jpg&#39;</span> <span class="k">for</span> <span class="n">num</span> <span class="ow">in</span> <span class="n">natural</span><span class="p">]</span>
<span class="n">display_images</span><span class="p">(</span><span class="n">im_files</span><span class="p">,</span> <span class="s2">&quot;Natural textures&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_models_Metamer-Portilla-Simoncelli_4_0.png" src="../../_images/tutorials_models_Metamer-Portilla-Simoncelli_4_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">im_files</span> <span class="o">=</span> <span class="p">[</span><span class="n">DATA_PATH</span> <span class="o">/</span> <span class="sa">f</span><span class="s1">&#39;fig</span><span class="si">{</span><span class="n">num</span><span class="si">}</span><span class="s1">.jpg&#39;</span> <span class="k">for</span> <span class="n">num</span> <span class="ow">in</span> <span class="n">artificial</span><span class="p">]</span>
<span class="n">display_images</span><span class="p">(</span><span class="n">im_files</span><span class="p">,</span> <span class="s1">&#39;Articial textures&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_models_Metamer-Portilla-Simoncelli_5_0.png" src="../../_images/tutorials_models_Metamer-Portilla-Simoncelli_5_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">im_files</span> <span class="o">=</span> <span class="p">[</span><span class="n">DATA_PATH</span> <span class="o">/</span> <span class="sa">f</span><span class="s1">&#39;fig</span><span class="si">{</span><span class="n">num</span><span class="si">}</span><span class="s1">.jpg&#39;</span> <span class="k">for</span> <span class="n">num</span> <span class="ow">in</span> <span class="n">hand_drawn</span><span class="p">]</span>
<span class="n">display_images</span><span class="p">(</span><span class="n">im_files</span><span class="p">,</span> <span class="s1">&#39;Hand-drawn / computer-generated textures&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_models_Metamer-Portilla-Simoncelli_6_0.png" src="../../_images/tutorials_models_Metamer-Portilla-Simoncelli_6_0.png" />
</div>
</div>
</section>
<section id="2.-How-to-generate-Portilla-Simoncelli-Metamers">
<h2>2. How to generate Portilla-Simoncelli Metamers<a class="headerlink" href="#2.-How-to-generate-Portilla-Simoncelli-Metamers" title="Link to this heading"></a></h2>
<section id="2.1-A-quick-reminder-of-what-metamers-are-and-why-we-are-calculating-them.">
<h3>2.1 A quick reminder of what metamers are and why we are calculating them.<a class="headerlink" href="#2.1-A-quick-reminder-of-what-metamers-are-and-why-we-are-calculating-them." title="Link to this heading"></a></h3>
<p>The primary reason that the original Portilla-Simoncelli paper developed the metamer procedure was to assess whether the model’s understanding of textures matches that of humans. While developing the model, the authors originally evaluated it by performing texture classification on a then-standard dataset (i.e., “is this a piece of fur or a patch of grass?”). The model aced the test, with 100% accuracy. After an initial moment of elation, the authors decided to double-check and performed the
same evaluation with a far simpler model, which used the steerable pyramid to compute oriented energy (the first stage of the model described here). That model also classified the textures with 100% accuracy. The authors interpreted this as their evaluation being too easy, and sought a method that would allow them to determine whether their model better matched human texture perception.</p>
<p>In the metamer paradigm they eventually arrived at, the authors generated model metamers: images with different pixel values but (near-)identical texture model outputs. They then evaluated whether these images belonged to the same texture class: does this model metamer of a basket also look like a basket, or does it look like something else? Importantly, they were not evaluating whether the images were <em>indistinguishable</em>, but whether they belonged to the same texture family. This paradigm thus
tests whether the model is capturing important information about how humans understand and group textures.</p>
</section>
<section id="2.2-How-do-we-use-the-plenoptic-package-to-generate-Portilla-Simoncelli-Texture-Metamers?">
<h3>2.2 How do we use the plenoptic package to generate Portilla-Simoncelli Texture Metamers?<a class="headerlink" href="#2.2-How-do-we-use-the-plenoptic-package-to-generate-Portilla-Simoncelli-Texture-Metamers?" title="Link to this heading"></a></h3>
<p>Generating a metamer starts with a target image:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">img</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">load_images</span><span class="p">(</span><span class="n">DATA_PATH</span> <span class="o">/</span> <span class="s1">&#39;fig4a.jpg&#39;</span><span class="p">)</span>
<span class="n">po</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_models_Metamer-Portilla-Simoncelli_8_0.png" src="../../_images/tutorials_models_Metamer-Portilla-Simoncelli_8_0.png" />
</div>
</div>
<p>Below we have an instance of the PortillaSimoncelli model with default parameters:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">n_scales=4</span></code>, The number of scales in the steerable pyramid underlying the model.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">n_orientations=4</span></code>, The number of orientations in the steerable pyramid.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">spatial_corr_width=9</span></code>, The size of the window used to calculate the correlations across steerable pyramid bands.</p></li>
</ul>
<p>Running the model on an image will return a tensor of numbers summarizing the “texturiness” of that image, which we refer to as the model’s representation. These statistics are measurements of different properties that the authors considered relevant to a texture’s appearance (where a texture is defined above), and capture some of the repeating properties of these types of images. Section 3 of this notebook explores those statistics and how they relate to texture properties.</p>
<p>When the model representation of two images match, the model considers the two images identical and we say that those two images are model metamers. Synthesizing a novel image that matches the representation of some arbitrary input is the goal of the <code class="docutils literal notranslate"><span class="pre">Metamer</span></code> class.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n</span><span class="o">=</span><span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">simul</span><span class="o">.</span><span class="n">PortillaSimoncelli</span><span class="p">([</span><span class="n">n</span><span class="p">,</span><span class="n">n</span><span class="p">])</span>
<span class="n">stats</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">stats</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
tensor([[[ 0.4350,  0.0407,  0.1622,  ..., -0.0078, -0.2282,  0.0023]]])
</pre></div></div>
</div>
<p>To use <code class="docutils literal notranslate"><span class="pre">Metamer</span></code>, simply initialize it with the target image and the model, then call <code class="docutils literal notranslate"><span class="pre">.synthesize()</span></code>. By setting <code class="docutils literal notranslate"><span class="pre">store_progress=True</span></code>, we update a variety of attributes (all of which start with <code class="docutils literal notranslate"><span class="pre">saved_</span></code>) on each iteration so we can later examine, for example, the synthesized image over time. Let’s quickly run it for just 10 iterations to see how it works.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">met</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">synth</span><span class="o">.</span><span class="n">Metamer</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
<span class="n">met</span><span class="o">.</span><span class="n">synthesize</span><span class="p">(</span><span class="n">store_progress</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/mnt/home/wbroderick/plenoptic/src/plenoptic/tools/validate.py:178: UserWarning: model is in training mode, you probably want to call eval() to switch to evaluation mode
  warnings.warn(
100%|██████████| 10/10 [00:00&lt;00:00, 13.96it/s, loss=4.5063e-02, learning_rate=0.01, gradient_norm=1.6559e-02, pixel_change_norm=1.2805e+00]
</pre></div></div>
</div>
<p>We can then call the <code class="docutils literal notranslate"><span class="pre">plot_synthesis_status</span></code> method to see how things are doing. The image on the left shows the metamer at this moment in synthesis, while the center plot shows the loss over time, with the red dot pointing out the current loss, and the rightmost plot shows the representation error. For the texture model, we plot the difference in representations split up across the different category of statistics (which we’ll describe in more detail later).</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># representation_error plot has three subplots, so we increase its relative width</span>
<span class="n">po</span><span class="o">.</span><span class="n">synth</span><span class="o">.</span><span class="n">metamer</span><span class="o">.</span><span class="n">plot_synthesis_status</span><span class="p">(</span><span class="n">met</span><span class="p">,</span> <span class="n">width_ratios</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;plot_representation_error&#39;</span><span class="p">:</span> <span class="mf">3.1</span><span class="p">});</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/mnt/home/wbroderick/plenoptic/src/plenoptic/tools/display.py:931: UserWarning: ax is not None, so we&#39;re ignoring figsize...
  warnings.warn(&#34;ax is not None, so we&#39;re ignoring figsize...&#34;)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_models_Metamer-Portilla-Simoncelli_14_1.png" src="../../_images/tutorials_models_Metamer-Portilla-Simoncelli_14_1.png" />
</div>
</div>
</section>
<section id="2.3-Portilla-Simoncelli-Texture-Model-Metamers">
<h3>2.3 Portilla-Simoncelli Texture Model Metamers<a class="headerlink" href="#2.3-Portilla-Simoncelli-Texture-Model-Metamers" title="Link to this heading"></a></h3>
<p>This section will show a successful texture synthesis for this wicker basket texture:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">po</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_models_Metamer-Portilla-Simoncelli_16_0.png" src="../../_images/tutorials_models_Metamer-Portilla-Simoncelli_16_0.png" />
</div>
</div>
<p>In the next block we will actually generate a metamer using the PortillaSimoncelli model, setting the following parameters for synthesis: <code class="docutils literal notranslate"><span class="pre">max_iter</span></code>, <code class="docutils literal notranslate"><span class="pre">store_progress</span></code>,<code class="docutils literal notranslate"><span class="pre">coarse_to_fine</span></code>, and <code class="docutils literal notranslate"><span class="pre">coarse_to_fine_kwargs</span></code>.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">max_iter=1000</span></code> puts an upper bound (of 1000) on the number of iterations that the optimization will run.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">store_progress=True</span></code> tells the metamer class to store the progress of the metamer synthesis process</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">coarse_to_fine='together'</span></code> activates the coarse_to_fine functionality. With this mode turned on the metamer synthesis optimizes the image for the statistics associated with the low spatial frequency bands first, adding subsequent bands after <code class="docutils literal notranslate"><span class="pre">ctf_iters_to_check</span></code> iterations.</p></li>
</ul>
<p>It takes about 50s to run 100 iterations on my laptop. And it takes hundreds of iterations to get convergence. So you’ll have to wait a few minutes to generate the texture metamer.</p>
<p>Note: we initialize synthesis with <code class="docutils literal notranslate"><span class="pre">im_init</span></code>, an initial uniform noise image with range <code class="docutils literal notranslate"><span class="pre">mean(target_signal)+[-.05,.05]</span></code>. Initial images with uniform random noise covering the full pixel domain <code class="docutils literal notranslate"><span class="pre">[0,1]</span></code> (which is the default choice for Metamer) don’t result in the very best metamers. With the full range initial image, the optimization seems to get stuck.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># send image and PS model to GPU, if available. then im_init and Metamer will also use GPU</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">simul</span><span class="o">.</span><span class="n">PortillaSimoncelli</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">im_init</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand_like</span><span class="p">(</span><span class="n">img</span><span class="p">)</span><span class="o">-</span><span class="mf">.5</span><span class="p">)</span> <span class="o">*</span> <span class="mf">.1</span> <span class="o">+</span> <span class="n">img</span><span class="o">.</span><span class="n">mean</span><span class="p">();</span>

<span class="n">met</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">synth</span><span class="o">.</span><span class="n">MetamerCTF</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss_function</span><span class="o">=</span><span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">l2_norm</span><span class="p">,</span> <span class="n">initial_image</span><span class="o">=</span><span class="n">im_init</span><span class="p">,</span>
                          <span class="n">coarse_to_fine</span><span class="o">=</span><span class="s1">&#39;together&#39;</span><span class="p">)</span>

<span class="n">o</span><span class="o">=</span><span class="n">met</span><span class="o">.</span><span class="n">synthesize</span><span class="p">(</span>
    <span class="n">max_iter</span><span class="o">=</span><span class="n">short_synth_max_iter</span><span class="p">,</span>
    <span class="n">store_progress</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="c1"># setting change_scale_criterion=None means that we change scales every ctf_iters_to_check,</span>
    <span class="c1"># see the metamer notebook for details.</span>
    <span class="n">change_scale_criterion</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">ctf_iters_to_check</span><span class="o">=</span><span class="mi">7</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/mnt/home/wbroderick/plenoptic/src/plenoptic/tools/validate.py:178: UserWarning: model is in training mode, you probably want to call eval() to switch to evaluation mode
  warnings.warn(
/mnt/home/wbroderick/plenoptic/src/plenoptic/tools/validate.py:211: UserWarning: Validating whether model can work with coarse-to-fine synthesis -- this can take a while!
  warnings.warn(&#34;Validating whether model can work with coarse-to-fine synthesis -- this can take a while!&#34;)
 57%|█████▋    | 573/1000 [00:21&lt;00:15, 27.65it/s, loss=1.0001e-01, learning_rate=0.01, gradient_norm=7.4166e-01, pixel_change_norm=1.6915e-01, current_scale=all, current_scale_loss=1.0001e-01]            /mnt/home/wbroderick/plenoptic/src/plenoptic/synthesize/metamer.py:661: UserWarning: Loss has converged, stopping synthesis
  warnings.warn(&#34;Loss has converged, stopping synthesis&#34;)
 57%|█████▊    | 575/1000 [00:21&lt;00:15, 26.63it/s, loss=1.0001e-01, learning_rate=0.01, gradient_norm=7.4166e-01, pixel_change_norm=1.6915e-01, current_scale=all, current_scale_loss=1.0001e-01]
</pre></div></div>
</div>
<p>Now we can visualize the output of the synthesis optimization. First we compare the <em>Target image</em> and the <em>Synthesized image</em> side-by-side. We can see that they appear perceptually similar — that is, for this texture image, matching the Portilla-Simoncelli texture stats gives you an image that the human visual system <em>also</em> considers similar.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">po</span><span class="o">.</span><span class="n">imshow</span><span class="p">([</span><span class="n">met</span><span class="o">.</span><span class="n">image</span><span class="p">,</span> <span class="n">met</span><span class="o">.</span><span class="n">metamer</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Target image&#39;</span><span class="p">,</span> <span class="s1">&#39;Synthesized metamer&#39;</span><span class="p">],</span> <span class="n">vrange</span><span class="o">=</span><span class="s1">&#39;auto1&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_models_Metamer-Portilla-Simoncelli_20_0.png" src="../../_images/tutorials_models_Metamer-Portilla-Simoncelli_20_0.png" />
</div>
</div>
<p>And to further visualize the result we can plot: the synthesized image, the synthesis loss over time, and the final model output error: <code class="docutils literal notranslate"><span class="pre">model(target</span> <span class="pre">image)</span> <span class="pre">-</span> <span class="pre">model(synthesized</span> <span class="pre">image)</span></code>.</p>
<p>We can see the synthesized texture on the leftmost plot. The overall synthesis error decreases over the synthesis iterations (subplot 2). The remaining plots show us the error broken out by the different texture statistics that we will go over in the next section.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">po</span><span class="o">.</span><span class="n">synth</span><span class="o">.</span><span class="n">metamer</span><span class="o">.</span><span class="n">plot_synthesis_status</span><span class="p">(</span><span class="n">met</span><span class="p">,</span> <span class="n">width_ratios</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;plot_representation_error&#39;</span><span class="p">:</span> <span class="mf">3.1</span><span class="p">});</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_models_Metamer-Portilla-Simoncelli_22_0.png" src="../../_images/tutorials_models_Metamer-Portilla-Simoncelli_22_0.png" />
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># For the remainder of the notebook we will use this helper function to</span>
<span class="c1"># run synthesis so that the cells are a bit less busy.</span>

<span class="c1"># Be sure to run this cell.</span>

<span class="k">def</span> <span class="nf">run_synthesis</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">im_init</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot; Performs synthesis with the full Portilla-Simoncelli model.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        img : Tensor</span>
<span class="sd">            A tensor containing an img.</span>
<span class="sd">        model :</span>
<span class="sd">            A model to constrain synthesis.</span>
<span class="sd">        im_init: Tensor</span>
<span class="sd">            A tensor to start image synthesis.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        met: Metamer</span>
<span class="sd">            Metamer from the full Portilla-Simoncelli Model</span>

<span class="sd">        &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">im_init</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">im_init</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand_like</span><span class="p">(</span><span class="n">img</span><span class="p">)</span> <span class="o">*</span> <span class="mf">.01</span> <span class="o">+</span> <span class="n">img</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">met</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">synth</span><span class="o">.</span><span class="n">MetamerCTF</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss_function</span><span class="o">=</span><span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">l2_norm</span><span class="p">,</span> <span class="n">initial_image</span><span class="o">=</span><span class="n">im_init</span><span class="p">,</span>
                              <span class="n">coarse_to_fine</span><span class="o">=</span><span class="s1">&#39;together&#39;</span><span class="p">)</span>
    <span class="n">met</span><span class="o">.</span><span class="n">synthesize</span><span class="p">(</span>
        <span class="n">max_iter</span><span class="o">=</span><span class="n">long_synth_max_iter</span><span class="p">,</span>
        <span class="n">store_progress</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">change_scale_criterion</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">ctf_iters_to_check</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="n">met</span>
</pre></div>
</div>
</div>
</section>
</section>
<section id="3.-The-importance-of-different-classes-Texture-Statistics">
<h2>3. The importance of different classes Texture Statistics<a class="headerlink" href="#3.-The-importance-of-different-classes-Texture-Statistics" title="Link to this heading"></a></h2>
<p>The Portilla-Simoncelli consists of a few different classes of statistics:</p>
<ul class="simple">
<li><p>Marginal Statistics. These include pixel statistics (mean, variance, skew, kurtosis, and range of the pixel values), as well as the skewness and kurtosis of the lowpass images computed at each level of the recursive pyramid decomposition.</p></li>
<li><p>Auto-Correlation Statistics. These include the auto-correlation of the real-valued pyramid bands, as well as the auto-correlation of the magnitude of the pyramid bands, and the mean of the magnitude of the pyramid bands.</p></li>
<li><p>Cross-Correlation Statistics. These include correlations across scale and across orientation bands of the pyramid (both for the real values of the pyramid and for the magnitude of the pyramid bands).</p></li>
</ul>
<p>The original paper uses synthesis to demonstrate the role of these different types of statistics. They show that the statistics can be used to constrain a synthesis optimization to generate new examples of textures. They also show that the absence of subsets of statistics results in synthesis failures. Here we replicate those results.</p>
<p>The first step is to create a version of the Portilla Simoncelli model where certain statistics can be turned off.</p>
<p>There are two important implementation details here, which you might be interested in if you’d like to write a similar extension of this model, and they both relate to coarse-to-fine synthesis. When removing statistics from the model, the most natural implementation would be to remove them from the model’s representation, changing the shape of the returned tensor. However, in order for coarse-to-fine synthesis to work, we need to know which scale each statistic aligns with, and changing the
shape destroys that mapping. Therefore, the proper way to remove statistics (in order to remain compatible with coarse-to-fine optimization) is to zero out those statistics instead: directly setting them to zero breaks the gradient so that they have no impact on the synthesis procedure. The second detail is that, during coarse-to-fine optimization, we must remove some set of statistics, which we do by calling the <code class="docutils literal notranslate"><span class="pre">remove_scales</span></code> method at the <em>end</em> of the function call. See the <code class="docutils literal notranslate"><span class="pre">forward</span></code>
call below for an example of this</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#  The following class extends the PortillaSimoncelli model so that you can specify which</span>
<span class="c1">#  statistics you would like to remove.  We have created this model so that we can examine</span>
<span class="c1">#  the consequences of the absence of specific statistics.</span>
<span class="c1">#</span>
<span class="c1">#  Be sure to run this cell.</span>

<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">OrderedDict</span>
<span class="k">class</span> <span class="nc">PortillaSimoncelliRemove</span><span class="p">(</span><span class="n">po</span><span class="o">.</span><span class="n">simul</span><span class="o">.</span><span class="n">PortillaSimoncelli</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Model for measuring a subset of texture statistics reported by PortillaSimoncelli</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    im_shape: int</span>
<span class="sd">        the size of the images being processed by the model</span>
<span class="sd">    remove_keys: list</span>
<span class="sd">        The dictionary keys for the statistics we will &quot;remove&quot;.  In practice we set them to zero.</span>
<span class="sd">        Possible keys: [&quot;pixel_statistics&quot;, &quot;auto_correlation_magnitude&quot;,</span>
<span class="sd">        &quot;skew_reconstructed&quot;, &quot;kurtosis_reconstructed&quot;, &quot;auto_correlation_reconstructed&quot;,</span>
<span class="sd">        &quot;std_reconstructed&quot;, &quot;magnitude_std&quot;, &quot;cross_orientation_correlation_magnitude&quot;,</span>
<span class="sd">        &quot;cross_scale_correlation_magnitude&quot; &quot;cross_scale_correlation_real&quot;, &quot;var_highpass_residual&quot;]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">im_shape</span><span class="p">,</span>
        <span class="n">remove_keys</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">im_shape</span><span class="p">,</span> <span class="n">n_scales</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">n_orientations</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">spatial_corr_width</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">remove_keys</span> <span class="o">=</span> <span class="n">remove_keys</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">scales</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Generate Texture Statistics representation of an image with `remove_keys` removed.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        image : torch.Tensor</span>
<span class="sd">            A tensor containing the image to analyze.</span>
<span class="sd">        scales : list, optional</span>
<span class="sd">            Which scales to include in the returned representation. If an empty</span>
<span class="sd">            list (the default), we include all scales. Otherwise, can contain</span>
<span class="sd">            subset of values present in this model&#39;s ``scales`` attribute.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        representation: torch.Tensor</span>
<span class="sd">            3d tensor of shape (batch, channel, stats) containing the measured texture stats.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># create the representation tensor (with all scales)</span>
        <span class="n">stats_vec</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
        <span class="c1"># convert to dict so it&#39;s easy to zero out the keys we don&#39;t care about</span>
        <span class="n">stats_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">convert_to_dict</span><span class="p">(</span><span class="n">stats_vec</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">kk</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">remove_keys</span><span class="p">:</span>
            <span class="c1"># we zero out the stats (instead of removing them) because removing them</span>
            <span class="c1"># makes it difficult to keep track of which stats belong to which scale</span>
            <span class="c1"># (which is necessary for coarse-to-fine synthesis) -- see discussion above.</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">stats_dict</span><span class="p">[</span><span class="n">kk</span><span class="p">],</span><span class="n">OrderedDict</span><span class="p">):</span>
                <span class="k">for</span> <span class="p">(</span><span class="n">key</span><span class="p">,</span><span class="n">val</span><span class="p">)</span> <span class="ow">in</span> <span class="n">stats_dict</span><span class="p">[</span><span class="n">kk</span><span class="p">]</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="n">stats_dict</span><span class="p">[</span><span class="n">kk</span><span class="p">][</span><span class="n">key</span><span class="p">]</span> <span class="o">*=</span> <span class="mi">0</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">stats_dict</span><span class="p">[</span><span class="n">kk</span><span class="p">]</span> <span class="o">*=</span> <span class="mi">0</span>
        <span class="c1"># then convert back to tensor and remove any scales we don&#39;t want (for coarse-to-fine)</span>
        <span class="c1"># -- see discussion above.</span>
        <span class="n">stats_vec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">stats_dict</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">scales</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">stats_vec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">remove_scales</span><span class="p">(</span><span class="n">stats_vec</span><span class="p">,</span> <span class="n">scales</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">stats_vec</span>
<br/></pre></div>
</div>
</div>
<section id="Pixel-Statistics-+-Marginal-statistics">
<h3>Pixel Statistics + Marginal statistics<a class="headerlink" href="#Pixel-Statistics-+-Marginal-statistics" title="Link to this heading"></a></h3>
<p>Beginning with some of the pixel and marginal statistics, we’ll demonstrate synthesis both with and without combinations of statistics.</p>
<p>The cell below replicates examples of synthesis failures with the following statistics removed:</p>
<ul class="simple">
<li><p>the pixel statistics: mean, variance, skew, kurtosis, minimum, maximum and</p></li>
<li><p>marginal statistics on the lowpass images computed at each level of the recursive pyramid (skew, kurtosis)</p></li>
</ul>
<p>These statistics play an important role constraining the histogram of pixel intensities to match across the original and synthesized image.</p>
<p>(see figure 3 of Portilla &amp; Simoncelli 2000)</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># which statistics to remove</span>
<span class="n">remove_statistics</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;pixel_statistics&#39;</span><span class="p">,</span><span class="s1">&#39;skew_reconstructed&#39;</span><span class="p">,</span><span class="s1">&#39;kurtosis_reconstructed&#39;</span><span class="p">]</span>

<span class="c1"># run on fig3a or fig3b to replicate paper</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">load_images</span><span class="p">(</span><span class="n">DATA_PATH</span> <span class="o">/</span> <span class="s1">&#39;fig3b.jpg&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>

<span class="c1"># synthesis with full PortillaSimoncelli model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">simul</span><span class="o">.</span><span class="n">PortillaSimoncelli</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">metamer</span> <span class="o">=</span> <span class="n">run_synthesis</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>

<span class="c1"># synthesis with pixel and marginal statistics absent</span>
<span class="n">model_remove</span> <span class="o">=</span> <span class="n">PortillaSimoncelliRemove</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:]</span> <span class="p">,</span><span class="n">remove_keys</span><span class="o">=</span><span class="n">remove_statistics</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">metamer_remove</span> <span class="o">=</span> <span class="n">run_synthesis</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">model_remove</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
 28%|██▊       | 850/3000 [00:31&lt;01:18, 27.41it/s, loss=9.0668e-02, learning_rate=0.01, gradient_norm=7.8342e-01, pixel_change_norm=1.6689e-01, current_scale=all, current_scale_loss=9.0668e-02]
 52%|█████▏    | 1573/3000 [01:01&lt;00:56, 25.43it/s, loss=6.3053e-02, learning_rate=0.01, gradient_norm=8.9502e-01, pixel_change_norm=1.4015e-01, current_scale=all, current_scale_loss=6.3053e-02]
</pre></div></div>
</div>
<p>In the following figure, we can see that not only does the metamer created with all statistics look more like the target image than the one creaated without the marginal statistics, but its pixel intensity histogram is much more similar to that of the target image.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># visualize results</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">imshow</span><span class="p">([</span><span class="n">metamer</span><span class="o">.</span><span class="n">image</span><span class="p">,</span> <span class="n">metamer</span><span class="o">.</span><span class="n">metamer</span><span class="p">,</span> <span class="n">metamer_remove</span><span class="o">.</span><span class="n">metamer</span><span class="p">],</span>
                <span class="n">title</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Target image&#39;</span><span class="p">,</span> <span class="s1">&#39;Full Statistics&#39;</span><span class="p">,</span> <span class="s1">&#39;Without Marginal Statistics&#39;</span><span class="p">],</span> <span class="n">vrange</span><span class="o">=</span><span class="s1">&#39;auto1&#39;</span><span class="p">);</span>
<span class="c1"># add plots showing the different pixel intensity histograms</span>
<span class="n">fig</span><span class="o">.</span><span class="n">add_axes</span><span class="p">([</span><span class="mf">.33</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mf">.33</span><span class="p">,</span> <span class="mf">.9</span><span class="p">])</span>
<span class="n">fig</span><span class="o">.</span><span class="n">add_axes</span><span class="p">([</span><span class="mf">.67</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mf">.33</span><span class="p">,</span> <span class="mf">.9</span><span class="p">])</span>
<span class="c1"># this helper function expects a metamer object. see the metamer notebook for details.</span>
<span class="n">po</span><span class="o">.</span><span class="n">synth</span><span class="o">.</span><span class="n">metamer</span><span class="o">.</span><span class="n">plot_pixel_values</span><span class="p">(</span><span class="n">metamer</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">fig</span><span class="o">.</span><span class="n">axes</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span>
<span class="n">fig</span><span class="o">.</span><span class="n">axes</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Full statistics&#39;</span><span class="p">)</span>
<span class="n">po</span><span class="o">.</span><span class="n">synth</span><span class="o">.</span><span class="n">metamer</span><span class="o">.</span><span class="n">plot_pixel_values</span><span class="p">(</span><span class="n">metamer_remove</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">fig</span><span class="o">.</span><span class="n">axes</span><span class="p">[</span><span class="mi">4</span><span class="p">])</span>
<span class="n">fig</span><span class="o">.</span><span class="n">axes</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Without marginal statistics&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Text(0.5, 1.0, &#39;Without marginal statistics&#39;)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_models_Metamer-Portilla-Simoncelli_29_1.png" src="../../_images/tutorials_models_Metamer-Portilla-Simoncelli_29_1.png" />
</div>
</div>
</section>
<section id="Coefficient-Correlations">
<h3>Coefficient Correlations<a class="headerlink" href="#Coefficient-Correlations" title="Link to this heading"></a></h3>
<p>The cell below replicates examples of synthesis failures with the following statistics removed:</p>
<ul class="simple">
<li><p>local auto-correlations of the lowpass images computed at each level of the recursive pyramid</p></li>
</ul>
<p>These statistics play a role in representing periodic structures and long-range correlations. For example, in the image named fig4b.jpg (the tile pattern) the absence of these statistics causes results in more difficulty synthesizing the long, continuous lines that stretch from one end of the image to the other.</p>
<p>(see figure 4 of Portilla &amp; Simoncelli 2000)</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># which statistics to remove. note that, in the original paper, std_reconstructed is implicitly contained within</span>
<span class="c1"># auto_correlation_reconstructed, view the section on differences between plenoptic and matlab implementation</span>
<span class="c1"># for details</span>
<span class="n">remove_statistics</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;auto_correlation_reconstructed&#39;</span><span class="p">,</span> <span class="s1">&#39;std_reconstructed&#39;</span><span class="p">]</span>

<span class="c1"># run on fig4a or fig4b to replicate paper</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">load_images</span><span class="p">(</span><span class="n">DATA_PATH</span> <span class="o">/</span> <span class="s1">&#39;fig4b.jpg&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>

<span class="c1"># synthesis with full PortillaSimoncelli model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">simul</span><span class="o">.</span><span class="n">PortillaSimoncelli</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">metamer</span> <span class="o">=</span> <span class="n">run_synthesis</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>

<span class="c1"># synthesis with coefficient correlations  absent</span>
<span class="n">model_remove</span> <span class="o">=</span> <span class="n">PortillaSimoncelliRemove</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:],</span> <span class="n">remove_keys</span><span class="o">=</span><span class="n">remove_statistics</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">metamer_remove</span> <span class="o">=</span> <span class="n">run_synthesis</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">model_remove</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
100%|██████████| 3000/3000 [01:51&lt;00:00, 26.87it/s, loss=1.0761e-01, learning_rate=0.01, gradient_norm=6.9022e-01, pixel_change_norm=1.5602e-01, current_scale=all, current_scale_loss=1.0761e-01]
100%|██████████| 3000/3000 [01:58&lt;00:00, 25.30it/s, loss=9.2051e-01, learning_rate=0.01, gradient_norm=9.3779e-03, pixel_change_norm=1.7486e-02, current_scale=all, current_scale_loss=9.2051e-01]
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># visualize results</span>
<span class="n">po</span><span class="o">.</span><span class="n">imshow</span><span class="p">([</span><span class="n">metamer</span><span class="o">.</span><span class="n">image</span><span class="p">,</span> <span class="n">metamer</span><span class="o">.</span><span class="n">metamer</span><span class="p">,</span> <span class="n">metamer_remove</span><span class="o">.</span><span class="n">metamer</span><span class="p">],</span>
          <span class="n">title</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Target image&#39;</span><span class="p">,</span> <span class="s1">&#39;Full Statistics&#39;</span><span class="p">,</span> <span class="s1">&#39;Without Correlation Statistics&#39;</span><span class="p">],</span> <span class="n">vrange</span><span class="o">=</span><span class="s1">&#39;auto1&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_models_Metamer-Portilla-Simoncelli_32_0.png" src="../../_images/tutorials_models_Metamer-Portilla-Simoncelli_32_0.png" />
</div>
</div>
<p>And we can double check the error plots to see the difference in their representations. The first figure shows the error for the metamer created without the correlation statistics (at right above), while the second shows the error for the metamer created with all statistics (center), and we can see that larger error in the first plot in the middle row in the first figure, especially the center plot, <code class="docutils literal notranslate"><span class="pre">auto_correlation_reconstructed</span></code>, since these statistics are unconstrained for the synthesis
done by <code class="docutils literal notranslate"><span class="pre">metamer_remove</span></code>. (Note we have to use <code class="docutils literal notranslate"><span class="pre">model</span></code>, not <code class="docutils literal notranslate"><span class="pre">model_remove</span></code> to create these plots, since <code class="docutils literal notranslate"><span class="pre">model_remove</span></code> always zeroes out those statistics.)</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">plot_representation</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">metamer_remove</span><span class="o">.</span><span class="n">metamer</span><span class="p">)</span> <span class="o">-</span> <span class="n">model</span><span class="p">(</span><span class="n">metamer</span><span class="o">.</span><span class="n">image</span><span class="p">),</span>
                                   <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">ylim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Without Correlation Statistics&#39;</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">plot_representation</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">metamer</span><span class="o">.</span><span class="n">metamer</span><span class="p">)</span> <span class="o">-</span> <span class="n">model</span><span class="p">(</span><span class="n">metamer</span><span class="o">.</span><span class="n">image</span><span class="p">),</span>
                                   <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">ylim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Full statistics&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_models_Metamer-Portilla-Simoncelli_34_0.png" src="../../_images/tutorials_models_Metamer-Portilla-Simoncelli_34_0.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_models_Metamer-Portilla-Simoncelli_34_1.png" src="../../_images/tutorials_models_Metamer-Portilla-Simoncelli_34_1.png" />
</div>
</div>
</section>
<section id="Magnitude-Correlation">
<h3>Magnitude Correlation<a class="headerlink" href="#Magnitude-Correlation" title="Link to this heading"></a></h3>
<p>The cell below replicates examples of synthesis failures with the following statistics removed:</p>
<ul class="simple">
<li><p>correlation of the complex magnitude of pairs of coefficients at adjacent positions, orientations and scales.</p></li>
</ul>
<p>These statistics play a role constraining high contrast locations to be organized along lines and edges across all scales. For example, in the image named fig6a.jpg the absence of these statistics results in a completely different organization of the orientation content in the edges.</p>
<p>(see figure 6 of Portilla &amp; Simoncelli 2000)</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># which statistics to remove. note that, in the original paper, magnitude_std is implicitly contained within</span>
<span class="c1"># auto_correlation_magnitude, view the section on differences between plenoptic and matlab implementation</span>
<span class="c1"># for details</span>
<span class="n">remove_statistics</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;magnitude_std&#39;</span><span class="p">,</span> <span class="s1">&#39;cross_orientation_correlation_magnitude&#39;</span><span class="p">,</span>
                     <span class="s1">&#39;cross_scale_correlation_magnitude&#39;</span><span class="p">,</span> <span class="s1">&#39;auto_correlation_magnitude&#39;</span><span class="p">]</span>

<span class="c1"># run on fig6a or fig6b to replicate paper</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">load_images</span><span class="p">(</span><span class="n">DATA_PATH</span> <span class="o">/</span> <span class="s1">&#39;fig6a.jpg&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>

<span class="c1"># synthesis with full PortillaSimoncelli model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">simul</span><span class="o">.</span><span class="n">PortillaSimoncelli</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">metamer</span> <span class="o">=</span> <span class="n">run_synthesis</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>

<span class="c1"># synthesis with pixel and marginal statistics absent</span>
<span class="n">model_remove</span> <span class="o">=</span> <span class="n">PortillaSimoncelliRemove</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:],</span><span class="n">remove_keys</span><span class="o">=</span><span class="n">remove_statistics</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">metamer_remove</span> <span class="o">=</span> <span class="n">run_synthesis</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">model_remove</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
 26%|██▌       | 783/3000 [00:28&lt;01:21, 27.35it/s, loss=7.4301e-02, learning_rate=0.01, gradient_norm=9.1828e-01, pixel_change_norm=1.5227e-01, current_scale=all, current_scale_loss=7.4301e-02]
 17%|█▋        | 517/3000 [00:20&lt;01:37, 25.39it/s, loss=6.7201e-02, learning_rate=0.01, gradient_norm=9.4763e-01, pixel_change_norm=1.4601e-01, current_scale=all, current_scale_loss=6.7201e-02]
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># visualize results</span>
<span class="n">po</span><span class="o">.</span><span class="n">imshow</span><span class="p">([</span><span class="n">metamer</span><span class="o">.</span><span class="n">image</span><span class="p">,</span> <span class="n">metamer</span><span class="o">.</span><span class="n">metamer</span><span class="p">,</span> <span class="n">metamer_remove</span><span class="o">.</span><span class="n">metamer</span><span class="p">],</span>
          <span class="n">title</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Target image&#39;</span><span class="p">,</span> <span class="s1">&#39;Full Statistics&#39;</span><span class="p">,</span><span class="s1">&#39;Without Magnitude Statistics&#39;</span><span class="p">],</span> <span class="n">vrange</span><span class="o">=</span><span class="s1">&#39;auto1&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_models_Metamer-Portilla-Simoncelli_37_0.png" src="../../_images/tutorials_models_Metamer-Portilla-Simoncelli_37_0.png" />
</div>
</div>
<p>And again, let’s look at the error plots. The first figure shows the error for the metamer created without the correlation statistics (at right above), while the second shows the error for the metamer created with all statistics (center), and we can see that larger error in the plot scorresponding to <code class="docutils literal notranslate"><span class="pre">auto_correlation_magnitude</span></code>, <code class="docutils literal notranslate"><span class="pre">cross_orientation_correlation_magnitude</span></code>, and <code class="docutils literal notranslate"><span class="pre">cross_scale_correlation_magnitude</span></code>., since these statistics are unconstrained for the synthesis done by
<code class="docutils literal notranslate"><span class="pre">metamer_remove</span></code>. (Note we have to use <code class="docutils literal notranslate"><span class="pre">model</span></code>, not <code class="docutils literal notranslate"><span class="pre">model_remove</span></code> to create these plots, since <code class="docutils literal notranslate"><span class="pre">model_remove</span></code> always zeroes out those statistics.)</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">plot_representation</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">metamer_remove</span><span class="o">.</span><span class="n">metamer</span><span class="p">)</span> <span class="o">-</span> <span class="n">model</span><span class="p">(</span><span class="n">metamer</span><span class="o">.</span><span class="n">image</span><span class="p">),</span>
                                   <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">ylim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Without Correlation Statistics&#39;</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">plot_representation</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">metamer</span><span class="o">.</span><span class="n">metamer</span><span class="p">)</span> <span class="o">-</span> <span class="n">model</span><span class="p">(</span><span class="n">metamer</span><span class="o">.</span><span class="n">image</span><span class="p">),</span>
                                   <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">ylim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Full statistics&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_models_Metamer-Portilla-Simoncelli_39_0.png" src="../../_images/tutorials_models_Metamer-Portilla-Simoncelli_39_0.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_models_Metamer-Portilla-Simoncelli_39_1.png" src="../../_images/tutorials_models_Metamer-Portilla-Simoncelli_39_1.png" />
</div>
</div>
</section>
<section id="Cross-scale-Phase-Statistics">
<h3>Cross-scale Phase Statistics<a class="headerlink" href="#Cross-scale-Phase-Statistics" title="Link to this heading"></a></h3>
<p>The cell below replicates examples of synthesis failures with the following statistics removed:</p>
<ul class="simple">
<li><p>relative phase of coefficients of bands at adjacent scales</p></li>
</ul>
<p>These statistics play a role constraining high contrast locations to be organized along lines and edges across all scales. These phase statistics are important in representing textures with strong illumination effects. When they are removed, the synthesized images appear much less three dimensional and lose the detailed structure of shadows.</p>
<p>(see figure 8 of Portilla &amp; Simoncelli 2000)</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># which statistics to remove</span>
<span class="n">remove_statistics</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;cross_scale_correlation_real&#39;</span><span class="p">]</span>

<span class="c1"># run on fig8a and fig8b to replicate paper</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">load_images</span><span class="p">(</span><span class="n">DATA_PATH</span> <span class="o">/</span> <span class="s1">&#39;fig8b.jpg&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>

<span class="c1"># synthesis with full PortillaSimoncelli model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">simul</span><span class="o">.</span><span class="n">PortillaSimoncelli</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">metamer</span> <span class="o">=</span> <span class="n">run_synthesis</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>

<span class="c1"># synthesis with pixel and marginal statistics absent</span>
<span class="n">model_remove</span> <span class="o">=</span> <span class="n">PortillaSimoncelliRemove</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:],</span> <span class="n">remove_keys</span><span class="o">=</span><span class="n">remove_statistics</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">metamer_remove</span> <span class="o">=</span> <span class="n">run_synthesis</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">model_remove</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
 19%|█▉        | 570/3000 [00:20&lt;01:29, 27.28it/s, loss=6.8483e-02, learning_rate=0.01, gradient_norm=8.8361e-01, pixel_change_norm=1.5385e-01, current_scale=all, current_scale_loss=6.8483e-02]
 16%|█▌        | 479/3000 [00:18&lt;01:38, 25.49it/s, loss=7.2986e-02, learning_rate=0.01, gradient_norm=8.7827e-01, pixel_change_norm=1.5543e-01, current_scale=all, current_scale_loss=7.2986e-02]
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># visualize results</span>
<span class="n">po</span><span class="o">.</span><span class="n">imshow</span><span class="p">([</span><span class="n">metamer</span><span class="o">.</span><span class="n">image</span><span class="p">,</span> <span class="n">metamer</span><span class="o">.</span><span class="n">metamer</span><span class="p">,</span> <span class="n">metamer_remove</span><span class="o">.</span><span class="n">metamer</span><span class="p">],</span>
          <span class="n">title</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Target image&#39;</span><span class="p">,</span> <span class="s1">&#39;Full Statistics&#39;</span><span class="p">,</span><span class="s1">&#39;Without Cross-Scale Phase Statistics&#39;</span><span class="p">],</span> <span class="n">vrange</span><span class="o">=</span><span class="s1">&#39;auto1&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_models_Metamer-Portilla-Simoncelli_42_0.png" src="../../_images/tutorials_models_Metamer-Portilla-Simoncelli_42_0.png" />
</div>
</div>
<p>And again, let’s look at the error plots. The first figure shows the error for the metamer created without the correlation statistics (at right above), while the second shows the error for the metamer created with all statistics (center), and we can see that larger error in the final plot in the first figure, <code class="docutils literal notranslate"><span class="pre">cross_scale_correlation_real</span></code>, since these statistics are unconstrained for the synthesis done by <code class="docutils literal notranslate"><span class="pre">metamer_remove</span></code>. (Note we have to use <code class="docutils literal notranslate"><span class="pre">model</span></code>, not <code class="docutils literal notranslate"><span class="pre">model_remove</span></code> to create these
plots, since <code class="docutils literal notranslate"><span class="pre">model_remove</span></code> always zeroes out those statistics.)</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">plot_representation</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">metamer_remove</span><span class="o">.</span><span class="n">metamer</span><span class="p">)</span> <span class="o">-</span> <span class="n">model</span><span class="p">(</span><span class="n">metamer</span><span class="o">.</span><span class="n">image</span><span class="p">),</span>
                                   <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">ylim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mf">1.2</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">))</span>
<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Without Correlation Statistics&#39;</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">plot_representation</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">metamer</span><span class="o">.</span><span class="n">metamer</span><span class="p">)</span> <span class="o">-</span> <span class="n">model</span><span class="p">(</span><span class="n">metamer</span><span class="o">.</span><span class="n">image</span><span class="p">),</span>
                                   <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">ylim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mf">1.2</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">))</span>
<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Full statistics&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_models_Metamer-Portilla-Simoncelli_44_0.png" src="../../_images/tutorials_models_Metamer-Portilla-Simoncelli_44_0.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_models_Metamer-Portilla-Simoncelli_44_1.png" src="../../_images/tutorials_models_Metamer-Portilla-Simoncelli_44_1.png" />
</div>
</div>
</section>
</section>
<section id="4.-Examples-from-different-texture-classes">
<h2>4. Examples from different texture classes<a class="headerlink" href="#4.-Examples-from-different-texture-classes" title="Link to this heading"></a></h2>
<section id="Hand-drawn-/-computer-generated-textures">
<h3>Hand-drawn / computer-generated textures<a class="headerlink" href="#Hand-drawn-/-computer-generated-textures" title="Link to this heading"></a></h3>
<p>(see figure 12 of Portilla Simoncelli 2000)</p>
<p>The following cell can be used to reproduce texture synthesis on the hand-drawn / computer-generated texture examples in the original paper, showing that the model can handle these simpler images as well.</p>
<p>Examples</p>
<ul class="simple">
<li><p>(12a) solid black squares</p></li>
<li><p>(12b) tilted gray columns</p></li>
<li><p>(12c) curvy lines</p></li>
<li><p>(12d) dashes</p></li>
<li><p>(12e) solid black circles</p></li>
<li><p>(12f) pluses</p></li>
</ul>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[27]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">img</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">load_images</span><span class="p">(</span><span class="n">DATA_PATH</span> <span class="o">/</span> <span class="s1">&#39;fig12a.jpg&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>

<span class="c1"># synthesis with full PortillaSimoncelli model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">simul</span><span class="o">.</span><span class="n">PortillaSimoncelli</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">metamer</span> <span class="o">=</span> <span class="n">run_synthesis</span><span class="p">(</span><span class="n">img</span><span class="p">,</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
100%|██████████| 3000/3000 [01:50&lt;00:00, 27.15it/s, loss=2.9222e+00, learning_rate=0.01, gradient_norm=3.4586e-01, pixel_change_norm=8.8696e-02, current_scale=all, current_scale_loss=2.9222e+00]
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[28]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">po</span><span class="o">.</span><span class="n">imshow</span><span class="p">([</span><span class="n">metamer</span><span class="o">.</span><span class="n">image</span><span class="p">,</span> <span class="n">metamer</span><span class="o">.</span><span class="n">metamer</span><span class="p">],</span>
          <span class="n">title</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Target image&#39;</span><span class="p">,</span> <span class="s1">&#39;Synthesized Metamer&#39;</span><span class="p">],</span> <span class="n">vrange</span><span class="o">=</span><span class="s1">&#39;auto1&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_models_Metamer-Portilla-Simoncelli_47_0.png" src="../../_images/tutorials_models_Metamer-Portilla-Simoncelli_47_0.png" />
</div>
</div>
</section>
<section id="Counterexample-to-the-Julesz-Conjecture">
<h3>Counterexample to the Julesz Conjecture<a class="headerlink" href="#Counterexample-to-the-Julesz-Conjecture" title="Link to this heading"></a></h3>
<p>The Julesz conjecture, originally from <a class="reference external" href="https://ieeexplore.ieee.org/abstract/document/1057698">Julesz 1962</a>, states that “humans cannot distinguish between textures with identical second-order statistics” (second-order statistics include cross- and auto-correlations, see paper for details). Following up on this initial paper, <a class="reference external" href="https://link.springer.com/article/10.1007/BF00336998">Julesz et al, 1978</a> and then <a class="reference external" href="https://opg.optica.org/josaa/abstract.cfm?uri=josaa-10-5-777">Yellot, 1993</a>
created images that served as counter-examples for this conjecture: pairs of images that had identical second-order statistics (they differed in their third- and higher-order statistics) but were readily distinguishable by humans. In figure 13 of Portilla &amp; Simoncelli, 2000, the authors show that the model is able to synthesize novel images based on these counterexamples that are <em>also</em> distinguishbale by humans, so the model does not confuse them either.</p>
<p>(see figure 13 of Portilla &amp; Simoncelli 2000)</p>
<p>Excerpt from paper: <em>“Figure 13 shows two pairs of counterexamples that have been used to refute the Julesz conjecture. [13a and 13b were ] originally created by Julesz et al. (1978): they have identical third-order pixel statistics, but are easily discriminated by human observers. Our model succeeds, in that it can reproduce the visual appearance of either of these textures. In particular, we have seen that the strongest statistical difference arises in the magnitude correlation statistcs. The
rightmost pair were constructed by Yellott (1993), to have identical sample autocorrelation. Again, our model does not confuse these, and can reproduce the visual appearance of either one.”</em></p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[29]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Run on fig13a, fig13b, fig13c, fig13d to replicate examples in paper</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">load_images</span><span class="p">(</span><span class="n">DATA_PATH</span> <span class="o">/</span> <span class="s1">&#39;fig13a.jpg&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>

<span class="c1"># synthesis with full PortillaSimoncelli model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">simul</span><span class="o">.</span><span class="n">PortillaSimoncelli</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">metamer_left</span> <span class="o">=</span> <span class="n">run_synthesis</span><span class="p">(</span><span class="n">img</span><span class="p">,</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
100%|██████████| 3000/3000 [01:50&lt;00:00, 27.19it/s, loss=3.9424e-01, learning_rate=0.01, gradient_norm=1.4060e-02, pixel_change_norm=3.7373e-02, current_scale=all, current_scale_loss=3.9424e-01]
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[30]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Run on fig13a, fig13b, fig13c, fig13d to replicate examples in paper</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">load_images</span><span class="p">(</span><span class="n">DATA_PATH</span> <span class="o">/</span> <span class="s1">&#39;fig13b.jpg&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>

<span class="c1"># synthesis with full PortillaSimoncelli model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">simul</span><span class="o">.</span><span class="n">PortillaSimoncelli</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">metamer_right</span> <span class="o">=</span> <span class="n">run_synthesis</span><span class="p">(</span><span class="n">img</span><span class="p">,</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
 55%|█████▍    | 1645/3000 [01:00&lt;00:49, 27.35it/s, loss=3.5176e-01, learning_rate=0.01, gradient_norm=2.2899e-01, pixel_change_norm=1.7363e-01, current_scale=all, current_scale_loss=3.5176e-01]
</pre></div></div>
</div>
<p>And note that the two synthesized images (right column) or as distinguishable from each other as the two hand-crafted counterexamples (left column):</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[31]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">po</span><span class="o">.</span><span class="n">imshow</span><span class="p">([</span><span class="n">metamer_left</span><span class="o">.</span><span class="n">image</span><span class="p">,</span> <span class="n">metamer_left</span><span class="o">.</span><span class="n">metamer</span><span class="p">,</span>
           <span class="n">metamer_right</span><span class="o">.</span><span class="n">image</span><span class="p">,</span> <span class="n">metamer_right</span><span class="o">.</span><span class="n">metamer</span><span class="p">],</span>
          <span class="n">title</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Target image 1&#39;</span><span class="p">,</span> <span class="s1">&#39;Synthesized Metamer 1&#39;</span><span class="p">,</span> <span class="s1">&#39;Target Image 2&#39;</span><span class="p">,</span> <span class="s1">&#39;Synthesized Metamer 2&#39;</span><span class="p">],</span>
          <span class="n">vrange</span><span class="o">=</span><span class="s1">&#39;auto1&#39;</span><span class="p">,</span> <span class="n">col_wrap</span><span class="o">=</span><span class="mi">2</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_models_Metamer-Portilla-Simoncelli_52_0.png" src="../../_images/tutorials_models_Metamer-Portilla-Simoncelli_52_0.png" />
</div>
</div>
</section>
<section id="Pseudo-periodic-Textures">
<h3>Pseudo-periodic Textures<a class="headerlink" href="#Pseudo-periodic-Textures" title="Link to this heading"></a></h3>
<p>(see figure 14 of Portilla &amp; Simoncelli 2000)</p>
<p>Excerpt from paper: <em>“Figure 14 shows synthesis results photographic textures that are pseudo-periodic, such as a brick wall and various types of woven fabric”</em></p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[32]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Run on fig14a, fig14b, fig14c, fig14d, fig14e, fig14f to replicate examples in paper</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">load_images</span><span class="p">(</span><span class="n">DATA_PATH</span> <span class="o">/</span> <span class="s1">&#39;fig14a.jpg&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>

<span class="c1"># synthesis with full PortillaSimoncelli model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">simul</span><span class="o">.</span><span class="n">PortillaSimoncelli</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">metamer</span> <span class="o">=</span> <span class="n">run_synthesis</span><span class="p">(</span><span class="n">img</span><span class="p">,</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
 40%|████      | 1206/3000 [00:43&lt;01:05, 27.46it/s, loss=1.0051e-01, learning_rate=0.01, gradient_norm=6.4287e-01, pixel_change_norm=1.7885e-01, current_scale=all, current_scale_loss=1.0051e-01]
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[33]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">po</span><span class="o">.</span><span class="n">imshow</span><span class="p">([</span><span class="n">metamer</span><span class="o">.</span><span class="n">image</span><span class="p">,</span> <span class="n">metamer</span><span class="o">.</span><span class="n">metamer</span><span class="p">],</span>
          <span class="n">title</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Target image&#39;</span><span class="p">,</span> <span class="s1">&#39;Synthesized Metamer&#39;</span><span class="p">],</span> <span class="n">vrange</span><span class="o">=</span><span class="s1">&#39;auto1&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_models_Metamer-Portilla-Simoncelli_55_0.png" src="../../_images/tutorials_models_Metamer-Portilla-Simoncelli_55_0.png" />
</div>
</div>
</section>
<section id="Aperiodic-Textures">
<h3>Aperiodic Textures<a class="headerlink" href="#Aperiodic-Textures" title="Link to this heading"></a></h3>
<p>(see figure 15 of Portilla &amp; Simoncelli 2000)</p>
<p>Excerpt from paper: <em>“Figure 15 shows synthesis results for a set of photographic textures that are aperiodic, such as the animal fur or wood grain”</em></p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[34]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Run on fig15a, fig15b, fig15c, fig15d to replicate examples in paper</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">load_images</span><span class="p">(</span><span class="n">DATA_PATH</span> <span class="o">/</span> <span class="s1">&#39;fig15a.jpg&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>

<span class="c1"># synthesis with full PortillaSimoncelli model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">simul</span><span class="o">.</span><span class="n">PortillaSimoncelli</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">metamer</span> <span class="o">=</span> <span class="n">run_synthesis</span><span class="p">(</span><span class="n">img</span><span class="p">,</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
 17%|█▋        | 511/3000 [00:20&lt;01:41, 24.49it/s, loss=8.1478e-02, learning_rate=0.01, gradient_norm=9.3391e-01, pixel_change_norm=1.5554e-01, current_scale=all, current_scale_loss=8.1478e-02]
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[35]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">po</span><span class="o">.</span><span class="n">imshow</span><span class="p">([</span><span class="n">metamer</span><span class="o">.</span><span class="n">image</span><span class="p">,</span> <span class="n">metamer</span><span class="o">.</span><span class="n">metamer</span><span class="p">],</span>
          <span class="n">title</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Target image&#39;</span><span class="p">,</span> <span class="s1">&#39;Synthesized Metamer&#39;</span><span class="p">],</span> <span class="n">vrange</span><span class="o">=</span><span class="s1">&#39;auto1&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_models_Metamer-Portilla-Simoncelli_58_0.png" src="../../_images/tutorials_models_Metamer-Portilla-Simoncelli_58_0.png" />
</div>
</div>
</section>
<section id="Complex-Structured-Photographic-Textures">
<h3>Complex Structured Photographic Textures<a class="headerlink" href="#Complex-Structured-Photographic-Textures" title="Link to this heading"></a></h3>
<p>(see figure 16 of Portilla &amp; Simoncelli 2000)</p>
<p>Excerpt from paper: <em>“Figure 16 shows several examples of textures with complex structures. Although the synthesis quality is not as good as in previous examples, we find the ability of our model to capture salient visual features of these textures quite remarkable. Especially notable are those examples in all three figures for which shading produces a strong impression of three-dimensionality.”</em></p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[36]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Run on fig16a, fig16b, fig16c, fig16d to replicate examples in paper</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">load_images</span><span class="p">(</span><span class="n">DATA_PATH</span> <span class="o">/</span> <span class="s1">&#39;fig16e.jpg&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>

<span class="c1"># synthesis with full PortillaSimoncelli model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">simul</span><span class="o">.</span><span class="n">PortillaSimoncelli</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">metamer</span> <span class="o">=</span> <span class="n">run_synthesis</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
 11%|█         | 326/3000 [00:12&lt;01:38, 27.14it/s, loss=8.1584e-02, learning_rate=0.01, gradient_norm=1.2133e+00, pixel_change_norm=1.4190e-01, current_scale=all, current_scale_loss=8.1584e-02]
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[37]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">po</span><span class="o">.</span><span class="n">imshow</span><span class="p">([</span><span class="n">metamer</span><span class="o">.</span><span class="n">image</span><span class="p">,</span> <span class="n">metamer</span><span class="o">.</span><span class="n">metamer</span><span class="p">],</span>
          <span class="n">title</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Target image&#39;</span><span class="p">,</span> <span class="s1">&#39;Synthesized metamer&#39;</span><span class="p">],</span> <span class="n">vrange</span><span class="o">=</span><span class="s1">&#39;auto1&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_models_Metamer-Portilla-Simoncelli_61_0.png" src="../../_images/tutorials_models_Metamer-Portilla-Simoncelli_61_0.png" />
</div>
</div>
</section>
</section>
<section id="5.-Extrapolation">
<h2>5. Extrapolation<a class="headerlink" href="#5.-Extrapolation" title="Link to this heading"></a></h2>
<p>(see figure 19 of Portilla &amp; Simoncelli 2000)</p>
<p>Here we explore using the texture synthesis model for extrapolating beyond its spatial boundaries.</p>
<p>Excerpt from paper: <em>“…[C]onsider the problem of extending a texture image beyond its spatial boundaries (spatial extrapolation). We want to synthesize an image in which the central pixels contain a copy of the original image, and the surrounding pixels are synthesized based on the statistical measurements of the original image. The set of all images with the same central subset of pixels is convex, and the projection onto such a convex set is easily inserted into the iterative loop of the
synthesis algorithm. Specifically, we need only re-set the central pixels to the desired values on each iteration of the synthesis loop. In practice, this substitution is done by multiplying the desired pixels by a smooth mask (a raised cosine) and adding this to the current synthesized image multiplied by the complement of this mask. The smooth mask prevents artifacts at the boundary between original and synthesized pixels, whereas convergence to the desired pixels within the mask support
region is achieved almost perfectly. This technique is applicable to the restoration of pictures which have been destroyed in some subregion (“filling holes”) (e.g., Hirani and Totsuka, 1996), although the estimation of parameters from the defective image is not straightforward. Figure 19 shows a set of examples that have been spatially extrapolated using this method. Observe that the border between real and synthetic data is barely noticeable. An additional potential benefit is that the
synthetic images are seamlessly periodic (due to circular boundary-handling within our algorithm), and thus may be used to tile a larger image.”</em></p>
<p>In the following, we mask out the boundaries of an image and use the texture model to extend it.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[38]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># The following class inherits from the PortillaSimoncelli model for</span>
<span class="c1"># the purpose of extrapolating (filling in) a chunk of an imaged defined</span>
<span class="c1"># by a mask.</span>

<span class="k">class</span> <span class="nc">PortillaSimoncelliMask</span><span class="p">(</span><span class="n">po</span><span class="o">.</span><span class="n">simul</span><span class="o">.</span><span class="n">PortillaSimoncelli</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Extend the PortillaSimoncelli model to operate on masked images.</span>

<span class="sd">    Additional Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    mask: Tensor</span>
<span class="sd">        boolean mask with True in the part of the image that will be filled in during synthesis</span>
<span class="sd">    target: Tensor</span>
<span class="sd">        image target for synthesis</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">im_shape</span><span class="p">,</span>
        <span class="n">n_scales</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
        <span class="n">n_orientations</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
        <span class="n">spatial_corr_width</span><span class="o">=</span><span class="mi">9</span><span class="p">,</span>
        <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">target</span><span class="o">=</span><span class="kc">None</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">im_shape</span><span class="p">,</span> <span class="n">n_scales</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">n_orientations</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">spatial_corr_width</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="o">=</span> <span class="n">mask</span><span class="p">;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="n">target</span><span class="p">;</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">scales</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Generate Texture Statistics representation of an image using the target for the masked portion</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        images : torch.Tensor</span>
<span class="sd">            A 4d tensor containing two images to analyze, with shape (2,</span>
<span class="sd">            channel, height, width).</span>
<span class="sd">        scales : list, optional</span>
<span class="sd">            Which scales to include in the returned representation. If an empty</span>
<span class="sd">            list (the default), we include all scales. Otherwise, can contain</span>
<span class="sd">            subset of values present in this model&#39;s ``scales`` attribute.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        representation_tensor: torch.Tensor</span>
<span class="sd">            3d tensor of shape (batch, channel, stats) containing the measured</span>
<span class="sd">            texture statistics.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">target</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">image</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">texture_masked_image</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">image</span><span class="p">,</span><span class="n">scales</span><span class="o">=</span><span class="n">scales</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">texture_masked_image</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">image</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot; Fill in part of the image (designated by the mask) with the saved target image</span>

<span class="sd">        Parameters</span>
<span class="sd">        ------------</span>
<span class="sd">        image : torch.Tensor</span>
<span class="sd">            A tensor containing a single image</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        texture_masked_image: torch.Tensor</span>
<span class="sd">            An image that is a combination of the input image and the saved target.</span>
<span class="sd">            Combination is specified by self.mask</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="o">+</span> <span class="n">image</span><span class="o">*</span><span class="p">(</span><span class="o">~</span><span class="bp">self</span><span class="o">.</span><span class="n">mask</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[39]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">img_file</span> <span class="o">=</span> <span class="n">DATA_PATH</span> <span class="o">/</span> <span class="s1">&#39;fig14b.jpg&#39;</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">load_images</span><span class="p">(</span><span class="n">img_file</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">im_init</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand_like</span><span class="p">(</span><span class="n">img</span><span class="p">)</span><span class="o">-</span><span class="mf">.5</span><span class="p">)</span> <span class="o">*</span> <span class="mf">.1</span> <span class="o">+</span> <span class="n">img</span><span class="o">.</span><span class="n">mean</span><span class="p">();</span>

<span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">256</span><span class="p">,</span><span class="mi">256</span><span class="p">)</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">ctr_dim</span> <span class="o">=</span> <span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span><span class="o">//</span><span class="mi">4</span><span class="p">,</span> <span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">//</span><span class="mi">4</span><span class="p">)</span>
<span class="n">mask</span><span class="p">[</span><span class="o">...</span><span class="p">,</span><span class="n">ctr_dim</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span><span class="mi">3</span><span class="o">*</span><span class="n">ctr_dim</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">ctr_dim</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span><span class="mi">3</span><span class="o">*</span><span class="n">ctr_dim</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">True</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">PortillaSimoncelliMask</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:],</span> <span class="n">target</span><span class="o">=</span><span class="n">img</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">met</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">synth</span><span class="o">.</span><span class="n">MetamerCTF</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss_function</span><span class="o">=</span><span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">l2_norm</span><span class="p">,</span> <span class="n">initial_image</span><span class="o">=</span><span class="n">im_init</span><span class="p">,</span>
                          <span class="n">coarse_to_fine</span><span class="o">=</span><span class="s1">&#39;together&#39;</span><span class="p">)</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">([</span><span class="n">met</span><span class="o">.</span><span class="n">metamer</span><span class="p">],</span><span class="n">lr</span><span class="o">=</span><span class="mf">.02</span><span class="p">,</span> <span class="n">amsgrad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">met</span><span class="o">.</span><span class="n">synthesize</span><span class="p">(</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
    <span class="n">max_iter</span><span class="o">=</span><span class="n">short_synth_max_iter</span><span class="p">,</span>
    <span class="n">store_progress</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">change_scale_criterion</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">ctf_iters_to_check</span><span class="o">=</span><span class="mi">3</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
 50%|████▉     | 498/1000 [00:18&lt;00:18, 27.33it/s, loss=1.6285e-01, learning_rate=0.02, gradient_norm=9.5552e-01, pixel_change_norm=2.8429e-01, current_scale=all, current_scale_loss=1.6285e-01]
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[40]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">po</span><span class="o">.</span><span class="n">imshow</span><span class="p">([</span><span class="n">met</span><span class="o">.</span><span class="n">image</span><span class="p">,</span> <span class="n">mask</span><span class="o">*</span><span class="n">met</span><span class="o">.</span><span class="n">image</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">texture_masked_image</span><span class="p">(</span><span class="n">met</span><span class="o">.</span><span class="n">metamer</span><span class="p">)],</span> <span class="n">vrange</span><span class="o">=</span><span class="s1">&#39;auto1&#39;</span><span class="p">,</span>
          <span class="n">title</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Full target image&#39;</span><span class="p">,</span> <span class="s1">&#39;Masked target&#39;</span> <span class="p">,</span><span class="s1">&#39;synthesized image&#39;</span><span class="p">]);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_models_Metamer-Portilla-Simoncelli_65_0.png" src="../../_images/tutorials_models_Metamer-Portilla-Simoncelli_65_0.png" />
</div>
</div>
<section id="5.2-Mixtures">
<h3>5.2 Mixtures<a class="headerlink" href="#5.2-Mixtures" title="Link to this heading"></a></h3>
<p>Here we explore creating a texture that is “in between” two textures by averaging their texture statistics and synthesizing an image that matches those average statistics.</p>
<p>Note that we do this differently than what is described in the paper. In the original paper, mixed statistics were computed by calculating the statistics on a single input image that consisted of half of each of two texture images pasted together. This led to an “oil and water” appearance in the resulting texture metamer, which appeared to have patches from each image.</p>
<p>In the following, we compute the texture statistics on two texture images separately and then average the resulting statistics, which appears to perform better. Note that, in all the other examples in this notebook, we knew there exists <em>at least one</em> image whose output matches our optimization target: the image we started with. For these mixtures, that is no longer the case.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[41]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># The following classes are designed to extend the PortillaSimoncelli model</span>
<span class="c1"># and the Metamer synthesis method for the purpose of mixing two target textures.</span>

<span class="k">class</span> <span class="nc">PortillaSimoncelliMixture</span><span class="p">(</span><span class="n">po</span><span class="o">.</span><span class="n">simul</span><span class="o">.</span><span class="n">PortillaSimoncelli</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Extend the PortillaSimoncelli model to mix two different images</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        im_shape: int</span>
<span class="sd">            the size of the images being processed by the model</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">im_shape</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">im_shape</span><span class="p">,</span> <span class="n">n_scales</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">n_orientations</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">spatial_corr_width</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>


    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">images</span><span class="p">,</span> <span class="n">scales</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Average Texture Statistics representations of two image</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        images : torch.Tensor</span>
<span class="sd">            A 4d tensor containing one or two images to analyze, with shape (i,</span>
<span class="sd">            channel, height, width), i in {1,2}.</span>
<span class="sd">        scales : list, optional</span>
<span class="sd">            Which scales to include in the returned representation. If an empty</span>
<span class="sd">            list (the default), we include all scales. Otherwise, can contain</span>
<span class="sd">            subset of values present in this model&#39;s ``scales`` attribute.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        representation_tensor: torch.Tensor</span>
<span class="sd">            3d tensor of shape (batch, channel, stats) containing the measured</span>
<span class="sd">            texture statistics.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">images</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="c1"># need the images to be 4d, so we use the &quot;1 element slice&quot;</span>
            <span class="n">stats0</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">images</span><span class="p">[:</span><span class="mi">1</span><span class="p">],</span> <span class="n">scales</span><span class="o">=</span><span class="n">scales</span><span class="p">)</span>
            <span class="n">stats1</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">2</span><span class="p">],</span> <span class="n">scales</span><span class="o">=</span><span class="n">scales</span><span class="p">)</span>
            <span class="k">return</span> <span class="p">(</span><span class="n">stats0</span><span class="o">+</span><span class="n">stats1</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">scales</span><span class="o">=</span><span class="n">scales</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">MetamerMixture</span><span class="p">(</span><span class="n">po</span><span class="o">.</span><span class="n">synth</span><span class="o">.</span><span class="n">MetamerCTF</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot; Extending metamer synthesis based on image-computable</span>
<span class="sd">    differentiable models, for mixing two images.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">_initialize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">initial_image</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize the metamer.</span>

<span class="sd">        Set the ``self.metamer`` attribute to be a parameter with</span>
<span class="sd">        the user-supplied data, making sure it&#39;s the right shape.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        initial_image :</span>
<span class="sd">            The tensor we use to initialize the metamer. If None (the</span>
<span class="sd">            default), we initialize with uniformly-distributed random</span>
<span class="sd">            noise lying between 0 and 1.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">initial_image</span><span class="o">.</span><span class="n">ndimension</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mi">4</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;initial_image must be torch.Size([n_batch&quot;</span>
                            <span class="s2">&quot;, n_channels, im_height, im_width]) but got &quot;</span>
                            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">initial_image</span><span class="o">.</span><span class="n">size</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="c1"># the difference between this and the regular version of Metamer is that</span>
        <span class="c1"># the regular version requires synthesized_signal and target_signal to have</span>
        <span class="c1"># the same shape, and here target_signal is (2, 1, 256, 256), not (1, 1, 256, 256)</span>
        <span class="n">metamer</span> <span class="o">=</span> <span class="n">initial_image</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
        <span class="n">metamer</span> <span class="o">=</span> <span class="n">metamer</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                             <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">metamer</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_metamer</span> <span class="o">=</span> <span class="n">metamer</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[42]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Figure 20. Examples of “mixture” textures.</span>
<span class="c1"># To replicate paper use the following combinations:</span>
<span class="c1"># (Fig. 15a, Fig. 15b); (Fig. 14b, Fig. 4a); (Fig. 15e, Fig. 14e).</span>

<span class="n">img_files</span> <span class="o">=</span> <span class="p">[</span><span class="n">DATA_PATH</span> <span class="o">/</span> <span class="s1">&#39;fig15e.jpg&#39;</span><span class="p">,</span> <span class="n">DATA_PATH</span> <span class="o">/</span> <span class="s1">&#39;fig14e.jpg&#39;</span><span class="p">]</span>
<span class="n">imgs</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">load_images</span><span class="p">(</span><span class="n">img_files</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">im_init</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand_like</span><span class="p">(</span><span class="n">imgs</span><span class="p">[</span><span class="mi">0</span><span class="p">,:,:,:]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span> <span class="o">*</span> <span class="mf">.01</span> <span class="o">+</span> <span class="n">imgs</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">n</span><span class="o">=</span><span class="n">imgs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">PortillaSimoncelliMixture</span><span class="p">([</span><span class="n">n</span><span class="p">,</span><span class="n">n</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">met</span> <span class="o">=</span> <span class="n">MetamerMixture</span><span class="p">(</span><span class="n">imgs</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss_function</span><span class="o">=</span><span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">l2_norm</span><span class="p">,</span> <span class="n">initial_image</span><span class="o">=</span><span class="n">im_init</span><span class="p">,</span>
                     <span class="n">coarse_to_fine</span><span class="o">=</span><span class="s1">&#39;together&#39;</span><span class="p">)</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">([</span><span class="n">met</span><span class="o">.</span><span class="n">metamer</span><span class="p">],</span><span class="n">lr</span><span class="o">=</span><span class="mf">.02</span><span class="p">,</span> <span class="n">amsgrad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">met</span><span class="o">.</span><span class="n">synthesize</span><span class="p">(</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
    <span class="n">max_iter</span><span class="o">=</span><span class="n">longest_synth_max_iter</span><span class="p">,</span>
    <span class="n">store_progress</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">change_scale_criterion</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">ctf_iters_to_check</span><span class="o">=</span><span class="mi">3</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
  7%|▋         | 292/4000 [00:10&lt;02:17, 26.93it/s, loss=3.9513e-01, learning_rate=0.02, gradient_norm=4.1310e-01, pixel_change_norm=3.3290e-01, current_scale=all, current_scale_loss=3.9513e-01]
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[43]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">po</span><span class="o">.</span><span class="n">imshow</span><span class="p">([</span><span class="n">met</span><span class="o">.</span><span class="n">image</span><span class="p">,</span> <span class="n">met</span><span class="o">.</span><span class="n">metamer</span><span class="p">],</span> <span class="n">vrange</span><span class="o">=</span><span class="s1">&#39;auto1&#39;</span><span class="p">,</span><span class="n">title</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Target image 1&#39;</span><span class="p">,</span> <span class="s1">&#39;Target image 2&#39;</span><span class="p">,</span> <span class="s1">&#39;Synthesized Mixture Metamer&#39;</span><span class="p">]);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_models_Metamer-Portilla-Simoncelli_69_0.png" src="../../_images/tutorials_models_Metamer-Portilla-Simoncelli_69_0.png" />
</div>
</div>
</section>
</section>
<section id="6.-Model-Limitations">
<h2>6. Model Limitations<a class="headerlink" href="#6.-Model-Limitations" title="Link to this heading"></a></h2>
<p>Not all texture model metamers look perceptually similar to humans. The paper’s figures 17 and 18 present two classes of failures: “inhomogeneous texture images not usually considered to be ‘texture’” (such as human faces, fig. 17) and some simple hand-drawn textures (fig. 18), many of which are simple geometric line drawings.</p>
<p>Note that for these examples, we were unable to locate the original images, so we present examples that serve the same purpose.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[44]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">img</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">einstein</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>

<span class="c1"># synthesis with full PortillaSimoncelli model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">simul</span><span class="o">.</span><span class="n">PortillaSimoncelli</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">metamer</span> <span class="o">=</span> <span class="n">run_synthesis</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
 14%|█▎        | 412/3000 [00:15&lt;01:34, 27.26it/s, loss=8.6688e-02, learning_rate=0.01, gradient_norm=8.7333e-01, pixel_change_norm=1.5081e-01, current_scale=all, current_scale_loss=8.6688e-02]
</pre></div></div>
</div>
<p>Here we can see that the texture model fails to capture anything that makes this image look “portrait-like”: there is no recognizable face or clothes in the synthesized metamer. As a portrait is generally not considered a texture, this is not a model <em>failure</em> per se, but does demonstrate the limits of this model.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[45]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">po</span><span class="o">.</span><span class="n">imshow</span><span class="p">([</span><span class="n">metamer</span><span class="o">.</span><span class="n">image</span><span class="p">,</span> <span class="n">metamer</span><span class="o">.</span><span class="n">metamer</span><span class="p">],</span>
          <span class="n">title</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Target image&#39;</span><span class="p">,</span> <span class="s1">&#39;Synthesized Metamer&#39;</span><span class="p">],</span> <span class="n">vrange</span><span class="o">=</span><span class="s1">&#39;auto1&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_models_Metamer-Portilla-Simoncelli_73_0.png" src="../../_images/tutorials_models_Metamer-Portilla-Simoncelli_73_0.png" />
</div>
</div>
<p>In this example, we see the model metamer fails to reproduce the randomly distributed oriented black lines on a white background: in particular, several lines are curved and several appear discontinuous. From the paper: “Althought a texture of single-orientation bars is reproduced fairly well (see Fig. 12), the mixture of bar orientations in this example leads ot the synthesis of curved line segments. In general, the model is unable to distinguish straight from curved contours, except when the
contours are all of the same orientation.”</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[46]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">img</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">load_images</span><span class="p">(</span><span class="n">DATA_PATH</span> <span class="o">/</span> <span class="s1">&#39;fig18a.png&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>

<span class="c1"># synthesis with full PortillaSimoncelli model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">simul</span><span class="o">.</span><span class="n">PortillaSimoncelli</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">metamer</span> <span class="o">=</span> <span class="n">run_synthesis</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
 46%|████▌     | 1377/3000 [00:50&lt;00:59, 27.46it/s, loss=2.0836e-01, learning_rate=0.01, gradient_norm=2.4266e-01, pixel_change_norm=9.8369e-02, current_scale=all, current_scale_loss=2.0836e-01]
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[47]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">po</span><span class="o">.</span><span class="n">imshow</span><span class="p">([</span><span class="n">metamer</span><span class="o">.</span><span class="n">image</span><span class="p">,</span> <span class="n">metamer</span><span class="o">.</span><span class="n">metamer</span><span class="p">],</span>
          <span class="n">title</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Target image&#39;</span><span class="p">,</span> <span class="s1">&#39;Synthesized Metamer&#39;</span><span class="p">],</span> <span class="n">vrange</span><span class="o">=</span><span class="s1">&#39;auto1&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_models_Metamer-Portilla-Simoncelli_76_0.png" src="../../_images/tutorials_models_Metamer-Portilla-Simoncelli_76_0.png" />
</div>
</div>
</section>
<section id="7.-Notable-differences-between-Matlab-and-Plenoptic-Implementations:">
<h2>7. Notable differences between Matlab and Plenoptic Implementations:<a class="headerlink" href="#7.-Notable-differences-between-Matlab-and-Plenoptic-Implementations:" title="Link to this heading"></a></h2>
<ol class="arabic">
<li><p><strong>Optimization</strong>. The matlab implementation of texture synthesis is designed specifically for the texture model. Gradient descent is performed on subsets of the texture statistics in a particular sequence (coarse-to-fine, etc.). The plenoptic implementation relies on the auto-differentiation and optimization tools available in pytorch. We only define the forward model and then allow pytorch to handle the optimization.</p>
<p>Why does this matter? We have qualitatively reproduced the results but cannot guarantee exact reproducibility. This is true in general for the plenoptic package: <a class="reference external" href="https://plenoptic.readthedocs.io/en/latest/reproducibility.html">https://plenoptic.readthedocs.io/en/latest/reproducibility.html</a>. This means that, in general, metamers synthesized by the two versions will differ.</p>
</li>
<li><p><strong>Lack of redundant statistics</strong>. As described in the next section, we output a different number of statistics than the Matlab implementation. The number of statistics returned in <code class="docutils literal notranslate"><span class="pre">plenoptic</span></code> matches the number of statistics reported in the paper, unlike the Matlab implementation. That is because the Matlab implementation included many redundant statistics, which were either exactly redundant (e.g., symmetric values in an auto-correlation matrix), placeholders (e.g., some 0s to make the
shapes of the output work out), or not mentioned in the paper. The implementation included in <code class="docutils literal notranslate"><span class="pre">plenoptic</span></code> returns only the necessary statistics. See the next section for more details.</p></li>
<li><p><strong>True correlations</strong>. In the <a class="reference external" href="https://github.com/LabForComputationalVision/textureSynth">Matlab implementation of Portilla Simoncelli statistics</a>, the auto-correlation, cross-scale and cross-orientation statistics are based on co-variance matrices. When using <code class="docutils literal notranslate"><span class="pre">torch</span></code> to perform optimization, this makes convergence more difficult. We thus normalize each of these matrices, dividing the auto-correlation matrices by their center values (the variance) and the cross-correlation matrices by
the square root of the product of the appropriate variances (so that we match <a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.corrcoef.html">numpy.corrcoef</a>). This means that the center of the auto-correlations and the diagonals of <code class="docutils literal notranslate"><span class="pre">cross_orientation_correlation_magnitude</span></code> are always 1 and are thus excluded from the representation, as discussed above. We have thus added two new statistics, <code class="docutils literal notranslate"><span class="pre">std_reconstructed</span></code> and <code class="docutils literal notranslate"><span class="pre">magnitude_std</span></code> (the standard deviation of the reconstructed
lowpass images and the standard deviation of the magnitudes of each steerable pyramid band), to compensate (see Note at end of cell). Note that the cross-scale correlations have no redundancies and do not have 1 along the diagonal. For the <code class="docutils literal notranslate"><span class="pre">cross_orientation_correlation_magnitude</span></code>, the value at <span class="math notranslate nohighlight">\(A_{i,j}\)</span> is the correlation between the magnitudes at orientation <span class="math notranslate nohighlight">\(i\)</span> and orientation <span class="math notranslate nohighlight">\(j\)</span> at the <em>same</em> scale, so that <span class="math notranslate nohighlight">\(A_{i,i}\)</span> is the correlation of a magnitude band with
itself, i.e., <span class="math notranslate nohighlight">\(1\)</span>. However, for <code class="docutils literal notranslate"><span class="pre">cross_scale_correlation_magnitude</span></code>, the value at <span class="math notranslate nohighlight">\(A_{i,j}\)</span> is the correlation between the magnitudes at orientation <span class="math notranslate nohighlight">\(i\)</span> and orientation <span class="math notranslate nohighlight">\(j\)</span> at <em>two adjacent scales</em>, and thus <span class="math notranslate nohighlight">\(A_{i,i}\)</span> is <em>not</em> the correlation of a band with itself; it is thus informative.</p></li>
</ol>
<p>Note: We use standard deviations, instead of variances, because the value of the standard deviations lie within approximately the same range as the other values in the model’s representation, which makes optimization work better.</p>
</section>
<section id="7.1-Redundant-statistics">
<h2>7.1 Redundant statistics<a class="headerlink" href="#7.1-Redundant-statistics" title="Link to this heading"></a></h2>
<p>The original Portilla-Simoncelli paper presents formulas to obtain the number of statistics in each class from the model parameters <code class="docutils literal notranslate"><span class="pre">n_scales</span></code>, <code class="docutils literal notranslate"><span class="pre">n_orientations</span></code> and <code class="docutils literal notranslate"><span class="pre">spatial_corr_width</span></code> (labeled in the original paper <span class="math notranslate nohighlight">\(N\)</span>, <span class="math notranslate nohighlight">\(K\)</span>, and <span class="math notranslate nohighlight">\(M\)</span> respectively). The formulas indicate the following statistics for each class:</p>
<ul class="simple">
<li><p><strong>Marginal statistics</strong>: <span class="math notranslate nohighlight">\(2(N+1)\)</span> skewness and kurtosis of lowpass images, <span class="math notranslate nohighlight">\(1\)</span> high-pass variance, <span class="math notranslate nohighlight">\(6\)</span> pixel statistics.</p></li>
<li><p><strong>Raw coefficient correlation</strong>: <span class="math notranslate nohighlight">\((N+1)\frac{M^2+1}{2}\)</span> statistics (<span class="math notranslate nohighlight">\(\frac{M^2+1}{2}\)</span> auto-correlations for each scale including lowpass)</p></li>
<li><p><strong>Coefficient magnitude statistics</strong>: <span class="math notranslate nohighlight">\(NK\frac{M^2+1}{2}\)</span> autocorrelation statistics, <span class="math notranslate nohighlight">\(N\frac{K(K-1)}{2}\)</span> cross-orientation correlations at same scale, <span class="math notranslate nohighlight">\(K^2(N-1)\)</span> cross-scale correlations.</p></li>
<li><p><strong>Cross-scale phase statistics</strong>: <span class="math notranslate nohighlight">\(2K^2(N-1)\)</span> statistics</p></li>
</ul>
<p>In particular, the paper reads <em>“For our texture examples, we have made choices of N = 4, K = 4 and M = 7, resulting in a total of 710 parameters”</em>. However, the output of the Portilla-Simoncelli code in <a class="reference external" href="https://github.com/LabForComputationalVision/textureSynth">Matlab</a> contains 1784 elements for these values of <span class="math notranslate nohighlight">\(N\)</span>, <span class="math notranslate nohighlight">\(K\)</span> and <span class="math notranslate nohighlight">\(M\)</span>. The discrepancy is because the Matlab output includes redundant statistics, placeholder values, and statistics not used during synthesis. The
<code class="docutils literal notranslate"><span class="pre">plenoptic</span></code> output on the other hand returns only the essential statistics, and its output is in agreement with the papers formulas.</p>
<p>The redundant statistics that are removed by the <code class="docutils literal notranslate"><span class="pre">plenoptic</span></code> package but that are present in the Matlab code are as follows:</p>
<ol class="arabic simple">
<li><p><strong>Auto-correlation reconstructed</strong>: An auto-covariance matrix <span class="math notranslate nohighlight">\(A\)</span> encodes the covariance of the elements in a signal and their neighbors. Indexing the central auto-covariance element as <span class="math notranslate nohighlight">\(A_{0,0}\)</span>, element <span class="math notranslate nohighlight">\(A_{i,j}\)</span> contains the covariance of the signal with it’s neighbor at a displacement <span class="math notranslate nohighlight">\(i,j\)</span>. Because auto-correlation matrices are <a class="reference external" href="https://en.wikipedia.org/wiki/Autocorrelation#Symmetry_property">even functions</a>, they have a symmetry where <span class="math notranslate nohighlight">\(A_{i,j}=A_{-i,-j}\)</span>
which means that every element except the central one (<span class="math notranslate nohighlight">\(A_{0,0}\)</span>, the variance) is duplicated (see Note at end of cell). Thus, in an autocorrelation matrix of size <span class="math notranslate nohighlight">\(M \times M\)</span>, there are <span class="math notranslate nohighlight">\(\frac{M^2+1}{2}\)</span> non-redundant elements (see this ratio appear in the auto-correlation statistics formulas above). The Matlab code returns the full auto-covariance matrices, that is, <span class="math notranslate nohighlight">\(M^2\)</span> instead of <span class="math notranslate nohighlight">\(\frac{M^2+1}{2}\)</span> elements for each covariance matrix.</p></li>
<li><p><strong>Auto-correlation magnitude</strong>: Same symmetry and redundancies as 1).</p></li>
<li><p><strong>Cross-orientation magnitude correlation</strong>: Covariance matrices <span class="math notranslate nohighlight">\(C\)</span> (size <span class="math notranslate nohighlight">\(K \times K\)</span>) have symmetry <span class="math notranslate nohighlight">\(C_{i,j} = C_{j,i}\)</span> (each off-diagonal element is duplicated, i.e., <a class="reference external" href="https://en.wikipedia.org/wiki/Covariance_matrix#Basic_properties">they’re symmetric</a>). Thus, a <span class="math notranslate nohighlight">\(K \times K\)</span> covariance matrix has <span class="math notranslate nohighlight">\(\frac{K(K+1)}{2}\)</span> non-redundant elements. However, the diagonal elements of the cross-orientation correlations are variances, which are already contained in the
central elements of the auto-correlation magnitude matrices. Thus, these covariances only hold <span class="math notranslate nohighlight">\(\frac{K(K-1)}{2}\)</span> non-redundant elements (see this term in the formulas above). The Matlab code returns the full covariances (with <span class="math notranslate nohighlight">\(K^2\)</span> elements) instead of the non-redundant ones. Also, the Matlab code returns an extra covariance matrix full of 0’s not mentioned in the paper (<span class="math notranslate nohighlight">\((N+1)\)</span> matrices instead of <span class="math notranslate nohighlight">\((N)\)</span>).</p></li>
<li><p><strong>Cross-scale real correlation (phase statistics)</strong>: Phase statistics contain the correlations between the <span class="math notranslate nohighlight">\(K\)</span> real orientations at a scale with the <span class="math notranslate nohighlight">\(2K\)</span> real and imaginary phase-doubled orientations at the following scale, making a total of <span class="math notranslate nohighlight">\(K \times 2K=2K^2\)</span> statistics (see this term in the formulas above). However, the Matlab output has matrices of size <span class="math notranslate nohighlight">\(2K \times 2K\)</span>, where half of the matrices are filled with 0’s. Also, the paper counts the <span class="math notranslate nohighlight">\((N-1)\)</span> pairs of
adjacent scales, but the Matlab output includes <span class="math notranslate nohighlight">\(N\)</span> matrices. The <code class="docutils literal notranslate"><span class="pre">plenoptic</span></code> output removes the 0’s and the extra matrix.</p></li>
<li><p><strong>Statistics not in paper</strong>: The Matlab code outputs the mean magnitude of each band and cross-orientation real correlations, but these are not enumerated in the paper. These statistics are removed in <code class="docutils literal notranslate"><span class="pre">plenoptic</span></code>. See the next section for some more detail about the magnitude means.</p></li>
</ol>
<p>Note: This can be understood by thinking of <span class="math notranslate nohighlight">\(A_{i,0}\)</span>, the autocorrelation of every pixel and the pixel <span class="math notranslate nohighlight">\(i\)</span> to their right. Computing this auto-covariance involves adding together all the products <span class="math notranslate nohighlight">\(I_{x,y}*I_{x+i,y}\)</span> for every x and y in the image. But this is equivalent to computing <span class="math notranslate nohighlight">\(A_{-i,0}\)</span>, because every pair of two neighbors <span class="math notranslate nohighlight">\(i\)</span> to the right <span class="math notranslate nohighlight">\(I_{x,y}*I_{x+i,y}\)</span> is also a pair of neighbors <span class="math notranslate nohighlight">\(i\)</span> to the left,
<span class="math notranslate nohighlight">\(I_{x+i,y}*I_{(x+i)-i,y}=I_{x+i,y}*I_{x,y}\)</span>. So, any opposite displacements around the central element in the auto-covariance matrix will have the same value.</p>
<p>As shown below, the output of <code class="docutils literal notranslate"><span class="pre">plenoptic</span></code> matches the number of statistics indicated in the paper:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[48]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">img</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">load_images</span><span class="p">(</span><span class="n">DATA_PATH</span> <span class="o">/</span> <span class="s1">&#39;fig4a.jpg&#39;</span><span class="p">)</span>
<span class="n">image_shape</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:</span><span class="mi">4</span><span class="p">]</span>

<span class="c1"># Initialize the minimal model. Use same params as paper</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">simul</span><span class="o">.</span><span class="n">PortillaSimoncelli</span><span class="p">(</span><span class="n">image_shape</span><span class="p">,</span> <span class="n">n_scales</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
                            <span class="n">n_orientations</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
                            <span class="n">spatial_corr_width</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>

<span class="n">stats</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Stats for N=4, K=4, M=7: </span><span class="si">{</span><span class="n">stats</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s1"> statistics&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Stats for N=4, K=4, M=7: 710 statistics
</pre></div></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">plenoptic</span></code> allows to convert the tensor of statistics into a dictionary containing matrices, similar to the Matlab output. In this dictionary, the redundant statistics are indicated with <code class="docutils literal notranslate"><span class="pre">NaN</span></code>s. We print one of the auto-correlation matrices showing the redundant elements it contains:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[49]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">stats_dict</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">convert_to_dict</span><span class="p">(</span><span class="n">stats</span><span class="p">)</span>
<span class="n">s</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">o</span> <span class="o">=</span> <span class="mi">2</span>
<span class="nb">print</span><span class="p">(</span><span class="n">stats_dict</span><span class="p">[</span><span class="s1">&#39;auto_correlation_magnitude&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,:,:,</span><span class="n">s</span><span class="p">,</span><span class="n">o</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
tensor([[ 0.0077,     nan,     nan,     nan,     nan,     nan,     nan],
        [ 0.0800,  0.1434,     nan,     nan,     nan,     nan,     nan],
        [ 0.0442,  0.3150,  0.6220,     nan,     nan,     nan,     nan],
        [-0.0039,  0.0177,  0.5022,     nan,     nan,     nan,     nan],
        [ 0.0150,  0.0171, -0.0338,  0.2946,     nan,     nan,     nan],
        [-0.0055,  0.0870,  0.2252,  0.0671,  0.0134,     nan,     nan],
        [-0.0460, -0.0640,  0.1255,  0.3935,  0.1982, -0.0199,     nan]])
</pre></div></div>
</div>
<p>We see in the output above that both the upper triangular part of the matrix, and the diagonal elements from the center onwards are redundant, as indicated in the text above. Note that although the central element is not redundant in auto-covariance matrices, when the covariances are converted to correlations, the central element is 1, and so uninformative (see previous section for more information).</p>
<p>We can count how many statistics are in this particular class:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[50]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">acm_not_redundant</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">~</span><span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">stats_dict</span><span class="p">[</span><span class="s1">&#39;auto_correlation_magnitude&#39;</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Non-redundant elements in acm: </span><span class="si">{</span><span class="n">acm_not_redundant</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Non-redundant elements in acm: 384
</pre></div></div>
</div>
<p>The number of non redundant elements is 16 elements short of the <span class="math notranslate nohighlight">\(NK\frac{M^2+1}{2} = 4\cdot 4 \cdot \frac{7^2+1}{2}=400\)</span> statistics indicated by the formula. This is because <code class="docutils literal notranslate"><span class="pre">plenoptic</span></code> removes the central elements of these matrices and holds them in <code class="docutils literal notranslate"><span class="pre">stats_dict['magnitude_std']</span></code>:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[51]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number magnitude band variances: </span><span class="si">{</span><span class="n">stats_dict</span><span class="p">[</span><span class="s1">&#39;magnitude_std&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Number magnitude band variances: 16
</pre></div></div>
</div>
<p>Next, lets see whether the number of statistics in each class match what is in the original paper:</p>
<ol class="arabic simple">
<li><p><strong>Marginal statistics</strong>: Total of <code class="docutils literal notranslate"><span class="pre">17</span></code> statistics</p>
<ul class="simple">
<li><p>kurtosis + skewness: <code class="docutils literal notranslate"><span class="pre">2*(N+1)</span> <span class="pre">=</span> <span class="pre">2*(4+1)</span> <span class="pre">=</span> <span class="pre">10</span></code></p></li>
<li><p>variance of high pass band: <code class="docutils literal notranslate"><span class="pre">1</span></code></p></li>
<li><p>pixel statistics: <code class="docutils literal notranslate"><span class="pre">6</span></code></p></li>
</ul>
</li>
<li><p><strong>Raw coefficient correlation</strong>: Total of <code class="docutils literal notranslate"><span class="pre">125</span></code> statistics</p>
<ul class="simple">
<li><p>Central samples of auto-correlation reconstructed: <code class="docutils literal notranslate"><span class="pre">(N+1)*(M^2+1)/2</span> <span class="pre">=</span> <span class="pre">(4+1)*(7^2+1)/2</span> <span class="pre">=</span> <span class="pre">125</span></code></p></li>
</ul>
</li>
<li><p><strong>Coefficient magnitude statistics</strong>: Total of <code class="docutils literal notranslate"><span class="pre">472</span></code> statistics</p>
<ul class="simple">
<li><p>Central samples of auto-correlation of magnitude of each subband <code class="docutils literal notranslate"><span class="pre">N*K*(M^2+1)/2</span> <span class="pre">=</span> <span class="pre">4*4*(7^2+1)/2</span> <span class="pre">=</span> <span class="pre">400</span></code></p></li>
<li><p>Cross-correlation of orientations in same scale: <code class="docutils literal notranslate"><span class="pre">N*K*(K-1)/2</span> <span class="pre">=</span> <span class="pre">4*4*(4-1)/2</span> <span class="pre">=</span> <span class="pre">24</span></code></p></li>
<li><p>Cross-correlation of magnitudes across scale: <code class="docutils literal notranslate"><span class="pre">K^2*(N-1)</span> <span class="pre">=</span> <span class="pre">4^2*(4-1)</span> <span class="pre">=</span> <span class="pre">48</span></code></p></li>
</ul>
</li>
<li><p><strong>Cross-scale phase statistics</strong>: Total <code class="docutils literal notranslate"><span class="pre">96</span></code> statistics</p>
<ul class="simple">
<li><p>Cross-correlation of real coeffs with both coeffs at broader scale: <code class="docutils literal notranslate"><span class="pre">2*K^2*(N-1)</span> <span class="pre">=</span> <span class="pre">2*4^2*(4-1)</span> <span class="pre">=</span> <span class="pre">96</span></code></p></li>
</ul>
</li>
</ol>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[52]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Sum marginal statistics</span>
<span class="n">marginal_stats_num</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">~</span><span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">stats_dict</span><span class="p">[</span><span class="s1">&#39;kurtosis_reconstructed&#39;</span><span class="p">]))</span> <span class="o">+</span>
                      <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">~</span><span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">stats_dict</span><span class="p">[</span><span class="s1">&#39;skew_reconstructed&#39;</span><span class="p">]))</span> <span class="o">+</span>
                      <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">~</span><span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">stats_dict</span><span class="p">[</span><span class="s1">&#39;var_highpass_residual&#39;</span><span class="p">]))</span> <span class="o">+</span>
                      <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">~</span><span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">stats_dict</span><span class="p">[</span><span class="s1">&#39;pixel_statistics&#39;</span><span class="p">])))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Marginal statistics: </span><span class="si">{</span><span class="n">marginal_stats_num</span><span class="si">}</span><span class="s1"> parameters, compared to 17 in paper&#39;</span><span class="p">)</span>

<span class="c1"># Sum raw coefficient correlations</span>
<span class="n">real_coefficient_corr_num</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">~</span><span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">stats_dict</span><span class="p">[</span><span class="s1">&#39;auto_correlation_reconstructed&#39;</span><span class="p">]))</span>
<span class="n">real_variances</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">~</span><span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">stats_dict</span><span class="p">[</span><span class="s1">&#39;std_reconstructed&#39;</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Raw coefficient correlation: </span><span class="si">{</span><span class="n">real_coefficient_corr_num</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">real_variances</span><span class="si">}</span><span class="s1"> parameters, &#39;</span>
      <span class="s1">&#39;compared to 125 in paper&#39;</span><span class="p">)</span>

<span class="c1"># Sum coefficient magnitude statistics</span>
<span class="n">coeff_magnitude_stats_num</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">~</span><span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">stats_dict</span><span class="p">[</span><span class="s1">&#39;auto_correlation_magnitude&#39;</span><span class="p">]))</span> <span class="o">+</span>
                             <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">~</span><span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">stats_dict</span><span class="p">[</span><span class="s1">&#39;cross_scale_correlation_magnitude&#39;</span><span class="p">]))</span> <span class="o">+</span>
                             <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">~</span><span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">stats_dict</span><span class="p">[</span><span class="s1">&#39;cross_orientation_correlation_magnitude&#39;</span><span class="p">])))</span>
<span class="n">coeff_magnitude_variances</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">~</span><span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">stats_dict</span><span class="p">[</span><span class="s1">&#39;magnitude_std&#39;</span><span class="p">]))</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Coefficient magnitude statistics: </span><span class="si">{</span><span class="n">coeff_magnitude_stats_num</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">coeff_magnitude_variances</span><span class="si">}</span><span class="s1"> &#39;</span>
      <span class="s1">&#39;parameters, compared to 472 in paper&#39;</span><span class="p">)</span>

<span class="c1"># Sum cross-scale phase statistics</span>
<span class="n">phase_statistics_num</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">~</span><span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">stats_dict</span><span class="p">[</span><span class="s1">&#39;cross_scale_correlation_real&#39;</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Phase statistics: </span><span class="si">{</span><span class="n">phase_statistics_num</span><span class="si">}</span><span class="s1"> parameters, compared to 96 in paper&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Marginal statistics: 17 parameters, compared to 17 in paper
Raw coefficient correlation: 125 parameters, compared to 125 in paper
Coefficient magnitude statistics: 472 parameters, compared to 472 in paper
Phase statistics: 96 parameters, compared to 96 in paper
</pre></div></div>
</div>
</section>
<section id="7.2-Magnitude-means">
<h2>7.2 Magnitude means<a class="headerlink" href="#7.2-Magnitude-means" title="Link to this heading"></a></h2>
<p>The mean of each magnitude band are slightly different from the redundant statistics discussed in the previous section. Each of those statistics are exactly redundant, e.g., the center value of an autocorrelation matrix will always be 1. They thus cannot include any additional information. However, the magnitude means are only <em>approximately</em> redundant and thus could improve the texture representation. The authors excluded these values because they did not seem to be necessary: the magnitude
means are constrained by the other statistics (though not perfectly), and thus including them does not improve the visual quality of the synthesized textures.</p>
<p>To demonstrate this, we will create a modified version of the <code class="docutils literal notranslate"><span class="pre">PortillaSimoncelli</span></code> class which includes the magnitude means to demonstrate:</p>
<ol class="arabic simple">
<li><p>Even without explicitly including them in the texture representation, they are still approximately matched between the original and synthesized texture images.</p></li>
<li><p>Including them in the representation does not significantly change the quality of the synthesized texture.</p></li>
</ol>
<p>First, let’s create the modified model:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[53]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">OrderedDict</span>

<span class="k">class</span> <span class="nc">PortillaSimoncelliMagMeans</span><span class="p">(</span><span class="n">po</span><span class="o">.</span><span class="n">simul</span><span class="o">.</span><span class="n">PortillaSimoncelli</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Include the magnitude means in the PS texture representation.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        im_shape: int</span>
<span class="sd">            the size of the images being processed by the model</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">im_shape</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">im_shape</span><span class="p">,</span> <span class="n">n_scales</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">n_orientations</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">spatial_corr_width</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>


    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">scales</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Average Texture Statistics representations of two image</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        image : torch.Tensor</span>
<span class="sd">            A 4d tensor (batch, channel, height, width) containing the image(s) to</span>
<span class="sd">            analyze.</span>
<span class="sd">        scales : list, optional</span>
<span class="sd">            Which scales to include in the returned representation. If an empty</span>
<span class="sd">            list (the default), we include all scales. Otherwise, can contain</span>
<span class="sd">            subset of values present in this model&#39;s ``scales`` attribute.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        representation_tensor: torch.Tensor</span>
<span class="sd">            3d tensor of shape (batch, channel, stats) containing the measured</span>
<span class="sd">            texture statistics.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">stats</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">scales</span><span class="o">=</span><span class="n">scales</span><span class="p">)</span>
        <span class="c1"># this helper function returns a list of tensors containing the steerable</span>
        <span class="c1"># pyramid coefficients at each scale</span>
        <span class="n">pyr_coeffs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_pyr_coeffs</span><span class="p">(</span><span class="n">image</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
        <span class="c1"># only compute the magnitudes for the desired scales</span>
        <span class="n">magnitude_pyr_coeffs</span> <span class="o">=</span> <span class="p">[</span><span class="n">coeff</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">coeff</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">pyr_coeffs</span><span class="p">)</span>
                                <span class="k">if</span> <span class="n">scales</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">scales</span><span class="p">]</span>
        <span class="n">magnitude_means</span> <span class="o">=</span> <span class="p">[</span><span class="n">mag</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="k">for</span> <span class="n">mag</span> <span class="ow">in</span> <span class="n">magnitude_pyr_coeffs</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">einops</span><span class="o">.</span><span class="n">pack</span><span class="p">([</span><span class="n">stats</span><span class="p">,</span> <span class="o">*</span><span class="n">magnitude_means</span><span class="p">],</span> <span class="s1">&#39;b c *&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># overwriting these following two methods allows us to use the plot_representation method</span>
    <span class="c1"># with the modified model, making examining it easier.</span>
    <span class="k">def</span> <span class="nf">convert_to_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">representation_tensor</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">OrderedDict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Convert tensor of stats to dictionary.&quot;&quot;&quot;</span>
        <span class="n">n_mag_means</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_orientations</span>
        <span class="n">rep</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">convert_to_dict</span><span class="p">(</span><span class="n">representation_tensor</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="o">-</span><span class="n">n_mag_means</span><span class="p">])</span>
        <span class="n">mag_means</span> <span class="o">=</span> <span class="n">representation_tensor</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="o">-</span><span class="n">n_mag_means</span><span class="p">:]</span>
        <span class="n">rep</span><span class="p">[</span><span class="s1">&#39;magnitude_means&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">einops</span><span class="o">.</span><span class="n">rearrange</span><span class="p">(</span><span class="n">mag_means</span><span class="p">,</span> <span class="s1">&#39;b c (s o) -&gt; b c s o&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_scales</span><span class="p">,</span> <span class="n">o</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_orientations</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">rep</span>

    <span class="k">def</span> <span class="nf">_representation_for_plotting</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rep</span><span class="p">:</span> <span class="n">OrderedDict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">OrderedDict</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Convert the data into a dictionary representation that is more convenient for plotting.</span>

<span class="sd">        Intended as a helper function for plot_representation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">mag_means</span> <span class="o">=</span> <span class="n">rep</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;magnitude_means&#39;</span><span class="p">)</span>
        <span class="n">data</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_representation_for_plotting</span><span class="p">(</span><span class="n">rep</span><span class="p">)</span>
        <span class="n">data</span><span class="p">[</span><span class="s1">&#39;magnitude_means&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">mag_means</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">data</span>
</pre></div>
</div>
</div>
<p>Now, let’s initialize our models and images for synthesis:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[54]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">img</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">load_images</span><span class="p">(</span><span class="n">DATA_PATH</span> <span class="o">/</span> <span class="s1">&#39;fig4a.jpg&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">simul</span><span class="o">.</span><span class="n">PortillaSimoncelli</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:],</span> <span class="n">spatial_corr_width</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">model_mag_means</span> <span class="o">=</span> <span class="n">PortillaSimoncelliMagMeans</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">im_init</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand_like</span><span class="p">(</span><span class="n">img</span><span class="p">)</span><span class="o">-</span><span class="mf">.5</span><span class="p">)</span> <span class="o">*</span> <span class="mf">.1</span> <span class="o">+</span> <span class="n">img</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<p>And run the synthesis with the regular model, which does not include the mean of the steerable pyramid magnitudes, and then the augmented model, which does.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[55]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the RNG seed to make the two synthesis procedures as similar as possible.</span>
<span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">met</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">synth</span><span class="o">.</span><span class="n">MetamerCTF</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss_function</span><span class="o">=</span><span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">l2_norm</span><span class="p">,</span> <span class="n">initial_image</span><span class="o">=</span><span class="n">im_init</span><span class="p">)</span>
<span class="n">met</span><span class="o">.</span><span class="n">synthesize</span><span class="p">(</span><span class="n">store_progress</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="n">short_synth_max_iter</span><span class="p">,</span> <span class="n">change_scale_criterion</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ctf_iters_to_check</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>

<span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">met_mag_means</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">synth</span><span class="o">.</span><span class="n">MetamerCTF</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">model_mag_means</span><span class="p">,</span> <span class="n">loss_function</span><span class="o">=</span><span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">l2_norm</span><span class="p">,</span> <span class="n">initial_image</span><span class="o">=</span><span class="n">im_init</span><span class="p">)</span>
<span class="n">met_mag_means</span><span class="o">.</span><span class="n">synthesize</span><span class="p">(</span><span class="n">store_progress</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="n">short_synth_max_iter</span><span class="p">,</span> <span class="n">change_scale_criterion</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ctf_iters_to_check</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
 73%|███████▎  | 730/1000 [00:26&lt;00:09, 27.31it/s, loss=7.9080e-02, learning_rate=0.01, gradient_norm=8.2237e-01, pixel_change_norm=1.6330e-01, current_scale=all, current_scale_loss=7.9080e-02]
 81%|████████  | 806/1000 [00:32&lt;00:07, 24.49it/s, loss=8.1238e-02, learning_rate=0.01, gradient_norm=8.3931e-01, pixel_change_norm=1.5536e-01, current_scale=all, current_scale_loss=8.1238e-02]
</pre></div></div>
</div>
<p>Now let’s examine the outputs. In the following plot, we display the synthesized metamer and the representation error for the metamer synthesized with and without explicitly constraining the magnitude means.</p>
<ul class="simple">
<li><p>The two synthesized metamers appear almost identical, so including the magnitude means does not substantially change the resulting metamer at all, let alone improve its visual quality.</p></li>
<li><p>The representation errors are (as we’d expect) also very similar. Let’s focus on the plot in the bottom right, labeled “magnitude_means”. Each stem shows the mean of one of the magnitude bands, with the scales increasing from left to right. Looking at the representation error for the first image, we can see that, even without explicitly including the means, the error in this statistic is on the same magnitude as the other statistics, showing that it is being implicitly constrained. By
comparing to the error for the second image, we can see that the error in the magnitude means does decrease, most notably in the coarsest scales.</p></li>
</ul>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[56]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">21</span><span class="p">,</span> <span class="mi">11</span><span class="p">),</span> <span class="n">gridspec_kw</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;width_ratios&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mf">3.1</span><span class="p">]})</span>
<span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">im</span><span class="p">,</span> <span class="n">info</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axes</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="n">met</span><span class="o">.</span><span class="n">metamer</span><span class="p">,</span> <span class="n">met_mag_means</span><span class="o">.</span><span class="n">metamer</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;with&#39;</span><span class="p">,</span> <span class="s1">&#39;without&#39;</span><span class="p">]):</span>
    <span class="n">po</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Metamer </span><span class="si">{</span><span class="n">info</span><span class="si">}</span><span class="s2"> magnitude means&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="n">model_mag_means</span><span class="o">.</span><span class="n">plot_representation</span><span class="p">(</span><span class="n">model_mag_means</span><span class="p">(</span><span class="n">met</span><span class="o">.</span><span class="n">metamer</span><span class="p">)</span><span class="o">-</span><span class="n">model_mag_means</span><span class="p">(</span><span class="n">img</span><span class="p">),</span> <span class="n">ylim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mf">.06</span><span class="p">,</span> <span class="mf">.06</span><span class="p">),</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]);</span>
<span class="n">model_mag_means</span><span class="o">.</span><span class="n">plot_representation</span><span class="p">(</span><span class="n">model_mag_means</span><span class="p">(</span><span class="n">met_mag_means</span><span class="o">.</span><span class="n">metamer</span><span class="p">)</span><span class="o">-</span><span class="n">model_mag_means</span><span class="p">(</span><span class="n">img</span><span class="p">),</span> <span class="n">ylim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mf">.06</span><span class="p">,</span> <span class="mf">.06</span><span class="p">),</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_models_Metamer-Portilla-Simoncelli_96_0.png" src="../../_images/tutorials_models_Metamer-Portilla-Simoncelli_96_0.png" />
</div>
</div>
<p>Thus, we can feel fairly confident in excluding these magnitude means from the model. Note this follows the same logic as earlier in the notebook, when we tried removing different statistics to see their effect; here, we tried <em>adding</em> a statistic to determine its effect. Feel free to try using other target images or adding other statistics!</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="04_Perceptual_distance.html" class="btn btn-neutral float-left" title="Perceptual distance" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../applications/09_Original_MAD.html" class="btn btn-neutral float-right" title="Reproducing Wang and Simoncelli, 2008 (MAD Competition)" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2019, Plenoptic authors.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>