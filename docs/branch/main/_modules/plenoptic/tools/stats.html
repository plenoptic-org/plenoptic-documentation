

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>plenoptic.tools.stats &mdash; plenoptic 1.3.2.dev55 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../../_static/plot_directive.css" />
      <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css?v=13237357" />
      <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
      <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-design.min.css?v=95c83b7e" />
      <link rel="stylesheet" type="text/css" href="../../../_static/custom.css?v=a2d047e6" />

  
      <script src="../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../../_static/documentation_options.js?v=dfd67d65"></script>
      <script src="../../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../../../_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="../../../_static/copybutton.js?v=35a8b989"></script>
      <script>let toggleHintShow = 'Click to show';</script>
      <script>let toggleHintHide = 'Click to hide';</script>
      <script>let toggleOpenOnPrint = 'true';</script>
      <script src="../../../_static/togglebutton.js?v=4a39c7ea"></script>
      <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
      <script src="../../../_static/design-tabs.js?v=f930bc37"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html" class="icon icon-home">
            plenoptic
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Basic concepts</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../install.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../jupyter.html">Using Jupyter to Run Example Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../conceptual_intro.html">Conceptual Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../models.html">Model requirements</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/quickstart.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../citation.html">Citation Guide and Bibliography</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Synthesis method introductions</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/intro/Eigendistortions.html">Eigendistortions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/intro/MAD_Competition_1.html">MAD Competition Conceptual Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/intro/MAD_Competition_2.html">MAD Competition Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/intro/Metamer.html">Metamers</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Models and metrics</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/models/Perceptual_distance.html">Perceptual distance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/models/Portilla_Simoncelli.html">Portilla-Simoncelli Texture Metamer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/models/Steerable_Pyramid.html">Steerable Pyramid</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Synthesis method examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/applications/Demo_Eigendistortion.html">Reproducing Berardino et al., 2017 (Eigendistortions)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/applications/Original_MAD.html">Reproducing Wang and Simoncelli, 2008 (MAD Competition)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced usage</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../synthesis.html">Synthesis object design</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tips.html">Tips and Tricks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../reproducibility.html">Reproducibility and Compatibility</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/modules.html">API Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/advanced/Display.html">Display and animate functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/advanced/Synthesis_extensions.html">Extending existing synthesis objects</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">plenoptic</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">plenoptic.tools.stats</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for plenoptic.tools.stats</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;Functions for computing image statistics on multi-dimensional tensors.&quot;&quot;&quot;</span>

<span class="c1"># numpydoc ignore=ES01</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">Tensor</span>


<div class="viewcode-block" id="variance">
<a class="viewcode-back" href="../../../api/plenoptic.tools.html#plenoptic.tools.stats.variance">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">variance</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">mean</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">keepdim</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate sample variance.</span>

<span class="sd">    Note that this is the uncorrected, or sample, variance, corresponding to</span>
<span class="sd">    ``torch.var(*, correction=0)``.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x</span>
<span class="sd">        The input tensor.</span>
<span class="sd">    mean</span>
<span class="sd">        Reuse a precomputed mean.</span>
<span class="sd">    dim</span>
<span class="sd">        The dimension or dimensions to reduce.</span>
<span class="sd">    keepdim</span>
<span class="sd">        Whether to retain the reduced dimensions (as singletons) or not.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    out</span>
<span class="sd">        The variance tensor.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    skew</span>
<span class="sd">        Calculate sample skewness.</span>
<span class="sd">    kurtosis</span>
<span class="sd">        Calculate sample kurtosis.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    .. plot::</span>

<span class="sd">        &gt;&gt;&gt; import matplotlib.pyplot as plt</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>
<span class="sd">        &gt;&gt;&gt; from plenoptic.tools.stats import variance</span>
<span class="sd">        &gt;&gt;&gt; from plenoptic.tools import set_seed</span>
<span class="sd">        &gt;&gt;&gt; set_seed(42)</span>
<span class="sd">        &gt;&gt;&gt; x = torch.randn(10000)</span>
<span class="sd">        &gt;&gt;&gt; v = variance(x)</span>
<span class="sd">        &gt;&gt;&gt; x_more = x * 3</span>
<span class="sd">        &gt;&gt;&gt; v_more = variance(x_more)</span>
<span class="sd">        &gt;&gt;&gt; x_less = x * 0.3</span>
<span class="sd">        &gt;&gt;&gt; v_less = variance(x_less)</span>
<span class="sd">        &gt;&gt;&gt; fig, (ax_less, ax, ax_more) = plt.subplots(</span>
<span class="sd">        ...     1, 3, sharex=True, sharey=True, figsize=(12, 4)</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; _ = ax_less.hist(x_less, bins=50)</span>
<span class="sd">        &gt;&gt;&gt; _ = ax_less.set(title=f&quot;σ=0.3\nVariance: {v_less:.4f}&quot;, ylabel=&quot;Frequency&quot;)</span>
<span class="sd">        &gt;&gt;&gt; _ = ax.hist(x, bins=50)</span>
<span class="sd">        &gt;&gt;&gt; _ = ax.set(title=f&quot;Standard Gaussian, σ=1\nVariance: {v:.4f}&quot;)</span>
<span class="sd">        &gt;&gt;&gt; _ = ax_more.hist(x_more, bins=50)</span>
<span class="sd">        &gt;&gt;&gt; _ = ax_more.set(title=f&quot;σ=3\nVariance: {v_more:.4f}&quot;)</span>

<span class="sd">    If you have precomputed the mean, you can pass it and avoid recomputing it:</span>

<span class="sd">    &gt;&gt;&gt; precomputed_mean = torch.mean(x)</span>
<span class="sd">    &gt;&gt;&gt; v = variance(x, mean=precomputed_mean)</span>
<span class="sd">    &gt;&gt;&gt; v</span>
<span class="sd">    tensor(1.0088)</span>

<span class="sd">    If you want to compute along a specific dimension, you can specify it:</span>

<span class="sd">    &gt;&gt;&gt; x = torch.randn(10000, 2)</span>
<span class="sd">    &gt;&gt;&gt; v = variance(x, dim=0)</span>
<span class="sd">    &gt;&gt;&gt; v</span>
<span class="sd">    tensor([1.0127, 1.0045])</span>

<span class="sd">    This function differs from :func:`torch.var` in that it does not apply a correction:</span>

<span class="sd">    &gt;&gt;&gt; plenoptic_v_corrected = v * x.shape[0] / (x.shape[0] - 1)</span>
<span class="sd">    &gt;&gt;&gt; torch_v = torch.var(x, dim=0)</span>
<span class="sd">    &gt;&gt;&gt; torch.isclose(plenoptic_v_corrected, torch_v)</span>
<span class="sd">    tensor([True, True])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">dim</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">dim</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">ndim</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">mean</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">x</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="n">keepdim</span><span class="p">)</span></div>



<div class="viewcode-block" id="skew">
<a class="viewcode-back" href="../../../api/plenoptic.tools.html#plenoptic.tools.stats.skew">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">skew</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">mean</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">var</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">keepdim</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate sample estimate of *asymmetry* about input&#39;s mean.</span>

<span class="sd">    To help with interpretation:</span>

<span class="sd">    - Skew of normal distribution is 0.</span>

<span class="sd">    - Negative skew, also known as left-skewed: the left tail is longer. Distribution</span>
<span class="sd">      appears as a right-leaning curve.</span>

<span class="sd">    - Positive skew, also known as right-skewed: the right tail is longer. Distribution</span>
<span class="sd">      appears as a left-leaning curve.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x</span>
<span class="sd">        The input tensor.</span>
<span class="sd">    mean</span>
<span class="sd">        Reuse a precomputed mean.</span>
<span class="sd">    var</span>
<span class="sd">        Reuse a precomputed variance.</span>
<span class="sd">    dim</span>
<span class="sd">        The dimension or dimensions to reduce.</span>
<span class="sd">    keepdim</span>
<span class="sd">        Whether to retain the reduced dimensions (as singletons) or not.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    out</span>
<span class="sd">        The skewness tensor.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    variance</span>
<span class="sd">        Calculate sample variance.</span>
<span class="sd">    kurtosis</span>
<span class="sd">        Calculate sample kurtosis.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    .. plot::</span>

<span class="sd">        &gt;&gt;&gt; import matplotlib.pyplot as plt</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>
<span class="sd">        &gt;&gt;&gt; from plenoptic.tools.stats import skew</span>
<span class="sd">        &gt;&gt;&gt; from plenoptic.tools import set_seed</span>
<span class="sd">        &gt;&gt;&gt; set_seed(42)</span>
<span class="sd">        &gt;&gt;&gt; x = torch.randn(10000)</span>
<span class="sd">        &gt;&gt;&gt; s = skew(x)</span>
<span class="sd">        &gt;&gt;&gt; x_right = torch.exp(x / 2)</span>
<span class="sd">        &gt;&gt;&gt; s_right = skew(x_right)</span>
<span class="sd">        &gt;&gt;&gt; x_left = -torch.exp(x / 2)</span>
<span class="sd">        &gt;&gt;&gt; s_left = skew(x_left)</span>
<span class="sd">        &gt;&gt;&gt; fig, (ax_left, ax, ax_right) = plt.subplots(</span>
<span class="sd">        ...     1, 3, sharex=True, figsize=(12, 4)</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; _ = ax_left.hist(x_left, bins=50)</span>
<span class="sd">        &gt;&gt;&gt; _ = ax_left.set(</span>
<span class="sd">        ...     title=f&quot;Left skew: {s_left:.4f}&quot;, ylabel=&quot;Frequency&quot;, xlim=(-5, 5)</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; _ = ax.hist(x, bins=50)</span>
<span class="sd">        &gt;&gt;&gt; _ = ax.set(title=f&quot;Standard Gaussian\nSkew: {s:.4f}&quot;)</span>
<span class="sd">        &gt;&gt;&gt; _ = ax_right.hist(x_right, bins=50)</span>
<span class="sd">        &gt;&gt;&gt; _ = ax_right.set(title=f&quot;Right skew: {s_right:.4f}&quot;)</span>

<span class="sd">    If you have precomputed the mean and/or variance,</span>
<span class="sd">    you can pass them and avoid recomputing:</span>

<span class="sd">    &gt;&gt;&gt; precomputed_mean = torch.mean(x)</span>
<span class="sd">    &gt;&gt;&gt; precomputed_var = variance(x)</span>
<span class="sd">    &gt;&gt;&gt; s = skew(x, mean=precomputed_mean, var=precomputed_var)</span>
<span class="sd">    &gt;&gt;&gt; s</span>
<span class="sd">    tensor(-0.0010)</span>

<span class="sd">    If you want to compute along a specific dimension, you can specify it:</span>

<span class="sd">    &gt;&gt;&gt; x = torch.randn(10000, 2)</span>
<span class="sd">    &gt;&gt;&gt; s = skew(x, dim=0)</span>
<span class="sd">    &gt;&gt;&gt; s</span>
<span class="sd">    tensor([-0.0257, -0.0063])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">dim</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">dim</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">ndim</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">mean</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">var</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">var</span> <span class="o">=</span> <span class="n">variance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="n">keepdim</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">x</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="n">keepdim</span><span class="p">)</span> <span class="o">/</span> <span class="n">var</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mf">1.5</span><span class="p">)</span></div>



<div class="viewcode-block" id="kurtosis">
<a class="viewcode-back" href="../../../api/plenoptic.tools.html#plenoptic.tools.stats.kurtosis">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">kurtosis</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">mean</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">var</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">keepdim</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate sample estimate of *tailedness* (presence of outliers).</span>

<span class="sd">    To help with interpretation:</span>

<span class="sd">    - Kurtosis of univariate normal is 3.</span>

<span class="sd">    - Smaller than 3: *platykurtic* (e.g. uniform distribution).</span>

<span class="sd">    - Greater than 3: *leptokurtic* (e.g. Laplace distribution).</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x</span>
<span class="sd">        The input tensor.</span>
<span class="sd">    mean</span>
<span class="sd">        Reuse a precomputed mean.</span>
<span class="sd">    var</span>
<span class="sd">        Reuse a precomputed variance.</span>
<span class="sd">    dim</span>
<span class="sd">        The dimension or dimensions to reduce.</span>
<span class="sd">    keepdim</span>
<span class="sd">        Whether to retain the reduced dimensions (as singletons) or not.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    out</span>
<span class="sd">        The kurtosis tensor.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    variance</span>
<span class="sd">        Calculate sample variance.</span>
<span class="sd">    skew</span>
<span class="sd">        Calculate sample skewness.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    .. plot::</span>

<span class="sd">        &gt;&gt;&gt; import matplotlib.pyplot as plt</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>
<span class="sd">        &gt;&gt;&gt; from plenoptic.tools.stats import kurtosis</span>
<span class="sd">        &gt;&gt;&gt; from plenoptic.tools import set_seed</span>
<span class="sd">        &gt;&gt;&gt; set_seed(42)</span>
<span class="sd">        &gt;&gt;&gt; x = torch.randn(10000)</span>
<span class="sd">        &gt;&gt;&gt; k = kurtosis(x)</span>
<span class="sd">        &gt;&gt;&gt; x_platy = torch.rand(10000) * 10 - 5</span>
<span class="sd">        &gt;&gt;&gt; k_platy = kurtosis(x_platy)</span>
<span class="sd">        &gt;&gt;&gt; x_lepto = torch.distributions.Laplace(loc=0.0, scale=1.0).sample((10000,))</span>
<span class="sd">        &gt;&gt;&gt; k_lepto = kurtosis(x_lepto)</span>
<span class="sd">        &gt;&gt;&gt; fig, (ax_platy, ax, ax_lepto) = plt.subplots(</span>
<span class="sd">        ...     1, 3, sharex=True, figsize=(12, 4)</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; _ = ax_platy.hist(x_platy.numpy(), bins=50)</span>
<span class="sd">        &gt;&gt;&gt; _ = ax_platy.set(</span>
<span class="sd">        ...     title=f&quot;Platykurtic (Uniform)\nKurtosis: {k_platy:.4f}&quot;,</span>
<span class="sd">        ...     ylabel=&quot;Frequency&quot;,</span>
<span class="sd">        ...     xlim=(-5, 5),</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; _ = ax.hist(x.numpy(), bins=50)</span>
<span class="sd">        &gt;&gt;&gt; _ = ax.set(title=f&quot;Standard Gaussian\nKurtosis: {k:.4f}&quot;)</span>
<span class="sd">        &gt;&gt;&gt; _ = ax_lepto.hist(x_lepto.numpy(), bins=50)</span>
<span class="sd">        &gt;&gt;&gt; _ = ax_lepto.set(title=f&quot;Leptokurtic (Laplace)\nKurtosis: {k_lepto:.4f}&quot;)</span>

<span class="sd">    If you have precomputed the mean and/or variance,</span>
<span class="sd">    you can pass them and avoid recomputing:</span>

<span class="sd">    &gt;&gt;&gt; precomputed_mean = torch.mean(x)</span>
<span class="sd">    &gt;&gt;&gt; precomputed_var = variance(x)</span>
<span class="sd">    &gt;&gt;&gt; k = kurtosis(x, mean=precomputed_mean, var=precomputed_var)</span>
<span class="sd">    &gt;&gt;&gt; k</span>
<span class="sd">    tensor(2.9354)</span>

<span class="sd">    If you want to compute along a specific dimension, you can specify it:</span>

<span class="sd">    &gt;&gt;&gt; x = torch.randn(10000, 2)</span>
<span class="sd">    &gt;&gt;&gt; k = kurtosis(x, dim=0)</span>
<span class="sd">    &gt;&gt;&gt; k</span>
<span class="sd">    tensor([3.0057, 2.9506])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">dim</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">dim</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">ndim</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">mean</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">var</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">var</span> <span class="o">=</span> <span class="n">variance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="n">keepdim</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="n">keepdim</span><span class="p">)</span> <span class="o">/</span> <span class="n">var</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span></div>

</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2019-2025, Plenoptic authors.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>