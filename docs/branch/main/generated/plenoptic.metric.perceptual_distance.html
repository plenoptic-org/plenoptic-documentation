
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>plenoptic.metric.perceptual_distance &#8212; plenoptic 1.3.2.dev304 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=9c3e77be" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=d54d67fd" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../_static/documentation_options.js?v=69473dd2"></script>
    <script src="../_static/doctools.js?v=fd6eb6e6"></script>
    <script src="../_static/sphinx_highlight.js?v=6ffebe34"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=6dbb43f8"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=1ae7504c"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@4/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'generated/plenoptic.metric.perceptual_distance';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_version = '0.16.1';
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = 'https://docs.plenoptic.org/docs/branch/main/_static/version_switcher.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = '1.3.2';
        DOCUMENTATION_OPTIONS.show_version_warning_banner =
            true;
        </script>
    <script src="../_static/custom-icon.js?v=0bae05a2"></script>
    <link rel="icon" href="../_static/plenoptic.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="plenoptic.synthesize.metamer" href="plenoptic.synthesize.metamer.html" />
    <link rel="prev" title="plenoptic.metric.model_metric" href="plenoptic.metric.model_metric.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="1.3.2" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/Plenoptic_Logo_CMYK_Full_Wide.svg" class="logo__image only-light" alt="plenoptic 1.3.2.dev304 documentation - Home"/>
    <img src="../_static/Plenoptic_Logo_CMYK_Full_DarkMode_Wide.svg" class="logo__image only-dark pst-js-only" alt="plenoptic 1.3.2.dev304 documentation - Home"/>
  
  
</a></div>
    
      <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-2"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-2"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-2"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-2">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../getting_started/index.html">
    Getting started
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../user_guide/index.html">
    User Guide
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../api.html">
    API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../reference/index.html">
    Reference
  </a>
</li>

            <li class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button"
                data-bs-toggle="dropdown" aria-expanded="false"
                aria-controls="pst-nav-more-links">
                    More
                </button>
                <ul id="pst-nav-more-links" class="dropdown-menu">
                    
<li class=" ">
  <a class="nav-link dropdown-item nav-external" href="https://github.com/plenoptic-org/plenoptic/releases">
    Changelog
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../developers/index.html">
    For developers
  </a>
</li>

                </ul>
            </li>
            
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://plenoptic.org" title="Home" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-solid fa-house fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Home</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/plenoptic-org/plenoptic" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fab fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/plenoptic" title="PyPI" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-custom fa-pypi fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPI</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar hide-on-wide">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../getting_started/index.html">
    Getting started
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../user_guide/index.html">
    User Guide
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../api.html">
    API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../reference/index.html">
    Reference
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://github.com/plenoptic-org/plenoptic/releases">
    Changelog
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../developers/index.html">
    For developers
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://plenoptic.org" title="Home" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-solid fa-house fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Home</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/plenoptic-org/plenoptic" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fab fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/plenoptic" title="PyPI" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-custom fa-pypi fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPI</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../api.html" class="nav-link">API</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">plenoptic.metric.perceptual_distance</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="module-plenoptic.metric.perceptual_distance">
<span id="plenoptic-metric-perceptual-distance"></span><h1>plenoptic.metric.perceptual_distance<a class="headerlink" href="#module-plenoptic.metric.perceptual_distance" title="Link to this heading">#</a></h1>
<p>Metrics designed to model human perceptual distance.</p>
<p>Metrics that model human perceptual distance seek to answer the question “how different
do humans find these two images?”.</p>
<p class="rubric">Functions</p>
<div class="pst-scrollable-table-container"><table class="autosummary longtable table">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#plenoptic.metric.perceptual_distance.ms_ssim" title="plenoptic.metric.perceptual_distance.ms_ssim"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ms_ssim</span></code></a>(img1, img2[, power_factors])</p></td>
<td><p>Multiscale structural similarity index (MS-SSIM).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#plenoptic.metric.perceptual_distance.nlpd" title="plenoptic.metric.perceptual_distance.nlpd"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nlpd</span></code></a>(img1, img2)</p></td>
<td><p>Compute the normalized Laplacian Pyramid Distance.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#plenoptic.metric.perceptual_distance.normalized_laplacian_pyramid" title="plenoptic.metric.perceptual_distance.normalized_laplacian_pyramid"><code class="xref py py-obj docutils literal notranslate"><span class="pre">normalized_laplacian_pyramid</span></code></a>(img)</p></td>
<td><p>Compute the normalized Laplacian Pyramid using pre-optimized parameters.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#plenoptic.metric.perceptual_distance.ssim" title="plenoptic.metric.perceptual_distance.ssim"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ssim</span></code></a>(img1, img2[, weighted, pad])</p></td>
<td><p>Compute the structural similarity index.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#plenoptic.metric.perceptual_distance.ssim_map" title="plenoptic.metric.perceptual_distance.ssim_map"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ssim_map</span></code></a>(img1, img2)</p></td>
<td><p>Structural similarity index map.</p></td>
</tr>
</tbody>
</table>
</div>
<dl class="py function">
<dt class="sig sig-object py" id="plenoptic.metric.perceptual_distance.ssim">
<span class="sig-name descname"><span class="pre">ssim</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">img2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weighted</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/metric/perceptual_distance.html#ssim"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.metric.perceptual_distance.ssim" title="Link to this definition">#</a></dt>
<dd><p>Compute the structural similarity index.</p>
<p>As described in Wang et al., 2004 <a class="footnote-reference brackets" href="#id8" id="id1" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a>, the structural similarity index (SSIM) is a
perceptual distance metric, giving the distance between two images. SSIM is based on
three comparison measurements between the two images: luminance, contrast, and
structure. All of these are computed convolutionally across the images. See the
references for more information.</p>
<p>This implementation follows the original implementation, as found online <a class="footnote-reference brackets" href="#id9" id="id2" role="doc-noteref"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></a>, as
well as providing the option to use the weighted version used in Wang and
Simoncelli, 2008 <a class="footnote-reference brackets" href="#id11" id="id3" role="doc-noteref"><span class="fn-bracket">[</span>4<span class="fn-bracket">]</span></a> (which was shown to consistently improve the image quality
prediction on the LIVE database). More info can be found online <a class="footnote-reference brackets" href="#id10" id="id4" role="doc-noteref"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></a>.</p>
<p>Note that this is a similarity metric (not a distance), and so 1 means the
two images are identical and 0 means they’re very different. When the two
images are negatively correlated, SSIM can be negative. SSIM is bounded
between -1 and 1.</p>
<p>This function returns the mean SSIM, a scalar-valued metric giving the
average over the whole image. For the SSIM map (showing the computed value
across the image), call <a class="reference internal" href="#plenoptic.metric.perceptual_distance.ssim_map" title="plenoptic.metric.perceptual_distance.ssim_map"><code class="xref py py-func docutils literal notranslate"><span class="pre">ssim_map</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>img1</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – The first image or batch of images, of shape (batch, channel, height, width).</p></li>
<li><p><strong>img2</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – The second image or batch of images, of shape (batch, channel, height, width).
The heights and widths of <code class="docutils literal notranslate"><span class="pre">img1</span></code> and <code class="docutils literal notranslate"><span class="pre">img2</span></code> must be the same. The numbers of
batches and channels of <code class="docutils literal notranslate"><span class="pre">img1</span></code> and <code class="docutils literal notranslate"><span class="pre">img2</span></code> need to be broadcastable: either
they are the same or one of them is 1. The output will be computed separately
for each channel (so channels are treated in the same way as batches). Both
images should have values between 0 and 1. Otherwise, the result may be
inaccurate, and we will raise a warning (but will still compute it).</p></li>
<li><p><strong>weighted</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span> (default: <code class="docutils literal notranslate"><span class="pre">False</span></code>)) – Whether to use the original, unweighted SSIM version (<code class="docutils literal notranslate"><span class="pre">False</span></code>) as used
in <a class="footnote-reference brackets" href="#id8" id="id5" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a> or the weighted version (<code class="docutils literal notranslate"><span class="pre">True</span></code>) as used in <a class="footnote-reference brackets" href="#id11" id="id6" role="doc-noteref"><span class="fn-bracket">[</span>4<span class="fn-bracket">]</span></a>. See Notes
section for the weight.</p></li>
<li><p><strong>pad</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Literal" title="(in Python v3.14)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Literal</span></code></a>[<code class="docutils literal notranslate"><span class="pre">False</span></code>, <code class="docutils literal notranslate"><span class="pre">'constant'</span></code>, <code class="docutils literal notranslate"><span class="pre">'reflect'</span></code>, <code class="docutils literal notranslate"><span class="pre">'replicate'</span></code>, <code class="docutils literal notranslate"><span class="pre">'circular'</span></code>]</span> (default: <code class="docutils literal notranslate"><span class="pre">False</span></code>)) – If not <code class="docutils literal notranslate"><span class="pre">False</span></code>, how to pad the image for the convolutions computing the
local average of each image. See <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.functional.pad.html#torch.nn.functional.pad" title="(in PyTorch v2.10)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.nn.functional.pad</span></code></a> for how
these work.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>mssim</em> – 2d tensor of shape (batch, channel) containing the mean SSIM for each
image, averaged over the whole image.</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.14)"><strong>ValueError</strong></a> – If either <code class="docutils literal notranslate"><span class="pre">img1</span></code> or <code class="docutils literal notranslate"><span class="pre">img2</span></code> is not 4d.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.14)"><strong>ValueError</strong></a> – If <code class="docutils literal notranslate"><span class="pre">img1</span></code> and <code class="docutils literal notranslate"><span class="pre">img2</span></code> have different height or width.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.14)"><strong>ValueError</strong></a> – If <code class="docutils literal notranslate"><span class="pre">img1</span></code> and <code class="docutils literal notranslate"><span class="pre">img2</span></code> have different batch or channel, unless one of them has
    a 1 there, so they can be broadcast.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.14)"><strong>ValueError</strong></a> – If <code class="docutils literal notranslate"><span class="pre">img1</span></code> and <code class="docutils literal notranslate"><span class="pre">img2</span></code> have different dtypes.</p></li>
</ul>
</dd>
<dt class="field-odd">Warns<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>UserWarning</strong> – If either <code class="docutils literal notranslate"><span class="pre">img1</span></code> or <code class="docutils literal notranslate"><span class="pre">img2</span></code> has multiple channels, as SSIM was designed for
grayscale images.</p></li>
<li><p><strong>UserWarning</strong> – If at least one scale from either <code class="docutils literal notranslate"><span class="pre">img1</span></code> or <code class="docutils literal notranslate"><span class="pre">img2</span></code> has height or width of
less than 11, since SSIM uses an 11x11 convolutional kernel.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The weight used when <code class="docutils literal notranslate"><span class="pre">weighted=True</span></code> is:</p>
<div class="math notranslate nohighlight">
\[\log((1+\frac{\sigma_1^2}{C_2})(1+\frac{\sigma_2^2}{C_2}))\]</div>
<p>where <span class="math notranslate nohighlight">\(\sigma_1^2\)</span> and <span class="math notranslate nohighlight">\(\sigma_2^2\)</span> are the variances of <code class="docutils literal notranslate"><span class="pre">img1</span></code>
and <code class="docutils literal notranslate"><span class="pre">img2</span></code>, respectively, and <span class="math notranslate nohighlight">\(C_2\)</span> is a constant. See <a class="footnote-reference brackets" href="#id11" id="id7" role="doc-noteref"><span class="fn-bracket">[</span>4<span class="fn-bracket">]</span></a> for more
details.</p>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id8" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id1">1</a>,<a role="doc-backlink" href="#id5">2</a>)</span>
<p>Z. Wang, A. C. Bovik, H. R. Sheikh, and E. P. Simoncelli, “Image
quality assessment: From error measurement to structural similarity”
IEEE Transactions on Image Processing, vol. 13, no. 1, Jan. 2004.</p>
</aside>
<aside class="footnote brackets" id="id9" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">2</a><span class="fn-bracket">]</span></span>
<p>matlab code: <a class="reference external" href="https://www.cns.nyu.edu/~lcv/ssim/ssim_index.m">https://www.cns.nyu.edu/~lcv/ssim/ssim_index.m</a></p>
</aside>
<aside class="footnote brackets" id="id10" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id4">3</a><span class="fn-bracket">]</span></span>
<p>project page: <a class="reference external" href="https://www.cns.nyu.edu/~lcv/ssim/">https://www.cns.nyu.edu/~lcv/ssim/</a></p>
</aside>
<aside class="footnote brackets" id="id11" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>4<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id3">1</a>,<a role="doc-backlink" href="#id6">2</a>,<a role="doc-backlink" href="#id7">3</a>)</span>
<p>Wang, Z., &amp; Simoncelli, E. P. (2008). Maximum differentiation (MAD)
competition: A methodology for comparing computational models of
perceptual discriminability. Journal of Vision, 8(12), 1–13.
<a class="reference external" href="https://dx.doi.org/10.1167/8.12.8">https://dx.doi.org/10.1167/8.12.8</a></p>
</aside>
</aside>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">plenoptic</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">po</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">einstein</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">po</span><span class="o">.</span><span class="n">metric</span><span class="o">.</span><span class="n">ssim</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">img</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand_like</span><span class="p">(</span><span class="n">img</span><span class="p">))</span>
<span class="go">tensor([[0.0519]])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="plenoptic.metric.perceptual_distance.ssim_map">
<span class="sig-name descname"><span class="pre">ssim_map</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">img2</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/metric/perceptual_distance.html#ssim_map"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.metric.perceptual_distance.ssim_map" title="Link to this definition">#</a></dt>
<dd><p>Structural similarity index map.</p>
<p>As described in Wang et al., 2004 <a class="footnote-reference brackets" href="#id16" id="id12" role="doc-noteref"><span class="fn-bracket">[</span>5<span class="fn-bracket">]</span></a>, the structural similarity index (SSIM) is a
perceptual distance metric, giving the distance between two images. SSIM is based on
three comparison measurements between the two images: luminance, contrast, and
structure. All of these are computed convolutionally across the images. See the
references for more information.</p>
<p>This implementation follows the original implementation, as found online <a class="footnote-reference brackets" href="#id17" id="id13" role="doc-noteref"><span class="fn-bracket">[</span>6<span class="fn-bracket">]</span></a>, as
well as providing the option to use the weighted version used in Wang and
Simoncelli, 2008 <a class="footnote-reference brackets" href="#id21" id="id14" role="doc-noteref"><span class="fn-bracket">[</span>8<span class="fn-bracket">]</span></a> (which was shown to consistently improve the image quality
prediction on the LIVE database). More info can be found online <a class="footnote-reference brackets" href="#id19" id="id15" role="doc-noteref"><span class="fn-bracket">[</span>7<span class="fn-bracket">]</span></a>.</p>
<p>Note that this is a similarity metric (not a distance), and so 1 means the
two images are identical and 0 means they’re very different. When the two
images are negatively correlated, SSIM can be negative. SSIM is bounded
between -1 and 1.</p>
<p>This function returns the SSIM map, showing the SSIM values across the
image. For the mean SSIM (a single value metric), call <a class="reference internal" href="#plenoptic.metric.perceptual_distance.ssim" title="plenoptic.metric.perceptual_distance.ssim"><code class="xref py py-func docutils literal notranslate"><span class="pre">ssim</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>img1</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – The first image or batch of images, of shape (batch, channel, height, width).</p></li>
<li><p><strong>img2</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – The second image or batch of images, of shape (batch, channel, height, width).
The heights and widths of <code class="docutils literal notranslate"><span class="pre">img1</span></code> and <code class="docutils literal notranslate"><span class="pre">img2</span></code> must be the same. The numbers of
batches and channels of <code class="docutils literal notranslate"><span class="pre">img1</span></code> and <code class="docutils literal notranslate"><span class="pre">img2</span></code> need to be broadcastable: either
they are the same or one of them is 1. The output will be computed separately
for each channel (so channels are treated in the same way as batches). Both
images should have values between 0 and 1. Otherwise, the result may be
inaccurate, and we will raise a warning (but will still compute it).</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>ssim_map</em> – 4d tensor containing the map of SSIM values.</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.14)"><strong>ValueError</strong></a> – If either <code class="docutils literal notranslate"><span class="pre">img1</span></code> or <code class="docutils literal notranslate"><span class="pre">img2</span></code> is not 4d.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.14)"><strong>ValueError</strong></a> – If <code class="docutils literal notranslate"><span class="pre">img1</span></code> and <code class="docutils literal notranslate"><span class="pre">img2</span></code> have different height or width.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.14)"><strong>ValueError</strong></a> – If <code class="docutils literal notranslate"><span class="pre">img1</span></code> and <code class="docutils literal notranslate"><span class="pre">img2</span></code> have different batch or channel, unless one of them has
    a 1 there, so they can be broadcast.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.14)"><strong>ValueError</strong></a> – If <code class="docutils literal notranslate"><span class="pre">img1</span></code> and <code class="docutils literal notranslate"><span class="pre">img2</span></code> have different dtypes.</p></li>
</ul>
</dd>
<dt class="field-odd">Warns<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>UserWarning</strong> – If either <code class="docutils literal notranslate"><span class="pre">img1</span></code> or <code class="docutils literal notranslate"><span class="pre">img2</span></code> has multiple channels, as SSIM was designed for
grayscale images.</p></li>
<li><p><strong>UserWarning</strong> – If at least one scale from either <code class="docutils literal notranslate"><span class="pre">img1</span></code> or <code class="docutils literal notranslate"><span class="pre">img2</span></code> has height or width of
less than 11, since SSIM uses an 11x11 convolutional kernel.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id16" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id12">5</a><span class="fn-bracket">]</span></span>
<p>Z. Wang, A. C. Bovik, H. R. Sheikh, and E. P. Simoncelli, “Image
quality assessment: From error measurement to structural similarity”
IEEE Transactions on Image Processing, vol. 13, no. 1, Jan. 2004.</p>
</aside>
<aside class="footnote brackets" id="id17" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id13">6</a><span class="fn-bracket">]</span></span>
<p>matlab code <a class="reference external" href="https://www.cns.nyu.edu/~lcv/ssim/ssim_index.m">https://www.cns.nyu.edu/~lcv/ssim/ssim_index.m</a></p>
</aside>
<aside class="footnote brackets" id="id19" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id15">7</a><span class="fn-bracket">]</span></span>
<p>project page <a class="reference external" href="https://www.cns.nyu.edu/~lcv/ssim/">https://www.cns.nyu.edu/~lcv/ssim/</a></p>
</aside>
<aside class="footnote brackets" id="id21" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id14">8</a><span class="fn-bracket">]</span></span>
<p>Wang, Z., &amp; Simoncelli, E. P. (2008). Maximum differentiation (MAD)
competition: A methodology for comparing computational models of
perceptual discriminability. Journal of Vision, 8(12), 1–13.
<a class="reference external" href="https://dx.doi.org/10.1167/8.12.8">https://dx.doi.org/10.1167/8.12.8</a></p>
</aside>
</aside>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">plenoptic</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">po</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">einstein</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ssim_map</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">metric</span><span class="o">.</span><span class="n">ssim_map</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">img</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand_like</span><span class="p">(</span><span class="n">img</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ssim_map</span><span class="o">.</span><span class="n">shape</span>
<span class="go">torch.Size([1, 1, 246, 246])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="plenoptic.metric.perceptual_distance.ms_ssim">
<span class="sig-name descname"><span class="pre">ms_ssim</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">img2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">power_factors</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/metric/perceptual_distance.html#ms_ssim"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.metric.perceptual_distance.ms_ssim" title="Link to this definition">#</a></dt>
<dd><p>Multiscale structural similarity index (MS-SSIM).</p>
<p>As described in Wang et al., 2003 <a class="footnote-reference brackets" href="#id24" id="id22" role="doc-noteref"><span class="fn-bracket">[</span>9<span class="fn-bracket">]</span></a>, multiscale structural similarity index
(MS-SSIM) is an improvement upon structural similarity index (SSIM) that takes into
account the perceptual distance between two images on different scales.</p>
<p>SSIM is based on three comparison measurements between the two images:
luminance, contrast, and structure. All of these are computed convolutionally
across the images, producing three maps instead of scalars. The SSIM map is
the elementwise product of these three maps. See <a class="reference internal" href="#plenoptic.metric.perceptual_distance.ssim" title="plenoptic.metric.perceptual_distance.ssim"><code class="xref py py-func docutils literal notranslate"><span class="pre">ssim</span></code></a> and
<a class="reference internal" href="#plenoptic.metric.perceptual_distance.ssim_map" title="plenoptic.metric.perceptual_distance.ssim_map"><code class="xref py py-func docutils literal notranslate"><span class="pre">ssim_map</span></code></a> for a full description of SSIM.</p>
<p>To get images of different scales, average pooling operations with kernel
size 2 are performed recursively on the input images. The product of
contrast map and structure map (the “contrast-structure map”) is computed
for all but the coarsest scales, and the overall SSIM map is only computed
for the coarsest scale. Their mean values are raised to exponents and
multiplied to produce MS-SSIM:</p>
<div class="math notranslate nohighlight">
\[MSSSIM = {SSIM}_M^{a_M} \prod_{i=1}^{M-1} ({CS}_i)^{a_i}\]</div>
<p>Here <span class="math notranslate nohighlight">\(M\)</span> is the number of scales, <span class="math notranslate nohighlight">\({CS}_i\)</span> is the mean value
of the contrast-structure map for the i’th finest scale, and <span class="math notranslate nohighlight">\({SSIM}_M\)</span>
is the mean value of the SSIM map for the coarsest scale. If at least one
of these terms are negative, the value of MS-SSIM is zero. The values of
<span class="math notranslate nohighlight">\(a_i, i=1,...,M\)</span> are taken from the argument <code class="docutils literal notranslate"><span class="pre">power_factors</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>img1</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – The first image or batch of images, of shape (batch, channel, height, width).</p></li>
<li><p><strong>img2</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – The second image or batch of images, of shape (batch, channel, height, width).
The heights and widths of <code class="docutils literal notranslate"><span class="pre">img1</span></code> and <code class="docutils literal notranslate"><span class="pre">img2</span></code> must be the same. The numbers of
batches and channels of <code class="docutils literal notranslate"><span class="pre">img1</span></code> and <code class="docutils literal notranslate"><span class="pre">img2</span></code> need to be broadcastable: either
they are the same or one of them is 1. The output will be computed separately
for each channel (so channels are treated in the same way as batches). Both
images should have values between 0 and 1. Otherwise, the result may be
inaccurate, and we will raise a warning (but will still compute it).</p></li>
<li><p><strong>power_factors</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a> | <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a></span> (default: <code class="docutils literal notranslate"><span class="pre">None</span></code>)) – Power exponents for the mean values of maps, for different scales (from
fine to coarse). The length of this array determines the number of scales.
If <code class="docutils literal notranslate"><span class="pre">None</span></code>, set to <code class="docutils literal notranslate"><span class="pre">[0.0448,</span> <span class="pre">0.2856,</span> <span class="pre">0.3001,</span> <span class="pre">0.2363,</span> <span class="pre">0.1333]</span></code>, which is what
psychophysical experiments in Wang et al., 2003 <a class="footnote-reference brackets" href="#id24" id="id23" role="doc-noteref"><span class="fn-bracket">[</span>9<span class="fn-bracket">]</span></a> found.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>msssim</em> – 2d tensor of shape (batch, channel) containing the MS-SSIM for each image.</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.14)"><strong>ValueError</strong></a> – If either <code class="docutils literal notranslate"><span class="pre">img1</span></code> or <code class="docutils literal notranslate"><span class="pre">img2</span></code> is not 4d.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.14)"><strong>ValueError</strong></a> – If <code class="docutils literal notranslate"><span class="pre">img1</span></code> and <code class="docutils literal notranslate"><span class="pre">img2</span></code> have different height or width.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.14)"><strong>ValueError</strong></a> – If <code class="docutils literal notranslate"><span class="pre">img1</span></code> and <code class="docutils literal notranslate"><span class="pre">img2</span></code> have different batch or channel, unless one of them has
    a 1 there, so they can be broadcast.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.14)"><strong>ValueError</strong></a> – If <code class="docutils literal notranslate"><span class="pre">img1</span></code> and <code class="docutils literal notranslate"><span class="pre">img2</span></code> have different dtypes.</p></li>
</ul>
</dd>
<dt class="field-odd">Warns<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>UserWarning</strong> – If either <code class="docutils literal notranslate"><span class="pre">img1</span></code> or <code class="docutils literal notranslate"><span class="pre">img2</span></code> has multiple channels, as MS-SSIM was designed
for grayscale images.</p></li>
<li><p><strong>UserWarning</strong> – If at least one scale from either <code class="docutils literal notranslate"><span class="pre">img1</span></code> or <code class="docutils literal notranslate"><span class="pre">img2</span></code> has height or width of
less than 11, since SSIM uses an 11x11 convolutional kernel.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id24" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>9<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id22">1</a>,<a role="doc-backlink" href="#id23">2</a>)</span>
<p>Wang, Zhou, Eero P. Simoncelli, and Alan C. Bovik. “Multiscale
structural similarity for image quality assessment.” The Thrity-Seventh
Asilomar Conference on Signals, Systems &amp; Computers, 2003. Vol. 2. IEEE, 2003.</p>
</aside>
</aside>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">plenoptic</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">po</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">einstein</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">po</span><span class="o">.</span><span class="n">metric</span><span class="o">.</span><span class="n">ms_ssim</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">img</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand_like</span><span class="p">(</span><span class="n">img</span><span class="p">))</span>
<span class="go">tensor([[0.4684]])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="plenoptic.metric.perceptual_distance.normalized_laplacian_pyramid">
<span class="sig-name descname"><span class="pre">normalized_laplacian_pyramid</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/metric/perceptual_distance.html#normalized_laplacian_pyramid"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.metric.perceptual_distance.normalized_laplacian_pyramid" title="Link to this definition">#</a></dt>
<dd><p>Compute the normalized Laplacian Pyramid using pre-optimized parameters.</p>
<p>Model parameters are those used in Laparra et al., 2016 <a class="footnote-reference brackets" href="#id27" id="id25" role="doc-noteref"><span class="fn-bracket">[</span>10<span class="fn-bracket">]</span></a>, copied from the
matlab code used in the paper, found online <a class="footnote-reference brackets" href="#id28" id="id26" role="doc-noteref"><span class="fn-bracket">[</span>11<span class="fn-bracket">]</span></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>img</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Image, or batch of images of shape (batch, channel, height, width). This
representation is designed for grayscale images and will be computed separately
for each channel (so channels are treated in the same way as batches).</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.14)"><code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code></a>[<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>normalized_laplacian_activations</em> – The normalized Laplacian Pyramid with six scales.</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id27" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id25">10</a><span class="fn-bracket">]</span></span>
<p>Laparra, V., Ballé, J., Berardino, A. and Simoncelli, E.P., 2016. Perceptual
image quality assessment using a normalized Laplacian pyramid. Electronic
Imaging, 2016(16), pp.1-6.</p>
</aside>
<aside class="footnote brackets" id="id28" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id26">11</a><span class="fn-bracket">]</span></span>
<p>matlab code: <a class="reference external" href="https://www.cns.nyu.edu/~lcv/NLPyr/NLP_dist.m">https://www.cns.nyu.edu/~lcv/NLPyr/NLP_dist.m</a></p>
</aside>
</aside>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">plenoptic</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">po</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">einstein</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pyramid</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">metric</span><span class="o">.</span><span class="n">normalized_laplacian_pyramid</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">shape</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">pyramid</span><span class="p">]</span>
<span class="go">[torch.Size([1, 1, 256, 256]),</span>
<span class="go"> torch.Size([1, 1, 128, 128]),</span>
<span class="go"> torch.Size([1, 1, 64, 64]),</span>
<span class="go"> torch.Size([1, 1, 32, 32]),</span>
<span class="go"> torch.Size([1, 1, 16, 16]),</span>
<span class="go"> torch.Size([1, 1, 8, 8])]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">po</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">pyramid</span><span class="p">,</span> <span class="n">col_wrap</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="go">&lt;PyrFigure size ...&gt;</span>
</pre></div>
</div>
<p>(<a class="reference download internal" download="" href="../_downloads/54e53db8b577624c5ecac8a9dd0fea17/plenoptic-metric-perceptual_distance-1.png"><code class="xref download docutils literal notranslate"><span class="pre">png</span></code></a>, <a class="reference download internal" download="" href="../_downloads/f26f0100ecd3fe05cb48711660f7f2c9/plenoptic-metric-perceptual_distance-1.hires.png"><code class="xref download docutils literal notranslate"><span class="pre">hires.png</span></code></a>, <a class="reference download internal" download="" href="../_downloads/3afafa6de9a1dbebef7a73838ef4b262/plenoptic-metric-perceptual_distance-1.pdf"><code class="xref download docutils literal notranslate"><span class="pre">pdf</span></code></a>)</p>
<figure class="align-default">
<img alt="../_images/plenoptic-metric-perceptual_distance-1.png" class="plot-directive" src="../_images/plenoptic-metric-perceptual_distance-1.png" />
</figure>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="plenoptic.metric.perceptual_distance.nlpd">
<span class="sig-name descname"><span class="pre">nlpd</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">img2</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/plenoptic/metric/perceptual_distance.html#nlpd"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#plenoptic.metric.perceptual_distance.nlpd" title="Link to this definition">#</a></dt>
<dd><p>Compute the normalized Laplacian Pyramid Distance.</p>
<p>As described in Laparra et al., 2016 <a class="footnote-reference brackets" href="#id31" id="id29" role="doc-noteref"><span class="fn-bracket">[</span>12<span class="fn-bracket">]</span></a>, this is an image quality metric based on
the transformations associated with the early visual system: local luminance
subtraction and local contrast gain control.</p>
<p>A laplacian pyramid subtracts a local estimate of the mean luminance at six scales.
Then a local gain control divides these centered coefficients by a weighted sum of
absolute values in spatial neighborhood.</p>
<p>These weights parameters were optimized for redundancy reduction over an training
database of (undistorted) natural images, as described in the paper. Parameters were
copied from matlab code used for the paper, found online <a class="footnote-reference brackets" href="#id32" id="id30" role="doc-noteref"><span class="fn-bracket">[</span>13<span class="fn-bracket">]</span></a>.</p>
<p>Note that we compute root mean squared error for each scale, and then average over
these, effectively giving larger weight to the lower frequency coefficients
(which are fewer in number, due to subsampling).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>img1</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – The first image or batch of images of shape (batch, channel, height, width).</p></li>
<li><p><strong>img2</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – The second image or batch of images of shape (batch, channel, height, width).
The heights and widths of <code class="docutils literal notranslate"><span class="pre">img1</span></code> and <code class="docutils literal notranslate"><span class="pre">img2</span></code> must be the same. The numbers of
batches and channels of <code class="docutils literal notranslate"><span class="pre">img1</span></code> and <code class="docutils literal notranslate"><span class="pre">img2</span></code> need to be broadcastable: either
they are the same or one of them is 1. The output will be computed separately
for each channel (so channels are treated in the same way as batches). Both
images should have values between 0 and 1. Otherwise, the result may be
inaccurate, and we will raise a warning (but will still compute it).</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>distance</em> – The normalized Laplacian Pyramid distance, with shape (batch, channel).</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.14)"><strong>ValueError</strong></a> – If either <code class="docutils literal notranslate"><span class="pre">img1</span></code> or <code class="docutils literal notranslate"><span class="pre">img2</span></code> is not 4d.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.14)"><strong>ValueError</strong></a> – If <code class="docutils literal notranslate"><span class="pre">img1</span></code> and <code class="docutils literal notranslate"><span class="pre">img2</span></code> have different height or width.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.14)"><strong>ValueError</strong></a> – If <code class="docutils literal notranslate"><span class="pre">img1</span></code> and <code class="docutils literal notranslate"><span class="pre">img2</span></code> have different batch or channel, unless one of them has
    a 1 there, so they can be broadcast.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.14)"><strong>ValueError</strong></a> – If <code class="docutils literal notranslate"><span class="pre">img1</span></code> and <code class="docutils literal notranslate"><span class="pre">img2</span></code> have different dtypes.</p></li>
</ul>
</dd>
<dt class="field-odd">Warns<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>UserWarning</strong> – If either <code class="docutils literal notranslate"><span class="pre">img1</span></code> or <code class="docutils literal notranslate"><span class="pre">img2</span></code> has multiple channels, as SSIM was designed for
grayscale images.</p></li>
<li><p><strong>UserWarning</strong> – If either <code class="docutils literal notranslate"><span class="pre">img1</span></code> or <code class="docutils literal notranslate"><span class="pre">img2</span></code> has a value outside of range <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">1]</span></code>.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id31" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id29">12</a><span class="fn-bracket">]</span></span>
<p>Laparra, V., Ballé, J., Berardino, A. and Simoncelli, E.P., 2016. Perceptual
image quality assessment using a normalized Laplacian pyramid. Electronic
Imaging, 2016(16), pp.1-6.</p>
</aside>
<aside class="footnote brackets" id="id32" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id30">13</a><span class="fn-bracket">]</span></span>
<p>matlab code: <a class="reference external" href="https://www.cns.nyu.edu/~lcv/NLPyr/NLP_dist.m">https://www.cns.nyu.edu/~lcv/NLPyr/NLP_dist.m</a></p>
</aside>
</aside>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">plenoptic</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">po</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">einstein_img</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">einstein</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">curie_img</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">curie</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">po</span><span class="o">.</span><span class="n">metric</span><span class="o">.</span><span class="n">nlpd</span><span class="p">(</span><span class="n">einstein_img</span><span class="p">,</span> <span class="n">curie_img</span><span class="p">)</span>
<span class="go">tensor([[1.3507]])</span>
</pre></div>
</div>
</dd></dl>

</section>


                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="plenoptic.metric.model_metric.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">plenoptic.metric.model_metric</p>
      </div>
    </a>
    <a class="right-next"
       href="plenoptic.synthesize.metamer.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">plenoptic.synthesize.metamer</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#plenoptic.metric.perceptual_distance.ssim"><code class="docutils literal notranslate"><span class="pre">ssim</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#plenoptic.metric.perceptual_distance.ssim_map"><code class="docutils literal notranslate"><span class="pre">ssim_map</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#plenoptic.metric.perceptual_distance.ms_ssim"><code class="docutils literal notranslate"><span class="pre">ms_ssim</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#plenoptic.metric.perceptual_distance.normalized_laplacian_pyramid"><code class="docutils literal notranslate"><span class="pre">normalized_laplacian_pyramid</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#plenoptic.metric.perceptual_distance.nlpd"><code class="docutils literal notranslate"><span class="pre">nlpd</span></code></a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2019-2025, Plenoptic authors.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 9.0.4.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.1.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>